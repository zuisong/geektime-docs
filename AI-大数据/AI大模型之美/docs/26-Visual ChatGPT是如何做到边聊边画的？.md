ä½ å¥½ï¼Œæˆ‘æ˜¯å¾æ–‡æµ©ã€‚

è¿‡å»ä¸‰è®²é‡Œï¼Œæˆ‘ä»¬åˆ†åˆ«ä½“éªŒäº†CLIPã€Stable Diffusionå’ŒControlNetè¿™ä¸‰ä¸ªæ¨¡å‹ã€‚æˆ‘ä»¬ç”¨è¿™äº›æ¨¡å‹æ¥è¯†åˆ«å›¾ç‰‡çš„å†…å®¹ï¼Œæˆ–è€…é€šè¿‡è¾“å…¥ä¸€æ®µæ–‡æœ¬æŒ‡ä»¤æ¥ç”»å›¾ã€‚è¿™äº›æ¨¡å‹éƒ½æ˜¯æ‰€è°“çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œèƒ½å¤ŸæŠŠå›¾ç‰‡å’Œæ–‡æœ¬ä¿¡æ¯è”ç³»åœ¨ä¸€èµ·ã€‚

ä¸è¿‡ï¼Œå¦‚æœæˆ‘ä»¬ä¸ä»…ä»…æ˜¯è¦éšä¾¿æ‰¾å‡ ä¸ªå…³é”®è¯ç”»ä¸¤å¼ ç”»ç©ä¸ªç¥¨ï¼Œè€Œæ˜¯è¦åœ¨å®é™…çš„å·¥ä½œç¯å¢ƒé‡Œç”Ÿæˆèƒ½ç”¨çš„å›¾ç‰‡ï¼Œé‚£ä¹ˆç°åœ¨çš„ä½“éªŒè¿˜æ˜¯è¿œè¿œä¸å¤Ÿçš„ã€‚å¯¹äºç”»å‡ºæ¥çš„å›¾æˆ‘ä»¬æ€»æœ‰å„ç§å„æ ·çš„ä¿®æ”¹å’Œç¼–è¾‘çš„éœ€æ±‚ã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬æ€»æ˜¯ä¼šé‡åˆ°å„ä¸ªå›¢é˜Ÿçš„äººå¯¹ç€è®¾è®¡å¸ˆçš„å›¾æŒ‡æ‰‹ç”»è„šåœ°æå‡ºå„ç§å„æ ·çš„æ„è§ï¼šâ€œèƒ½ä¸èƒ½æŠŠå°ç‹—ç§»åˆ°å›¾ç‰‡çš„å³è¾¹ï¼Ÿâ€â€œèƒ½ä¸èƒ½æŠŠèƒŒæ™¯ä»è‰åœ°æ”¹æˆæ£®æ—ï¼Ÿâ€â€œæˆ‘æƒ³è¦ä¸€ä¸ªè‰²å½©æ–‘æ–“çš„é»‘ã€‚â€ç­‰ç­‰ã€‚

æ‰€ä»¥ï¼Œ **ç†æƒ³ä¸­çš„AIç”»ç”»çš„åŠŸèƒ½ï¼Œæœ€å¥½è¿˜èƒ½é…ä¸Šä¸€ä¸ªå¬å¾—æ‡‚äººè¯çš„AIï¼Œèƒ½å¤Ÿæ ¹æ®æˆ‘ä»¬è¿™äº›å¤–è¡Œçš„æŒ‡æ‰‹ç”»è„šæ¥ä¿®æ”¹ç”Ÿæˆçš„å›¾ç‰‡ã€‚** é’ˆå¯¹è¿™ä¸ªéœ€æ±‚ï¼Œæˆ‘ä»¬å°±æ¥ä»‹ç»ä¸€ä¸‹å¾®è½¯å¼€æºçš„Visual ChatGPTã€‚

å’Œä¹‹å‰æˆ‘ä»¬è‡ªå·±å†™ä»£ç ä¸åŒï¼Œè¿™ä¸€è®²æˆ‘ä»¬ä¸€èµ·æ¥è¯»ä¸€è¯» [Visual ChatGPT](https://github.com/microsoft/TaskMatrix) è¿™ä¸ªå¼€æºé¡¹ç›®çš„ä»£ç ï¼Œçœ‹çœ‹å®ƒæ˜¯å¦‚ä½•åšåˆ°èƒ½è®©æˆ‘ä»¬èŠç€å¤©å°±æŠŠå›¾ç‰‡ç»™ä¿®æ”¹å®Œäº†çš„ã€‚

## ä½“éªŒ Visual ChatGPT

æˆ‘ä»¬å…ˆæ¥ä½“éªŒä¸€ä¸‹Visual ChatGPTçš„æ•ˆæœæ˜¯æ€ä¹ˆæ ·çš„ã€‚è¿™ä¸€æ¬¡ï¼ŒColabé‡Œçš„GPUä¹Ÿä¸å¤Ÿæˆ‘ä»¬ç”¨äº†ã€‚Visual ChatGPTè¦åŠ è½½å¾ˆå¤šä¸ªä¸åŒçš„å›¾ç‰‡ç›¸å…³çš„æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹åŠ èµ·æ¥çš„æ˜¾å­˜å¾—æœ‰40GBä»¥ä¸Šã€‚

å¥½åœ¨ï¼Œå¾®è½¯é€šè¿‡HuggingFaceçš„SpaceåŠŸèƒ½æä¾›äº†ä¸€ä¸ª [å…è´¹çš„ Space](https://huggingface.co/spaces/microsoft/visual_chatgpt)ï¼Œè®©ä½ å¯ä»¥ç›´æ¥ä½“éªŒVisual ChatGPTçš„åŠŸèƒ½ã€‚ä¸è¿‡ï¼Œè€ƒè™‘åˆ°ç”¨çš„äººå¾ˆå¤šï¼Œä½¿ç”¨çš„è¿‡ç¨‹ä¸­ä½ çš„è¯·æ±‚ä¼šè¢«æ’é˜Ÿå¤„ç†ï¼Œå¾€å¾€è¦ç­‰å¾…å¾ˆé•¿æ—¶é—´æ‰èƒ½å®Œæˆä¸€æ¡æŒ‡ä»¤ã€‚æ‰€ä»¥ï¼Œæˆ‘å»ºè®®ä½ èŠ±ä¸ªå‡ ç¾å…ƒçš„å°é’±ï¼Œéƒ¨ç½²ä¸€ä¸ªè‡ªå·±çš„Visual ChatGPTçš„Spaceæ¥ä½“éªŒä¸€ä¸‹å®ƒçš„åŠŸèƒ½ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/36/d0/3636e392e72ff192301f90668b09d6d0.png?wh=1020x1204)

ä½ å¯ä»¥ç‚¹å‡»å¾®è½¯æä¾›çš„Spaceåº•éƒ¨çš„Duplicate Spaceï¼Œéƒ¨ç½²ä¸€ä¸ªå®Œå…¨ä¸€æ ·çš„Visual ChatGPT Spaceåˆ°è‡ªå·±çš„è´¦å·ä¸‹ï¼Œè¿™æ ·ä½ å°±ä¸ç”¨å’Œå…¶ä»–äººæ’é˜Ÿç­‰ç€äº†ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/07/90/0759e98e7d596a4b1ecd9da7e96eab90.png?wh=1258x545)

å› ä¸ºæˆ‘ä»¬å¤åˆ¶çš„æ˜¯åŸå…ˆçš„Spaceï¼Œæ‰€ä»¥å¯¹åº”çš„ç¡¬ä»¶é…ç½®ä¹Ÿæ˜¯å’Œå¾®è½¯å…è´¹æä¾›çš„ä¸€æ ·ã€‚é€šè¿‡ä¸€å—46Gæ˜¾å­˜çš„A10æ˜¾å¡ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥è£…è½½æ‰€æœ‰ç”¨åˆ°çš„æ¨¡å‹ã€‚ä¸è¿‡ï¼Œä½¿ç”¨A10æ˜¾å¡çš„Spaceæ˜¯æœ‰æˆæœ¬çš„ï¼Œä¸€ä¸ªå°æ—¶å°±è¦èŠ±å»ä½ 3.15ç¾å…ƒã€‚æ‰€ä»¥åœ¨å¤åˆ¶Spaceçš„æ—¶å€™ï¼Œæœ‰ä¸¤ä¸ªå‚æ•°ä½ éœ€è¦æ³¨æ„ã€‚

- ç¬¬ä¸€ä¸ªæ˜¯Sleep time settingsï¼Œæˆ‘å»ºè®®ä½ è®¾ç½®æˆ5åˆ†é’Ÿã€‚è¿™æ ·ï¼Œä¸€æ—¦5åˆ†é’Ÿæ²¡æœ‰äººä½¿ç”¨è¿™ä¸ªSpaceï¼Œå®ƒå°±ä¼šè¿›å…¥ä¼‘çœ çŠ¶æ€ã€‚è€ŒHuggingFaceåœ¨ä¼‘çœ çŠ¶æ€ä¸‹å°±ä¸ä¼šæ”¶å–ä½ ä»»ä½•è´¹ç”¨ã€‚åªæ˜¯ä¸‹ä¸€æ¬¡ä½ è¦ä½¿ç”¨è¿™ä¸ªSpaceçš„æ—¶å€™ï¼Œä¼šé‡æ–°å¯åŠ¨æ•´ä¸ªSpaceï¼Œéœ€è¦ä¸€ç‚¹ç‚¹æ—¶é—´ã€‚
- å¦ä¸€ä¸ªæ˜¯Spaceçš„Visibilityï¼Œæˆ‘å»ºè®®ä½ é€‰æ‹©Privateã€‚è¿™æ ·ï¼Œè¿™ä¸ªSpaceåªæœ‰ä½ èƒ½çœ‹åˆ°ã€‚ä¸ç„¶çš„è¯ï¼Œå°±ç®—ä½ è®¾ç½®äº†è‡ªåŠ¨ä¼‘çœ ï¼Œä¹Ÿå…ä¸äº†æœ‰äººçœ‹åˆ°ä½ çš„Spaceä¸Šæ¥è¯•ä¸€è¯•ã€‚å¦‚æœä¸æ–­æœ‰äººæ¥ä½¿ç”¨ä½ çš„Spaceçš„è¯ï¼Œå®ƒä¼šä¸€ç›´åœ¨çº¿è¿è¡Œï¼Œè€Œä½ å°±æ˜¯é‚£ä¸ªä»˜è´¦å•çš„äººã€‚

åœ¨å¤åˆ¶çš„Spaceéƒ¨ç½²å®Œæˆä¹‹åï¼Œä½ å°±å¯ä»¥å…ˆæ¥è¯•ä¸€ä¸‹Visual ChatGPTäº†ã€‚é¦–å…ˆä½ éœ€è¦åœ¨å³ä¸Šè§’è¾“å…¥ä½ çš„OpenAIçš„API Keyï¼Œå¹¶æŒ‰ä¸‹å›è½¦é”®ã€‚è¿™æ ·ï¼Œæ•´ä¸ªçª—å£çš„ä¸‹æ–¹å°±ä¼šå‡ºç°å¯ä»¥è¾“å…¥æ–‡æœ¬çš„èŠå¤©çª—å£ã€‚ä½ å¯ä»¥é€‰æ‹©è‡ªç”±è¾“å…¥ä½ æƒ³è¦ç”»çš„å†…å®¹ï¼Œä¹Ÿå¯ä»¥åœ¨ä¸‹é¢çš„Examplesé‡Œé€‰æ‹©é¢„è®¾å¥½çš„ä¸€äº›æŒ‡ä»¤ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/06/e1/063369368ccbdce8d2591d5851d967e1.png?wh=1005x1048)

æˆ‘ä»¬å¯ä»¥åˆ†åˆ«è¯•ä¸€ä¸‹Examplesé‡Œé¢ç»™å‡ºçš„æŒ‡ä»¤ã€‚

1. æˆ‘ä»¬å…ˆè®©Visual ChatGPTç”»ä¸€å¹…å°çŒ«åœ¨èŠ±å›­é‡Œå¥”è·‘çš„å›¾ç‰‡ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/66/a5/661088917d40bf99836184c20d9828a5.png?wh=1011x519)

2. ç„¶åå†æŠŠç”»é¢é‡Œçš„å°çŒ«æ¢æˆå°ç‹—ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/cc/16/cc1985b4cc9d0d10bdc6fcea253af716.png?wh=1013x523)

3. æ¥ç€å»æ‰ç”»é¢ä¸­çš„å°ç‹—ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/33/68/33d3b56b982bee56613fbcf3e8dffa68.png?wh=1024x523)

4. å†æŠŠå›¾ç‰‡é£æ ¼æ¢æˆæ°´å½©ç”»ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/e4/aa/e47a2c7695566ae9de6f876b5b9e54aa.png?wh=1017x515)

5. æœ€åæˆ‘ä»¬è®©Visual ChatGPTæè¿°ä¸€ä¸‹å›¾ç‰‡çš„å†…å®¹ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/75/70/756feb6e6f3c6e5858a99e880d5cdc70.png?wh=1016x528)

å¯ä»¥çœ‹åˆ°ï¼ŒVisual ChatGPTå¾ˆå¥½åœ°å®Œæˆäº†æˆ‘ä»¬çš„æ¯ä¸€æ¡æŒ‡ä»¤ã€‚è€Œè¿™æ ·çš„äº¤äº’ä½“éªŒå¤§å¤§æå‡äº†æˆ‘ä»¬ç”¨AIç”»ç”»çš„å®é™…ä½“éªŒã€‚æ¯”å¦‚ï¼Œä¸Šä¸€è®²é‡Œæˆ‘ä»¬é€šè¿‡Cannyç®—æ³•è·å–äº†â€œæˆ´çç è€³ç¯çš„å°‘å¥³â€ç”»åƒçš„è½®å»“ï¼Œç„¶åé€šè¿‡ControlNetç»˜åˆ¶äº†åŒæ ·å§¿åŠ¿çš„å…¶ä»–æ˜æ˜Ÿçš„å¤´åƒã€‚åŸæœ¬è¿™ä¸ªè¿‡ç¨‹æˆ‘ä»¬æ˜¯é€šè¿‡ä¸€ç³»åˆ—çš„ä»£ç æ¥å®ç°çš„ï¼Œç°åœ¨æˆ‘ä»¬å®Œå…¨å¯ä»¥ç”¨Visual ChatGPTï¼Œé€šè¿‡ä¸€ç³»åˆ—çš„å¯¹è¯å‘AIä¸‹è¾¾æŒ‡ä»¤æ¥å®ç°ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡UploadæŒ‰é’®æŠŠâ€œæˆ´çç è€³ç¯çš„å°‘å¥³â€å›¾ç‰‡ä¸Šä¼ ä¸Šå»ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/97/47/97b3e527347f353aaf12a34456934c47.png?wh=1015x615)

æ¥ç€ï¼Œæˆ‘ä»¬åœ¨å¯¹è¯æ¡†é‡Œè¾“å…¥æ–‡æœ¬ â€œGenerate the canny edge of the imageâ€ï¼ŒVisual ChatGPTå°±ä¼šæŠŠä¸Šä¼ å›¾ç‰‡çš„è¾¹ç¼˜æå–å‡ºæ¥ï¼Œå¹¶ä¸”ç”Ÿæˆä¸€å¼ æ–°çš„å›¾ç‰‡ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/63/61/6323d1b16737c4d0bde69c8a6c94c561.png?wh=1028x617)

æœ€åï¼Œæˆ‘ä»¬åœ¨å¯¹è¯æ¡†é‡Œè¾“å…¥ â€œGenerate a real color Taylor Swift photo from this canny imageâ€ï¼ŒVisual ChatGPTå°±ä¼šåŸºäºä¸Šé¢è¾¹ç¼˜æ£€æµ‹çš„è½®å»“å›¾ç”Ÿæˆä¸€ä¸ªæ–°çš„äººåƒå›¾ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/64/29/64e7cac2d8db67cc36540498byyb2729.png?wh=1026x619)

è¿™æ ·ï¼Œæˆ‘ä»¬ä¸éœ€è¦æ’°å†™ä»»ä½•ä»£ç ï¼Œé€šè¿‡ä¸€ä¸ªèŠå¤©çª—å£å°±èƒ½å®Œæˆå¯¹å›¾ç‰‡çš„ç¼–è¾‘å’Œä¿®æ”¹å·¥ä½œã€‚

## Visual ChatGPTçš„åŸç†ä¸å®ç°

Visual ChatGPTçš„æ•ˆæœéå¸¸ç¥å¥‡ï¼Œä½†æ˜¯å…¶å®å†…éƒ¨åŸç†å´éå¸¸ç®€å•ã€‚Visual ChatGPTè§£å†³é—®é¢˜çš„åŠæ³•å°±æ˜¯ä½¿ç”¨ [ç¬¬ 17 è®²](https://time.geekbang.org/column/article/648461) æˆ‘ä»¬ä»‹ç»è¿‡çš„LangChainçš„ReAct Agentæ¨¡å¼ï¼Œå®ƒåšäº†è¿™æ ·å‡ ä»¶äº‹æƒ…ã€‚

1. å®ƒæŠŠå„ç§å„æ ·å›¾åƒå¤„ç†çš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVisual Foundation Modelï¼‰éƒ½å°è£…æˆäº†ä¸€ä¸ªä¸ªToolã€‚
2. ç„¶åï¼Œå°†è¿™äº›Tooléƒ½äº¤ç»™äº†ä¸€ä¸ªconversation-react-descriptionç±»å‹çš„Agentã€‚æ¯æ¬¡ä½ è¾“å…¥æ–‡æœ¬çš„æ—¶å€™ï¼Œå…¶å®å°±æ˜¯å’Œè¿™ä¸ªAgentåœ¨äº¤æµã€‚Agentæ¥æ”¶åˆ°ä½ çš„æ–‡æœ¬ï¼Œå°±è¦åˆ¤æ–­è‡ªå·±åº”è¯¥ä½¿ç”¨å“ªä¸€ä¸ªToolï¼Œè¿˜æœ‰åº”è¯¥ä»è¾“å…¥çš„å†…å®¹é‡Œæå–ä»€ä¹ˆå‚æ•°ç»™åˆ°è¿™ä¸ªToolã€‚è¿™äº›è¾“å…¥å‚æ•°ä¸­æ—¢åŒ…æ‹¬éœ€è¦ä¿®æ”¹å“ªä¸€ä¸ªå›¾ç‰‡ï¼Œä¹ŸåŒ…æ‹¬ä½¿ç”¨ä»€ä¹ˆæ ·çš„æç¤ºè¯­ã€‚è¿™é‡Œçš„AgentèƒŒåä½¿ç”¨çš„å°±æ˜¯ChatGPTã€‚
3. æœ€åï¼ŒAgentä¼šå®é™…å»è°ƒç”¨è¿™ä¸ªToolï¼Œç”Ÿæˆä¸€å¼ æ–°çš„å›¾ç‰‡è¿”å›ç»™ä½ ã€‚

é‚£æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±è¿›å…¥Visual ChatGPTçš„ä»£ç ï¼Œæ¥çœ‹ä¸€ä¸‹å…·ä½“çš„ä»£ç æ˜¯æ€ä¹ˆåšçš„ã€‚Visual ChatGPTçš„æºä»£ç åªæœ‰ä¸€ä¸ªæ–‡ä»¶ [visual\_chatgpt.py](https://github.com/microsoft/TaskMatrix/blob/main/visual_chatgpt.py)ã€‚æ•´ä¸ªæ–‡ä»¶ä»å¤´åˆ°å°¾å¯ä»¥åˆ†æˆå››ä¸ªéƒ¨åˆ†ã€‚

1. ä¸€ç³»åˆ—é¢„å…ˆå®šä¹‰å¥½çš„ChatGPTçš„Promptï¼Œä»¥åŠä¸€äº›ä¼šè¢«è°ƒç”¨çš„è¾…åŠ©å‡½æ•°ã€‚
2. ä¸€ç³»åˆ—è§†è§‰æ¨¡å‹çš„Classï¼Œæ¯ä¸€ä¸ªClasséƒ½ä»£è¡¨äº†ä¸€ä¸ªæˆ–è€…å¤šä¸ªå›¾ç‰‡å¤„ç†çš„å·¥å…·ã€‚
3. ä¸€ä¸ªå«åšConversationBotçš„Classï¼Œå®é™…å°è£…äº†é€šè¿‡å¯¹è¯è°ƒç”¨å„ç§è§†è§‰æ¨¡å‹å·¥å…·çš„æµç¨‹ã€‚
4. å®é™…ä»å‘½ä»¤è¡Œå¯åŠ¨æ•´ä¸ªåº”ç”¨çš„å…¥å£ï¼Œå…¶å®å°±æ˜¯å¯¹ConverationBotæä¾›äº†ä¸€ä¸ªGradioåº”ç”¨çš„å°è£…ã€‚

### Visual ChatGPTçš„è°ƒç”¨å…¥å£

å¯¹äºæºç ï¼Œæˆ‘ä»¬å¯ä»¥å€’è¿‡æ¥ä»ä¸‹å¾€ä¸Šçœ‹ï¼Œä»Visual ChatGPTçš„å¯åŠ¨å…¥å£æ¥å­¦ä¹ ä»£ç ã€‚å¯¹åº”çš„å¯åŠ¨ä»£ç å…¶å®å¾ˆç®€å•ï¼Œå°±æ˜¯å¹²äº†ä¸¤ä»¶äº‹æƒ…ã€‚

1. ä»å‘½ä»¤è¡ŒåŠ è½½äº†loadå‚æ•°ï¼Œå¹¶ä¸”æŠŠå¯¹åº”çš„å­—ç¬¦ä¸²è§£ææˆä¸€ä¸ª `load_dict`ï¼Œç„¶åé€šè¿‡ `load_dict` åˆ›å»ºäº†ConversationBotã€‚

```python
if __name__ == '__main__':
    if not os.path.exists("checkpoints"):
        os.mkdir("checkpoints")
    parser = argparse.ArgumentParser()
    parser.add_argument('--load', type=str, default="ImageCaptioning_cuda:0,Text2Image_cuda:0")
    args = parser.parse_args()
    load_dict = {e.split('_')[0].strip(): e.split('_')[1].strip() for e in args.load.split(',')}
    bot = ConversationBot(load_dict=load_dict)
    â€¦â€¦

```

2. ç„¶åå°†æ•´ä¸ªConversationBotåšæˆäº†ä¸€ä¸ªæœ‰ç•Œé¢çš„Gradioåº”ç”¨ã€‚

```python
â€¦â€¦
    with gr.Blocks(css="#chatbot .overflow-y-auto{height:500px}") as demo:
        lang = gr.Radio(choices = ['Chinese','English'], value=None, label='Language')
        chatbot = gr.Chatbot(elem_id="chatbot", label="Visual ChatGPT")
        state = gr.State([])
        with gr.Row(visible=False) as input_raws:
            with gr.Column(scale=0.7):
                txt = gr.Textbox(show_label=False, placeholder="Enter text and press enter, or upload an image").style(
                    container=False)
            with gr.Column(scale=0.15, min_width=0):
                clear = gr.Button("Clear")
            with gr.Column(scale=0.15, min_width=0):
                btn = gr.UploadButton(label="ğŸ–¼ï¸",file_types=["image"])

        lang.change(bot.init_agent, [lang], [input_raws, lang, txt, clear])
        txt.submit(bot.run_text, [txt, state], [chatbot, state])
        txt.submit(lambda: "", None, txt)
        btn.upload(bot.run_image, [btn, state, txt, lang], [chatbot, state, txt])
        clear.click(bot.memory.clear)
        clear.click(lambda: [], None, chatbot)
        clear.click(lambda: [], None, state)
    demo.launch(server_name="0.0.0.0", server_port=7860)

```

æˆ‘ä»¬çœ‹ä¸€ä¸‹loadå‚æ•°ï¼Œå…¶å®å°±æ˜¯æŒ‡å®šäº†ä¸åŒçš„å·¥å…·ç±»åº”è¯¥ä½¿ç”¨CPUè¿˜æ˜¯GPUï¼Œä»¥åŠå¯¹åº”çš„æ¨¡å‹åº”è¯¥åŠ è½½åˆ°å“ªä¸€ä¸ªGPUä¸Šã€‚

```python
python visual_chatgpt.py --load "Text2Box_cuda:0,Segmenting_cuda:0,
    Inpainting_cuda:0,ImageCaptioning_cuda:0,
    Text2Image_cuda:1,Image2Canny_cpu,CannyText2Image_cuda:1,
    Image2Depth_cpu,DepthText2Image_cuda:1,VisualQuestionAnswering_cuda:2,
    InstructPix2Pix_cuda:2,Image2Scribble_cpu,ScribbleText2Image_cuda:2,
    SegText2Image_cuda:2,Image2Pose_cpu,PoseText2Image_cuda:2,
    Image2Hed_cpu,HedText2Image_cuda:3,Image2Normal_cpu,
    NormalText2Image_cuda:3,Image2Line_cpu,LineText2Image_cuda:3"

```

### ConversationBotï¼Œä¸€ä¸ªLangchain Agnet

æ¥ä¸‹æ¥æˆ‘ä»¬å†æ¥çœ‹çœ‹æ§åˆ¶Visual ChatGPTçš„æ ¸å¿ƒè¿è½¬æµç¨‹çš„ConversationBotæ˜¯ä»€ä¹ˆæ ·çš„ã€‚ConversationBoté‡Œé¢åŒ…å«äº†å››ä¸ªå‡½æ•°ï¼Œåˆ†åˆ«æ˜¯ `__init__` çš„æ„é€ å‡½æ•°ã€ `init_agent` å‡½æ•°ã€ `run_text` å’Œ `run_image` å‡½æ•°ã€‚

- `__init__` çš„æ„é€ å‡½æ•°ç”¨æ¥åŠ è½½ä½¿ç”¨çš„å„ä¸ªè§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVisual Foundation Modelï¼‰ã€‚
- `init_agent` å‡½æ•°æ„é€ äº†ä¸€ä¸ªLangChainçš„conversation-react-descriptionç±»å‹çš„Agentï¼Œç”¨æ¥å®é™…å¤„ç†æ•´ä¸ªAIå¯¹è¯è¿‡ç¨‹ã€‚
- `run_text` å¤„ç†ç”¨æˆ·çš„æ–‡æœ¬è¾“å…¥ã€‚
- `run_image` å¤„ç†ç”¨æˆ·çš„å›¾ç‰‡è¾“å…¥ã€‚

#### `__init__` æ„é€ å‡½æ•°

æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹ `__init__` è¿™ä¸ªæ„é€ å‡½æ•°ã€‚

```python
def __init__(self, load_dict):
        # load_dict = {'VisualQuestionAnswering':'cuda:0', 'ImageCaptioning':'cuda:1',...}
        print(f"Initializing VisualChatGPT, load_dict={load_dict}")
        if 'ImageCaptioning' not in load_dict:
            raise ValueError("You have to load ImageCaptioning as a basic function for VisualChatGPT")

        self.models = {}
        # Load Basic Foundation Models
        for class_name, device in load_dict.items():
            self.models[class_name] = globals()[class_name](device=device)

        # Load Template Foundation Models
        for class_name, module in globals().items():
            if getattr(module, 'template_model', False):
                template_required_names = {k for k in inspect.signature(module.__init__).parameters.keys() if k!='self'}
                loaded_names = set([type(e).__name__ for e in self.models.values()])
                if template_required_names.issubset(loaded_names):
                    self.models[class_name] = globals()[class_name](
                        **{name: self.models[name] for name in template_required_names})

        print(f"All the Available Functions: {self.models}")

â€¦â€¦

```

ä»£ç å…¶å®å¾ˆç®€å•ï¼Œé¦–å…ˆå°±æ˜¯å°†å‰é¢ä»å‘½ä»¤è¡Œè¯»å…¥çš„ `load_dict` é‡Œé¢çš„æ¯ä¸€ä¸ªClasséƒ½å®ä¾‹åŒ–ï¼Œåé¢æˆ‘ä»¬ä¼šçœ‹åˆ°ï¼Œåœ¨å®ä¾‹åŒ–çš„è¿‡ç¨‹ä¸­ï¼Œè¿™äº›Classéƒ½ä¼šæŠŠå„ç§é¢„è®­ç»ƒå¥½çš„æ¨¡å‹åŠ è½½åˆ°CPUæˆ–è€…GPUé‡Œé¢æ¥ã€‚

è¿™å…¶ä¸­æœ‰ä¸€ä¸ªæƒ…å†µéœ€è¦æ³¨æ„ï¼Œæœ‰äº›æ¨¡å‹Classåœ¨æˆ‘ä»¬è¿™é‡Œå«åš **template\_modelï¼Œå…¶å®å°±æ˜¯èƒ½å¤Ÿç»„åˆå¤šä¸ªæ¨¡å‹ç»„åˆï¼Œæ¥è§£å†³ä¸€ä¸ªå•ä¸€çš„ä»»åŠ¡ã€‚** è¿™äº›Classä¸æ˜¯é€šè¿‡å‘½ä»¤è¡Œä¼ å…¥çš„å‚æ•°åç§°æ¥åŠ è½½çš„ï¼Œè€Œæ˜¯å»åˆ¤æ–­è¿™ä¸ªClasséœ€è¦çš„å…¶ä»–æ¨¡å‹æ˜¯å¦éƒ½å·²ç»åŠ è½½äº†ï¼Œå¦‚æœéƒ½åŠ è½½äº†ï¼Œé‚£ä¹ˆè¿™ä¸ªClassè‡ªç„¶å¯ä»¥ç”¨ï¼Œä¸éœ€è¦é¢å¤–å ç”¨æ˜¾å­˜æˆ–è€…å†…å­˜ã€‚å¦åˆ™çš„è¯ï¼Œè¿™ä¸ªClasså°±ä¸ä¼šè¢«åŠ è½½ã€‚

æ¥ä¸‹æ¥å°±æ˜¯éå†æ‰€æœ‰çš„è¿™äº›Classï¼Œæ‰¾åˆ°é‡Œé¢ä»¥inferenceå¼€å¤´çš„å‡½æ•°ã€‚æ¯ä¸€ä¸ªå‡½æ•°éƒ½ä¼šè¢«å½“ä½œæ˜¯ä¸€ä¸ªLangChainé‡Œé¢çš„Toolï¼Œæ”¾åˆ°å½“å‰å®ä¾‹çš„Toolsæ•°ç»„ä¸­å»ã€‚

ç„¶åå°±åˆ›å»ºäº†Agentéœ€è¦çš„LLMå’ŒMemoryï¼Œ **å¦‚æœä½ æƒ³è¦ç”¨GPT-4æ¥ç®¡ç†å¯¹è¯è¿‡ç¨‹ä»¥å–å¾—æ›´å¥½çš„æ•ˆæœï¼Œä½ å°±å¯ä»¥åœ¨è¿™é‡Œç”¨GPT-4æ›¿æ¢æ‰LLMæ¥åšåˆ°è¿™ä¸€ç‚¹**ã€‚

```python
â€¦â€¦
        self.tools = []
        for instance in self.models.values():
            for e in dir(instance):
                if e.startswith('inference'):
                    func = getattr(instance, e)
                    self.tools.append(Tool(name=func.name, description=func.description, func=func))
        self.llm = OpenAI(temperature=0)
        self.memory = ConversationBufferMemory(memory_key="chat_history", output_key='output')

```

#### `init_agent` å‡½æ•°

æ¥ä¸‹æ¥çš„ `init_agent` å‡½æ•°å°±ç‰¹åˆ«ç®€å•äº†ï¼Œå®ƒå…¶å®å°±æ˜¯åˆ©ç”¨ä¸Šé¢æˆ‘ä»¬åŠ è½½çš„Toolsã€Memory ä»¥åŠ LLM åˆ›å»ºäº†ä¸€ä¸ª conversational-react-descriptionç±»å‹çš„Agentã€‚è¿™ä¸ªAgentæˆ‘ä»¬åœ¨ [ç¬¬ 17 è®²](https://time.geekbang.org/column/article/648461) å…¶å®å·²ç»ä»‹ç»è¿‡äº†ä¸€éã€‚

ä¸è¿‡ï¼Œè¿™é‡Œæˆ‘ä»¬é€šè¿‡ `agent_kwargs` ä¸ºè¿™ä¸ªAgentä¸“é—¨å®šåˆ¶äº†å¯¹åº”çš„æç¤ºè¯­ã€‚è¿™éƒ¨åˆ†æç¤ºè¯­æˆ‘ä»¬æ™šä¸€ç‚¹å†ä»‹ç»ã€‚è¿™é‡Œï¼Œå¯¹äºä¸­æ–‡å’Œè‹±æ–‡Visual ChatGPTåªæ˜¯é€šè¿‡ç®€å•çš„ `if...else` æä¾›äº†ä¸€ç»„ä¸åŒçš„æç¤ºè¯­è€Œå·²ã€‚

```python
    def init_agent(self, lang):
        self.memory.clear() #clear previous history
        if lang=='English':
            PREFIX, FORMAT_INSTRUCTIONS, SUFFIX = VISUAL_CHATGPT_PREFIX, VISUAL_CHATGPT_FORMAT_INSTRUCTIONS, VISUAL_CHATGPT_SUFFIX
            place = "Enter text and press enter, or upload an image"
            label_clear = "Clear"
        else:
            PREFIX, FORMAT_INSTRUCTIONS, SUFFIX = VISUAL_CHATGPT_PREFIX_CN, VISUAL_CHATGPT_FORMAT_INSTRUCTIONS_CN, VISUAL_CHATGPT_SUFFIX_CN
            place = "è¾“å…¥æ–‡å­—å¹¶å›è½¦ï¼Œæˆ–è€…ä¸Šä¼ å›¾ç‰‡"
            label_clear = "æ¸…é™¤"
        self.agent = initialize_agent(
            self.tools,
            self.llm,
            agent="conversational-react-description",
            verbose=True,
            memory=self.memory,
            return_intermediate_steps=True,
            agent_kwargs={'prefix': PREFIX, 'format_instructions': FORMAT_INSTRUCTIONS,
                          'suffix': SUFFIX}, )
        return gr.update(visible = True), gr.update(visible = False), gr.update(placeholder=place), gr.update(value=label_clear)

```

#### `run_text` å’Œ `run_image` å‡½æ•°

å®é™…å¤„ç†å¯¹è¯çš„ `run_text` å’Œ `run_image` å‡½æ•°ä¹Ÿéå¸¸ç®€å•ã€‚ `run_text` å‡½æ•°å°±æ˜¯å…ˆç¡®ä¿Memoryä¸è¦è¶…å‡ºæˆ‘ä»¬è®¾ç½®çš„ä¸Šä¸‹æ–‡é•¿åº¦çš„é™åˆ¶ã€‚ç„¶åç›´æ¥è°ƒç”¨Agentæ¥åº”å¯¹ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ã€‚å¹¶ä¸”å¯¹äºè¾“å‡ºçš„ç»“æœï¼Œå®ƒåªæ˜¯åšäº†ä¸€äº›æ–‡ä»¶åä¸Šçš„å­—ç¬¦ä¸²æ˜¾ç¤ºçš„å¤„ç†è€Œå·²ã€‚

```python
    def run_text(self, text, state):
        self.agent.memory.buffer = cut_dialogue_history(self.agent.memory.buffer, keep_last_n_words=500)
        res = self.agent({"input": text.strip()})
        res['output'] = res['output'].replace("\\", "/")
        response = re.sub('(image/[-\w]*.png)', lambda m: f'![](file={m.group(0)})*{m.group(0)}*', res['output'])
        state = state + [(text, response)]
        print(f"\nProcessed run_text, Input text: {text}\nCurrent state: {state}\n"
              f"Current Memory: {self.agent.memory.buffer}")
        return state, state

```

è€Œ `run_image` å‡½æ•°ï¼Œåˆ™æ˜¯æŠŠç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡è½¬æ¢æˆå®Œå…¨ç›¸åŒçš„å°ºå¯¸å’Œæ ¼å¼ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜ä¼šä½¿ç”¨ImageCaptioningè¿™ä¸ªæ¨¡å‹æ‹¿åˆ°å›¾ç‰‡çš„æè¿°ã€‚æœ€åï¼Œæ¨¡å‹å°†å›¾ç‰‡åç§°å’Œæè¿°ç­‰ä¿¡æ¯ä¹Ÿä½œä¸ºä¸€è½®å¯¹è¯æ‹¼æ¥åˆ°Agentçš„memoryé‡Œé¢å»ã€‚

```python

    def run_image(self, image, state, txt, lang):
        image_filename = os.path.join('image', f"{str(uuid.uuid4())[:8]}.png")
        print("======>Auto Resize Image...")
        img = Image.open(image.name)
        width, height = img.size
        ratio = min(512 / width, 512 / height)
        width_new, height_new = (round(width * ratio), round(height * ratio))
        width_new = int(np.round(width_new / 64.0)) * 64
        height_new = int(np.round(height_new / 64.0)) * 64
        img = img.resize((width_new, height_new))
        img = img.convert('RGB')
        img.save(image_filename, "PNG")
        print(f"Resize image form {width}x{height} to {width_new}x{height_new}")
        description = self.models['ImageCaptioning'].inference(image_filename)
        if lang == 'Chinese':
            Human_prompt = f'\nHuman: æä¾›ä¸€å¼ åä¸º {image_filename}çš„å›¾ç‰‡ã€‚å®ƒçš„æè¿°æ˜¯: {description}ã€‚ è¿™äº›ä¿¡æ¯å¸®åŠ©ä½ ç†è§£è¿™ä¸ªå›¾åƒï¼Œä½†æ˜¯ä½ åº”è¯¥ä½¿ç”¨å·¥å…·æ¥å®Œæˆä¸‹é¢çš„ä»»åŠ¡ï¼Œè€Œä¸æ˜¯ç›´æ¥ä»æˆ‘çš„æè¿°ä¸­æƒ³è±¡ã€‚ å¦‚æœä½ æ˜ç™½äº†, è¯´ \"æ”¶åˆ°\". \n'
            AI_prompt = "æ”¶åˆ°ã€‚  "
        else:
            Human_prompt = f'\nHuman: provide a figure named {image_filename}. The description is: {description}. This information helps you to understand this image, but you should use tools to finish following tasks, rather than directly imagine from my description. If you understand, say \"Received\". \n'
            AI_prompt = "Received.  "
        self.agent.memory.buffer = self.agent.memory.buffer + Human_prompt + 'AI: ' + AI_prompt
        state = state + [(f"![](file={image_filename})*{image_filename}*", AI_prompt)]
        print(f"\nProcessed run_image, Input image: {image_filename}\nCurrent state: {state}\n"
              f"Current Memory: {self.agent.memory.buffer}")
        return state, state, f'{txt} {image_filename} '

```

### Visual Foundation Modelï¼Œå®é™…å¤„ç†å›¾ç‰‡çš„å·¥å…·

çœ‹å®Œäº†ConversationBotï¼Œæˆ‘ä»¬å°±çŸ¥é“å…¶å®æˆ‘ä»¬å‘Visual ChatGPTè¾“å…¥çš„å„ç§æ–‡æœ¬æŒ‡ä»¤ï¼Œéƒ½ä¼šå˜æˆå¯¹æŸä¸€ä¸ªè§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVisual Foundation Modelï¼‰çš„è°ƒç”¨ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬å°±æŒ‘ä¸€ä¸¤ä¸ªè§†è§‰åŸºç¡€æ¨¡å‹ï¼Œæ¥çœ‹çœ‹å…·ä½“é‡Œé¢æ˜¯å¦‚ä½•è°ƒç”¨çš„ã€‚

æˆ‘ä»¬è¿˜æ˜¯æ‹¿ä¹‹å‰æˆ‘ä»¬æ¯”è¾ƒç†Ÿæ‚‰çš„é€šè¿‡Cannyç®—æ³•è¿›è¡Œè¾¹ç¼˜æ£€æµ‹çš„CannyText2Imageæ¥æ¼”ç¤ºå¥½äº†ã€‚åœ¨è¿™ä¸ªClassçš„æ„é€ å‡½æ•°é‡Œï¼Œæˆ‘ä»¬è¿˜æ˜¯é€šè¿‡Diffusersçš„PipelineåŠ è½½äº†Stable Diffusionå’ŒControlNetçš„æ¨¡å‹ã€‚è¿™æ ·ï¼Œåé¢æˆ‘ä»¬å°±å¯ä»¥ç”¨è¿™ä¸ªPipelineæ¥å¯¹å›¾ç‰‡è¿›è¡Œå¤„ç†äº†ã€‚

å¦å¤–ï¼Œåœ¨æ„é€ å‡½æ•°çš„æœ€åï¼Œå®ƒè¿˜è®¾ç½®äº†ä¸€ç³»åˆ—æ­£é¢å’Œè´Ÿé¢çš„æç¤ºè¯­å†…å®¹ã€‚è´Ÿé¢çš„æç¤ºè¯­ç”¨äºæ’é™¤ä½è´¨é‡çš„ç…§ç‰‡ï¼Œè€Œæ­£é¢çš„æç¤ºè¯­åˆ™ä¼šå’Œç”¨æˆ·è¾“å…¥çš„æç¤ºè¯­æ‹¼æ¥åˆ°ä¸€èµ·ï¼Œç”¨æ¥ç”Ÿæˆå›¾ç‰‡ã€‚

```python
class CannyText2Image:
    def __init__(self, device):
        print(f"Initializing CannyText2Image to {device}")
        self.torch_dtype = torch.float16 if 'cuda' in device else torch.float32
        self.controlnet = ControlNetModel.from_pretrained("fusing/stable-diffusion-v1-5-controlnet-canny",
                                                          torch_dtype=self.torch_dtype)
        self.pipe = StableDiffusionControlNetPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5", controlnet=self.controlnet, safety_checker=None,
            torch_dtype=self.torch_dtype)
        self.pipe.scheduler = UniPCMultistepScheduler.from_config(self.pipe.scheduler.config)
        self.pipe.to(device)
        self.seed = -1
        self.a_prompt = 'best quality, extremely detailed'
        self.n_prompt = 'longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, ' \
                            'fewer digits, cropped, worst quality, low quality'

```

é™¤äº†æ„é€ å‡½æ•°ï¼Œè¿™ä¸ªClassè¿˜æœ‰ä¸€ä¸ªinferenceå‡½æ•°ã€‚è¿™ä¸ªå‡½æ•°é€šè¿‡Promptsè¿™ä¸ªdecoratorå®šä¹‰äº†nameå’Œdescriptionå±æ€§ï¼Œè¿™äº›å±æ€§ä¹Ÿæ˜¯æˆ‘ä»¬å®é™…åŠ è½½Toolsçš„æ—¶å€™ä½¿ç”¨çš„å‚æ•°ã€‚Agentå°±ä¼šæ ¹æ®è¿™äº›æè¿°åˆ¤æ–­ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬æ˜¯å¦åº”è¯¥ä½¿ç”¨å½“å‰è¿™ä¸ªå·¥å…·ã€‚æ¯”å¦‚è¿™é‡Œ CannyText2Imageçš„descriptioné‡Œï¼Œå°±å‘Šè¯‰ä½ ç”¨æˆ·ä¸€èˆ¬ä¼šé€šè¿‡â€œgenerate a real image of a object or something from this canny imageâ€ è¿™æ ·çš„æŒ‡ä»¤æ¥è°ƒç”¨å½“å‰çš„å·¥å…·ã€‚

è€Œå¯¹åº”çš„inferenceå‡½æ•°çš„å†…å®¹ï¼Œå°±æ˜¯ç®€å•åœ°æ ¹æ®è¾“å…¥çš„æ–‡æœ¬è°ƒç”¨æ¨¡å‹æ¥å¤„ç†å›¾ç‰‡ã€‚ä¸è¿‡è¦æ³¨æ„ï¼Œè¿™é‡Œä½œä¸ºè¾“å…¥çš„Inputsæ–‡æœ¬ï¼Œå¹¶ä¸æ˜¯ç”¨æˆ·åŸå§‹è¾“å…¥çš„å†…å®¹ã€‚è€Œæ˜¯é€šè¿‡ConversationBotçš„Agentï¼Œç»è¿‡â€œæ€è€ƒâ€ä¹‹åæ‹¿åˆ°çš„Action Inputsã€‚è¿™ä¸ªInputsé‡Œé¢ï¼Œæ—¢ä¼šåŒ…å«éœ€è¦å¤„ç†çš„å›¾ç‰‡è·¯å¾„ï¼Œä¹Ÿä¼šåŒ…å«å¯¹åº”çš„Promptsã€‚

```python
    @prompts(name="Generate Image Condition On Canny Image",
             description="useful when you want to generate a new real image from both the user description and a canny image."
                         " like: generate a real image of a object or something from this canny image,"
                         " or generate a new real image of a object or something from this edge image. "
                         "The input to this tool should be a comma separated string of two, "
                         "representing the image_path and the user description. ")
    def inference(self, inputs):
        image_path, instruct_text = inputs.split(",")[0], ','.join(inputs.split(',')[1:])
        image = Image.open(image_path)
        self.seed = random.randint(0, 65535)
        seed_everything(self.seed)
        prompt = f'{instruct_text}, {self.a_prompt}'
        image = self.pipe(prompt, image, num_inference_steps=20, eta=0.0, negative_prompt=self.n_prompt,
                          guidance_scale=9.0).images[0]
        updated_image_path = get_new_image_name(image_path, func_name="canny2image")
        image.save(updated_image_path)
        print(f"\nProcessed CannyText2Image, Input Canny: {image_path}, Input Text: {instruct_text}, "
              f"Output Text: {updated_image_path}")
        return updated_image_path

```

å½“ç„¶ï¼Œä¸æ˜¯æ‰€æœ‰æ¨¡å‹Classçš„inferenceå‡½æ•°éƒ½è¿™ä¹ˆç®€å•ã€‚æœ‰äº›Classï¼Œç‰¹åˆ«æ˜¯æˆ‘ä»¬å‰é¢ä»‹ç»è¿‡çš„template\_modelçš„Classï¼Œå®ƒçš„inferenceå‡½æ•°ä¼šå¤æ‚ä¸€äº›ï¼Œéœ€è¦å¤šæ¬¡è°ƒç”¨å¤šä¸ªæ¨¡å‹ç»„åˆæ¥å®Œæˆä»»åŠ¡ã€‚æ¯”å¦‚InfinityOutPaintingè¿™ä¸ªClassï¼Œå°±éœ€è¦ä¸æ–­å¾ªç¯è°ƒç”¨VisualQuestionAnsweringå’ŒImageCaptionæ¥è·å–å›¾ç‰‡çš„æè¿°ï¼Œç„¶åé€šè¿‡Inpaintingæ¥è¡¥å…¨å›¾ç‰‡ä¸­æ²¡æœ‰ç”»å‡ºæ¥çš„éƒ¨åˆ†ï¼Œæœ€ç»ˆå®ç°æŠŠå›¾ç‰‡æ— é™æ‰©å¤§ï¼Œè¡¥å…¨æ‰©å¤§å‡ºæ¥çš„éƒ¨åˆ†èƒŒæ™¯çš„èƒ½åŠ›ã€‚

### å¤ç›˜Promptï¼Œç†è§£Task Matrixæœºåˆ¶

æˆ‘ä»¬åˆšæ‰è¯´è¿‡ï¼Œæ¯ä¸ªClassæ¨¡å‹æ‹¿åˆ°çš„inputsè¾“å…¥éƒ½æ˜¯æ¨¡å‹â€œæ€è€ƒâ€ä¹‹åæ ¹æ®ç”¨æˆ·è¾“å…¥æå–å‡ºæ¥çš„Action Inputsã€‚è¿™ä¸€ç‚¹ï¼Œå…¶å®è¿˜æ˜¯è¦å½’åŠŸäºChatGPTå¼ºå¤§çš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬åªè¦å›åˆ°ä»£ç çš„å¼€å¤´ï¼Œçœ‹ä¸€ä¸‹å¯¹åº”çš„Promptså…¶å®å°±èƒ½çŸ¥é“Visual ChatGPTæ˜¯æ€ä¹ˆåšåˆ°çš„äº†ã€‚å®é™…ä¸Šï¼Œæ¯æ¬¡ç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼Œéƒ½æ˜¯é€šè¿‡VISUAL\_CHATGPT\_PREFIXã€VISUAL\_CHATGPT\_FORMAT\_INSTRUCTIONSå’ŒVISUAL\_CHATGPT\_SUFFIXè¿™ä¸‰æ®µPromptsæ‹¼æ¥è€Œæˆçš„ã€‚

è€ŒAIçš„æ€è€ƒè¿‡ç¨‹ï¼Œå…¶å®å°±æ˜¯VISUAL\_CHATGPT\_FORMAT\_INSTRUCTIONSè¿™ä¸€å°æ®µã€‚

```python
VISUAL_CHATGPT_FORMAT_INSTRUCTIONS = """To use a tool, please use the following format:

Thought: Do I need to use a tool? Yes
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action

When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:

Thought: Do I need to use a tool? No
{ai_prefix}: [your response here]

"""

```

è¿™ä¸ªå…¶å®å°±æ˜¯æˆ‘åœ¨ [ç¬¬ 17 è®²](https://time.geekbang.org/column/article/648461) é‡Œç»™ä½ çœ‹è¿‡çš„MRKLçš„æç¤ºè¯­æ¨¡ç‰ˆã€‚AIé€šè¿‡Thoughtã€Actionã€Action Input å’Œ Observation è¿™æ ·çš„å››è½®å¾ªç¯ï¼Œå®Œæˆä¸€æ¬¡Toolsçš„åˆ¤å®šä¸è°ƒç”¨ã€‚å¹¶ä¸”ï¼Œæ¯æ¬¡ç»™åˆ°Agentçš„è¾“å…¥é‡Œï¼Œéƒ½å¯ä»¥åŒ…å«å¤šä¸ªè¿­ä»£çš„Actionå’ŒAction Inputï¼Œè°ƒç”¨å¤šæ¬¡æ¨¡å‹Classæ¥è§£å†³é—®é¢˜ã€‚

## å°ç»“

çœ‹å®Œè¿™ä¸ªä»£ç ä¹‹åï¼Œç›¸ä¿¡ä½ å®Œå…¨æœ‰èƒ½åŠ›ä¿®æ”¹ä»£ç æ»¡è¶³è‡ªå·±çš„éœ€æ±‚äº†ã€‚å¦‚æœæœ‰ä¸€å¤©å‡ºç°äº†ä¸€ä¸ªæ›´å¥½ç”¨çš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼Œä½ å®Œå…¨å¯ä»¥æŠŠè¿™ä¸ªæ–°çš„æ¨¡å‹ClassåŠ å…¥åˆ°Visual ChatGPTä¸­ã€‚ä½ åªéœ€è¦é€šè¿‡ `__init__` å‡½æ•°åŠ è½½æ¨¡å‹ï¼Œç„¶åå®šä¹‰å¥½å®ƒå¯¹åº”çš„æç¤ºè¯­ä»¥åŠinferenceå‡½æ•°ï¼Œå°±èƒ½è®©Visual ChatGPTæ”¯æŒä¸€ç§æ–°çš„å›¾ç‰‡ç¼–è¾‘å’Œç»˜åˆ¶åŠŸèƒ½äº†ã€‚

![](https://static001.geekbang.org/resource/image/a8/f8/a8073d98yy964983cc03c35deb0a42f8.png?wh=2284x1560)

å›é¡¾æ•´ä¸ªVisual ChatGPTçš„ä»£ç ï¼Œå…¶å®å¹¶ä¸å¤æ‚ã€‚å®ƒå°±æ˜¯å°† [ç¬¬ 17 è®²](https://time.geekbang.org/column/article/648461) æˆ‘ä»¬ä»‹ç»è¿‡çš„LangChainçš„Agentï¼Œå’Œè¿‡å»3è®²æˆ‘ä»¬ä»‹ç»çš„å„ç§è§†è§‰å¤§æ¨¡å‹ç»„åˆèµ·æ¥ï¼Œé€šè¿‡ChatGPTçš„è¯­è¨€å’Œé€»è¾‘æ¨ç†èƒ½åŠ›å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œé€šè¿‡LangChainçš„Agentæœºåˆ¶æ¥è°ƒåº¦æ¨ç†è¿‡ç¨‹å’Œå·¥å…·çš„ä½¿ç”¨ï¼Œé€šè¿‡è§†è§‰å¤§æ¨¡å‹å®é™…æ¥å¤„ç†å›¾ç‰‡ä»¥åŠç†è§£å›¾ç‰‡çš„å†…å®¹ã€‚

è¿™æ ·çš„æœºåˆ¶å…¶å®ä¸ä»…å¯ä»¥ç”¨æ¥å¤„ç†å›¾ç‰‡ï¼Œä¹Ÿå¯ä»¥ç”¨åœ¨å…¶ä»–æœºå™¨å­¦ä¹ çš„æ¨¡å‹é‡Œï¼Œæ¯”å¦‚è¯­éŸ³ã€è§†é¢‘ï¼Œç”šè‡³ä½ è¿˜å¯ä»¥åˆ©ç”¨å®ƒå†å»è°ƒç”¨åˆ«çš„å¤§è¯­è¨€æ¨¡å‹ã€‚è€Œè¿™ä¸ªæœºåˆ¶ï¼Œåæ¥ä¹Ÿè¢«å¾®è½¯è¿›ä¸€æ­¥æ‰©å±•åˆ°Task Matrixè¿™ä¸ªæ¦‚å¿µé‡Œã€‚Visual ChatGPTçš„ä»£ç åº“çš„åç§°ä»Šå¤©ä¹Ÿè¢«æ”¹æˆäº†Task Matrixï¼Œä¹Ÿå°±æ˜¯â€œä»»åŠ¡çŸ©é˜µâ€çš„æ„æ€ã€‚

## æ€è€ƒé¢˜

æœ€åï¼ŒæŒ‰ç…§æƒ¯ä¾‹è¿˜æ˜¯ç»™ä½ ç•™ä¸€é“æ€è€ƒé¢˜ã€‚

Stable Diffusionçš„æç¤ºè¯­æ˜¯ä¸æ”¯æŒä¸­æ–‡çš„ï¼Œä½†æ˜¯Visual ChatGPTæ”¯æŒä½ é€šè¿‡ä¸­æ–‡è¾“å…¥ä½ å¯¹å›¾ç‰‡çš„ç»˜åˆ¶å’Œä¿®æ”¹è¦æ±‚ã€‚ä½ è§‰å¾—å®ƒç›®å‰çš„å®ç°æœ‰æ²¡æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿå¦‚æœæˆ‘ä»¬æƒ³è¦è®©å®ƒä¸åªæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡ï¼Œä¹Ÿèƒ½æ”¯æŒå¾·æ–‡ã€æ³•æ–‡ã€è¥¿ç­ç‰™æ–‡ç­‰å„ä¸ªè¯­ç§ï¼Œæˆ‘ä»¬å¯ä»¥æ€ä¹ˆåšï¼Ÿæ¬¢è¿ä½ æŠŠæ€è€ƒåçš„ç»“æœåˆ†äº«åˆ°è¯„è®ºåŒºï¼Œæˆ‘ä»¬ä¸€èµ·è®¨è®ºï¼Œä¹Ÿæ¬¢è¿ä½ æŠŠè¿™ä¸€è®²åˆ†äº«ç»™éœ€è¦çš„æœ‹å‹ï¼Œæˆ‘ä»¬ä¸‹ä¸€è®²å†è§ï¼

## æ¨èé˜…è¯»

åœ¨Visual ChatGPTä¹‹åï¼Œå¾®è½¯æ›´è¿›ä¸€æ­¥å°†è¿™ä¸ªæ¦‚å¿µæ‰©å±•æˆä¸ºTask Matrixï¼Œä¹Ÿå¯¹åº”å‘è¡¨äº†ä¸€ç¯‡ [è®ºæ–‡](https://arxiv.org/abs/2303.16434)ã€‚ä½ æœ‰å…´è¶£çš„è¯ï¼Œå¯ä»¥å»é˜…è¯»ä¸€ä¸‹ã€‚