ä½ å¥½ï¼Œæˆ‘æ˜¯å¾æ–‡æµ©ã€‚

ä¸Šä¸€è®²é‡Œï¼Œæˆ‘ä»¬å·²ç»å­¦ä¼šäº†é€šè¿‡AIæ¥è¿›è¡Œè¯­éŸ³åˆæˆã€‚æœ‰äº†è¯­éŸ³è¯†åˆ«ã€ChatGPTï¼Œå†åŠ ä¸Šè¿™ä¸ªè¯­éŸ³åˆæˆï¼Œæˆ‘ä»¬å°±å¯ä»¥åšä¸€ä¸ªèƒ½å’Œæˆ‘ä»¬è¯­éŸ³èŠå¤©çš„æœºå™¨äººäº†ã€‚ä¸è¿‡å…‰æœ‰å£°éŸ³è¿˜ä¸å¤Ÿï¼Œæˆ‘ä»¬è¿˜å¸Œæœ›è¿™ä¸ªå£°éŸ³å¯ä»¥æ˜¯æŸä¸€ä¸ªç‰¹å®šçš„äººçš„å£°éŸ³ã€‚å°±å¥½åƒåœ¨ç”µå½±ã€ŠHerã€‹é‡Œé¢é‚£æ ·ï¼ŒAIå› ä¸ºç”¨äº†å½±æ˜Ÿæ–¯å˜‰ä¸½Â·çº¦ç¿°é€Šçš„é…éŸ³ï¼Œä¹Ÿå¸å¼•åˆ°ä¸å°‘è§‚ä¼—ã€‚æœ€åï¼Œå…‰æœ‰å£°éŸ³è¿˜ä¸å¤Ÿï¼Œæˆ‘ä»¬è¿˜å¸Œæœ›èƒ½å¤Ÿæœ‰è§†è§‰ä¸Šçš„æ•ˆæœï¼Œæœ€å¥½èƒ½å¤Ÿæ¨¡æ‹Ÿè‡ªå·±çœŸçš„åœ¨é•œå¤´é¢å‰ä¾ƒä¾ƒè€Œè°ˆçš„æ ·å­ã€‚

è¿™äº›éœ€æ±‚ç»“åˆåœ¨ä¸€èµ·ï¼Œå°±æ˜¯æœ€è¿‘å¸‚é¢ä¸Šå¾ˆç«çš„â€œæ•°å­—äººâ€ï¼Œä¹Ÿæ˜¯æˆ‘ä»¬è¿™ä¸€è®²è¦å­¦ä¹ çš„å†…å®¹ã€‚å½“ç„¶ï¼Œåœ¨è¿™ä¹ˆçŸ­çš„æ—¶é—´é‡Œï¼Œæˆ‘ä»¬åšå‡ºæ¥çš„æ•°å­—äººçš„æ•ˆæœè‚¯å®šæ¯”ä¸ä¸Šå•†ä¸šå…¬å¸çš„æ–¹æ¡ˆã€‚ä¸è¿‡ä½œä¸ºæ¦‚å¿µæ¼”ç¤ºä¹Ÿå®Œå…¨å¤Ÿç”¨äº†ã€‚

## åˆ¶ä½œä¸€ä¸ªè¯­éŸ³èŠå¤©æœºå™¨äºº

### ä»æ–‡æœ¬ChatBotèµ·æ­¥

æˆ‘ä»¬å…ˆä»æœ€ç®€å•çš„æ–‡æœ¬ChatBotèµ·æ­¥ï¼Œå…ˆæ¥åšä¸€ä¸ªå’Œ[ç¬¬ 6 è®²](https://time.geekbang.org/column/article/643915)ä¸€æ ·çš„æ–‡æœ¬èŠå¤©æœºå™¨äººã€‚å¯¹åº”çš„ä»£ç é€»è¾‘å’Œç¬¬6è®²çš„ChatGPTåº”ç”¨åŸºæœ¬ä¸€æ ·ï¼Œæ•´ä¸ªçš„UIç•Œé¢ä¹Ÿè¿˜æ˜¯ä½¿ç”¨Gradioæ¥åˆ›å»ºã€‚

å”¯ä¸€çš„åŒºåˆ«åœ¨äºï¼Œæˆ‘ä»¬æŠŠåŸå…ˆè‡ªå·±å°è£…çš„Conversationç±»æ¢æˆäº†Langchainçš„ConversationChainæ¥å®ç°ï¼Œå¹¶ä¸”ä½¿ç”¨äº†SummaryBufferMemoryã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å°±ä¸éœ€è¦å¼ºè¡Œè®¾å®šåªä¿ç•™è¿‡å»å‡ è½®å¯¹è¯äº†ã€‚

```python
import openai, os
import gradio as gr
from langchain import OpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationSummaryBufferMemory
from langchain.chat_models import ChatOpenAI

openai.api_key = os.environ["OPENAI_API_KEY"]

memory = ConversationSummaryBufferMemory(llm=ChatOpenAI(), max_token_limit=2048)
conversation = ConversationChain(
    llm=OpenAI(max_tokens=2048, temperature=0.5), 
    memory=memory,
)

def predict(input, history=[]):
    history.append(input)
    response = conversation.predict(input=input)
    history.append(response)
    responses = [(u,b) for u,b in zip(history[::2], history[1::2])]
    return responses, history

with gr.Blocks(css="#chatbot{height:800px} .overflow-y-auto{height:800px}") as demo:
    chatbot = gr.Chatbot(elem_id="chatbot")
    state = gr.State([])

    with gr.Row():
        txt = gr.Textbox(show_label=False, placeholder="Enter text and press enter").style(container=False)
        
    txt.submit(predict, [txt, state], [chatbot, state])

demo.launch()
```

å¯¹åº”ç•Œé¢ï¼š

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/f7/00/f7d911de018acd1959efa040c8658d00.png?wh=1019x877)

### å¢åŠ è¯­éŸ³è¾“å…¥åŠŸèƒ½

æ¥ç€ï¼Œæˆ‘ä»¬æ¥ç»™è¿™ä¸ªèŠå¤©æœºå™¨äººåŠ ä¸Šè¯­éŸ³è¾“å…¥çš„åŠŸèƒ½ï¼ŒGradioè‡ªå¸¦Audioæ¨¡å—ï¼Œæ‰€ä»¥è¦åšåˆ°è¿™ä¸€ç‚¹ä¹Ÿä¸éš¾ã€‚

1. é¦–å…ˆï¼Œæˆ‘ä»¬åœ¨Gradioçš„ç•Œé¢ä»£ç é‡Œé¢å¢åŠ ä¸€ä¸ªAudioç»„ä»¶ã€‚è¿™ä¸ªç»„ä»¶å¯ä»¥å½•åˆ¶ä½ çš„éº¦å…‹é£çš„å£°éŸ³ã€‚

```python
    with gr.Row():
        txt = gr.Textbox(show_label=False, placeholder="Enter text and press enter").style(container=False)
```

2. ç„¶åï¼Œæˆ‘ä»¬å°è£…äº†ä¸€ä¸ªtranscribeæ–¹æ³•ï¼Œé€šè¿‡è°ƒç”¨OpenAIçš„Whisper APIå°±èƒ½å¤Ÿå®Œæˆè¯­éŸ³è¯†åˆ«ã€‚è¿™é‡Œæœ‰ä¸€ç‚¹éœ€è¦æ³¨æ„ï¼ŒOpenAIçš„Whisper APIæœ‰ç‚¹ç¬¨ï¼Œå®ƒæ˜¯æ ¹æ®æ–‡ä»¶åçš„åç¼€æ¥åˆ¤æ–­æ˜¯å¦æ˜¯å®ƒæ”¯æŒçš„æ–‡ä»¶æ ¼å¼çš„ã€‚è€ŒGradioçš„Audioç»„ä»¶å½•åˆ¶å‡ºæ¥çš„WAVæ–‡ä»¶æ²¡æœ‰åç¼€ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦åœ¨è¿™é‡Œåšä¸ªæ–‡ä»¶é‡å‘½åçš„å·¥ä½œã€‚

```python
def transcribe(audio):
    os.rename(audio, audio + '.wav')
    audio_file = open(audio + '.wav', "rb")
    transcript = openai.Audio.transcribe("whisper-1", audio_file)
    return transcript['text']    
```

3. æ¥ç€ï¼Œæˆ‘ä»¬å°±è¦æŠŠéº¦å…‹é£å½•å¥½çš„å£°éŸ³è‡ªåŠ¨å‘é€ç»™è¯­éŸ³è¯†åˆ«ï¼Œç„¶åå†æäº¤ç»™åŸå…ˆåŸºäºæ–‡æœ¬èŠå¤©çš„æœºå™¨äººå°±å¥½äº†ã€‚

```python
    audio.change(process_audio, [audio, state], [chatbot, state])
```

æˆ‘ä»¬å…ˆåœ¨Audioçš„changeäº‹ä»¶é‡Œï¼Œå®šä¹‰äº†è§¦å‘process\_audioçš„å‡½æ•°ã€‚è¿™æ ·ï¼Œä¸€æ—¦éº¦å…‹é£çš„å£°éŸ³å½•åˆ¶ä¸‹æ¥ï¼Œå°±ä¼šç›´æ¥è§¦å‘èŠå¤©å¯¹è¯ï¼Œä¸éœ€è¦å†å•ç‹¬æ‰‹å·¥æäº¤ä¸€æ¬¡å†…å®¹ã€‚

```python
def process_audio(audio, history=[]):
    text = transcribe(audio)
    return predict(text, history)
```

ç„¶ååœ¨process\_audioå‡½æ•°é‡Œï¼Œæˆ‘ä»¬å…ˆæ˜¯è½¬å½•å¯¹åº”çš„æ–‡æœ¬ï¼Œå†è°ƒç”¨æ–‡æœ¬èŠå¤©æœºå™¨äººçš„predictå‡½æ•°ï¼Œè§¦å‘å¯¹è¯ã€‚

ä¿®æ”¹åçš„å®Œæ•´ä»£ç åœ¨ä¸‹é¢ï¼Œä½ å¯ä»¥åœ¨æœ¬åœ°è¿è¡Œï¼Œä½“éªŒä¸€ä¸‹ã€‚

```python
import openai, os
import gradio as gr
import azure.cognitiveservices.speech as speechsdk
from langchain import OpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationSummaryBufferMemory
from langchain.chat_models import ChatOpenAI

openai.api_key = os.environ["OPENAI_API_KEY"]

memory = ConversationSummaryBufferMemory(llm=ChatOpenAI(), max_token_limit=2048)
conversation = ConversationChain(
    llm=OpenAI(max_tokens=2048, temperature=0.5), 
    memory=memory,
)

def predict(input, history=[]):
    history.append(input)
    response = conversation.predict(input=input)
    history.append(response)
    responses = [(u,b) for u,b in zip(history[::2], history[1::2])]
    return responses, history

def transcribe(audio):
    os.rename(audio, audio + '.wav')
    audio_file = open(audio + '.wav', "rb")
    transcript = openai.Audio.transcribe("whisper-1", audio_file)
    return transcript['text']    

def process_audio(audio, history=[]):
    text = transcribe(audio)
    return predict(text, history)

with gr.Blocks(css="#chatbot{height:350px} .overflow-y-auto{height:500px}") as demo:
    chatbot = gr.Chatbot(elem_id="chatbot")
    state = gr.State([])

    with gr.Row():
        txt = gr.Textbox(show_label=False, placeholder="Enter text and press enter").style(container=False)
        
    with gr.Row():
        audio = gr.Audio(source="microphone", type="filepath")
        
    txt.submit(predict, [txt, state], [chatbot, state])
    audio.change(process_audio, [audio, state], [chatbot, state])

demo.launch()
```

å¯¹åº”ç•Œé¢ï¼š

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/95/73/954c7e642beca777016922f180444873.png?wh=1022x992 "æƒ³è¦å½•æ–°çš„ä¸€å¥è¯ï¼Œç‚¹å‡»çº¢è‰²æ–¹æ¡†å†…çš„Xï¼Œé‡æ–°è¿›å…¥å½•éŸ³ç•Œé¢")

### å¢åŠ è¯­éŸ³å›å¤åŠŸèƒ½

åœ¨èƒ½å¤Ÿæ¥æ”¶è¯­éŸ³è¾“å…¥ä¹‹åï¼Œæˆ‘ä»¬è¦åšçš„å°±æ˜¯è®©AIä¹Ÿèƒ½å¤Ÿç”¨è¯­éŸ³æ¥å›ç­”æˆ‘ä»¬çš„é—®é¢˜ã€‚è€Œè¿™ä¸ªåŠŸèƒ½ï¼Œé€šè¿‡[ä¸Šä¸€è®²](https://time.geekbang.org/column/article/650449)æˆ‘ä»¬ä»‹ç»è¿‡çš„Azureçš„è¯­éŸ³åˆæˆåŠŸèƒ½å°±èƒ½å®ç°ã€‚æˆ‘ä»¬åªéœ€è¦å°è£…ä¸€ä¸ªå‡½æ•°ï¼Œæ¥å®ç°è¯­éŸ³åˆæˆä¸æ’­æ”¾çš„åŠŸèƒ½ï¼Œç„¶ååœ¨predictå‡½æ•°é‡Œé¢ï¼Œæ‹¿åˆ°ChatGPTè¿”å›çš„å›ç­”ä¹‹åè°ƒç”¨ä¸€ä¸‹è¿™ä¸ªå‡½æ•°å°±å¥½äº†ã€‚

1. å°è£…ä¸€ä¸ªå‡½æ•°è¿›è¡Œè¯­éŸ³åˆæˆä¸æ’­æ”¾ã€‚

```python

speech_config = speechsdk.SpeechConfig(subscription=os.environ.get('AZURE_SPEECH_KEY'), region=os.environ.get('AZURE_SPEECH_REGION'))
audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)

# The language of the voice that speaks.
speech_config.speech_synthesis_language='zh-CN'
speech_config.speech_synthesis_voice_name='zh-CN-XiaohanNeural'

speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)

def play_voice(text):
    speech_synthesizer.speak_text_async(text)

```

2. åœ¨æ‹¿åˆ°ChatGPTçš„è¿”å›ç»“æœä¹‹åè°ƒç”¨ä¸€ä¸‹è¿™ä¸ªå‡½æ•°ã€‚

```python
def predict(input, history=[]):
    history.append(input)
    response = conversation.predict(input=input)
    history.append(response)
    play_voice(response)
    responses = [(u,b) for u,b in zip(history[::2], history[1::2])]
    return responses, history
```

å®Œæ•´çš„è¯­éŸ³å¯¹è¯çš„Demoä»£ç æˆ‘ä¸€å¹¶æ”¾åœ¨äº†ä¸‹é¢ï¼Œä½ å¯ä»¥åƒ[ç¬¬ 6 è®²](https://time.geekbang.org/column/article/643915)é‡Œæˆ‘ä»¬ä»‹ç»è¿‡çš„é‚£æ ·ï¼Œç›´æ¥éƒ¨ç½²åˆ°Gradioé‡Œé¢ä½“éªŒä¸€ä¸‹åˆ†äº«å‡ºå»ã€‚

```python
import openai, os
import gradio as gr
import azure.cognitiveservices.speech as speechsdk
from langchain import OpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationSummaryBufferMemory
from langchain.chat_models import ChatOpenAI

openai.api_key = os.environ["OPENAI_API_KEY"]

memory = ConversationSummaryBufferMemory(llm=ChatOpenAI(), max_token_limit=2048)
conversation = ConversationChain(
    llm=OpenAI(max_tokens=2048, temperature=0.5), 
    memory=memory,
)

speech_config = speechsdk.SpeechConfig(subscription=os.environ.get('AZURE_SPEECH_KEY'), region=os.environ.get('AZURE_SPEECH_REGION'))
audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)

# The language of the voice that speaks.
speech_config.speech_synthesis_language='zh-CN'
speech_config.speech_synthesis_voice_name='zh-CN-XiaohanNeural'

speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)

def play_voice(text):
    speech_synthesizer.speak_text_async(text)

def predict(input, history=[]):
    history.append(input)
    response = conversation.predict(input=input)
    history.append(response)
    play_voice(response)
    responses = [(u,b) for u,b in zip(history[::2], history[1::2])]
    return responses, history

def transcribe(audio):
    os.rename(audio, audio + '.wav')
    audio_file = open(audio + '.wav', "rb")
    transcript = openai.Audio.transcribe("whisper-1", audio_file)
    return transcript['text']    

def process_audio(audio, history=[]):
    text = transcribe(audio)
    return predict(text, history)

with gr.Blocks(css="#chatbot{height:800px} .overflow-y-auto{height:800px}") as demo:
    chatbot = gr.Chatbot(elem_id="chatbot")
    state = gr.State([])

    with gr.Row():
        txt = gr.Textbox(show_label=False, placeholder="Enter text and press enter").style(container=False)
        
    with gr.Row():
        audio = gr.Audio(source="microphone", type="filepath")
        
    txt.submit(predict, [txt, state], [chatbot, state])
    audio.change(process_audio, [audio, state], [chatbot, state])

demo.launch()
```

## ç”¨D-IDç»™è¯­éŸ³å¯¹å£å‹

è¿™é‡Œæˆ‘ä»¬è®¾è®¡çš„èŠå¤©æœºå™¨äººä¸ä»…èƒ½å¤Ÿå®Œå…¨å¬æ‡‚æˆ‘ä»¬è¯´çš„è¯ï¼Œè¿˜èƒ½é€šè¿‡è¯­éŸ³æ¥å¯¹è¯ï¼Œè¿™çš„ç¡®æ˜¯ä¸€ä»¶å¾ˆé…·çš„äº‹æƒ…ã€‚è€Œä¸”è¿™é‡Œæˆ‘ä»¬ç®—ä¸Šç©ºè¡Œï¼Œä¹Ÿåªç”¨äº†60è¡Œä»£ç ã€‚ä¸è¿‡ï¼Œæˆ‘ä»¬å¹¶ä¸ä¼šæ­¢æ­¥äºæ­¤ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¿˜è¦ä¸ºè¿™ä¸ªèŠå¤©æœºå™¨äººé…ä¸Šè§†é¢‘ç”»é¢å’Œå£å‹ã€‚

ç°åœ¨ï¼Œå›½å†…å¤–å·²ç»æœ‰ä¸€äº›å…¬å¸å¼€å§‹æä¾›åŸºäºAIç”Ÿæˆèƒ½å¯¹ä¸Šå£å‹çš„â€œæ•°å­—äººâ€çš„ä¸šåŠ¡äº†ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬å°±æ¥è¯•è¯•ç›®å‰ç”¨æˆ·æ¯”è¾ƒå¤šçš„ [D-ID](https://www.d-id.com/) æä¾›çš„APIï¼Œæ¯•ç«Ÿå®ƒç›´æ¥ä¸ºæ‰€æœ‰å¼€å‘è€…æä¾›äº†å¼€æ”¾å¹³å°ï¼Œå¹¶ä¸”è¿˜æœ‰5åˆ†é’Ÿçš„å…è´¹é¢åº¦ã€‚

### é€šè¿‡D-IDç”Ÿæˆè§†é¢‘

é¦–å…ˆï¼Œä½ è¦å»d-id.comæ³¨å†Œä¸€ä¸ªè´¦å·ã€‚åˆ«ç´§å¼ ï¼Œd-id.com æœ‰é‚®ç®±å°±èƒ½æ³¨å†Œè´¦å·ï¼Œä¸åƒChatGPTé‚£ä¹ˆéº»çƒ¦ï¼Œå¹¶ä¸”D-IDé€ç»™æ³¨å†Œç”¨æˆ·20æ¬¡è°ƒç”¨APIçš„æœºä¼šï¼Œæˆ‘ä»¬å¯ä»¥å¥½å¥½åˆ©ç”¨è¿™äº›å…è´¹é¢åº¦ã€‚

æ³¨å†Œå¥½è´¦å·ä»¥åï¼Œä½ å°±å¯ä»¥å»è®¿é—®è‡ªå·±çš„ [Account Setting](https://studio.d-id.com/account-settings) é¡µé¢ç”Ÿæˆä¸€ä¸ªAPI\_KEYäº†ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/40/3a/40219e8ff1ea0fcea51263163b7ded3a.png?wh=1017x541)

ä¹‹åï¼Œä½ å¯ä»¥æŸ¥çœ‹ä¸€ä¸‹D-IDçš„æ–‡æ¡£ï¼Œé‡Œé¢ä¸ä»…æœ‰APIçš„ä½¿ç”¨è¯´æ˜ï¼Œè¿˜æœ‰ä¸€ä¸ªç±»ä¼¼Playgroundçš„ç•Œé¢ï¼Œä½ å¯ä»¥è®¾ç½®å‚æ•°ï¼Œå¹¶ä¸”å¯ä»¥æµ‹è¯•è°ƒç”¨APIã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/7b/6c/7b5afe6c026e6cffd62824247985ef6c.png?wh=1235x1069)

æˆ‘ä»¬è®¾ç½®ä¸€ä¸‹å¯¹åº”çš„API KEYå¹¶ä¸”ç¡®ä¿å®‰è£…äº†requestsè¿™ä¸ªä¸“é—¨ç”¨æ¥å†™HTTPè¯·æ±‚çš„PythonåŒ…ï¼Œå°±å¯ä»¥æµ‹è¯•ä¸€ä¸‹è¿™ä¸ªä»£ç çš„æ•ˆæœäº†ã€‚

å®‰è£…requestsåŒ…ï¼š

```python
pip install requests
```

è®¾ç½®DID\_API\_KEYçš„ç¯å¢ƒå˜é‡ï¼š

```python
export DID_API_KEY=YOUR_DID_API_KEY
```

æˆ‘ä»¬å¯ä»¥å…ˆè°ƒç”¨D-IDçš„**Create A Talk**æ¥å£ï¼Œæ¥åˆ›å»ºä¸€æ®µå°è§†é¢‘ã€‚åªéœ€è¦è¾“å…¥ä¸¤ä¸ªä¸œè¥¿ï¼šä¸€ä¸ªæ˜¯æˆ‘ä»¬å¸Œæœ›è¿™ä¸ªè§†é¢‘å¿µå‡ºæ¥çš„æ–‡æœ¬ä¿¡æ¯inputï¼Œå¦ä¸€ä¸ªå°±æ˜¯ä¸€ä¸ªæ¸…æ™°çš„æ­£é¢å¤´åƒç…§ç‰‡ã€‚

åœ¨ä¸‹é¢çš„ä»£ç é‡Œé¢å¯ä»¥çœ‹åˆ°ï¼Œè¿™å…¶å®å°±æ˜¯ä¸€ä¸ªç®€å•çš„HTTPè¯·æ±‚ï¼Œå¹¶ä¸”æ–‡æœ¬è½¬æ¢æˆè¯­éŸ³çš„è¿‡ç¨‹ï¼Œå…¶å®è°ƒç”¨çš„ä¹Ÿæ˜¯Azureçš„è¯­éŸ³åˆæˆåŠŸèƒ½ã€‚

```python
import requests
import os

def generate_talk(input, avatar_url, 
                  voice_type = "microsoft", 
                  voice_id = "zh-CN-XiaomoNeural", 
                  api_key = os.environ.get('DID_API_KEY')):
    url = "https://api.d-id.com/talks"
    payload = {
        "script": {
            "type": "text",
            "provider": {
                "type": voice_type,
                "voice_id": voice_id
            },
            "ssml": "false",
            "input": input
        },
        "config": {
            "fluent": "false",
            "pad_audio": "0.0"
        },
        "source_url": avatar_url
    }
    headers = {
        "accept": "application/json",
        "content-type": "application/json",
        "authorization": "Basic " + api_key
    }

    response = requests.post(url, json=payload, headers=headers)
    return response.json()

avatar_url = "https://cdn.discordapp.com/attachments/1065596492796153856/1095617463112187984/John_Carmack_Potrait_668a7a8d-1bb0-427d-8655-d32517f6583d.png"
text = "ä»Šå¤©å¤©æ°”çœŸä¸é”™å‘€ã€‚"

response = generate_talk(input=text, avatar_url=avatar_url)
print(response)
```

è¾“å‡ºç»“æœï¼š

```python
{'id': 'tlk_Nk9OfTGu_ZvLztD3HHC4b', 'created_at': '2023-04-12T03:07:38.593Z', 'created_by': 'google-oauth2|103752135956955592319', 'status': 'created', 'object': 'talk'}
```

è¿™æ®µä»£ç è¿è¡ŒæˆåŠŸä¹‹åï¼Œè¿”å›çš„ç»“æœæ˜¯ä¸€ä¸ªJSONã€‚JSONé‡Œé¢æœ‰ä¸€ä¸ªå¯¹åº”è§†é¢‘çš„idï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è¿™ä¸ªidç”¨Get A Talkçš„APIæ‹¿åˆ°æˆ‘ä»¬åˆšåˆšç”Ÿæˆçš„å£æ’­è§†é¢‘ï¼Œç„¶ååœ¨Notebooké‡Œé¢æ’­æ”¾ã€‚

è·å–ç”Ÿæˆçš„Talkè§†é¢‘ï¼š

```python
def get_a_talk(id, api_key = os.environ.get('DID_API_KEY')):
    url = "https://api.d-id.com/talks/" + id
    headers = {
        "accept": "application/json",
        "authorization": "Basic "+api_key
    }
    response = requests.get(url, headers=headers)
    return response.json()

talk = get_a_talk(response['id'])
print(talk)
```

è¾“å‡ºç»“æœï¼š

```python
{'metadata': {'driver_url': 'bank://lively/driver-03/original', 'mouth_open': False, 'num_faces': 1, 'num_frames': 48, 'processing_fps': 22.996171137505605, 'resolution': [512, 512], 'size_kib': 386.990234375}, 'audio_url': 'https://d-id-talks-prod.s3.us-west-2.amazonaws.com/google-oauth2%7C103752135956955592319/tlk_Nk9OfTGu_ZvLztD3HHC4b/microsoft.wav?AWSAccessKeyId=AKIA5CUMPJBIK65W6FGA&Expires=1681355260&Signature=2RluUIQyg%2FnIz54O2xEIr%2FqjaXA%3D', 'created_at': '2023-04-12T03:07:38.593Z', 'face': {'mask_confidence': -1, 'detection': [205, 115, 504, 552], 'overlap': 'no', 'size': 618, 'top_left': [45, 25], 'face_id': 0, 'detect_confidence': 0.9987131357192993}, 'config': {'stitch': False, 'pad_audio': 0, 'align_driver': True, 'sharpen': True, 'auto_match': True, 'normalization_factor': 1, 'logo': {'url': 'd-id-logo', 'position': [0, 0]}, 'motion_factor': 1, 'result_format': '.mp4', 'fluent': False, 'align_expand_factor': 0.3}, 'source_url': 'https://d-id-talks-prod.s3.us-west-2.amazonaws.com/google-oauth2%7C103752135956955592319/tlk_Nk9OfTGu_ZvLztD3HHC4b/source/noelle.jpeg?AWSAccessKeyId=AKIA5CUMPJBIK65W6FGA&Expires=1681355260&Signature=LNSFBaEUWtPYUo469qzmUGeHzec%3D', 'created_by': 'google-oauth2|103752135956955592319', 'status': 'done', 'driver_url': 'bank://lively/', 'modified_at': '2023-04-12T03:07:42.570Z', 'user_id': 'google-oauth2|103752135956955592319', 'result_url': 'https://d-id-talks-prod.s3.us-west-2.amazonaws.com/google-oauth2%7C103752135956955592319/tlk_Nk9OfTGu_ZvLztD3HHC4b/noelle.mp4?AWSAccessKeyId=AKIA5CUMPJBIK65W6FGA&Expires=1681355262&Signature=slWpvS1eEqcw4N%2FqVWN6K0zewuU%3D', 'id': 'tlk_Nk9OfTGu_ZvLztD3HHC4b', 'duration': 2, 'started_at': '2023-04-12T03:07:40.402'}
```

å°†å¯¹åº”çš„è§†é¢‘å±•ç¤ºæ’­æ”¾å‡ºæ¥ï¼š

```python
from IPython.display import display, HTML
def play_mp4_video(url):
    video_tag = f"""
    <video width="640" height="480" controls>
        <source src="{url}" type="video/mp4">
    Your browser does not support the video tag.
    </video>
    """
    return HTML(video_tag)
result_url = talk['result_url'])
play_mp4_video(result_url)
```

è¾“å‡ºå±•ç¤ºï¼š

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/75/7b/754e0357c3dd475b3b7f42c7c9beff7b.png?wh=346x259)

åœ¨è¿™é‡Œï¼Œæˆ‘ç”¨Midjourneyç”Ÿæˆäº†ä¸€å¼ ID Softwareçš„åˆ›å§‹äººâ€”â€”å¤§ç¥çº¦ç¿°å¡é©¬å…‹çš„å¤´åƒã€‚ç„¶åè®©D-IDç»™è¿™ä¸ªå¤´åƒç”Ÿæˆå¯¹åº”çš„å¯¹å£å‹çš„è§†é¢‘ï¼Œçœ‹åˆ°å¿ƒç›®ä¸­çš„æŠ€æœ¯å¶åƒå¼€å£è¯´è¯è¿˜æ˜¯éå¸¸è®©äººéœ‡æ’¼çš„ã€‚

### å°†è§†é¢‘åµŒå…¥åˆ°Gradioåº”ç”¨ä¸­

æœ‰äº†è¿™æ ·å¯ä»¥å¯¹å£å‹æ’­æ”¾çš„è§†é¢‘ï¼Œæˆ‘ä»¬å°±å¯ä»¥å†æ”¹é€ ä¸€ä¸‹åˆšæ‰é€šè¿‡Gradioåˆ›å»ºçš„åº”ç”¨ï¼Œä¸è¦å…‰è®©æœºå™¨äººç”¨è¯­éŸ³äº†ï¼Œç›´æ¥ç”¨è§†é¢‘æ¥å¼€å£è¯´è¯å§ã€‚

æˆ‘ä»¬åœ¨å‰é¢è¯­éŸ³èŠå¤©ç•Œé¢çš„åŸºç¡€ä¸Šï¼Œåˆåšäº†å‡ å¤„æ”¹é€ ã€‚

1. æˆ‘ä»¬åœ¨åŸæœ‰çš„Gradioç•Œé¢ä¸­ï¼Œåˆå¢åŠ äº†ä¸€ä¸ªHTMLç»„ä»¶ï¼Œæ˜¾ç¤ºå¤´åƒå›¾ç‰‡ï¼Œå¹¶ç”¨æ¥æ’­æ”¾å¯¹å¥½å£å‹çš„è§†é¢‘ã€‚é»˜è®¤ä¸€å¼€å§‹ï¼Œæ˜¾ç¤ºçš„æ˜¯ä¸€å¼ å›¾ç‰‡ã€‚

```python
â€¦â€¦
    with gr.Row():
        video = gr.HTML(f'<img src="{avatar_url}" width="320" height="240" alt="John Carmack">', live=False)
```

æ³¨ï¼šè¿™é‡Œå¢åŠ äº†ä¸€ä¸ªç”¨æ¥æ’­æ”¾è§†é¢‘çš„HTMLç»„ä»¶ã€‚

2. åœ¨å½•éŸ³è½¬å½•åè§¦å‘Predictå‡½æ•°çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸å†é€šè¿‡Azureçš„è¯­éŸ³åˆæˆæŠ€æœ¯æ¥ç”Ÿæˆè¯­éŸ³ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨ D-ID çš„APIæ¥ç”ŸæˆåŸºäºå¤´åƒçš„ä¸”å£å‹åŒæ­¥çš„è§†é¢‘åŠ¨ç”»ã€‚å¹¶ä¸”è§†é¢‘åŠ¨ç”»åœ¨ç”Ÿæˆä¹‹åï¼Œå°†å‰é¢HTMLç»„ä»¶çš„å†…å®¹æ›¿æ¢æˆæ–°ç”Ÿæˆçš„è§†é¢‘ï¼Œå¹¶è‡ªåŠ¨æ’­æ”¾ã€‚

```python
def predict(input, history=[]):
    if input is not None:
        history.append(input)
        response = conversation.predict(input=input)    
        video_url = get_mp4_video(input=response, avatar_url=avatar_url)
        video_html = f"""<video width="320" height="240" controls autoplay><source src="{video_url}" type="video/mp4"></video>"""
        history.append(response)
        responses = [(u,b) for u,b in zip(history[::2], history[1::2])]
        return responses, video_html, history
    else:
        video_html = f'<img src="{avatar_url}" width="320" height="240" alt="John Carmack">'
        responses = [(u,b) for u,b in zip(history[::2], history[1::2])]
        return responses, video_html, history        
```

æ³¨ï¼šé€šè¿‡ChatGPTè·å–å›ç­”ï¼Œç„¶åå°†å›ç­”å’Œå¤´åƒä¸€èµ·ç”Ÿæˆä¸€ä¸ªè§†é¢‘æ–‡ä»¶è‡ªåŠ¨æ’­æ”¾ã€‚

3. åœ¨è·å–è§†é¢‘çš„æ—¶å€™éœ€è¦æ³¨æ„ä¸€ç‚¹ï¼Œå°±æ˜¯æˆ‘ä»¬éœ€è¦ç­‰å¾…è§†é¢‘åœ¨D-IDçš„æœåŠ¡å™¨ç”Ÿæˆå®Œæ¯•ï¼Œæ‰èƒ½æ‹¿åˆ°å¯¹åº”çš„result\_urlã€‚å…¶å®æ›´åˆç†çš„åšæ³•æ˜¯æ³¨å†Œä¸€ä¸ªwebhookï¼Œç­‰å¾…d-idé€šè¿‡webhooké€šçŸ¥æˆ‘ä»¬è§†é¢‘ç”Ÿæˆå®Œæ¯•äº†ï¼Œå†æ’­æ”¾è§†é¢‘ã€‚ä¸è¿‡è€ƒè™‘åˆ°æ¼”ç¤ºçš„ç®€ä¾¿å’Œä»£ç æ•°é‡ï¼Œæˆ‘ä»¬å°±æ²¡æœ‰å†å¯ç”¨ä¸€ä¸ªHTTPæœåŠ¡æ¥æ¥æ”¶webhookï¼Œè€Œæ˜¯é‡‡ç”¨sleep 1ç§’ç„¶åé‡è¯•çš„æ–¹å¼ï¼Œæ¥å®ç°è·å–è§†é¢‘çš„æ•ˆæœã€‚

```python
def get_mp4_video(input, avatar_url=avatar_url):
    response = generate_talk(input=input, avatar_url=avatar_url)
    talk = get_a_talk(response['id'])
    video_url = ""
    index = 0
    while index < 30:
        index += 1
        if 'result_url' in talk:    
            video_url = talk['result_url']
            return video_url
        else:
            time.sleep(1)
            talk = get_a_talk(response['id'])
    return video_url
```

æ³¨ï¼šresult\_urlå­—æ®µä¼šåœ¨æœåŠ¡å™¨ç«¯æŠŠæ•´ä¸ªè§†é¢‘ç”Ÿæˆå®Œæˆä¹‹åæ‰å‡ºç°ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å¾ªç¯ç­‰å¾…ã€‚

æ”¹é€ å®Œæ•´ä½“ä»£ç å¦‚ä¸‹ï¼š

```python
import openai, os, time, requests
import gradio as gr
from gradio import HTML
from langchain import OpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationSummaryBufferMemory
from langchain.chat_models import ChatOpenAI

openai.api_key = os.environ["OPENAI_API_KEY"]

memory = ConversationSummaryBufferMemory(llm=ChatOpenAI(), max_token_limit=2048)
conversation = ConversationChain(
Â  Â  llm=OpenAI(max_tokens=2048, temperature=0.5),Â 
Â  Â  memory=memory,
)

avatar_url = "https://cdn.discordapp.com/attachments/1065596492796153856/1095617463112187984/John_Carmack_Potrait_668a7a8d-1bb0-427d-8655-d32517f6583d.png"

def generate_talk(input, avatar_url,Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  voice_type = "microsoft",Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  voice_id = "zh-CN-YunyeNeural",Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  api_key = os.environ.get('DID_API_KEY')):
Â  Â  url = "https://api.d-id.com/talks"
Â  Â  payload = {
Â  Â  Â  Â  "script": {
Â  Â  Â  Â  Â  Â  "type": "text",
Â  Â  Â  Â  Â  Â  "provider": {
Â  Â  Â  Â  Â  Â  Â  Â  "type": voice_type,
Â  Â  Â  Â  Â  Â  Â  Â  "voice_id": voice_id
Â  Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  Â  "ssml": "false",
Â  Â  Â  Â  Â  Â  "input": input
Â  Â  Â  Â  },
Â  Â  Â  Â  "config": {
Â  Â  Â  Â  Â  Â  "fluent": "false",
Â  Â  Â  Â  Â  Â  "pad_audio": "0.0"
Â  Â  Â  Â  },
Â  Â  Â  Â  "source_url": avatar_url
Â  Â  }
Â  Â  headers = {
Â  Â  Â  Â  "accept": "application/json",
Â  Â  Â  Â  "content-type": "application/json",
Â  Â  Â  Â  "authorization": "Basic " + api_key
Â  Â  }

Â  Â  response = requests.post(url, json=payload, headers=headers)
Â  Â  return response.json()



def get_a_talk(id, api_key = os.environ.get('DID_API_KEY')):
Â  Â  url = "https://api.d-id.com/talks/" + id
Â  Â  headers = {
Â  Â  Â  Â  "accept": "application/json",
Â  Â  Â  Â  "authorization": "Basic "+api_key
Â  Â  }
Â  Â  response = requests.get(url, headers=headers)
Â  Â  return response.json()



def get_mp4_video(input, avatar_url=avatar_url):
Â  Â  response = generate_talk(input=input, avatar_url=avatar_url)
Â  Â  talk = get_a_talk(response['id'])
Â  Â  video_url = ""
Â  Â  index = 0
Â  Â  while index < 30:
Â  Â  Â  Â  index += 1
Â  Â  Â  Â  if 'result_url' in talk:Â  Â Â 
Â  Â  Â  Â  Â  Â  video_url = talk['result_url']
Â  Â  Â  Â  Â  Â  return video_url
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  time.sleep(1)
Â  Â  Â  Â  Â  Â  talk = get_a_talk(response['id'])
Â  Â  return video_url

def predict(input, history=[]):
Â  Â  if input is not None:
Â  Â  Â  Â  history.append(input)
Â  Â  Â  Â  response = conversation.predict(input=input)Â  Â Â 
Â  Â  Â  Â  video_url = get_mp4_video(input=response, avatar_url=avatar_url)
Â  Â  Â  Â  video_html = f"""<video width="320" height="240" controls autoplay><source src="{video_url}" type="video/mp4"></video>"""
Â  Â  Â  Â  history.append(response)
Â  Â  Â  Â  responses = [(u,b) for u,b in zip(history[::2], history[1::2])]
Â  Â  Â  Â  return responses, video_html, history
Â  Â  else:
Â  Â  Â  Â  video_html = f'<img src="{avatar_url}" width="320" height="240" alt="John Carmack">'
Â  Â  Â  Â  responses = [(u,b) for u,b in zip(history[::2], history[1::2])]
Â  Â  Â  Â  return responses, video_html, historyÂ  Â  Â  Â Â 

def transcribe(audio):
Â  Â  os.rename(audio, audio + '.wav')
Â  Â  audio_file = open(audio + '.wav', "rb")
Â  Â  transcript = openai.Audio.transcribe("whisper-1", audio_file, prompt="è¿™æ˜¯ä¸€æ®µç®€ä½“ä¸­æ–‡çš„é—®é¢˜ã€‚")
Â  Â  return transcript['text']Â  Â Â 

def process_audio(audio, history=[]):
Â  Â  if audio is not None:
Â  Â  Â  Â  text = transcribe(audio)
Â  Â  Â  Â  return predict(text, history)
Â  Â  else:
Â  Â  Â  Â  text = None
Â  Â  Â  Â  return predict(text, history)

with gr.Blocks(css="#chatbot{height:500px} .overflow-y-auto{height:500px}") as demo:
Â  Â  chatbot = gr.Chatbot(elem_id="chatbot")
Â  Â  state = gr.State([])

Â  Â  with gr.Row():
Â  Â  Â  Â  txt = gr.Textbox(show_label=False, placeholder="Enter text and press enter").style(container=False)
Â  Â  Â  Â Â 
Â  Â  with gr.Row():
Â  Â  Â  Â  audio = gr.Audio(source="microphone", type="filepath")

Â  Â  with gr.Row():
Â  Â  Â  Â  video = gr.HTML(f'<img src="{avatar_url}" width="320" height="240" alt="John Carmack">', live=False)

Â  Â  txt.submit(predict, [txt, state], [chatbot, video, state])
Â  Â  audio.change(process_audio, [audio, state], [chatbot, video, state])
Â  Â Â 
demo.launch()
```

è¾“å‡ºç»“æœï¼š

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/65/2e/6531d11d7e54114bd4cd43fe8603622e.png?wh=1020x1014)

æ”¹é€ å®Œæ•´ä¸ªåº”ç”¨ï¼Œä½ å¯ä»¥è¯•ç€è¿è¡Œä¸€ä¸‹ã€‚ä½ çš„é—®é¢˜ä¼šç”±IDå¤§ç¥å¡é©¬å…‹â€œäº²å£â€+â€œå½“é¢â€å›ç­”ï¼Œæ˜¯ä¸æ˜¯éå¸¸é…·ç‚«ï¼Ÿ

## ä½“éªŒPaddleGANå¼€æºæ¨¡å‹ä¸‹çš„æ•°å­—ä¸»æ’­

ä¸è¿‡ï¼Œä½¿ç”¨D-IDçš„ä»·æ ¼ä¹Ÿä¸ä¾¿å®œï¼Œè€Œå‰é¢çš„å„ä¸ªæ¨¡å—ï¼Œæˆ‘å…¶å®éƒ½ç»™ä½ çœ‹è¿‡å¯¹åº”çš„å¼€æºè§£å†³æ–¹æ¡ˆã€‚æ¯”å¦‚ChatGPTæˆ‘ä»¬å¯ä»¥ç”¨ChatGLMæ¥ä»£æ›¿ï¼Œè¯­éŸ³è¯†åˆ«æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æœ¬åœ°çš„Whisperæ¨¡å‹ï¼Œè¯­éŸ³åˆæˆä¹Ÿå¯ä»¥é€šè¿‡PaddleSpeeché‡Œçš„fastspeech2çš„å¼€æºæ¨¡å‹æ¥å®Œæˆã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬è¿™é‡Œä¹Ÿæ¥å°è¯•ä¸€ä¸‹é€šè¿‡å¼€æºæ¨¡å‹æ¥åˆæˆè¿™æ ·çš„å£æ’­è§†é¢‘ã€‚

ç›®å‰æ¯”è¾ƒå®¹æ˜“æ‰¾åˆ°çš„è§£å†³æ–¹æ¡ˆï¼Œæ˜¯ç™¾åº¦PaddlePaddleä¸‹çš„ [PaddleBobo](https://github.com/JiehangXie/PaddleBoBo) å¼€æºé¡¹ç›®ã€‚å®ƒèƒŒåä½¿ç”¨çš„æ˜¯PaddleGANçš„å¯¹æŠ—ç”Ÿæˆç½‘ç»œç®—æ³•ï¼Œæ¥å®ç°å”‡å½¢å’Œè¡¨æƒ…çš„åŒ¹é…ã€‚ä¸è¿‡PaddleGANå¾ˆä¹…æ²¡æœ‰æ›´æ–°äº†ï¼Œå¯¹äºæœ€æ–°çš„Python3.10çš„æ”¯æŒå’Œä¾èµ–æœ‰äº›é—®é¢˜ã€‚æˆ‘ä»¬ä¹Ÿåªèƒ½åœ¨è¿™é‡Œåšä¸€ä¸ªç®€å•çš„æ¼”ç¤ºã€‚

è¿™é‡Œçš„ä»£ç ä½ ä¸ä¸€å®šéœ€è¦è¿è¡Œï¼Œå› ä¸ºè¿™ä¸ªç¨‹åºå¯¹äºGPUçš„æ˜¾å­˜è¦æ±‚æ¯”è¾ƒé«˜ï¼Œè€Œä¸”å¯¹äºPythonä»¥åŠCudaçš„ç‰ˆæœ¬éƒ½æœ‰è¦æ±‚ã€‚è€Œå¦‚æœä½ ä½¿ç”¨CPUçš„è¯ï¼Œå¯¹åº”çš„è§†é¢‘åˆæˆéœ€è¦å¾ˆé•¿æ—¶é—´ã€‚ä½ ä½“éªŒä¸€ä¸‹æœ€ååˆæˆçš„è§†é¢‘æ•ˆæœå°±å¥½äº†ã€‚

é¦–å…ˆæˆ‘ä»¬éœ€è¦é…ç½®ä¸€ä¸ªPython3.8çš„ç¯å¢ƒï¼Œå¹¶ä¸”å®‰è£…å¯¹åº”çš„ä¾èµ–åŒ…ã€‚

```python
conda create -n py38 python=3.8
conda activate py38

#pip install paddlepaddle
#å®‰è£…ä½¿ç”¨GPUçš„PaddlePaddle
pip install paddlepaddle-gpu  
pip install ppgan
pip install isort
pip install typing-extensions
pip install lazy-object-proxy
pip install wrapt
pip install yacs
pip install paddlespeech
pip install "numpy<1.24.0"

brew install ffmpeg
```

ç„¶åï¼Œæˆ‘ä»¬å°†PaddleBoboçš„ä»£ç é€šè¿‡Gitä¸‹è½½åˆ°æœ¬åœ°ï¼Œå¹¶è¿›å…¥å¯¹åº”çš„ç›®å½•ã€‚

```python
git clone https://github.com/JiehangXie/PaddleBoBo
cd PaddleBobo
```

æˆ‘ä»¬å°†çº¦ç¿°å¡é©¬å…‹çš„å¤´åƒæ–‡ä»¶å‘½åæˆjohncarmack.pngï¼Œå¤åˆ¶åˆ°PaddleBoboçš„file/inputç›®å½•ä¸‹ï¼Œç„¶åä¿®æ”¹å¯¹åº”çš„default.ymlçš„é…ç½®ï¼Œè®©æˆ‘ä»¬çš„è§†é¢‘éƒ½åŸºäºçº¦ç¿°å¡é©¬å…‹çš„å¤´åƒæ¥ç”Ÿæˆã€‚

```python
GANDRIVING:
  FOM_INPUT_IMAGE: './file/input/johncarmack.png'
  FOM_DRIVING_VIDEO: './file/input/zimeng.mp4'
  FOM_OUTPUT_VIDEO: './file/input/johncarmack.mp4'

TTS:
  SPEED: 1.0
  PITCH: 1.0
  ENERGY: 1.0

SAVEPATH:
  VIDEO_SAVE_PATH: './file/output/video/'
  AUDIO_SAVE_PATH: './file/output/audio/'
```

æ³¨ï¼šä¿®æ”¹GanDrivingçš„ç›¸å…³é…ç½®ã€‚

æ¥ç€æˆ‘ä»¬æŒ‰ç…§PaddleBoboçš„æ–‡æ¡£ï¼Œé€šè¿‡create\_virtual\_humanå…ˆç”Ÿæˆä¸€ä¸ªèƒ½å¤ŸåŠ¨èµ·æ¥çš„äººè„¸è§†é¢‘ã€‚å¦‚æœä½ ä½¿ç”¨çš„æ˜¯CPUçš„è¯ï¼Œè¿™ä¸ªè¿‡ç¨‹ä¼šå¾ˆé•¿ï¼Œéœ€è¦ä¸€ä¸¤ä¸ªå°æ—¶ã€‚

```python
python create_virtual_human.py --config default.yaml
```

å› ä¸ºPaddleBoboè¿™ä¸ªé¡¹ç›®æœ‰ä¸€æ®µæ—¶é—´æ²¡æœ‰ç»´æŠ¤äº†ï¼Œå¯¹äºæœ€æ–°ç‰ˆæœ¬çš„PaddleSpeechæœ‰ä¸€äº›å°å°çš„å…¼å®¹é—®é¢˜ï¼Œæ‰€ä»¥ä½ è¿˜éœ€è¦è°ƒæ•´ä¸€ä¸‹ PaddleTools é‡Œé¢çš„TTS.pyæ–‡ä»¶ï¼Œä¿®æ”¹import MODEL\_HOMEåŒ…çš„åç§°ã€‚

```python
from paddlespeech.utils.env import MODEL_HOME
```

ç„¶åï¼Œæˆ‘ä»¬å†é€šè¿‡generate\_demoè¾“å…¥æˆ‘ä»¬å¸Œæœ›è¿™ä¸ªè§†é¢‘å£æ’­çš„æ–‡å­—æ˜¯ä»€ä¹ˆã€‚

```python
python general_demo.py \
    --human ./file/input/johncarmack.mp4 \
    --output johncarmack_output.mp4 \
    --text "æˆ‘æ˜¯çº¦ç¿°å¡é©¬å…‹ï¼Œå¾ˆé«˜å…´è®¤è¯†å¤§å®¶"
```

æœ€åç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶ï¼Œæˆ‘ä¹Ÿæ”¾åˆ°æˆ‘ä»¬çš„[ä»£ç åº“çš„ data ç›®å½•](https://github.com/xuwenhao/geektime-ai-course/tree/main/data)é‡Œäº†ï¼Œä½ å¯ä»¥ä¸‹è½½ä¸‹æ¥ä½“éªŒä¸€ä¸‹æ•ˆæœæ˜¯æ€ä¹ˆæ ·çš„ã€‚ç›®å‰æ¥è¯´ï¼Œé€šè¿‡GANç”Ÿæˆå½±åƒçš„æ–¹å¼ï¼Œéœ€è¦èŠ±è´¹çš„æ—¶é—´è¿˜æ˜¯æ¯”è¾ƒé•¿çš„ï¼Œæœªæ¥çš„æŠ€æœ¯å‘å±•ä¹Ÿå¯èƒ½æ›´åå‘äºDiffuserç±»å‹çš„ç®—æ³•ï¼Œå› æ­¤ä»Šå¤©æˆ‘ä»¬æ›´å¤šåœ°æ˜¯æä¾›ä¸€ç§æ–°çš„ä½“éªŒï¼Œè®©ä½ æ„Ÿå—ä¸€ä¸‹äººå·¥æ™ºèƒ½å¸¦æ¥çš„å½±åƒæ–¹é¢çš„åˆ›æ–°ã€‚

è¿™äº›å‘½ä»¤è¡Œå¯¹åº”çš„Pythonç¨‹åºå…¶å®ä¹Ÿå¾ˆç®€å•ï¼Œä¸è¶…è¿‡50è¡Œä»£ç ï¼Œä½ æœ‰å…´è¶£çš„è¯ï¼Œå¯ä»¥è¯»ä¸€ä¸‹æºä»£ç çœ‹çœ‹å®ƒå…·ä½“æ˜¯è°ƒç”¨å“ªäº›æ¨¡å‹æ¥å®ç°çš„ã€‚

## å°ç»“

å¥½äº†ï¼Œè¿™ä¸€èŠ‚è¯¾ï¼Œåˆ°è¿™é‡Œå°±ç»“æŸäº†ã€‚

ä»Šå¤©æˆ‘ä»¬æ•´åˆå‰ä¸¤è®²å­¦ä¹ çš„çŸ¥è¯†ï¼Œæ‰“é€ äº†ä¸€ä¸ªå¯ä»¥é€šè¿‡è¯­éŸ³æ¥äº¤äº’çš„èŠå¤©æœºå™¨äººã€‚è¿›ä¸€æ­¥åœ°ï¼Œæˆ‘ä»¬é€šè¿‡D-ID.comè¿™ä¸ªSaaSï¼Œæä¾›äº†ä¸€ä¸ªèƒ½å¤Ÿå¯¹ä¸Šå£å‹ã€æœ‰è¡¨æƒ…çš„æ•°å­—äººæ¥å›å¤é—®é¢˜ã€‚å½“ç„¶ï¼ŒD-ID.comçš„ä»·æ ¼æ¯”è¾ƒæ˜‚è´µï¼Œå°¤å…¶æ˜¯å¯¹äºAPIè°ƒç”¨çš„æ¬¡æ•°å’Œç”Ÿæˆè§†é¢‘çš„æ•°é‡éƒ½æœ‰ä¸€å®šçš„é™åˆ¶ã€‚æ‰€ä»¥æˆ‘ä»¬è¿›ä¸€æ­¥å°è¯•ä½¿ç”¨å¼€æºçš„PaddleBoboé¡¹ç›®ï¼Œæ¥æ ¹æ®æ–‡æœ¬ç”Ÿæˆå¸¦å£å‹çš„å£æ’­è§†é¢‘ã€‚è€Œå¦‚æœæˆ‘ä»¬æŠŠè¯­éŸ³è¯†åˆ«ä»äº‘æ¢æˆæœ¬åœ°çš„Whisperæ¨¡å‹ï¼ŒæŠŠChatGPTæ¢æˆä¹‹å‰æµ‹è¯•è¿‡çš„å¼€æºçš„ChatGLMï¼Œæˆ‘ä»¬å°±æœ‰äº†ä¸€ä¸ªå®Œå…¨å¼€æºçš„æ•°å­—äººè§£å†³æ–¹æ¡ˆã€‚

å½“ç„¶ï¼Œä»Šå¤©æˆ‘ä¸ºä½ æ¼”ç¤ºçš„æ•°å­—äººï¼Œä»æ•ˆæœä¸Šæ¥çœ‹è¿˜å¾ˆä¸€èˆ¬ã€‚ä¸è¿‡ï¼Œè¦çŸ¥é“æˆ‘ä»¬å¹¶æ²¡æœ‰ä½¿ç”¨ä»»ä½•æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè€Œæ˜¯å®Œå…¨ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„å¼€æºæ¨¡å‹ã€‚æˆ‘å†™å¯¹åº”çš„æ¼”ç¤ºä»£ç ä¹Ÿå°±åªç”¨äº†ä¸€ä¸¤å¤©æ™šä¸Šçš„æ—¶é—´è€Œå·²ã€‚å¦‚æœæƒ³è¦è¿›ä¸€æ­¥ä¼˜åŒ–æ•ˆæœï¼Œæˆ‘ä»¬å®Œå…¨å¯ä»¥åŸºäºè¿™äº›å¼€æºæ¨¡å‹è¿›ä¸€æ­¥å»æ”¹é€ å¾®è°ƒã€‚

ä»Šå¤©ï¼Œå¤§éƒ¨åˆ†å¼€æºçš„æ·±åº¦å­¦ä¹ æŠ€æœ¯å·²ç»è¿›å…¥äº†ä¸€ä¸ªé‡å¤§çš„æ‹ç‚¹ï¼Œä»»ä½•äººéƒ½å¯ä»¥é€šè¿‡äº‘æœåŠ¡çš„APIå’Œå¼€æºæ¨¡å‹æ­å»ºä¸€ä¸ªAIäº§å“å‡ºæ¥äº†ã€‚å¸Œæœ›è¿™ä¸€è®²èƒ½è®©ä½ æ‹¥æœ‰å……è¶³çš„çŸ¥è¯†å’Œè¶³å¤Ÿçš„åˆ›æ„å»åšå‡ºä¸€ä¸ªä¸ä¼—ä¸åŒçš„äº§å“æ¥ã€‚

## æ€è€ƒé¢˜

è¯­éŸ³ç›¸å…³çš„AIäº§å“å¸‚åœºä¸Šè¿˜æœ‰å¾ˆå¤šï¼Œä½†ç›®å‰å¾ˆå¤šå¥½çš„äº§å“è¿˜éƒ½æ˜¯é—­æºæ”¶è´¹çš„ã€‚æ¯”å¦‚ [elevenlabs](https://beta.elevenlabs.io/speech-synthesis) å°±å¯ä»¥æ¨¡ä»¿äººçš„è¯­éŸ³è¯­è°ƒã€‚å®ƒä¹Ÿæ”¯æŒä¸­æ–‡ï¼Œè€Œä¸”é¢„è®¾çš„â€œè€å¤–â€è¯­éŸ³è¯´å‡ºæ¥çš„ä¸­æ–‡è¿˜çœŸæœ‰ç‚¹å„¿è€å¤–è¯´ä¸­æ–‡çš„è…”è°ƒï¼Œä½ å¯ä»¥è¯•ç€å»ä½“éªŒä¸€ä¸‹ã€‚æˆ‘ä»¬ä¸Šä¸€è®²ä»‹ç»è¿‡çš„PaddleSpeechï¼Œç™¾åº¦å®˜æ–¹ä¹Ÿç»™å‡ºäº†å¯¹åº”çš„[å°æ ·æœ¬åˆæˆå’Œå°æ•°æ®å¾®è°ƒ](https://aistudio.baidu.com/aistudio/projectdetail/4573549?sUid=2470186&shared=1&ts=1663753541400)çš„ç¤ºä¾‹ï¼Œä½ ä¹Ÿå¯ä»¥çœ‹ä¸€ä¸‹ã€‚

åŸºäºè¿™äº›SaaSæˆ–è€…å¼€æºé¡¹ç›®ï¼Œä½ æ˜¯å¦å¯ä»¥å°è¯•ä¸€ä¸‹ï¼ŒæŠŠå¯¹åº”çš„æ•°å­—äººçš„å£°éŸ³æ›¿æ¢æˆä½ è‡ªå·±çš„ï¼Ÿæ¬¢è¿ä½ å¤§èƒ†å°è¯•å¹¶ä¸”æŠŠä½ çš„ä½“ä¼šåˆ†äº«åˆ°ç•™è¨€åŒºï¼Œä¹Ÿæ¬¢è¿ä½ æŠŠè¿™ä¸€è®²çš„å†…å®¹åˆ†äº«ç»™æ„Ÿå…´è¶£çš„æœ‹å‹ï¼Œæˆ‘ä»¬ä¸‹ä¸€è®²å†è§ã€‚

## æ¨èé˜…è¯»

å…³äºæ•°å­—äººï¼Œæœ‰å¾ˆå¤šå¼€æºæ–¹æ¡ˆï¼Œæ¯”å¦‚ [FACIAL](https://github.com/zhangchenxu528/FACIAL) å°±æ˜¯ç”±å¤šä¸ªé™¢æ ¡å’Œä¸‰æ˜Ÿç ”ç©¶é™¢åˆä½œçš„è§£å†³æ–¹æ¡ˆã€‚ä½ ä¹Ÿå¯ä»¥åŸºäºå®ƒä»¬æä¾›çš„ä»£ç æ¥è®­ç»ƒä¸€ä¸ªã€‚æ„Ÿå…´è¶£çš„è¯ï¼Œå¯ä»¥å»è¯»ä¸€è¯»å®ƒä»¬çš„æºç å’Œè®ºæ–‡ã€‚
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ11ï¼‰</strong></div><ul>
<li><span>å‹‡.Max</span> ğŸ‘ï¼ˆ13ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>ç‰¹æ„èµ¶åˆ°æœ€æ–°è¿›åº¦çš„æ–‡ç« ç»™è€å¸ˆç•™è¨€å’¨è¯¢ä¸ªé—®é¢˜ï¼š
èƒŒæ™¯ï¼šé¦–å…ˆï¼Œè¿™ä¸ªè¯¾ç¨‹çœŸçš„æ˜¯å¹²è´§æ»¡æ»¡ï¼Œç‰©è¶…æ‰€å€¼ï¼Œæ„Ÿè°¢è€å¸ˆçš„è¾›è‹¦ã€è®¤çœŸä»˜å‡ºï¼ä½†æ˜¯ï¼Œä½œä¸ºä¸€ä¸ª10æ¥å¹´ç»éªŒçš„è€ç å†œï¼ˆç°åœ¨æ˜¯åŒºå—é“¾æ–¹é¢çš„æ¶æ„ã€ç ”å‘ï¼‰æ€»è§‰å¾—è·Ÿå¾—æœ‰ç‚¹åƒåŠ›ï¼ŒåŸå› æ˜¯ç¼ºå°‘AIæ–¹é¢çš„åŸºç¡€çŸ¥è¯†ï¼Œå¯¹è¯¾ç¨‹ä¸­çš„ä¸€äº›åº“ã€ç®—æ³•çš„åŸç†ç¼ºå°‘åŸºæœ¬çš„æ¦‚å¿µè®¤çŸ¥ã€‚å½“ç„¶å¦‚æœåªå±€é™äºâ€è¿‡ä¸€éä»£ç ã€ç†Ÿç»ƒä½¿ç”¨â€œåŸºæœ¬æ˜¯å¤Ÿäº†ï¼Œä½†æ˜¯æˆ‘è§‰å¾—è¿˜è¾¾ä¸åˆ°å…¥é—¨çº§ã€‚æ‰€ä»¥ï¼Œç‰¹åœ°æ¥è¯·æ•™ä¸‹è€å¸ˆå“ªäº›å¯ä»¥ä½œä¸ºå…¥é—¨çš„ä¸€æ‰‹çŸ¥è¯†ï¼Œè¶Šç²¾ç®€è¶Šå¥½ã€‚
é—®é¢˜ï¼šèƒ½å¦è¯·è€å¸ˆæ¨èæˆ–è€…æ€»ç»“å½’çº³ä¸‹å…¥é—¨AIæˆ–è€…å¤§è¯­è¨€æ¨¡å‹çš„æœ€å°åŸºç¡€çŸ¥è¯†æ˜¯å“ªäº›ï¼Ÿï¼ˆæç¬‘æ¥è€å¸ˆæè¿‡çš„å…¥é—¨ä¸€ä¸ªæ–°é¢†åŸŸçš„MAKE [Minimal Actionable Knowledge and Experience]) 
å¯èƒ½ä¸Šé¢çš„é—®é¢˜æœ‰ç‚¹å¤§ï¼Œæˆ‘å†ç¼©å°ä¸‹ï¼Œæˆ‘çš„ç›®çš„ä¸æ˜¯è½¬è¡ŒAIé¢†åŸŸå¼€å‘ï¼Œè€Œæ˜¯å¾—å¿ƒåº”æ‰‹çš„ä½¿ç”¨AIå¤§è¯­è¨€æ¨¡å‹å¼€å‘è‡ªå·±çš„åº”ç”¨æˆ–è€…æé«˜å·¥ä½œæ•ˆç‡ï¼Œæ¯”å¦‚ä½¿ç”¨AIåšäº›è´¢åŠ¡å»ºè®®ã€æŠ•ç ”ä¹‹ç±»çš„åº”ç”¨ã€‚æˆ‘æ€»è§‰å¾—åªæ˜¯ä¼šè°ƒæ¥å£ï¼Œå®Œå…¨ä¸ç†è§£åŸºç¡€æ¦‚å¿µè¿˜æ˜¯æ— æ³•æ¸¸åˆƒæœ‰ä½™çš„ä½¿ç”¨ï¼Œç¦»å¼€è¯¾ç¨‹ï¼Œå°±å¾ˆéš¾æœ‰æ€è·¯åšè‡ªä¸»å¼€å‘äº†ã€‚

è¯´çš„æœ‰ç‚¹å•°å—¦äº†ï¼Œæ„Ÿè°¢è€å¸ˆï¼
</p>2023-04-24</li><br/><li><span>abcğŸ™‚</span> ğŸ‘ï¼ˆ3ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>è€å¸ˆï¼Œå¦‚æœæƒ³è¦AIå­¦ä¹ æˆ‘çš„å†™ä½œé£æ ¼ï¼ŒæŒ‰ç…§æˆ‘çš„é£æ ¼å†™ä½œï¼Œè¦æ€ä¹ˆè®­ç»ƒå‘¢ï¼Ÿ</p>2023-04-25</li><br/><li><span>John</span> ğŸ‘ï¼ˆ3ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>è¿™ä¸ªpaddleBoBoéƒ½ä¸€å¹´æ²¡æ›´æ–°å•¦ è¿˜æœ‰æ²¡æœ‰å¹³æ›¿æˆ–è€…æ½œåœ¨æ–°äº§å“å‘¢</p>2023-04-24</li><br/><li><span>John</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>ç°åœ¨HeyGenä¸é”™ å°±æ˜¯æ”¶è´¹ä¸ä½</p>2023-04-24</li><br/><li><span>åŠ‰ä»²ä»²</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>å‡ºç°error:module &#39;pexpect&#39; has no attribute &#39;spawn&#39;,å·²ç»æ˜¯æœ€æ–°çš„pexpect</p>2023-04-28</li><br/><li><span>ç²‰å¢¨ä¹‹ä¸‹</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>æœ¬åœ°è¿è¡Œåï¼Œå›å¤æ—¶æŠ¥é”™ï¼šRetrying langchain.llms.openai.completion_with_retry.&lt;locals&gt;._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host=&#39;api.openai.com&#39;, port=443): Max retries exceeded with url: &#47;v1&#47;completions (Caused by NewConnectionError(&#39;&lt;urllib3.connection.HTTPSConnection object at 0x000001F9C7DAD670&gt;: Failed to establish a new connection: [WinError 10060] ç”±äºè¿æ¥æ–¹åœ¨ä¸€æ®µæ—¶é—´åæ²¡æœ‰æ­£ç¡®ç­”å¤æˆ–è¿æ¥çš„ä¸»æœºæ²¡æœ‰ååº”ï¼Œè¿æ¥å°è¯•å¤±è´¥ã€‚&#39;)).</p>2023-04-24</li><br/><li><span>ä¸€å¶</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>åˆšçœ‹äº†ä¸‹,è¿™ä¸ªdidçš„ä»·æ ¼ä¸æ˜¯ä¸€èˆ¬çš„è´µ....</p>2023-04-24</li><br/><li><span>å°ç†æƒ³ã€‚</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>txt = gr.Textbox(show_label=False, placeholder=&quot;Enter text and press enter&quot;).style(container=False)
å®˜ç½‘æ–‡æ¡£ä¹Ÿéƒ½æ²¡æœ‰.style(container=False)</p>2023-11-09</li><br/><li><span>å°ç†æƒ³ã€‚</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>audio = gr.Audio(source=&quot;microphone&quot;, type=&quot;filepath&quot;)
è€å¸ˆè¿™æ®µä»£ç æ²¡æœ‰sourceå±æ€§ï¼Œè¿™ä¸ªå±æ€§æ˜¯sourcesæ‰å¯ä»¥ï¼Œå¯èƒ½å†™é”™äº†å“ˆå“ˆå“ˆ
audio=gr.Audio(sources=&quot;microphone&quot;, type=&quot;filepath&quot;)</p>2023-11-09</li><br/><li><span>å°ç†æƒ³ã€‚</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>https:&#47;&#47;cdn.discordapp.com&#47;attachments&#47;1065596492796153856&#47;1095617463112187984&#47;John_Carmack_Potrait_668a7a8d-1bb0-427d-8655-d32517f6583d.png
è€å¸ˆè¿™ä¸ªåœ°å€è®¿é—®ä¸äº†ï¼Œæ˜¯ä¸æ˜¯æˆ‘éœ€è¦æŠŠæ–‡ä»¶ä¸‹è½½ä¸‹æ¥è‡ªå·±æ˜ å°„ä¸€ä¸‹å“ˆ</p>2023-11-07</li><br/><li><span>é™å¿ƒ</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>å¦‚æœèƒ½æœ‰ä¸€ä¸ªå®Œæ•´çš„æ•°å­—äººå¼€æºæ–¹æ¡ˆå°±å¥½äº†</p>2023-07-12</li><br/>
</ul>