ä½ å¥½ï¼Œæˆ‘æ˜¯å¾æ–‡æµ©ã€‚

[ä¸Šä¸€è®²](https://time.geekbang.org/column/article/653489)ï¼Œæˆ‘ä»¬ä¸€èµ·ä½“éªŒäº†CLIPè¿™ä¸ªå¤šæ¨¡æ€çš„æ¨¡å‹ã€‚åœ¨è¿™ä¸ªæ¨¡å‹é‡Œï¼Œæˆ‘ä»¬å·²ç»èƒ½å¤ŸæŠŠä¸€æ®µæ–‡æœ¬å’Œå¯¹åº”çš„å›¾ç‰‡å…³è”èµ·æ¥äº†ã€‚çœ‹åˆ°æ–‡æœ¬å’Œå›¾ç‰‡çš„å…³è”ï¼Œæƒ³å¿…ä½ ä¹Ÿèƒ½è”æƒ³åˆ°è¿‡å»åŠå¹´éå¸¸ç«çƒ­çš„â€œæ–‡ç”Ÿå›¾â€ï¼ˆText-To-Imageï¼‰çš„åº”ç”¨æµªæ½®äº†ã€‚ç›¸æ¯”äºåœ¨å¤§è¯­è¨€æ¨¡å‹é‡ŒOpenAIçš„ä¸€æç‹¬ç§€ã€‚æ–‡ç”Ÿå›¾é¢†åŸŸå°±å±äºç™¾èŠ±é½æ”¾äº†ï¼ŒOpenAIé™†ç»­å‘è¡¨äº†DALL-Eå’Œ [DALL-E 2](https://labs.openai.com/)ï¼ŒGoogleä¹Ÿä¸ç”˜ç¤ºå¼±åœ°å‘è¡¨äº† [Imagen](https://imagen.research.google/)ï¼Œè€Œå¸‚åœºä¸Šå®é™…è¢«ç”¨å¾—æœ€å¤šã€åé¦ˆæœ€å¥½çš„ç”¨æˆ·ç«¯äº§å“æ˜¯ [Midjourney](https://midjourney.com/home/)ã€‚

ä¸è¿‡ï¼Œåœ¨æ•´ä¸ªæŠ€æœ¯ç¤¾åŒºé‡Œï¼Œæœ€æµè¡Œçš„äº§å“åˆ™æ˜¯Stable Diffusionã€‚å› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå®Œå…¨å¼€æºçš„äº§å“ï¼Œæˆ‘ä»¬ä¸ä»…å¯ä»¥è°ƒç”¨Stable Diffusionå†…ç½®çš„æ¨¡å‹æ¥ç”Ÿæˆå›¾ç‰‡ï¼Œè¿˜èƒ½å¤Ÿä¸‹è½½ç¤¾åŒºé‡Œå…¶ä»–äººè®­ç»ƒå¥½çš„æ¨¡å‹æ¥ç”Ÿæˆå›¾ç‰‡ã€‚æˆ‘ä»¬ä¸ä»…å¯ä»¥é€šè¿‡æ–‡æœ¬æ¥ç”Ÿæˆå›¾ç‰‡ï¼Œè¿˜èƒ½é€šè¿‡å›¾ç‰‡æ¥ç”Ÿæˆå›¾ç‰‡ï¼Œé€šè¿‡æ–‡æœ¬æ¥ç¼–è¾‘å›¾ç‰‡ã€‚

é‚£ä¹ˆä»Šå¤©è¿™ä¸€è®²ï¼Œæˆ‘ä»¬å°±æ¥çœ‹çœ‹å¦‚ä½•ä½¿ç”¨Stable Diffusionï¼Œåšåˆ°ä¸Šé¢è¿™äº›äº‹æƒ…ã€‚

## ä½¿ç”¨Stable Diffusionç”Ÿæˆå›¾ç‰‡

### æ–‡ç”Ÿå›¾

å¯èƒ½ä½ è¿˜æ²¡æ€ä¹ˆä½“éªŒè¿‡æ–‡ç”Ÿå›¾çš„åº”ç”¨ï¼Œé‚£æˆ‘ä»¬å…ˆç”¨å‡ è¡Œæœ€ç®€å•çš„ä»£ç ä½“éªŒä¸€ä¸‹ã€‚åœ¨è¿™ä¸€è®²é‡Œï¼Œæˆ‘å»ºè®®ä¸€å®šè¦ç”¨Colabæˆ–è€…å…¶ä»–çš„GPUç¯å¢ƒï¼Œå› ä¸ºç”¨CPUæ¥æ‰§è¡Œçš„è¯ï¼Œé€Ÿåº¦ä¼šæ…¢åˆ°è®©äººæ— æ³•æ¥å—ã€‚

å®‰è£…ä¾èµ–åŒ…ï¼š

```python
%pip install diffusers accelerate transformers
```

ä»£ç ï¼š

```python
from diffusers import DiffusionPipeline
pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
pipeline.to("cuda")
image = pipeline("a photograph of an astronaut riding a horse").images[0]
image
```

è¾“å‡ºç»“æœï¼š  
![å›¾ç‰‡](https://static001.geekbang.org/resource/image/72/57/7217f995c7fd7143ef6807d8e0dfc057.png?wh=512x512)

ä»£ç éå¸¸ç®€å•ï¼Œåªæœ‰å¯¥å¯¥å‡ è¡Œã€‚è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨äº†Huggingfaceçš„Diffusersåº“ï¼Œé€šè¿‡DiffusionPipelineåŠ è½½äº†RunwayMLçš„stable-diffusion-v1-5çš„æ¨¡å‹ã€‚ç„¶åï¼ŒæŒ‡å®šäº†è¿™ä¸ªPipelineä½¿ç”¨CUDAä¹Ÿå°±æ˜¯åˆ©ç”¨GPUæ¥è¿›è¡Œè®¡ç®—ã€‚æœ€åå‘è¿™ä¸ªPipelineè¾“å…¥äº†ä¸€æ®µæ–‡æœ¬ï¼Œé€šè¿‡è¿™æ®µæ–‡æœ¬æˆ‘ä»¬å°±ç”Ÿæˆäº†ä¸€å¼ å›¾ç‰‡ã€‚

è¿™é‡Œï¼Œæˆ‘ä»¬ç”»çš„æ˜¯åœ¨Stable Diffusioné‡Œéå¸¸ç»å…¸çš„ä¸€å¼ â€œå®‡èˆªå‘˜åœ¨å¤ªç©ºéª‘é©¬â€çš„å›¾ç‰‡ã€‚ä¹‹æ‰€ä»¥ç”»è¿™ä¹ˆä¸€å¼ å›¾ç‰‡ï¼Œæ˜¯ä¸ºäº†è¯æ˜æˆ‘ä»¬å¹¶ä¸æ˜¯é€šè¿‡â€œæœç´¢â€çš„æ–¹å¼æ‰¾åˆ°ä¸€å¼ å·²ç»å­˜åœ¨çš„å›¾ç‰‡ã€‚æ¯”å¦‚ï¼Œä¸Šä¸€è®²é‡Œæˆ‘ä»¬ä»‹ç»è¿‡CLIPæ¨¡å‹ï¼Œå…¶å®å°±å¯ä»¥å®Œæˆä»æ–‡æœ¬åˆ°å›¾ç‰‡çš„æœç´¢åŠŸèƒ½ã€‚è€ŒStable Diffusionï¼Œæ˜¯çœŸçš„è®©AIâ€œç”»â€å‡ºæ¥ä¸€å¼ æ–°çš„å›¾ç‰‡ã€‚æ¯•ç«Ÿï¼Œä»¥å‰å®‡èˆªå‘˜ä¹Ÿä»æ¥æ²¡æœ‰åœ¨å¤ªç©ºéª‘è¿‡é©¬ï¼Œä¹Ÿä¸å¯èƒ½æœ‰äººæ‹ä¸‹è¿‡è¿™æ ·çš„ç…§ç‰‡ã€‚

### Stable Diffusionçš„åŸºæœ¬åŸç†

Stable Diffusionç”Ÿæˆçš„å›¾ç‰‡æ•ˆæœçš„ç¡®ä¸é”™ï¼Œç›¸ä¿¡ä½ ä¹Ÿå¾ˆå¥½å¥‡è¿™ä¸ªäº‹æƒ…çš„åŸç†æ˜¯ä»€ä¹ˆã€‚å…¶å®ï¼ŒStable DiffusionèƒŒåä¸æ˜¯å•ç‹¬çš„ä¸€ä¸ªæ¨¡å‹ï¼Œè€Œæ˜¯ç”±å¤šä¸ªæ¨¡å‹ç»„åˆè€Œæˆçš„ã€‚æ•´ä¸ªStable Diffusionæ–‡ç”Ÿå›¾çš„è¿‡ç¨‹æ˜¯ç”±è¿™æ ·ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ç»„æˆçš„ã€‚

- ç¬¬ä¸€ä¸ªæ¨¡å—æ˜¯ä¸€ä¸ªText-Encoderï¼ŒæŠŠæˆ‘ä»¬è¾“å…¥çš„æ–‡æœ¬å˜æˆä¸€ä¸ªå‘é‡ã€‚å®é™…ä½¿ç”¨çš„å°±æ˜¯æˆ‘ä»¬ä¸Šä¸€è®²ä»‹ç»çš„CLIPæ¨¡å‹ã€‚å› ä¸ºCLIPæ¨¡å‹å­¦ä¹ çš„æ˜¯æ–‡æœ¬å’Œå›¾åƒä¹‹é—´çš„å…³ç³»ï¼Œæ‰€ä»¥å¾—åˆ°çš„è¿™ä¸ªå‘é‡æ—¢ç†è§£äº†æ–‡æœ¬çš„å«ä¹‰ï¼Œåˆèƒ½å’Œå›¾ç‰‡çš„ä¿¡æ¯å…³è”èµ·æ¥ã€‚
- ç¬¬äºŒä¸ªæ˜¯Generationæ¨¡å—ï¼Œé¡¾åæ€ä¹‰æ˜¯ä¸€ä¸ªå›¾ç‰‡ä¿¡æ¯ç”Ÿæˆæ¨¡å—ã€‚è¿™é‡Œä¹Ÿæœ‰ä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå«åšUNetï¼Œè¿˜æœ‰ä¸€ä¸ªè°ƒåº¦å™¨ï¼ˆSchedulerï¼‰ï¼Œç”¨æ¥ä¸€æ­¥æ­¥åœ°å»é™¤å™ªå£°ã€‚è¿™ä¸ªæ¨¡å—çš„å·¥ä½œæµç¨‹æ˜¯å…ˆå¾€å‰é¢çš„ç”¨CLIPæ¨¡å‹æ¨ç†å‡ºæ¥çš„å‘é‡é‡Œæ·»åŠ å¾ˆå¤šå™ªå£°ï¼Œå†é€šè¿‡UNet+Scheduleré€æ¸å»é™¤å™ªå£°ï¼Œæœ€åæ‹¿åˆ°äº†ä¸€ä¸ªæ–°çš„å¼ é‡ã€‚è¿™ä¸ªå¼ é‡å¯ä»¥è®¤ä¸ºæ˜¯ä¸€ä¸ªå°ºå¯¸ä¸Šç¼©å°äº†çš„å›¾ç‰‡ä¿¡æ¯å‘é‡ï¼Œé‡Œé¢éšå«äº†æˆ‘ä»¬è¦ç”Ÿæˆçš„å›¾ç‰‡ä¿¡æ¯ã€‚
- æœ€åä¸€ä¸ªæ¨¡å—ï¼Œåˆ™æ˜¯Decoderæˆ–è€…å«åšè§£ç å™¨ã€‚èƒŒåä¹Ÿæ˜¯ä¸€ä¸ªæœºå™¨å­¦ä¹ çš„æ¨¡å‹ï¼Œå«åšVAEã€‚å®ƒä¼šæ ¹æ®ç¬¬äºŒæ­¥çš„è¿”å›ç»“æœæŠŠè¿™ä¸ªå›¾åƒä¿¡æ¯è¿˜åŸæˆæœ€ç»ˆçš„å›¾ç‰‡ã€‚

è¿™ä¸ªè¿‡ç¨‹ï¼Œä½ å¯ä»¥ç»“åˆStable Diffusionç›¸å…³è®ºæ–‡é‡Œçš„ä¸€å¼ æ¨¡å‹æ¶æ„å›¾æ¥çœ‹ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/4c/cb/4ca19441686120b9c28c8d5ba11baacb.png?wh=598x310)

è¿™æ ·å¬èµ·æ¥å¯èƒ½æœ‰ç‚¹å¤ªç†è®ºäº†ï¼Œé‚£æˆ‘ä»¬è¿˜æ˜¯çœ‹çœ‹å…·ä½“çš„ä»£ç å’Œå›¾ç‰‡ç”Ÿæˆçš„è¿‡ç¨‹å§ï¼Œè¿™æ ·å°±æ¯”è¾ƒå®¹æ˜“ç†è§£å›¾ç‰‡æ˜¯æ€ä¹ˆç”Ÿæˆçš„äº†ã€‚

æˆ‘ä»¬å…ˆæŠŠDiffusionPipelineæ‰“å°å‡ºæ¥ï¼Œçœ‹çœ‹å®ƒå†…éƒ¨æ˜¯ç”±å“ªäº›éƒ¨åˆ†ç»„æˆçš„ã€‚

```python
pipeline
```

è¾“å‡ºç»“æœï¼š

```python
StableDiffusionPipeline {
  "_class_name": "StableDiffusionPipeline",
  "_diffusers_version": "0.15.1",
  "feature_extractor": [
    "transformers",
    "CLIPFeatureExtractor"
  ],
  "requires_safety_checker": true,
  "safety_checker": [
    "stable_diffusion",
    "StableDiffusionSafetyChecker"
  ],
  "scheduler": [
    "diffusers",
    "PNDMScheduler"
  ],
  "text_encoder": [
    "transformers",
    "CLIPTextModel"
  ],
  "tokenizer": [
    "transformers",
    "CLIPTokenizer"
  ],
  "unet": [
    "diffusers",
    "UNet2DConditionModel"
  ],
  "vae": [
    "diffusers",
    "AutoencoderKL"
  ]
}
```

è¿™ä¸ªå¯¹è±¡é‡Œé¢æœ‰3éƒ¨åˆ†ã€‚

1. Tokenizerå’ŒText\_Encoderï¼Œå°±æ˜¯æˆ‘ä»¬ä¸Šé¢è¯´çš„æŠŠæ–‡æœ¬å˜æˆå‘é‡çš„Text Encoderã€‚å¯ä»¥çœ‹åˆ°æˆ‘ä»¬è¿™é‡Œç”¨çš„æ¨¡å‹å°±æ˜¯ä¸Šä¸€è®²çš„CLIPæ¨¡å‹ã€‚
2. UNetå’ŒSchedulerï¼Œå°±æ˜¯å¯¹æ–‡æœ¬å‘é‡ä»¥åŠè¾“å…¥çš„å™ªå£°è¿›è¡Œå™ªå£°å»é™¤çš„ç»„ä»¶ï¼Œä¹Ÿå°±æ˜¯Generationæ¨¡å—ã€‚è¿™é‡Œç”¨çš„æ˜¯UNet2DConditionModelæ¨¡å‹ï¼Œè¿˜æŠŠPNDMSchedulerç”¨ä½œäº†å»é™¤å™ªå£°çš„è°ƒåº¦å™¨ã€‚
3. VAEï¼Œä¹Ÿå°±æ˜¯è§£ç å™¨ï¼ˆDecoderï¼‰ï¼Œè¿™é‡Œç”¨çš„æ˜¯AutoencoderKLï¼Œå®ƒä¼šæ ¹æ®ä¸Šé¢ç”Ÿæˆçš„å›¾ç‰‡ä¿¡æ¯æœ€åè¿˜åŸå‡ºä¸€å¼ é«˜åˆ†è¾¨ç‡çš„å›¾ç‰‡ã€‚

å‰©ä¸‹çš„feature\_extractorï¼Œå¯ä»¥ç”¨æ¥æå–å›¾åƒç‰¹å¾ï¼Œå¦‚æœæˆ‘ä»¬ä¸æƒ³æ–‡ç”Ÿå›¾ï¼Œæƒ³è¦å›¾ç”Ÿå›¾ï¼Œå®ƒå°±ä¼šè¢«ç”¨æ¥æŠŠæˆ‘ä»¬è¾“å…¥çš„å›¾ç‰‡çš„ç‰¹å¾æå–æˆä¸ºå‘é‡ã€‚è€Œsafety\_checkeråˆ™æ˜¯ç”¨æ¥æ£€æŸ¥ç”Ÿæˆå†…å®¹ï¼Œé¿å…ç”Ÿæˆå…·æœ‰å†’çŠ¯æ€§çš„å›¾ç‰‡ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±è‡ªå·±æ¥ç»„åˆä¸€ä¸‹è¿™äº›æ¨¡å‹ï¼Œæ¥æŠŠæ•´ä¸ªå›¾ç‰‡ç”Ÿæˆçš„è¿‡ç¨‹ç»™æ¼”ç¤ºå‡ºæ¥ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æŠŠä¸Šé¢Stable Diffusion 1.5éœ€è¦çš„æ¨¡å‹ç»„ä»¶éƒ½åŠ è½½å‡ºæ¥ã€‚

```python
from transformers import CLIPTextModel, CLIPTokenizer
from diffusers import AutoencoderKL, UNet2DConditionModel, PNDMScheduler

vae = AutoencoderKL.from_pretrained("runwayml/stable-diffusion-v1-5", subfolder="vae")
tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-large-patch14")
text_encoder = CLIPTextModel.from_pretrained("openai/clip-vit-large-patch14")
unet = UNet2DConditionModel.from_pretrained("runwayml/stable-diffusion-v1-5", subfolder="unet")
scheduler = PNDMScheduler.from_pretrained("runwayml/stable-diffusion-v1-5", subfolder="scheduler")

torch_device = "cuda"
vae.to(torch_device)
text_encoder.to(torch_device)
unet.to(torch_device)
```

**æ³¨æ„ï¼Œå¯¹åº”çš„CLIPTokenizerå’ŒCLIPTextModelçš„åå­—å¹¶ä¸æ˜¯stable-diffusion-v1-5ï¼Œå¦‚æœä½¿ç”¨Diffusersåº“çš„Pipelineçš„è¯ï¼Œå¯ä»¥ä»æ¨¡å‹é‡Œé¢å¯¹åº”æ¨¡å—çš„ [config.json](https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/text_encoder/config.json) è¯»å–åˆ°å®ƒä»¬ã€‚**

ç„¶åï¼Œæˆ‘ä»¬æŠŠæ¥ä¸‹æ¥ç”Ÿæˆå›¾ç‰‡çš„å‚æ•°åˆå§‹åŒ–ä¸€ä¸‹ï¼ŒåŒ…æ‹¬æ–‡æœ¬ã€å¯¹åº”çš„å›¾ç‰‡åˆ†è¾¨ç‡ï¼Œä»¥åŠä¸€ç³»åˆ—æ¨¡å‹ä¸­éœ€è¦ä½¿ç”¨çš„è¶…å‚æ•°ã€‚

```python
import torch

prompt = ["a photograph of an astronaut riding a horse"]
height = 512  # default height of Stable Diffusion
width = 512  # default width of Stable Diffusion
num_inference_steps = 25  # Number of denoising steps
guidance_scale = 7.5  # Scale for classifier-free guidance
generator = torch.manual_seed(42)  # Seed generator to create the inital latent noise
batch_size = len(prompt)
```

ç„¶åï¼Œæˆ‘ä»¬æŠŠå¯¹åº”çš„è¾“å…¥æ–‡æœ¬å˜æˆä¸€ä¸ªå‘é‡ï¼Œç„¶åå†æ ¹æ®ä¸€ä¸ªç©ºå­—ç¬¦ä¸²ç”Ÿæˆä¸€ä¸ªâ€œæ— æ¡ä»¶â€çš„å‘é‡ï¼Œæœ€åæŠŠä¸¤ä¸ªå‘é‡æ‹¼æ¥åœ¨ä¸€èµ·ã€‚æˆ‘ä»¬å®é™…ç”Ÿæˆå›¾ç‰‡çš„è¿‡ç¨‹ï¼Œå°±æ˜¯é€æ¸ä»è¿™ä¸ªæ— æ¡ä»¶çš„å‘é‡å‘è¾“å…¥æ–‡æœ¬è¡¨ç¤ºçš„å‘é‡é æ‹¢çš„è¿‡ç¨‹ã€‚

```python
text_input = tokenizer(
    prompt, padding="max_length", max_length=tokenizer.model_max_length, truncation=True, return_tensors="pt"
)

with torch.no_grad():
    text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]

max_length = text_input.input_ids.shape[-1]
uncond_input = tokenizer([""] * batch_size, padding="max_length", max_length=max_length, return_tensors="pt")
uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]

text_embeddings = torch.cat([uncond_embeddings, text_embeddings])
```

ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å…ˆç”Ÿæˆä¸€ç³»åˆ—éšæœºå™ªå£°ã€‚

```python
latents = torch.randn(
    (batch_size, unet.in_channels, height // 8, width // 8),
    generator=generator,
)
latents = latents.to(torch_device)

latents = latents * scheduler.init_noise_sigma
```

æ¥ä¸‹æ¥å°±æ˜¯ç”Ÿæˆå›¾ç‰‡çš„ä»£ç äº†ï¼Œæˆ‘ä»¬å…ˆå®šä¹‰ä¸¤ä¸ªå‡½æ•°ï¼Œå®ƒä»¬ä¼šåˆ†åˆ«æ˜¾ç¤ºGenerationæ¨¡å—ç”Ÿæˆå‡ºæ¥çš„å›¾ç‰‡ä¿¡æ¯ï¼Œä»¥åŠDecoderæ¨¡å—è¿˜åŸå‡ºæ¥çš„æœ€ç»ˆå›¾ç‰‡ã€‚

```python
import PIL
import torch
import numpy as np
from PIL import Image
from IPython.display import display

def display_denoised_sample(sample, i):
    image_processed = sample.cpu().permute(0, 2, 3, 1)
    image_processed = (image_processed + 1.0) * 127.5
    image_processed = image_processed.numpy().astype(np.uint8)

    image_pil = PIL.Image.fromarray(image_processed[0])
    display(f"Denoised Sample @ Step {i}")
    display(image_pil)
    return image_pil

def display_decoded_image(latents, i):
  # scale and decode the image latents with vae
  latents = 1 / 0.18215 * latents
  with torch.no_grad():
    image = vae.decode(latents).sample
    image = (image / 2 + 0.5).clamp(0, 1)
    image = image.detach().cpu().permute(0, 2, 3, 1).numpy()
    images = (image * 255).round().astype("uint8")
    pil_images = [Image.fromarray(image) for image in images]
    display(f"Decoded Image @ step {i}")
    display(pil_images[0])
    return pil_images[0]
```

æœ€åï¼Œæˆ‘ä»¬é€šè¿‡Diffusionç®—æ³•ä¸€æ­¥ä¸€æ­¥æ¥ç”Ÿæˆå›¾ç‰‡å°±å¥½äº†ã€‚æˆ‘ä»¬æ ¹æ®å‰é¢æŒ‡å®šçš„å‚æ•°ï¼Œå¾ªç¯äº†25æ­¥ï¼Œæ¯ä¸€æ­¥éƒ½é€šè¿‡Schedulerå’ŒUNetæ¥è¿›è¡Œå›¾ç‰‡å»å™ªå£°çš„æ“ä½œã€‚å¹¶ä¸”æ¯5æ­¥éƒ½æŠŠå¯¹åº”å»å™ªåçš„å›¾ç‰‡ä¿¡æ¯ï¼Œä»¥åŠè§£ç åè¿˜åŸçš„å›¾ç‰‡æ˜¾ç¤ºå‡ºæ¥ã€‚

```python
from tqdm.auto import tqdm

scheduler.set_timesteps(num_inference_steps)

denoised_images = []
decoded_images = []
for i, t in enumerate(tqdm(scheduler.timesteps)):
    # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.
    latent_model_input = torch.cat([latents] * 2)

    latent_model_input = scheduler.scale_model_input(latent_model_input, timestep=t)

    # predict the noise residual
    with torch.no_grad():
        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample

    # perform guidance
    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)
    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)

    # compute the previous noisy sample x_t -> x_t-1
    latents = scheduler.step(noise_pred, t, latents).prev_sample
    if i % 5 == 0:
      denoised_image = display_denoised_sample(latents, i)
      decoded_image = display_decoded_image(latents, i)
      denoised_images.append(denoised_image)
      decoded_images.append(decoded_image)
```

è¾“å‡ºç»“æœï¼š

```plain
Denoised Sample @ Step 0
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/e8/77/e8fa98c88172482a84f3dbfeb0ecdf77.png?wh=64x64)

```plain
Decoded Image @ step 0
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/e2/b9/e2ef3c2972d3b73a3c93976ce19a6fb9.png?wh=512x512)

```plain
Denoised Sample @ Step 5
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/7e/c1/7e385e61f741f470c490c39d41b0c3c1.png?wh=64x64)

```plain
Decoded Image @ step 5
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/b8/dd/b81cb29b003412c80519c7b9f01baedd.png?wh=512x512)

```plain
Denoised Sample @ Step 10
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/fd/06/fd262baafbb52271b0d906d00a167c06.png?wh=64x64)

```plain
Decoded Image @ step 10
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/a6/22/a6be734e2813e80b8bd8b936c0741a22.png?wh=512x512)

```plain
Denoised Sample @ Step 15
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/04/8c/04e1da57c913da86b83a6e30ddc1338c.png?wh=64x64)

```plain
Decoded Image @ step 15
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/88/88/888d083873245d5b08780f52d8990788.png?wh=512x512)

```plain
Denoised Sample @ Step 20
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/8a/b3/8a8ee2751036cfe7yy6e2c0d70104bb3.png?wh=64x64)

```plain
Decoded Image @ step 20
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/8f/f7/8f094d4deacec42876201388c2ab24f7.png?wh=512x512)

```plain
Denoised Sample @ Step 25
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/6a/a3/6a4c08550f36f249ac495e4f966a90a3.png?wh=64x64)

```plain
Decoded Image @ step 25
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/e3/37/e3de66377a02e3db266ced384de8b337.png?wh=512x512)

è¿è¡Œå®Œç¨‹åºï¼Œä½ å°±å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„å›¾ç‰‡æ˜¯å¦‚ä½•ä¸€æ­¥æ­¥ä»å®Œå…¨çš„å™ªç‚¹è¿˜åŸæˆä¸€å¼ å›¾ç‰‡çš„äº†ã€‚è€Œä¸”ä½ ä»”ç»†è§‚å¯Ÿï¼Œè¿˜å¯ä»¥çœ‹åˆ°Generationç”Ÿæˆçš„å›¾åƒä¿¡æ¯ï¼Œç±»ä¼¼äºDecoderè¿˜åŸå‡ºæ¥çš„å›¾åƒä¿¡æ¯çš„è½®å»“ã€‚è¿™æ˜¯å› ä¸ºU-Netå…¶å®æ˜¯ä¸€ä¸ªå›¾ç‰‡è¯­ä¹‰åˆ†å‰²çš„æ¨¡å‹ã€‚

è€Œå¦‚æœæˆ‘ä»¬æ‰“å°ä¸€ä¸‹ç”Ÿæˆçš„å›¾ç‰‡çš„ç»´åº¦ï¼Œä½ ä¹Ÿå¯ä»¥çœ‹åˆ°ï¼ŒGenerationç”Ÿæˆçš„å›¾åƒä¿¡æ¯åˆ†è¾¨ç‡åªæœ‰64x64ï¼Œè€Œæˆ‘ä»¬è¿˜åŸå‡ºæ¥çš„å›¾ç‰‡åˆ†è¾¨ç‡æ˜¯512x512ã€‚

```plain
print(latents.shape)
latents = 1 / 0.18215 * latents
with torch.no_grad():
    image = vae.decode(latents).sample
    print(image.shape)
```

è¾“å‡ºç»“æœï¼š

```plain
torch.Size([1, 4, 64, 64])
torch.Size([1, 3, 512, 512])
```

### å›¾ç”Ÿå›¾

ç›¸ä¿¡ä½ å·²ç»ç†è§£äº†è¿™ä¸ªStable Diffusionç”Ÿæˆå›¾ç‰‡çš„è¿‡ç¨‹ï¼Œä»¥åŠè¿‡ç¨‹é‡Œæ¯ä¸ªæ¨¡å—çš„å·¥ä½œäº†ã€‚é‚£ä½ åº”è¯¥æ¯”è¾ƒå®¹æ˜“ç†è§£å¦‚ä½•é€šè¿‡Stable Diffusionå®ç°å›¾ç”Ÿå›¾äº†ï¼Œæˆ‘ä»¬ä¸‹é¢å°±æ¥å…·ä½“çœ‹ä¸€çœ‹ã€‚

å½“ç„¶ï¼Œè¿™ä¸€æ¬¡æˆ‘ä»¬å°±ä¸ç”¨è‡ªå·±ä¸€æ­¥æ­¥è°ƒç”¨å„ä¸ªæ¨¡å—æ¥å®ç°å›¾ç”Ÿå›¾äº†ã€‚æˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨Diffusersåº“é‡Œè‡ªå¸¦çš„Pipelineã€‚

```plain
import torch
from PIL import Image
from io import BytesIO

from diffusers import StableDiffusionImg2ImgPipeline

device = "cuda"
model_id_or_path = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)
pipe = pipe.to(device)

image_file = "./data/sketch-mountains-input.jpg"

init_image = Image.open(image_file).convert("RGB")
init_image = init_image.resize((768, 512))

prompt = "A fantasy landscape, trending on artstation"

images = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images

display(init_image)
display(images[0])
```

è¾“å‡ºç»“æœï¼š  
![å›¾ç‰‡](https://static001.geekbang.org/resource/image/d2/2c/d262d17cb96yyd721eeca30c70e40c2c.png?wh=768x512)

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/71/e4/712c084e85b258ceeb2ca64c8d043fe4.png?wh=768x512)

å¯¹åº”çš„ä»£ç ä¹Ÿéå¸¸ç®€å•ï¼Œæˆ‘ä»¬æŠŠPipelineæ¢æˆäº†StableDiffusionImg2ImgPipelineï¼Œæ­¤å¤–é™¤äº†è¾“å…¥ä¸€æ®µæ–‡æœ¬ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸€å¼ è‰ç¨¿å›¾ã€‚ç„¶åï¼Œä½ å¯ä»¥çœ‹åˆ°å¯¹åº”ç”Ÿæˆçš„å›¾ç‰‡çš„è½®å»“ï¼Œå°±ç±»ä¼¼äºæˆ‘ä»¬æä¾›çš„è‰ç¨¿å›¾ã€‚è€Œå›¾ç‰‡çš„å†…å®¹é£æ ¼ï¼Œåˆ™æ˜¯æŒ‰ç…§æˆ‘ä»¬æ–‡æœ¬æç¤ºè¯­çš„å†…å®¹ç”Ÿæˆçš„ã€‚

StableDiffusionImg2ImgPipelineçš„ç”Ÿæˆè¿‡ç¨‹ï¼Œå…¶å®å’Œæˆ‘ä»¬ä¹‹å‰æ‹†è§£çš„ä¸€æ­¥æ­¥ç”Ÿæˆå›¾ç‰‡çš„è¿‡ç¨‹æ˜¯ç›¸åŒçš„ã€‚**å”¯ä¸€çš„ä¸€ä¸ªåŒºåˆ«æ˜¯ï¼Œæˆ‘ä»¬å…¶å®ä¸æ˜¯ä»ä¸€ä¸ªå®Œå…¨éšæœºçš„å™ªå£°å¼€å§‹çš„ï¼Œè€Œæ˜¯æŠŠå¯¹åº”çš„è‰ç¨¿å›¾ï¼Œé€šè¿‡VAEçš„ç¼–ç å™¨ï¼Œå˜æˆå›¾åƒç”Ÿæˆä¿¡æ¯ï¼Œåˆåœ¨ä¸Šé¢åŠ äº†éšæœºçš„å™ªå£°ã€‚**æ‰€ä»¥ï¼Œå»é™¤å™ªéŸ³çš„è¿‡ç¨‹ä¸­ï¼Œå¯¹åº”çš„è‰ç¨¿å›¾çš„è½®å»“å°±ä¼šé€æ­¥å‡ºç°äº†ã€‚è€Œåœ¨ä¸€æ­¥æ­¥ç”Ÿæˆå›¾ç‰‡çš„è¿‡ç¨‹ä¸­ï¼Œå†…å®¹åˆä¼šå‘æˆ‘ä»¬ç»™å‡ºçš„æç¤ºè¯­çš„å†…å®¹æ¥å­¦ä¹ ã€‚

è€Œå¦‚æœæˆ‘ä»¬æ¢ä¸€ä¸‹æç¤ºè¯­ï¼Œå°±èƒ½æ›´æ”¹ç”Ÿæˆçš„å…·ä½“å†…å®¹ã€‚æ¯”å¦‚æˆ‘ä»¬æƒ³æ¢æˆå®«å´éªçš„é£æ ¼ï¼Œå¹¶ä¸”å¸Œæœ›åé¢é«˜è€¸çš„ä¸æ˜¯å±±ï¼Œè€Œæ˜¯åŸå ¡ï¼Œå‡ºç°çš„å›¾ç‰‡è¿˜æ˜¯ç›¸åŒçš„è½®å»“ï¼Œä½†æ˜¯ç”¨ä¸åŒçš„å†…å®¹ã€‚æˆ‘åœ¨ä¸‹é¢ç»™å‡ºäº†ä¸€ä¸ªä»£ç ç¤ºä¾‹ï¼Œä½ å¯ä»¥è‡ªå·±çœ‹ä¸€çœ‹ã€‚

```plain
prompt = "ghibli style, a fantasy landscape with castles"
images = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images

display(init_image)
display(images[0])
```

è¾“å‡ºç»“æœï¼š  
![å›¾ç‰‡](https://static001.geekbang.org/resource/image/bb/ff/bb7a09c91feda214ee71a57d3ab479ff.png?wh=768x512)

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/b8/de/b8c0054e8abc08a5657f8a6f9c6afede.png?wh=768x512)

### æ›´å¤šä½¿ç”¨æ–¹æ³•

ç†è§£äº†Stable Diffusionçš„åŸºæœ¬æ¡†æ¶ï¼Œä½ å¯ä»¥è¯•ä¸€è¯•æ›´å¤šç›¸å…³çš„Pipelineçš„ç”¨æ³•ã€‚æ¯”å¦‚ï¼Œé™¤äº†å¼•å¯¼å†…å®¹ç”Ÿæˆçš„æç¤ºè¯­ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è®¾ç½®ä¸€ä¸ªè´Ÿé¢çš„æç¤ºè¯­ï¼ˆnegative promptï¼‰ï¼Œä¹Ÿå°±æ˜¯æ’é™¤ä¸€äº›å†…å®¹ã€‚

```plain
prompt = "ghibli style, a fantasy landscape with castles"
negative_prompt = "river"
images = pipe(prompt=prompt, negative_prompt=negative_prompt, image=init_image, strength=0.75, guidance_scale=7.5).images

display(images[0])
```

è¾“å‡ºç»“æœï¼š  
![å›¾ç‰‡](https://static001.geekbang.org/resource/image/2b/1c/2b9ce1b91e306d256fc29dc13d68d51c.png?wh=768x512)

å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨å›¾ç‰‡é‡Œé¢å°½é‡æ’é™¤â€œRiverâ€ã€‚è€Œæ–°ç”Ÿæˆçš„å›¾ç‰‡ï¼Œå³è¾¹å°±æ²¡æœ‰äº†ä»»ä½•ç±»ä¼¼äºæ²³æµçš„å†…å®¹ï¼Œè€Œä¸­é—´è“è‰²çš„éƒ¨åˆ†ä¹Ÿæ›´åƒä¸€ä¸ªæ’æ°´æ¸ è€Œä¸æ˜¯è‡ªç„¶çš„æ²³æµã€‚è´Ÿé¢æç¤ºè¯­å¹¶ä¸ä¼šæ”¹å˜æ¨¡å‹çš„ç»“æ„ã€‚å®ƒå…¶å®å°±æ˜¯æŠŠåŸå…ˆçš„â€œæ— æ¡ä»¶â€å‘é‡ï¼Œæ›¿æ¢æˆäº†è´Ÿé¢æç¤ºè¯­çš„å‘é‡ã€‚è¿™æ ·ï¼Œæ¨¡å‹å°±å°½å¯èƒ½ä»è´Ÿé¢çš„æç¤ºè¯­æ–‡æœ¬å†…å®¹ä¸­å‘æˆ‘ä»¬æ­£é¢çš„æç¤ºè¯­æ–‡æœ¬å†…å®¹å­¦ä¹ ï¼Œä¹Ÿå°±æ˜¯å°½é‡è¿œç¦»è´Ÿé¢æç¤ºè¯­çš„å†…å®¹ã€‚

åŒæ ·ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡Stable Diffusionæ¥æå‡å›¾ç‰‡çš„åˆ†è¾¨ç‡ï¼Œåªä¸è¿‡éœ€è¦ä¸€ä¸ªå•ç‹¬çš„æ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹å°±æ˜¯ä¸“é—¨åœ¨ä¸€ä¸ªé«˜ä½åˆ†è¾¨ç‡çš„å›¾ç‰‡ç»„åˆä¸Šè®­ç»ƒå‡ºæ¥çš„ã€‚å¯¹åº”çš„UNetå’ŒVAEçš„æ¨¡å‹æ˜¯å’ŒåŸå§‹çš„Stable Diffusionä¸ä¸€æ ·çš„ã€‚

```plain
from diffusers import StableDiffusionUpscalePipeline

# load model and scheduler
model_id = "stabilityai/stable-diffusion-x4-upscaler"
pipeline = StableDiffusionUpscalePipeline.from_pretrained(
    model_id, revision="fp16", torch_dtype=torch.float16
)
pipeline = pipeline.to("cuda")

# let's download an  image
low_res_img_file = "./data/low_res_cat.png"
low_res_img = Image.open(low_res_img_file).convert("RGB")
low_res_img = low_res_img.resize((128, 128))

prompt = "a white cat"

upscaled_image = pipeline(prompt=prompt, image=low_res_img).images[0]

low_res_img_resized = low_res_img.resize((512, 512))

display(low_res_img_resized)
display(upscaled_image)
```

è¾“å‡ºç»“æœï¼š  
![å›¾ç‰‡](https://static001.geekbang.org/resource/image/f4/c4/f47e50c28203eb7a0d8f7667f69023c4.png?wh=512x512)

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/2b/b6/2be70a657f415b11489afa86639faeb6.png?wh=512x512)

å¦‚æœæˆ‘ä»¬æ‰“å°ä¸€ä¸‹pipelineï¼Œå¯¹åº”çš„æ¨¡å‹çš„ç»„ä»¶è¿˜æ˜¯ç›¸åŒçš„ã€‚

```plain
pipeline
```

è¾“å‡ºç»“æœï¼š

```plain
StableDiffusionUpscalePipeline {
  "_class_name": "StableDiffusionUpscalePipeline",
  "_diffusers_version": "0.15.1",
  "low_res_scheduler": [
    "diffusers",
    "DDPMScheduler"
  ],
  "max_noise_level": 350,
  "scheduler": [
    "diffusers",
    "DDIMScheduler"
  ],
  "text_encoder": [
    "transformers",
    "CLIPTextModel"
  ],
  "tokenizer": [
    "transformers",
    "CLIPTokenizer"
  ],
  "unet": [
    "diffusers",
    "UNet2DConditionModel"
  ],
  "vae": [
    "diffusers",
    "AutoencoderKL"
  ]
}
```

ä½†æ˜¯å¦‚æœä½ å»çœ‹å¯¹åº”æ¨¡å‹çš„é…ç½®æ–‡ä»¶ï¼Œå¯ä»¥çœ‹åˆ° [VAE](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler/blob/main/vae/config.json) å’Œ [UNet](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler/blob/main/unet/config.json) é‡Œä½¿ç”¨çš„æ¨¡å‹éƒ½æ˜¯ä¸ä¸€æ ·çš„ã€‚

## ä½¿ç”¨ç¤¾åŒºé‡Œçš„å…¶ä»–æ¨¡å‹

åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°Stable Diffusionå¹¶ä¸æ˜¯æŒ‡æŸä¸€ä¸ªç‰¹å®šçš„æ¨¡å‹ï¼Œè€Œæ˜¯æŒ‡ä¸€ç±»æ¨¡å‹ç»“æ„ã€‚å› ä¸ºStable Diffusionæ˜¯å®Œå…¨å¼€æºçš„ï¼Œæ‰€ä»¥ä½ å¤§å¯ä»¥åˆ©ç”¨è‡ªå·±çš„æ•°æ®å»è®­ç»ƒä¸€ä¸ªå±äºè‡ªå·±çš„æ¨¡å‹ã€‚äº‹å®ä¸Šï¼Œå¸‚é¢ä¸Šå¼€æºè®­ç»ƒå‡ºæ¥çš„Stable Diffusionçš„æ¨¡å‹éå¸¸å¤šï¼Œä¹Ÿå·²ç»æœ‰äº†åƒ [CIVITAI](https://civitai.com/) è¿™æ ·çš„åˆ†äº«Stable Diffusionæ¨¡å‹çš„å¹³å°ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/a1/4d/a119771cc79yyf74d283a195c663c04d.png?wh=1240x1213 "CIVITAI é‡Œæœ‰ç”¨æˆ·ä»¬è‡ªå·±è®­ç»ƒçš„å„ç§é£æ ¼çš„æ¨¡å‹")

æˆ‘ä»¬å¯ä»¥å»CIVITAIçš„ç½‘ç«™ï¼Œæ‰¾åˆ°æˆ‘ä»¬å–œæ¬¢çš„æ¨¡å‹ã€‚æ¯”å¦‚æˆ‘ä»¬ä¸“é—¨æ‰¾ä¸€ä¸ªäºŒæ¬¡å…ƒçš„æ¨¡å‹ [counterfeit-V2.5](https://civitai.com/models/4468/counterfeit-v25)ã€‚åœ¨å¯¹åº”çš„æ¨¡å‹é¡µé¢ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒç›´æ¥å°±åŒ…å«äº†Huggingfaceé‡Œé¢çš„æ¨¡å‹ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/2c/15/2cd2d729e7ac70e0f829c319d85a1715.png?wh=1240x730)

æ‰€ä»¥æˆ‘ä»¬å°±å¯ä»¥ç›´æ¥é€šè¿‡Diffuersåº“æ¥è°ƒç”¨è¿™ä¸ªæ¨¡å‹ã€‚

```plain
pipeline.to("cuda")

prompt = "((masterpiece,best quality)),1girl, solo, animal ears, rabbit, barefoot, knees up, dress, sitting, rabbit ears, short sleeves, looking at viewer, grass, short hair, smile, white hair, puffy sleeves, outdoors, puffy short sleeves, bangs, on ground, full body, animal, white dress, sunlight, brown eyes, dappled sunlight, day, depth of field"
negative_prompt = "EasyNegative, extra fingers,fewer fingers,"
image = pipeline(prompt=prompt, negative_prompt=negative_prompt).images[0]
image
```

è¾“å‡ºç»“æœï¼š

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/03/50/03041115b93c8d53ed71fd2ff7fcf750.png?wh=512x512)

å½“ç„¶ï¼Œä¸æ˜¯æ‰€æœ‰CIVITAIé‡Œçš„æ¨¡å‹éƒ½åœ¨Huggingfaceä¸Šæä¾›äº†è‡ªå·±çš„æ¨¡å‹ç‰ˆæœ¬ã€‚é»˜è®¤CIVITAIçš„æ¨¡å‹ï¼Œå¾€å¾€åªæ˜¯æä¾›äº†ä¸€ä¸ªæ¨¡å‹æƒé‡æ–‡ä»¶ã€‚ä½ å¯ä»¥ä½¿ç”¨ç°åœ¨æœ€æµè¡Œçš„ [Stable-Diffusion-Web-UI åº”ç”¨](https://github.com/AUTOMATIC1111/stable-diffusion-webui)æ¥ä½¿ç”¨è¿™ä¸ªæ¨¡å‹æƒé‡æ–‡ä»¶ã€‚ä½ å¯ä»¥æŠŠWeb-UIåœ¨æœ¬åœ°éƒ¨ç½²èµ·æ¥ï¼Œå®ƒä¼šæä¾›ä¸€ä¸ªå›¾å½¢ç•Œé¢è®©ä½ ä¸ç”¨å†™ä»£ç å°±å¯ä»¥ç›´æ¥è°ƒæ•´å„ç§å‚æ•°æ¥ç”Ÿæˆå›¾ç‰‡ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/61/1d/616244d69ed59bb3e8935ec7fbfba91d.png?wh=1236x966 "æ¥è‡ª stable-diffusion-web-ui çš„å›¾å½¢ç•Œé¢")

[CIVITAI çš„ Wiki](https://github.com/civitai/civitai/wiki) é‡Œé¢ä¹Ÿè¯¦ç»†æä¾›äº†åœ¨Stable-Diffusion-Web-UIé‡Œé¢ä½¿ç”¨æ¨¡å‹çš„æ­¥éª¤ï¼Œä½ å¯ä»¥ç…§ç€è¿™ä¸ªæ­¥éª¤å¤šæ‹¿å‡ ä¸ªæ¨¡å‹è¯•è¯•çœ‹ã€‚

## å°ç»“

å¥½äº†ï¼Œè¿™å°±æ˜¯ä»Šå¤©çš„ä¸»è¦å†…å®¹ï¼Œæœ€åæˆ‘ä»¬ä¸€èµ·æ¥å›é¡¾ä¸€ä¸‹ã€‚

è¿™ä¸€è®²ï¼Œæˆ‘å¸¦ç€ä½ ä½“éªŒäº†ä¸€ä¸‹Stable Diffusionè¿™ä¸ªå›¾ç‰‡ç”Ÿæˆçš„å¼€æºæ¨¡å‹ã€‚æˆ‘ä»¬ä¸ä»…é€šè¿‡Diffusersè¿™ä¸ªå°è£…å¥½çš„Pythonåº“ï¼Œä½“éªŒäº†æ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ã€æå‡å›¾ç‰‡åˆ†è¾¨ç‡ç­‰ä¸€ç³»åˆ—åº”ç”¨ï¼Œä¹Ÿæ·±å…¥åˆ°Stable Diffusionçš„æ¨¡å‹å†…éƒ¨ï¼Œç†è§£äº†æ•´ä¸ªæ¨¡å‹çš„ç»“æ„ï¼Œè¿˜çœ‹åˆ°æˆ‘ä»¬æ˜¯å¦‚ä½•ä¸€æ­¥æ­¥ä»ä¸€å¼ å…¨æ˜¯å™ªç‚¹çš„å›¾ç‰‡ï¼Œé€æ¸å»é™¤å™ªå£°å˜æˆä¸€å¼ å¯ç”¨çš„å›¾ç‰‡çš„ã€‚

åœ¨ä½“éªŒäº†åŸºç¡€çš„æ¨¡å‹ä¹‹åï¼Œæˆ‘ä»¬ä¹Ÿä¸€èµ·å°è¯•äº†ä¸€ä¸‹å…¶ä»–çˆ±å¥½è€…è‡ªå·±ç”Ÿæˆçš„æ¨¡å‹ã€‚è¿™ä¹Ÿæ˜¯ä¸‹ä¸€è®²æˆ‘ä»¬è¦ä»‹ç»çš„é‡ç‚¹å†…å®¹ã€‚æˆ‘ä»¬ä¼šäº†è§£åˆ°å¦‚ä½•é€šè¿‡ LoRa è¿™æ ·çš„ç®—æ³•è¿›è¡Œæ¨¡å‹å¾®è°ƒï¼Œä»¥åŠå¦‚ä½•é€šè¿‡ControlNetè®©æˆ‘ä»¬ç”Ÿæˆçš„å›¾ç‰‡æ›´åŠ å¯æ§ã€‚

## æ€è€ƒé¢˜

æœ€åï¼ŒæŒ‰ç…§æƒ¯ä¾‹è¿˜æ˜¯ç»™ä½ ç•™ä¸€é“æ€è€ƒé¢˜ã€‚é™¤äº†ä»Šå¤©ç»™ä½ æ¼”ç¤ºçš„è¿™äº›åº”ç”¨ä¹‹å¤–ï¼ŒHuggingFaceè¿˜æä¾›äº†å¾ˆå¤šå®æˆ˜åœºæ™¯ã€‚æ¯”å¦‚ï¼Œä½ å°±å¯ä»¥é€šè¿‡ [StableDiffusionInpaintPipeline](https://huggingface.co/docs/diffusers/using-diffusers/inpaint)ï¼Œç”¨ä¸€ä¸ªé®ç…§å›¾ç‰‡å’Œä¸€æ®µæç¤ºè¯­æ¥ä¿®æ”¹å›¾ç‰‡ç”»é¢ä¸­çš„æŸä¸€éƒ¨åˆ†å…ƒç´ ã€‚

ä½ å¯ä»¥ç…§ç€[å®˜æ–¹æ–‡æ¡£](https://huggingface.co/docs/diffusers/using-diffusers/inpaint)ï¼Œä½“éªŒä¸€ä¸‹è¿™ä¸ªåŠŸèƒ½ï¼Œç ”ç©¶ä¸€ä¸‹æºä»£ç ï¼Œæƒ³æƒ³è¿™ä¸ªåŠŸèƒ½æ˜¯å¦‚ä½•é€šè¿‡Stable Diffusionçš„æ¨¡å‹ç»“æ„å®ç°çš„ã€‚æ¬¢è¿ä½ æŠŠä½ ä½“éªŒä¹‹åçš„æ„Ÿå—ä»¥åŠæ€è€ƒåçš„ç»“æœåˆ†äº«åœ¨è¯„è®ºåŒºï¼Œä¹Ÿæ¬¢è¿ä½ æŠŠè¿™ä¸€è®²åˆ†äº«ç»™æ„Ÿå…´è¶£çš„æœ‹å‹ï¼Œæˆ‘ä»¬ä¸‹ä¸€è®²å†è§ï¼

## æ¨èé˜…è¯»

è¿™ä¸€è®²é‡Œï¼Œæˆ‘ä»¬åªæ˜¯ç®€å•ä»‹ç»äº†ä¸€ä¸‹Stable Diffusionçš„æ¨¡å‹ç»“æ„ã€‚å…¶å®ï¼Œæ— è®ºæ˜¯DALL-E 2è¿˜æ˜¯Imagenï¼Œé‡‡ç”¨çš„å›¾ç‰‡ç”Ÿæˆæ–¹å¼éƒ½æ˜¯å’ŒStable Diffusionç±»ä¼¼çš„ã€‚å¦‚æœä½ æƒ³è¦æ·±å…¥äº†è§£ä¸€ä¸‹è¿™äº›æ¨¡å‹çš„ç»“æ„ï¼Œå¯ä»¥å»çœ‹ä¸€ä¸‹Bç«™é‡Œé¢â€œè·Ÿææ²å­¦AIâ€é‡Œé¢å¯¹äº [DALL-E 2 è®ºæ–‡çš„è®²è§£](https://www.bilibili.com/video/BV17r4y1u77B/?spm_id_from=333.999.0.0)ã€‚
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ15ï¼‰</strong></div><ul>
<li><span>ä¸œæ–¹å¥‡éª¥</span> ğŸ‘ï¼ˆ9ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<p>è€å¸ˆï¼Œä¸ºä»€ä¹ˆè¦åŠ äº†å™ªå£°ï¼Œå†å»é™¤å™ªå£°ï¼Ÿ</p>2023-05-05</li><br/><li><span>peter</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ5ï¼‰<p>è¯·æ•™è€å¸ˆå‡ ä¸ªé—®é¢˜ï¼š
Q1ï¼šstable Diffusioné‡‡ç”¨çš„CLIPæ˜¯è‡ªèº«çš„å—ï¼Ÿè¿˜æ˜¯è°ƒç”¨chatGPTï¼Ÿ
Q2ï¼šå…ˆåŠ å™ªå£°ï¼Œå†å»æ‰ï¼Œæœ‰ä»€ä¹ˆæ„ä¹‰ï¼Ÿåƒä¸€å£å†åä¸€å£ï¼Œæœ‰æ„æ€å—ï¼Ÿ
â€œå…ˆå¾€å‰é¢çš„ç”¨ CLIP æ¨¡å‹æ¨ç†å‡ºæ¥çš„å‘é‡é‡Œæ·»åŠ å¾ˆå¤šå™ªå£°ï¼Œå†é€šè¿‡ UNet+Scheduler é€æ¸å»é™¤å™ªå£°ï¼Œæœ€åæ‹¿åˆ°äº†ä¸€ä¸ªæ–°çš„å¼ é‡â€ã€‚
Q3ï¼šæœ¬è¯¾çš„ä»£ç æ˜¯åœ¨æœ¬æœºä¸Šè¿è¡Œçš„å—ï¼Ÿæˆ‘çš„ç¬”è®°æœ¬ä¸Šæ˜¯æ™®é€šé…ç½®ï¼Œèƒ½è¿è¡Œå¹¶ç”Ÿæˆå›¾å—ï¼Ÿï¼ˆæˆ–è€…ï¼Œå›¾çš„ç”Ÿæˆæ˜¯è°ƒç”¨äº†æŸä¸ªæœåŠ¡å™¨ï¼Ÿï¼‰
Q4ï¼šå¯ä»¥å¯¹å›¾ç‰‡è¿›è¡ŒåŠ å·¥å—ï¼Ÿ æ¯”å¦‚åœ¨ä¸€ä¸ªç…§ç‰‡çš„å¤´ä¸ŠåŠ ä¸€ä¸ªå¸½å­ã€‚</p>2023-05-06</li><br/><li><span>ä¸€å¶</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>è€å¸ˆ å¦‚ä½• æ‰‹åŠ¨æŠŠæ¨¡å‹ä¸‹è½½,ç„¶åå†ä¸Šä¼ åˆ°æœåŠ¡å™¨ ? æˆ‘æœåŠ¡å™¨æœ¬åœ°liunxçš„,å‘ç°ä¸‹è½½å¾ˆæ…¢..... DiffusionPipeline.from_pretrained</p>2023-05-10</li><br/><li><span>åšç§¯è–„å‘</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB 
already allocated; 10.81 MiB free; 13.46 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated 
memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and 
PYTORCH_CUDA_ALLOC_CONF   è€å¸ˆï¼Œcolab gpuä¸å¤Ÿäº†ï¼Œé»˜è®¤çš„16gä¸å¤Ÿï¼Œæ˜¯ä¸æ˜¯éœ€è¦è´­ä¹°æ›´å¤§çš„gpu</p>2023-05-08</li><br/><li><span>Oliå¼ å¸†</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>è¯·æ•™ä¸€ä¸‹è€å¸ˆï¼Œç»“åˆæ‚¨ä¹‹å‰è®²çš„HuggingFaceï¼Œæˆ‘å¯ä»¥é€šè¿‡HuggingFaceï¼Œå…è´¹è°ƒç”¨Stable Diffusionçš„æ¥å£ï¼Œæ¥äº§ç”Ÿå¤§é‡çš„å›¾ç‰‡ã€‚é‚£è¿™æ•´ä¸ªæµç¨‹ä¸­éœ€è¦çš„å¤§é‡ç®—åŠ›ï¼Œæ˜¯è°æ¥ä¹°å•çš„å‘¢ï¼Ÿ</p>2023-05-06</li><br/><li><span>Toni</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ10ï¼‰<p>1. ä½¿ç”¨ GPU æ— ç–‘ä¼šåŠ å¿«å›¾åƒçš„ç”Ÿæˆï¼Œä½†å®åœ¨æ²¡æœ‰åŠæ³•ä½¿ç”¨ GPU æ—¶ï¼Œå°±ç”¨ CPUï¼Œåªè¦å°†ä¸‹é¢ä»£ç ä¸­çš„ &quot;cuda&quot; æ”¹æˆ &quot;cpu&quot; å³å¯ï¼Œæ…¢æ¯”æ²¡æœ‰å¼ºã€‚

pipeline.to(&quot;cuda&quot;) =&gt; pipeline.to(&quot;cpu&quot;) 
---------------------
from diffusers import DiffusionPipeline
pipeline = DiffusionPipeline.from_pretrained(&quot;runwayml&#47;stable-diffusion-v1-5&quot;)
pipeline.to(&quot;cpu&quot;)

image = pipeline(&quot;Sports car, road, rural areas, blue sky, white clouds, endless grassland in the background&quot;).images[0]
image

--------------
ç”Ÿæˆä¸Šé¢çš„å›¾åœ¨ cpu æ¡ä»¶ä¸‹çº¦10åˆ†é’Ÿã€‚

2. æè¿°å›¾åƒçš„ prompt å¦‚æœå¤ªé•¿ä¼šæŠ¥é”™ï¼Œ æ¯”å¦‚
Token indices sequence length is longer than the specified maximum sequence length for this model (161 &gt; 77). 

ç¨‹åºä¼šç»§ç»­è¿è¡Œï¼Œä½†è¾“å‡ºç»“æœæ˜¯é»‘æ¿ã€‚
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and&#47;or seed.

prompt ä¸­çš„ Token æ•°è¶…è¿‡é™å®šæ—¶ï¼Œè¦åœæ­¢è¿è¡Œï¼Œä»¥èŠ‚çœæ—¶é—´ã€‚</p>2023-05-05</li><br/><li><span>Jack</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>ç¬¬ä¸€æ¬¡è¿è¡Œâ€œa photograph of an astronaut riding a horseâ€ï¼Œåªæœ‰é©¬ï¼Œæ²¡æœ‰å®‡èˆªå‘˜ï¼Œå¤šè¿è¡Œå‡ æ¬¡å°±æœ‰äº†ï¼Œä¸è¿‡å›¾ç‰‡æ²¡æœ‰è€å¸ˆçš„å¥½çœ‹</p>2023-05-05</li><br/><li><span>Jacob.C</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<p>è€å¸ˆå¯ä»¥è®²ä¸€ä¸‹ï¼Œcolab ä¸Šï¼Œè·‘è¿™ä¸ªå¤ªç©ºäººéª‘é©¬è¦è¿è¡Œè€—æ—¶å¤šä¹…å—ï¼Ÿ</p>2023-05-05</li><br/><li><span>Geek_7ee455</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ4ï¼‰<p>è€å¸ˆ,åœ¨macä¸Šèƒ½è‡ªå·±éƒ¨ç½²ä¸€å¥—stable diffusionå—</p>2023-05-05</li><br/><li><span>è¹</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>ç›´æ¥æ–°å»ºä¸€ä¸ªcolab notebookåé»˜è®¤ä¸æ˜¯ç”¨çš„GPUï¼Œè¿è¡Œä»£ç å‡ºé”™äº†&quot;RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http:&#47;&#47;www.nvidia.com&#47;Download&#47;index.aspx&quot;

é‡åˆ°åŒæ ·é”™è¯¯çš„å°ä¼™ä¼´è®°å¾—åœ¨Runtimeèœå•é‡Œé€‰æ‹©Change runtime typeï¼Œé€‰æ‹©GPU, T4ã€‚æˆ‘é‡åˆ°äº†åœ¨è¿è¡Œä¹Ÿä¸æˆåŠŸçš„æƒ…å†µï¼Œè¿™æ—¶å¯ä»¥å†åœ¨Runtimeèœå•é‡Œé€‰æ‹©Restart runtimeæˆ–è€…Restart and run allã€‚è¿™æ ·ï¼Œæˆ‘é‡åˆ°çš„é”™è¯¯å°±è§£å†³äº†ã€‚</p>2023-06-02</li><br/><li><span>piboye</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>ææ²çš„è¯¾ç¨‹å¤ªå¥½äº†</p>2023-05-05</li><br/><li><span>Amark</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>ä¸ºå•¥æœ‰çš„å›¾ç‰‡è·Ÿæ–‡å­—ä¸ç¬¦ï¼Œæ–‡å­—æè¿°æœ‰å•¥è¦æ±‚å—</p>2024-02-01</li><br/><li><span>å°ç†æƒ³ã€‚</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>å¤§å®¶æ²¡é‡åˆ°huggingfaceå®Œå…¨è®¿é—®ä¸äº†çš„æƒ…å†µå—ï¼Ÿ</p>2023-11-17</li><br/><li><span>æ˜µç§°C</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>æ€è€ƒé¢˜æœ‰åšå‡ºæ¥çš„å—ï¼Ÿè€å¸ˆæœ‰ç­”æ¡ˆå—ï¼Ÿ
</p>2023-07-25</li><br/><li><span>å’ŒæŸæ¬¢</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>è€å¸ˆï¼Œcolabå¦‚ä½•å¼•å…¥Counterfeit-V3.0 è¿™ä¸ªæ¨¡å‹å‘¢ï¼Ÿç¤ºä¾‹ä»£ç æ²¡çœ‹æ‡‚ï¼Œè¿è¡Œçš„æ—¶å€™æŠ¥ NameError: name &#39;pipeline&#39; is not defined.</p>2023-06-18</li><br/>
</ul>