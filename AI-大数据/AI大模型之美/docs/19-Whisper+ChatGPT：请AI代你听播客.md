ä½ å¥½ï¼Œæˆ‘æ˜¯å¾æ–‡æµ©ã€‚

ä»Šå¤©ï¼Œæˆ‘ä»¬çš„è¯¾ç¨‹å¼€å§‹è¿›å…¥ä¸€ä¸ªæ–°çš„ä¸»é¢˜äº†ï¼Œé‚£å°±æ˜¯è¯­éŸ³è¯†åˆ«ã€‚è¿‡å»å‡ å‘¨æˆ‘ä»¬ä»‹ç»çš„ChatGPTè™½ç„¶å¾ˆå¼ºå¤§ï¼Œä½†æ˜¯åªèƒ½æ¥å—æ–‡æœ¬çš„è¾“å…¥ã€‚è€Œåœ¨ç°å®ç”Ÿæ´»ä¸­ï¼Œå¾ˆå¤šæ—¶å€™æˆ‘ä»¬å¹¶ä¸æ–¹ä¾¿åœä¸‹æ¥æ‰“å­—ã€‚å¾ˆå¤šå†…å®¹æ¯”å¦‚åƒæ’­å®¢ä¹Ÿæ²¡æœ‰æ–‡å­—ç‰ˆï¼Œæ‰€ä»¥è¿™ä¸ªæ—¶å€™ï¼Œæˆ‘ä»¬å°±éœ€è¦ä¸€ä¸ªèƒ½å¤Ÿå°†è¯­éŸ³å†…å®¹è½¬æ¢æˆæ–‡æœ¬çš„èƒ½åŠ›ã€‚

ä½œä¸ºç›®å‰AIç•Œçš„é¢†å¯¼è€…ï¼ŒOpenAIè‡ªç„¶ä¹Ÿä¸ä¼šæ”¾è¿‡è¿™ä¸ªéœ€æ±‚ã€‚ä»–ä»¬ä¸ä»…å‘è¡¨äº†ä¸€ä¸ªé€šç”¨çš„è¯­éŸ³è¯†åˆ«æ¨¡å‹ Whisperï¼Œè¿˜æŠŠå¯¹åº”çš„ä»£ç å¼€æºäº†ã€‚åœ¨ä»Šå¹´çš„1æœˆä»½ï¼Œä»–ä»¬ä¹Ÿåœ¨APIé‡Œæä¾›äº†å¯¹åº”çš„è¯­éŸ³è¯†åˆ«æœåŠ¡ã€‚é‚£ä¹ˆä»Šå¤©ï¼Œæˆ‘ä»¬å°±ä¸€èµ·æ¥çœ‹çœ‹Whisperè¿™ä¸ªè¯­éŸ³è¯†åˆ«çš„æ¨¡å‹å¯ä»¥æ€ä¹ˆç”¨ã€‚

## Whisper API 101

æˆ‘è‡ªå·±ç»å¸¸ä¼šåœ¨å·®æ—…çš„è¿‡ç¨‹ä¸­å¬æ’­å®¢ã€‚ä¸è¿‡ï¼Œç­›é€‰å¬ä»€ä¹ˆæ’­å®¢çš„æ—¶å€™ï¼Œæœ‰ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯å…‰çœ‹æ ‡é¢˜å’Œç®€ä»‹å…¶å®ä¸æ˜¯ç‰¹åˆ«å¥½åˆ¤æ–­é‡Œé¢çš„å†…å®¹æˆ‘æ˜¯ä¸æ˜¯çœŸçš„æ„Ÿå…´è¶£ã€‚æ‰€ä»¥ï¼Œåœ¨çœ‹åˆ°Whisperå’ŒChatGPTè¿™ä¸¤ä¸ªäº§å“ä¹‹åï¼Œæˆ‘è‡ªç„¶å°±æƒ³åˆ°äº†å¯ä»¥é€šè¿‡ç»„åˆè¿™ä¸¤ä¸ªAPIï¼Œè®©AIæ¥ä»£æˆ‘å¬æ’­å®¢ã€‚**æˆ‘æƒ³é€šè¿‡WhisperæŠŠæƒ³è¦å¬çš„æ’­å®¢è½¬å½•æˆæ–‡å­—ç¨¿ï¼Œå†é€šè¿‡ChatGPTåšä¸ªå°ç»“ï¼Œçœ‹çœ‹AIæ€»ç»“çš„å°ç»“å†…å®¹æ˜¯ä¸æ˜¯æˆ‘æƒ³è¦å¬çš„ã€‚**

æˆ‘å‰ä¸€é˜µåˆšå¬è¿‡ä¸€ä¸ª[å…³äº ChatGPT çš„æ’­å®¢](https://www.listennotes.com/podcasts/onboard/ep-26-10pmK95wovN/)ï¼Œæˆ‘ä»¬ä¸å¦¨å°±ä»è¿™ä¸ªå¼€å§‹ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ [listennotes](https://www.listennotes.com/) è¿™ä¸ªç½‘ç«™æ¥æœç´¢æ’­å®¢ï¼Œè¿˜èƒ½å¤Ÿä¸‹è½½åˆ°æ’­å®¢çš„æºæ–‡ä»¶ã€‚è€Œä¸”ï¼Œè¿™ä¸ªç½‘ç«™è¿˜æœ‰ä¸€ä¸ªå¾ˆæœ‰ç”¨çš„åŠŸèƒ½ï¼Œå°±æ˜¯å¯ä»¥ç›´æ¥åˆ‡å‡ºæ’­å®¢ä¸­çš„ä¸€æ®µå†…å®¹ï¼Œåˆ›å»ºå‡ºä¸€ä¸ªåˆ‡ç‰‡ï¼ˆclipï¼‰ã€‚

æˆ‘ä»¬å…ˆæ‹¿ä¸€ä¸ªå°çš„åˆ‡ç‰‡æ¥è¯•è¯•Whisperçš„APIï¼Œå¯¹åº”çš„åˆ‡ç‰‡çš„[é“¾æ¥](https://www.listennotes.com/podcast-clips/ep-26-chatgpt%E4%B8%8E%E7%94%9F%E6%88%90%E5%BC%8Fai%E7%9A%84%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E4%B8%8E%E5%95%86%E4%B8%9A%E6%9C%AA%E6%9D%A5%E5%AF%B9%E8%AF%9Dgoogle-P9dfstDKIV6/)æˆ‘ä¹Ÿæ”¾åœ¨è¿™é‡Œäº†ã€‚è¯¾ç¨‹Githubçš„dataç›®å½•é‡Œä¹Ÿæœ‰å·²ç»ä¸‹è½½å¥½çš„MP3æ–‡ä»¶ã€‚

OpenAIæä¾›çš„Whisperçš„APIéå¸¸ç®€å•ï¼Œä½ åªè¦è°ƒç”¨ä¸€ä¸‹transcribeå‡½æ•°ï¼Œå°±èƒ½å°†éŸ³é¢‘æ–‡ä»¶è½¬å½•æˆæ–‡å­—ã€‚

```python
import openai, os

openai.api_key = os.getenv("OPENAI_API_KEY")

audio_file= open("./data/podcast_clip.mp3", "rb")
transcript = openai.Audio.transcribe("whisper-1", audio_file)
print(transcript['text'])
```

è¾“å‡ºç»“æœï¼š

```python
æ¬¢è¿æ¥åˆ° Onboard çœŸå®çš„ä¸€çº¿ç»éªŒ èµ°æ–°çš„æŠ•èµ„æ€è€ƒ æˆ‘æ˜¯ Monica æˆ‘æ˜¯é«˜å® æˆ‘ä»¬ä¸€èµ·èŠèŠè½¯ä»¶å¦‚ä½•æ”¹å˜ä¸–ç•Œ å¤§å®¶å¥½ æ¬¢è¿æ¥åˆ° Onboard æˆ‘æ˜¯ Monica è‡ªä»OpenAIå‘å¸ƒçš„ChatGBT æ€èµ·äº†å¸­å·ä¸–ç•Œçš„AIçƒ­æ½® ä¸åˆ°ä¸‰ä¸ªæœˆå°±ç§¯ç´¯äº† è¶…è¿‡ä¸€äº¿çš„è¶Šè´§ç”¨æˆ· è¶…è¿‡1300ä¸‡çš„æ—¥è´§ç”¨æˆ· çœŸçš„æ˜¯å±•ç°äº†AIè®©äººæƒŠè®¶çš„ ä¹Ÿè®©å¾ˆå¤šäººç›´å‘¼ è¿™å°±æ˜¯ä¸‹ä¸€ä¸ªäº’è”ç½‘çš„æœªæ¥ æœ‰ä¸å°‘è§‚ä¼—éƒ½è¯´ å¸Œæœ›æˆ‘ä»¬å†åšä¸€æœŸAIçš„è®¨è®º äºæ˜¯è¿™æ¬¡ç¡¬æ ¸è®¨è®ºå°±æ¥äº† è¿™æ¬¡æˆ‘ä»¬è¯·æ¥äº† Google Brainçš„ç ”ç©¶å‘˜é›ªèŠ å¥¹æ˜¯Googleå¤§è¯­è¨€æ¨¡å‹PALM Pathway Language Modelçš„ä½œè€…ä¹‹ä¸€ è¦çŸ¥é“è¿™ä¸ªæ¨¡å‹çš„å‚æ•°é‡ æ˜¯GPT-3çš„ä¸‰å€è¿˜å¤š å¦å¤–è¿˜æœ‰ä¸¤ä½AIäº§å“å¤§ç‰› ä¸€ä½æ¥è‡ªè‘—åçš„StableDM èƒŒåçš„å•†ä¸šå…¬å¸Stability AI å¦ä¸€ä½æ¥è‡ªæŸç¡…è°·ç§‘æŠ€å¤§å‚ ä¹Ÿæ›¾åœ¨å´æ©è¾¾æ•™æˆçš„Landing AIä¸­ æ‹…ä»»äº§å“è´Ÿè´£äºº æ­¤å¤– è«å¦®å‡¯è¿˜é‚€è¯·åˆ°ä¸€ä½ ä¸€ç›´å…³æ³¨AIçš„æŠ•èµ„äººæœ‹å‹Bill å½“åšæˆ‘çš„ç‰¹é‚€å…±åŒä¸»æŒå˜‰å®¾ æˆ‘ä»¬ä¸»è¦è®¨è®ºå‡ ä¸ªè¯é¢˜ ä¸€æ–¹é¢ä»ç ”ç©¶çš„è§†è§’ æœ€å‰æ²¿çš„ç ”ç©¶è€…åœ¨å…³æ³¨ä»€ä¹ˆ ç°åœ¨æŠ€æœ¯çš„å¤©èŠ±æ¿ å’Œæœªæ¥å¤§çš„å˜é‡å¯èƒ½ä¼šåœ¨å“ªé‡Œ ç¬¬äºŒä¸ªé—®é¢˜æ˜¯ æœªæ¥å¤§çš„å˜é‡å¯èƒ½ä¼šåœ¨å“ªé‡Œ ä»äº§å“å’Œå•†ä¸šçš„è§’åº¦ ä»€ä¹ˆæ˜¯ä¸€ä¸ªå¥½çš„AIäº§å“ æ•´ä¸ªç”Ÿæ€å¯èƒ½éšç€æŠ€æœ¯ æœ‰æ€æ ·çš„æ¼”å˜ æ›´é‡è¦çš„ æˆ‘ä»¬åˆèƒ½ä»ä¸Šä¸€æ³¢ AIçš„åˆ›ä¸šçƒ­æ½®ä¸­å­¦åˆ°ä»€ä¹ˆ æœ€å è«å¦®å‡¯å’ŒBillè¿˜ä¼šä»æŠ•èµ„äººçš„è§†è§’ åšä¸€ä¸ªå›é¡¾ æ€»ç»“å’Œç•…æƒ³ è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªå°çš„update åœ¨æœ¬é›†å‘å¸ƒçš„æ—¶å€™ Googleä¹Ÿå¯¹çˆ†å‘å¼å¢é•¿çš„ Chad GPTåšå‡ºäº†å›åº” æ­£åœ¨æµ‹è¯•ä¸€ä¸ªåŸºäºLambda æ¨¡å‹çš„èŠå¤©æœºå™¨äºº ApprenticeBot æ­£å¼å‘å¸ƒåä¼šæœ‰æ€æ ·çš„æƒŠå–œ æˆ‘ä»¬éƒ½æ‹­ç›®ä»¥å¾… AIæ— ç–‘æ˜¯æœªæ¥å‡ å¹´ æœ€ä»¤äººå…´å¥‹çš„å˜é‡ä¹‹ä¸€ è«å¦®å‡¯ä¹Ÿå¸Œæœ›æœªæ¥èƒ½é‚€è¯·åˆ°æ›´å¤š ä¸€çº¿ä»ä¸šè€… ä»ä¸åŒè§’åº¦è®¨è®ºè¿™ä¸ªè¯é¢˜ ä¸è®ºæ˜¯æƒ³è¦åšåˆ›ä¸š ç ”ç©¶ äº§å“ è¿˜æ˜¯æŠ•èµ„çš„åŒå­¦ å¸Œæœ›è¿™äº›å¯¹è¯ å¯¹äºå¤§å®¶äº†è§£è¿™äº›æŠ€æœ¯æ¼”è¿› å•†ä¸šçš„å¯èƒ½ ç”šè‡³æœªæ¥å¯¹äºæˆ‘ä»¬æ¯ä¸ªäºº æ¯ä¸ªç¤¾ä¼šæ„å‘³ç€ä»€ä¹ˆ éƒ½èƒ½å¼•å‘ä¸€äº›æ€è€ƒ æä¾›ä¸€äº›å¯å‘ è¿™æ¬¡çš„è®¨è®ºæœ‰äº›æŠ€æœ¯ç¡¬æ ¸ éœ€è¦å„ä½å¯¹ç”Ÿæˆå¼AI å¤§æ¨¡å‹éƒ½æœ‰ä¸€äº›åŸºç¡€äº†è§£ è®¨è®ºä¸­æ¶‰åŠåˆ°çš„è®ºæ–‡å’Œé‡è¦æ¦‚å¿µ ä¹Ÿä¼šæ€»ç»“åœ¨æœ¬é›†çš„ç®€ä»‹ä¸­ ä¾›å¤§å®¶å¤ä¹ å‚è€ƒ å‡ ä½å˜‰å®¾åœ¨åŒ—ç¾å·¥ä½œç”Ÿæ´»å¤šå¹´ å¤¹æ‚è‹±æ–‡åœ¨æ‰€éš¾å… ä¹Ÿè¯·å¤§å®¶ä½“è°…äº† æ¬¢è¿æ¥åˆ°æœªæ¥ å¸Œæœ›å¤§å®¶enjoy
```

ä»è½¬å½•çš„ç»“æœæ¥çœ‹ï¼Œæœ‰ä¸€ä¸ªå¥½æ¶ˆæ¯å’Œä¸€ä¸ªåæ¶ˆæ¯ã€‚å¥½æ¶ˆæ¯æ˜¯ï¼Œè¯­éŸ³è¯†åˆ«çš„è½¬å½•æ•ˆæœéå¸¸å¥½ã€‚æˆ‘ä»¬çœ‹åˆ°å°½ç®¡æ’­å®¢é‡Œé¢æ··æ‚ç€ä¸­è‹±æ–‡ï¼Œä½†æ˜¯Whisperè¿˜æ˜¯å¾ˆå¥½åœ°è¯†åˆ«å‡ºæ¥äº†ã€‚åæ¶ˆæ¯æ˜¯ï¼Œè½¬å½•å‡ºæ¥çš„å†…å®¹åªæœ‰ç©ºæ ¼çš„åˆ†éš”ç¬¦ï¼Œæ²¡æœ‰æ ‡ç‚¹ç¬¦å·ã€‚

ä¸è¿‡ï¼Œè¿™ä¸ªé—®é¢˜ä¹Ÿå¹¶ä¸éš¾è§£å†³ã€‚æˆ‘ä»¬åªè¦åœ¨å‰é¢çš„ä»£ç é‡Œé¢ï¼Œå¢åŠ ä¸€ä¸ªPromptå‚æ•°å°±å¥½äº†ã€‚

```python
audio_file= open("./data/podcast_clip.mp3", "rb")
transcript = openai.Audio.transcribe("whisper-1", audio_file, 
                                     prompt="è¿™æ˜¯ä¸€æ®µä¸­æ–‡æ’­å®¢å†…å®¹ã€‚")
print(transcript['text'])
```

è¾“å‡ºç»“æœï¼š

```python
æ¬¢è¿æ¥åˆ° Onboard,çœŸå®çš„ä¸€çº¿ç»éªŒ,èµ°æ–°çš„æŠ•èµ„æ€è€ƒã€‚ æˆ‘æ˜¯ Monicaã€‚ æˆ‘æ˜¯é«˜å®ã€‚æˆ‘ä»¬ä¸€èµ·èŠèŠè½¯ä»¶å¦‚ä½•æ”¹å˜ä¸–ç•Œã€‚ å¤§å®¶å¥½,æ¬¢è¿æ¥åˆ° Onboard,æˆ‘æ˜¯ Monicaã€‚ è‡ªä» OpenAI å‘å¸ƒçš„ ChatGBT æ€èµ·äº†å¸­å·ä¸–ç•Œçš„ AI çƒ­æ½®, ä¸åˆ°ä¸‰ä¸ªæœˆå°±ç§¯ç´¯äº†è¶…è¿‡ä¸€äº¿çš„è¶Šæ´»ç”¨æˆ·,è¶…è¿‡ä¸€åƒä¸‰ç™¾ä¸‡çš„æ—¥æ´»ç”¨æˆ·ã€‚ çœŸçš„æ˜¯å±•ç°äº† AI è®©äººæƒŠå¹çš„èƒ½åŠ›, ä¹Ÿè®©å¾ˆå¤šäººç›´å‘¼è¿™å°±æ˜¯ä¸‹ä¸€ä¸ªäº’è”ç½‘çš„æœªæ¥ã€‚ æœ‰ä¸å°‘è§‚ä¼—éƒ½è¯´å¸Œæœ›æˆ‘ä»¬å†åšä¸€æœŸ AI çš„è®¨è®º, äºæ˜¯è¿™æ¬¡ç¡¬æ ¸è®¨è®ºå°±æ¥äº†ã€‚ è¿™æ¬¡æˆ‘ä»¬è¯·æ¥äº† Google Brain çš„ç ”ç©¶å‘˜é›ªèŠ, å¥¹æ˜¯ Google å¤§è¯­è¨€æ¨¡å‹ PAMP,Pathway Language Model çš„ä½œè€…ä¹‹ä¸€ã€‚ è¦çŸ¥é“,è¿™ä¸ªæ¨¡å‹çš„å‚æ•°é‡æ˜¯ GPT-3 çš„ä¸‰å€è¿˜å¤šã€‚ å¦å¤–è¿˜æœ‰ä¸¤ä½ AI äº§å“å¤§ç‰›,ä¸€ä½æ¥è‡ªè‘—åçš„ Stable Diffusion èƒŒåçš„å•†ä¸šå…¬å¸ Stability AI, å¦ä¸€ä½æ¥è‡ªæŸç¡…è°·ç§‘æŠ€å¤§å‚,ä¹Ÿæ›¾åœ¨å´æ©è¾¾æ•™æˆçš„ Landing AI ä¸­æ‹…ä»»äº§å“è´Ÿè´£äººã€‚ æ­¤å¤–,Monica è¿˜é‚€è¯·åˆ°ä¸€ä½ä¸€ç›´å…³æ³¨ AI çš„æŠ•èµ„äººæœ‹å‹ Bill å½“ä½œæˆ‘çš„ç‰¹é‚€å…±åŒä¸»æŒå˜‰å®¾ã€‚ æˆ‘ä»¬ä¸»è¦è®¨è®ºå‡ ä¸ªè¯é¢˜,ä¸€æ–¹é¢ä»ç ”ç©¶çš„è§†è§’,æœ€å‰æ²¿çš„ç ”ç©¶è€…åœ¨å…³æ³¨ä»€ä¹ˆ? ç°åœ¨æŠ€æœ¯çš„å¤©èŠ±æ¿å’Œæœªæ¥å¤§çš„å˜é‡å¯èƒ½ä¼šåœ¨å“ªé‡Œ? ä»äº§å“å’Œå•†ä¸šçš„è§’åº¦,ä»€ä¹ˆæ˜¯ä¸€ä¸ªå¥½çš„ AI äº§å“? æ•´ä¸ªç”Ÿæ€å¯èƒ½éšç€æŠ€æœ¯æœ‰æ€æ ·çš„æ¼”å˜? æ›´é‡è¦çš„,æˆ‘ä»¬åˆèƒ½ä»ä¸Šä¸€æ³¢ AI çš„åˆ›ä¸šçƒ­æ½®ä¸­å­¦åˆ°ä»€ä¹ˆ? æœ€å,Monica å’Œ Bill è¿˜ä¼šä»æŠ•èµ„äººçš„è§†è§’åšä¸€ä¸ªå›é¡¾ã€æ€»ç»“å’Œç•…æƒ³ã€‚ è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªå°çš„ update,åœ¨æœ¬é›†å‘å¸ƒçš„æ—¶å€™, Google ä¹Ÿå¯¹çˆ†å‘å¼å¢é•¿çš„ChatGPT åšå‡ºäº†å›åº”, æ­£åœ¨æµ‹è¯•ä¸€ä¸ªåŸºäº Lambda æ¨¡å‹çš„èŠå¤©æœºå™¨äºº ApprenticeBotã€‚ æ­£å¼å‘å¸ƒåä¼šæœ‰æ€æ ·çš„æƒŠå–œ?æˆ‘ä»¬éƒ½æ‹­ç›®ä»¥å¾…ã€‚ AI æ— ç–‘æ˜¯æœªæ¥å‡ å¹´æœ€ä»¤äººå…´å¥‹çš„å˜é‡ä¹‹ä¸€, Monica ä¹Ÿå¸Œæœ›æœªæ¥èƒ½é‚€è¯·åˆ°æ›´å¤šä¸€çº¿ä»ä¸šè€…ä»ä¸åŒè§’åº¦è®¨è®ºè¿™ä¸ªè¯é¢˜ã€‚ ä¸è®ºæ˜¯æƒ³è¦åšåˆ›ä¸šã€ç ”ç©¶ã€äº§å“è¿˜æ˜¯æŠ•èµ„çš„åŒå­¦, å¸Œæœ›è¿™äº›å¯¹è¯å¯¹äºå¤§å®¶äº†è§£è¿™äº›æŠ€æœ¯æ¼”è¿›ã€å•†ä¸šçš„å¯èƒ½, ç”šè‡³æœªæ¥å¯¹äºæˆ‘ä»¬æ¯ä¸ªäººã€æ¯ä¸ªç¤¾ä¼šæ„å‘³ç€ä»€ä¹ˆ, éƒ½èƒ½å¼•å‘ä¸€äº›æ€è€ƒ,æä¾›ä¸€äº›å¯å‘ã€‚ è¿™æ¬¡çš„è®¨è®ºæœ‰äº›æŠ€æœ¯ç¡¬æ ¸,éœ€è¦å„ä½å¯¹ç”Ÿæˆå¼ AI å¤§æ¨¡å‹éƒ½æœ‰ä¸€äº›åŸºç¡€äº†è§£ã€‚ è®¨è®ºä¸­æ¶‰åŠåˆ°çš„è®ºæ–‡å’Œé‡è¦æ¦‚å¿µ,ä¹Ÿä¼šæ€»ç»“åœ¨æœ¬é›†çš„ç®€ä»‹ä¸­,ä¾›å¤§å®¶å¤ä¹ å‚è€ƒã€‚ å‡ ä½å˜‰å®¾åœ¨åŒ—ç¾å·¥ä½œç”Ÿæ´»å¤šå¹´,å¤¹æ‚è‹±æ–‡åœ¨æ‰€éš¾å…,ä¹Ÿè¯·å¤§å®¶ä½“è°…äº†ã€‚ æ¬¢è¿æ¥åˆ°æœªæ¥,å¤§å®¶ enjoy!
```

æˆ‘ä»¬åœ¨transcribeå‡½æ•°è¢«è°ƒç”¨çš„æ—¶å€™ï¼Œä¼ å…¥äº†ä¸€ä¸ªPromptå‚æ•°ã€‚é‡Œé¢æ˜¯ä¸€å¥å¼•å¯¼Whisperæ¨¡å‹çš„æç¤ºè¯­ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬çš„Prompté‡Œç”¨äº†ä¸€å¥ä¸­æ–‡ä»‹ç»ï¼Œå¹¶ä¸”å¸¦ä¸Šäº†æ ‡ç‚¹ç¬¦å·ã€‚ä½ å°±ä¼šå‘ç°ï¼Œtranscribeå‡½æ•°è½¬å½•å‡ºæ¥çš„å†…å®¹ä¹Ÿå°±å¸¦ä¸Šäº†æ­£ç¡®çš„æ ‡ç‚¹ç¬¦å·ã€‚

ä¸è¿‡ï¼Œè½¬å½•å‡ºæ¥çš„å†…å®¹è¿˜æœ‰ä¸€ç‚¹å°å°çš„ç‘•ç–µã€‚é‚£å°±æ˜¯ä¸­è‹±æ–‡æ··æ’çš„å†…å®¹é‡Œé¢ï¼Œè‹±æ–‡å‰åä¼šå¤šå‡ºä¸€äº›ç©ºæ ¼ã€‚é‚£æˆ‘ä»¬å°±å†ä¿®æ”¹ä¸€ä¸‹Promptï¼Œåœ¨æç¤ºè¯­é‡Œé¢ä¹Ÿä½¿ç”¨ä¸­è‹±æ–‡æ··æ’å¹¶ä¸”ä¸ç•™ç©ºæ ¼ã€‚

```python
audio_file= open("./data/podcast_clip.mp3", "rb")
transcript = openai.Audio.transcribe("whisper-1", audio_file, 
                                     prompt="è¿™æ˜¯ä¸€æ®µOnboardæ’­å®¢çš„å†…å®¹ã€‚")
print(transcript['text'])
```

è¾“å‡ºç»“æœï¼š

```python
æ¬¢è¿æ¥åˆ°Onboard,çœŸå®çš„ä¸€çº¿ç»éªŒ,èµ°æ–°çš„æŠ•èµ„æ€è€ƒã€‚ æˆ‘æ˜¯Monica,æˆ‘æ˜¯é«˜å®,æˆ‘ä»¬ä¸€èµ·èŠèŠè½¯ä»¶å¦‚ä½•æ”¹å˜ä¸–ç•Œã€‚ å¤§å®¶å¥½,æ¬¢è¿æ¥åˆ°Onboard,æˆ‘æ˜¯Monicaã€‚ è‡ªä»OpenAIå‘å¸ƒçš„ChatGBTæ€èµ·äº†å¸­å·ä¸–ç•Œçš„AIçƒ­æ½®, ä¸åˆ°ä¸‰ä¸ªæœˆå°±ç§¯ç´¯äº†è¶…è¿‡ä¸€äº¿çš„è¶Šæ´»ç”¨æˆ·,è¶…è¿‡1300ä¸‡çš„æ—¥æ´»ç”¨æˆ·ã€‚ çœŸçš„æ˜¯å±•ç°äº†AIè®©äººæƒŠå¹çš„èƒ½åŠ›,ä¹Ÿè®©å¾ˆå¤šäººç›´å‘¼è¿™å°±æ˜¯ä¸‹ä¸€ä¸ªäº’è”ç½‘çš„æœªæ¥ã€‚ æœ‰ä¸å°‘è§‚ä¼—éƒ½è¯´å¸Œæœ›æˆ‘ä»¬å†åšä¸€æœŸAIçš„è®¨è®º,äºæ˜¯è¿™æ¬¡ç¡¬æ ¸è®¨è®ºå°±æ¥äº†ã€‚ è¿™æ¬¡æˆ‘ä»¬è¯·æ¥äº†Google Brainçš„ç ”ç©¶å‘˜é›ªèŠ, å¥¹æ˜¯Googleå¤§è¯­è¨€æ¨¡å‹POM,Pathway Language Modelçš„ä½œè€…ä¹‹ä¸€ã€‚ è¦çŸ¥é“è¿™ä¸ªæ¨¡å‹çš„å‚æ•°é‡æ˜¯GPT-3çš„ä¸‰å€è¿˜å¤šã€‚ å¦å¤–è¿˜æœ‰ä¸¤ä½AIäº§å“å¤§ç‰›,ä¸€ä½æ¥è‡ªè‘—åçš„Stable DiffusionèƒŒåçš„å•†ä¸šå…¬å¸Stability AI, å¦ä¸€ä½æ¥è‡ªæŸç¡…è°·ç§‘æŠ€å¤§å‚,ä¹Ÿæ›¾åœ¨å´æ©è¾¾æ•™æˆçš„Landing AIä¸­æ‹…ä»»äº§å“è´Ÿè´£äººã€‚ æ­¤å¤–,Monicaè¿˜é‚€è¯·åˆ°ä¸€ä½ä¸€ç›´å…³æ³¨AIçš„æŠ•èµ„äººæœ‹å‹Bill,å½“åšæˆ‘çš„ç‰¹é‚€å…±åŒä¸»æŒå˜‰å®¾ã€‚ æˆ‘ä»¬ä¸»è¦è®¨è®ºå‡ ä¸ªè¯é¢˜,ä¸€æ–¹é¢ä»ç ”ç©¶çš„è§†è§’,æœ€å‰æ²¿çš„ç ”ç©¶è€…åœ¨å…³æ³¨ä»€ä¹ˆ? ç°åœ¨çš„æŠ€æœ¯çš„å¤©èŠ±æ¿å’Œæœªæ¥å¤§çš„å˜é‡å¯èƒ½ä¼šåœ¨å“ªé‡Œ? ä»äº§å“å’Œå•†ä¸šçš„è§’åº¦,ä»€ä¹ˆæ˜¯ä¸€ä¸ªå¥½çš„AIäº§å“? æ•´ä¸ªç”Ÿæ€å¯èƒ½éšç€æŠ€æœ¯æœ‰æ€æ ·çš„æ¼”å˜? æ›´é‡è¦çš„,æˆ‘ä»¬åˆèƒ½ä»ä¸Šä¸€æ³¢AIçš„åˆ›ä¸šçƒ­æ½®ä¸­å­¦åˆ°ä»€ä¹ˆ? æœ€å,Monicaå’ŒBillè¿˜ä¼šä»æŠ•èµ„äººçš„è§†è§’åšä¸€ä¸ªå›é¡¾ã€æ€»ç»“å’Œç•…æƒ³ã€‚ è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªå°çš„update,åœ¨æœ¬é›†å‘å¸ƒçš„æ—¶å€™, Googleä¹Ÿå¯¹çˆ†å‘å¼å¢é•¿çš„ChatGPTåšå‡ºäº†å›åº”, æ­£åœ¨æµ‹è¯•ä¸€ä¸ªåŸºäºLambdaæ¨¡å‹çš„èŠå¤©æœºå™¨äººApprenticeBotã€‚ æ­£å¼å‘å¸ƒåä¼šæœ‰æ€æ ·çš„æƒŠå–œ?æˆ‘ä»¬éƒ½æ‹­ç›®ä»¥å¾…ã€‚ AIæ— ç–‘æ˜¯æœªæ¥å‡ å¹´æœ€ä»¤äººå…´å¥‹çš„å˜é‡ä¹‹ä¸€, Monicaä¹Ÿå¸Œæœ›æœªæ¥èƒ½é‚€è¯·åˆ°æ›´å¤šä¸€çº¿ä»ä¸šè€…ä»ä¸åŒè§’åº¦è®¨è®ºè¿™ä¸ªè¯é¢˜ã€‚ ä¸è®ºæ˜¯æƒ³è¦åšåˆ›ä¸šã€ç ”ç©¶ã€äº§å“è¿˜æ˜¯æŠ•èµ„çš„åŒå­¦, å¸Œæœ›è¿™äº›å¯¹è¯å¯¹äºå¤§å®¶äº†è§£è¿™äº›æŠ€æœ¯æ¼”è¿›ã€å•†ä¸šçš„å¯èƒ½, ç”šè‡³æœªæ¥å¯¹äºæˆ‘ä»¬æ¯ä¸ªäººã€æ¯ä¸ªç¤¾ä¼šæ„å‘³ç€ä»€ä¹ˆ, éƒ½èƒ½å¼•å‘ä¸€äº›æ€è€ƒ,æä¾›ä¸€äº›å¯å‘ã€‚ è¿™æ¬¡çš„è®¨è®ºæœ‰äº›æŠ€æœ¯ç¡¬æ ¸,éœ€è¦å„ä½å¯¹ç”Ÿæˆå¼AIã€å¤§æ¨¡å‹éƒ½æœ‰ä¸€äº›åŸºç¡€äº†è§£ã€‚ è®¨è®ºä¸­æ¶‰åŠåˆ°çš„è®ºæ–‡å’Œé‡è¦æ¦‚å¿µ,ä¹Ÿä¼šæ€»ç»“åœ¨æœ¬é›†çš„ç®€ä»‹ä¸­,ä¾›å¤§å®¶å¤ä¹ å‚è€ƒã€‚ å‡ ä½å˜‰å®¾åœ¨åŒ—ç¾å·¥ä½œç”Ÿæ´»å¤šå¹´,å¤¹æ‚è‹±æ–‡åœ¨æ‰€éš¾å…,ä¹Ÿè¯·å¤§å®¶ä½“è°…äº†ã€‚ æ¬¢è¿æ¥åˆ°æœªæ¥,å¤§å®¶enjoy!
```

å¯ä»¥çœ‹åˆ°ï¼Œè¾“å‡ºç»“æœçš„è‹±æ–‡å‰åä¹Ÿå°±æ²¡æœ‰ç©ºæ ¼äº†ã€‚**èƒ½å¤Ÿåœ¨éŸ³é¢‘å†…å®¹çš„è½¬å½•ä¹‹å‰æä¾›ä¸€æ®µPromptï¼Œæ¥å¼•å¯¼æ¨¡å‹æ›´å¥½åœ°åšè¯­éŸ³è¯†åˆ«ï¼Œæ˜¯Whisperæ¨¡å‹çš„ä¸€å¤§äº®ç‚¹ã€‚**å¦‚æœä½ è§‰å¾—éŸ³é¢‘é‡Œé¢ä¼šæœ‰å¾ˆå¤šä¸“æœ‰åè¯ï¼Œæ¨¡å‹å®¹æ˜“è¯†åˆ«é”™ï¼Œä½ å°±å¯ä»¥åœ¨Prompté‡ŒåŠ ä¸Šå¯¹åº”çš„ä¸“æœ‰åè¯ã€‚æ¯”å¦‚ï¼Œåœ¨ä¸Šé¢çš„å†…å®¹è½¬å½•é‡Œé¢ï¼Œæ¨¡å‹å°±æŠŠChatGPTä¹Ÿå¬é”™äº†ï¼Œå˜æˆäº†ChatGBTã€‚Googleçš„PALMæ¨¡å‹ä¹Ÿç»™å¬é”™äº†ï¼Œå¬æˆäº†POMã€‚å¯¹åº”çš„å…¨ç§°Pathways Language Modelä¹Ÿå°‘äº†ä¸€ä¸ªsã€‚è€Œé’ˆå¯¹è¿™äº›é”™æ¼ï¼Œæˆ‘ä»¬åªè¦å†ä¿®æ”¹ä¸€ä¸‹Promptï¼Œå®ƒå°±èƒ½å¤Ÿè½¬å½•æ­£ç¡®äº†ã€‚

```python
audio_file= open("./data/podcast_clip.mp3", "rb")
transcript = openai.Audio.transcribe("whisper-1", audio_file, 
                                     prompt="è¿™æ˜¯ä¸€æ®µOnboardæ’­å®¢ï¼Œé‡Œé¢ä¼šèŠåˆ°ChatGPTä»¥åŠPALMè¿™ä¸ªå¤§è¯­è¨€æ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹ä¹Ÿå«åšPathways Language Modelã€‚")
print(transcript['text'])
```

è¾“å‡ºç»“æœï¼š

```python
æ¬¢è¿æ¥åˆ°Onboard,çœŸå®çš„ä¸€çº¿ç»éªŒ,èµ°æ–°çš„æŠ•èµ„æ€è€ƒã€‚æˆ‘æ˜¯Monicaã€‚ æˆ‘æ˜¯é«˜å®ã€‚æˆ‘ä»¬ä¸€èµ·èŠèŠè½¯ä»¶å¦‚ä½•æ”¹å˜ä¸–ç•Œã€‚ å¤§å®¶å¥½,æ¬¢è¿æ¥åˆ°Onboard,æˆ‘æ˜¯Monicaã€‚ è‡ªä»OpenAIå‘å¸ƒçš„ChatGPTæ€èµ·äº†å¸­å·ä¸–ç•Œçš„AIçƒ­æ½®,ä¸åˆ°ä¸‰ä¸ªæœˆå°±ç§¯ç´¯äº†è¶…è¿‡ä¸€äº¿çš„è¶Šæ´»ç”¨æˆ·,è¶…è¿‡1300ä¸‡çš„æ—¥æ´»ç”¨æˆ·ã€‚ çœŸçš„æ˜¯å±•ç°äº†AIè®©äººæƒŠå¹çš„èƒ½åŠ›,ä¹Ÿè®©å¾ˆå¤šäººç›´å‘¼è¿™å°±æ˜¯ä¸‹ä¸€ä¸ªäº’è”ç½‘çš„æœªæ¥ã€‚ æœ‰ä¸å°‘è§‚ä¼—éƒ½è¯´å¸Œæœ›æˆ‘ä»¬å†åšä¸€æœŸAIçš„è®¨è®º,äºæ˜¯è¿™æ¬¡ç¡¬æ ¸è®¨è®ºå°±æ¥äº†ã€‚ è¿™æ¬¡æˆ‘ä»¬è¯·æ¥äº†Google Brainçš„ç ”ç©¶å‘˜é›ªèŠ,å¥¹æ˜¯Googleå¤§è¯­è¨€æ¨¡å‹PALM Pathways Language Modelçš„ä½œè€…ä¹‹ä¸€ã€‚ è¦çŸ¥é“,è¿™ä¸ªæ¨¡å‹çš„å‚æ•°é‡æ˜¯GPT-3çš„ä¸‰å€è¿˜å¤šã€‚ å¦å¤–è¿˜æœ‰ä¸¤ä½AIäº§å“å¤§ç‰›,ä¸€ä½æ¥è‡ªè‘—åçš„Stable DiffusionèƒŒåçš„å•†ä¸šå…¬å¸Stability AI, å¦ä¸€ä½æ¥è‡ªæŸç¡…è°·ç§‘æŠ€å¤§å‚,ä¹Ÿæ›¾åœ¨å´æ©è¾¾æ•™æˆçš„Landing AIä¸­æ‹…ä»»äº§å“è´Ÿè´£äººã€‚ æ­¤å¤–,Monicaè¿˜é‚€è¯·åˆ°ä¸€ä½ä¸€ç›´å…³æ³¨AIçš„æŠ•èµ„äººæœ‹å‹Billå½“ä½œæˆ‘çš„ç‰¹é‚€å…±åŒä¸»æŒå˜‰å®¾ã€‚ æˆ‘ä»¬ä¸»è¦è®¨è®ºå‡ ä¸ªè¯é¢˜,ä¸€æ–¹é¢ä»ç ”ç©¶çš„è§†è§’,æœ€å‰æ²¿çš„ç ”ç©¶è€…åœ¨å…³æ³¨ä»€ä¹ˆ? ç°åœ¨çš„æŠ€æœ¯çš„å¤©èŠ±æ¿å’Œæœªæ¥å¤§çš„å˜é‡å¯èƒ½ä¼šåœ¨å“ªé‡Œ? ä»äº§å“å’Œå•†ä¸šçš„è§’åº¦,ä»€ä¹ˆæ˜¯ä¸€ä¸ªå¥½çš„AIäº§å“? æ•´ä¸ªç”Ÿæ€å¯èƒ½éšç€æŠ€æœ¯æœ‰æ€æ ·çš„æ¼”å˜? æ›´é‡è¦çš„,æˆ‘ä»¬åˆèƒ½ä»ä¸Šä¸€æ³¢AIçš„åˆ›ä¸šçƒ­æ½®ä¸­å­¦åˆ°ä»€ä¹ˆ? æœ€å,Monicaå’ŒBillè¿˜ä¼šä»æŠ•èµ„äººçš„è§†è§’åšä¸€ä¸ªå›é¡¾ã€æ€»ç»“å’Œç•…æƒ³ã€‚ è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªå°çš„update,åœ¨æœ¬é›†å‘å¸ƒçš„æ—¶å€™,Googleä¹Ÿå¯¹çˆ†å‘å¼å¢é•¿çš„Chat GPTåšå‡ºäº†å›åº”ã€‚ æ­£åœ¨æµ‹è¯•ä¸€ä¸ªåŸºäºLambdaæ¨¡å‹çš„èŠå¤©æœºå™¨äººApprenticeBotã€‚ è¯å®å‘å¸ƒåä¼šæœ‰æ€æ ·çš„æƒŠå–œ,æˆ‘ä»¬éƒ½æ‹­ç›®ä»¥å¾…ã€‚ AIæ— ç–‘æ˜¯æœªæ¥å‡ å¹´æœ€ä»¤äººå…´å¥‹çš„å˜é‡ä¹‹ä¸€ã€‚ Monicaä¹Ÿå¸Œæœ›æœªæ¥èƒ½é‚€è¯·åˆ°æ›´å¤šä¸€çº¿ä»ä¸šè€…ä»ä¸åŒè§’åº¦è®¨è®ºè¿™ä¸ªè¯é¢˜ã€‚ ä¸è®ºæ˜¯æƒ³è¦åšåˆ›ä¸šã€ç ”ç©¶ã€äº§å“è¿˜æ˜¯æŠ•èµ„çš„åŒå­¦, å¸Œæœ›è¿™äº›å¯¹è¯å¯¹äºå¤§å®¶äº†è§£è¿™äº›æŠ€æœ¯æ¼”è¿›ã€å•†ä¸šçš„å¯èƒ½,ç”šè‡³æœªæ¥å¯¹äºæˆ‘ä»¬æ¯ä¸ªäººã€æ¯ä¸ªç¤¾ä¼šæ„å‘³ç€ä»€ä¹ˆéƒ½èƒ½å¼•å‘ä¸€äº›æ€è€ƒ,æä¾›ä¸€äº›å¯å‘ã€‚ è¿™æ¬¡çš„è®¨è®ºæœ‰äº›æŠ€æœ¯ç¡¬æ ¸,éœ€è¦å„ä½å¯¹ç”Ÿæˆå¼AIå¤§æ¨¡å‹éƒ½æœ‰ä¸€äº›åŸºç¡€äº†è§£ã€‚ è®¨è®ºä¸­æ¶‰åŠåˆ°çš„è®ºæ–‡å’Œé‡è¦æ¦‚å¿µä¹Ÿä¼šæ€»ç»“åœ¨æœ¬é›†çš„ç®€ä»‹ä¸­,ä¾›å¤§å®¶å¤ä¹ å‚è€ƒã€‚ å‡ ä½å˜‰å®¾åœ¨åŒ—ç¾å·¥ä½œç”Ÿæ´»å¤šå¹´,å¤¹æ‚è‹±æ–‡åœ¨æ‰€éš¾å…,ä¹Ÿè¯·å¤§å®¶ä½“è°…äº†ã€‚ æ¬¢è¿æ¥åˆ°æœªæ¥,å¤§å®¶enjoy!
```

å‡ºç°è¿™ä¸ªç°è±¡çš„åŸå› ï¼Œä¸»è¦å’ŒWhisperçš„æ¨¡å‹åŸç†ç›¸å…³ï¼Œå®ƒä¹Ÿæ˜¯ä¸€ä¸ªå’ŒGPTç±»ä¼¼çš„æ¨¡å‹ï¼Œä¼šç”¨å‰é¢è½¬å½•å‡ºæ¥çš„æ–‡æœ¬å»é¢„æµ‹ä¸‹ä¸€å¸§éŸ³é¢‘çš„å†…å®¹ã€‚é€šè¿‡åœ¨æœ€å‰é¢åŠ ä¸Šæ–‡æœ¬Promptï¼Œå°±ä¼šå½±å“åé¢è¯†åˆ«å‡ºæ¥çš„å†…å®¹çš„æ¦‚ç‡ï¼Œä¹Ÿå°±æ˜¯èƒ½å¤Ÿèµ·åˆ°ç»™ä¸“æœ‰åè¯â€œçº é”™â€çš„ä½œç”¨ã€‚

é™¤äº†æ¨¡å‹åç§°ã€éŸ³é¢‘æ–‡ä»¶å’ŒPromptä¹‹å¤–ï¼Œtranscribeæ¥å£è¿˜æ”¯æŒè¿™æ ·ä¸‰ä¸ªå‚æ•°ã€‚

1. response\_formatï¼Œä¹Ÿå°±æ˜¯è¿”å›çš„æ–‡ä»¶æ ¼å¼ï¼Œæˆ‘ä»¬è¿™é‡Œæ˜¯é»˜è®¤å€¼ï¼Œä¹Ÿå°±æ˜¯JSONã€‚å®é™…ä½ è¿˜å¯ä»¥é€‰æ‹©TEXTè¿™æ ·çš„çº¯æ–‡æœ¬ï¼Œæˆ–è€…SRTå’ŒVTTè¿™æ ·çš„éŸ³é¢‘å­—å¹•æ ¼å¼ã€‚è¿™ä¸¤ä¸ªæ ¼å¼é‡Œé¢ï¼Œé™¤äº†æ–‡æœ¬å†…å®¹ï¼Œè¿˜ä¼šæœ‰å¯¹åº”çš„æ—¶é—´ä¿¡æ¯ï¼Œæ–¹ä¾¿ä½ ç»™è§†é¢‘å’ŒéŸ³é¢‘åšå­—å¹•ã€‚ä½ å¯ä»¥ç›´æ¥è¯•ç€è¿è¡Œä¸€ä¸‹çœ‹çœ‹æ•ˆæœã€‚
2. temperatureï¼Œè¿™ä¸ªå’Œæˆ‘ä»¬ä¹‹å‰åœ¨ChatGPTç±»å‹æ¨¡å‹é‡Œçš„å‚æ•°å«ä¹‰ç±»ä¼¼ï¼Œå°±æ˜¯é‡‡æ ·ä¸‹ä¸€å¸§çš„æ—¶å€™ï¼Œå¦‚ä½•è°ƒæ•´æ¦‚ç‡åˆ†å¸ƒã€‚è¿™é‡Œçš„å‚æ•°èŒƒå›´æ˜¯0-1ä¹‹é—´ã€‚
3. languageï¼Œå°±æ˜¯éŸ³é¢‘çš„è¯­è¨€ã€‚æå‰ç»™æ¨¡å‹æŒ‡å®šéŸ³é¢‘çš„è¯­è¨€ï¼Œæœ‰åŠ©äºæå‡æ¨¡å‹è¯†åˆ«çš„å‡†ç¡®ç‡å’Œé€Ÿåº¦ã€‚

è¿™äº›å‚æ•°ä½ éƒ½å¯ä»¥è‡ªå·±è¯•ç€æ”¹ä¸€ä¸‹ï¼Œçœ‹çœ‹æ•ˆæœã€‚

```python
audio_file= open("./data/podcast_clip.mp3", "rb")
transcript = openai.Audio.transcribe("whisper-1", audio_file, response_format="srt",
                                     prompt="è¿™æ˜¯ä¸€æ®µOnboardæ’­å®¢ï¼Œé‡Œé¢ä¼šèŠåˆ°PALMè¿™ä¸ªå¤§è¯­è¨€æ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹ä¹Ÿå«åšPathways Language Modelã€‚")
print(transcript)
```

è¾“å‡ºç»“æœï¼š

```python
1
00:00:01,000 --> 00:00:07,000
æ¬¢è¿æ¥åˆ°Onboard,çœŸå®çš„ä¸€çº¿ç»éªŒ,èµ°æ–°çš„æŠ•èµ„æ€è€ƒã€‚æˆ‘æ˜¯Monicaã€‚
2
00:00:07,000 --> 00:00:11,000
æˆ‘æ˜¯é«˜å®ã€‚æˆ‘ä»¬ä¸€èµ·èŠèŠè½¯ä»¶å¦‚ä½•æ”¹å˜ä¸–ç•Œã€‚
3
00:00:15,000 --> 00:00:17,000
å¤§å®¶å¥½,æ¬¢è¿æ¥åˆ°Onboard,æˆ‘æ˜¯Monicaã€‚
4
00:00:17,000 --> 00:00:28,000
è‡ªä»OpenAIå‘å¸ƒçš„ChatGBTæ€èµ·äº†å¸­å·ä¸–ç•Œçš„AIçƒ­æ½®,ä¸åˆ°ä¸‰ä¸ªæœˆå°±ç§¯ç´¯äº†è¶…è¿‡ä¸€äº¿çš„è¶Šæ´»ç”¨æˆ·,è¶…è¿‡1300ä¸‡çš„æ—¥æ´»ç”¨æˆ·ã€‚
5
00:00:28,000 --> 00:00:34,000
çœŸçš„æ˜¯å±•ç°äº†AIè®©äººæƒŠå¹çš„èƒ½åŠ›,ä¹Ÿè®©å¾ˆå¤šäººç›´å‘¼è¿™å°±æ˜¯ä¸‹ä¸€ä¸ªäº’è”ç½‘çš„æœªæ¥ã€‚
6
00:00:34,000 --> 00:00:41,000
æœ‰ä¸å°‘è§‚ä¼—éƒ½è¯´å¸Œæœ›æˆ‘ä»¬å†åšä¸€æœŸAIçš„è®¨è®º,äºæ˜¯è¿™æ¬¡ç¡¬æ ¸è®¨è®ºå°±æ¥äº†ã€‚
7
...
æ¬¢è¿æ¥åˆ°æœªæ¥,å¤§å®¶enjoy!
```

## è½¬å½•çš„æ—¶å€™é¡ºä¾¿ç¿»è¯‘ä¸€ä¸‹

é™¤äº†åŸºæœ¬çš„éŸ³é¢‘è½¬å½•åŠŸèƒ½ï¼ŒWhisperçš„APIè¿˜é¢å¤–æä¾›äº†ä¸€ä¸ªå«åštranslationçš„æ¥å£ã€‚è¿™ä¸ªæ¥å£å¯ä»¥åœ¨è½¬å½•éŸ³é¢‘çš„æ—¶å€™ç›´æ¥æŠŠè¯­éŸ³ç¿»è¯‘æˆè‹±æ–‡ï¼Œæˆ‘ä»¬ä¸å¦¨æ¥è¯•ä¸€ä¸‹ã€‚

```python
audio_file= open("./data/podcast_clip.mp3", "rb")
translated_prompt="""This is a podcast discussing ChatGPT and PaLM model. 
The full name of PaLM is Pathways Language Model."""
transcript = openai.Audio.translate("whisper-1", audio_file, 
                                    prompt=translated_prompt)
print(transcript['text'])
```

è¾“å‡ºç»“æœï¼š

```python
Welcome to Onboard. Real first-line experience. New investment thinking. I am Monica. I am Gao Ning. Let's talk about how software can change the world. Hello everyone, welcome to Onboard. I am Monica. Since the release of ChatGPT by OpenAI, the world's AI has been in a frenzy. In less than three months, it has accumulated more than 100 million active users, and more than 13 million active users. It really shows the amazing ability of AI. It also makes many people say that this is the future of the next Internet. Many viewers said that they wanted us to do another AI discussion. So this discussion came. This time we invited a researcher from Google Brain, Xue Zhi. He is one of the authors of Google's large-scale model PaLM, Pathways Language Model. You should know that the number of parameters of this model is three times more than ChatGPT-3. In addition, there are two AI product big cows. One is from the famous company behind Stable Diffusion, Stability AI. The other is from a Silicon Valley technology factory. He was also the product manager in Professor Wu Wenda's Landing AI. In addition, Monica also invited a friend of AI who has been paying attention to AI, Bill, as my special guest host. We mainly discuss several topics. On the one hand, from the perspective of research, what are the most cutting-edge researchers paying attention to? Where are the cutting-edge technologies and the large variables of the future? From the perspective of products and business, what is a good AI product? What kind of evolution may the whole state follow? More importantly, what can we learn from the previous wave of AI entrepreneurship? Finally, Monica and Bill will also make a review, summary and reflection from the perspective of investors. Here is a small update. When this issue was released, Google also responded to the explosive growth of ChatGPT. We are testing an Apprentice Bot based on Lambda model. What kind of surprises will be released? We are looking forward to it. AI is undoubtedly one of the most exciting variables in the coming years. Monica also hopes to invite more first-line entrepreneurs to discuss this topic from different angles. Whether you want to do entrepreneurship, research, product or investment, I hope these conversations will help you understand the possibilities of these technical horizons and business. Even in the future, it can cause some thoughts and inspire us to think about what it means to each person and each society. This discussion is a bit technical, and requires you to have some basic understanding of the biometric AI model. The papers and important concepts involved in the discussion will also be summarized in this episode's summary, which is for your reference. You have worked in North America for many years, and you may have some English mistakes. Please understand. Welcome to the future. Enjoy. Let me give you a brief introduction. Some of your past experiences. A fun fact. Using an AI to represent the world is now palped.
```

è¿™ä¸ªæ¥å£åªèƒ½æŠŠå†…å®¹ç¿»è¯‘æˆè‹±æ–‡ï¼Œä¸èƒ½å˜æˆå…¶ä»–è¯­è¨€ã€‚æ‰€ä»¥å¯¹åº”çš„ï¼ŒPromptä¹Ÿå¿…é¡»æ¢æˆè‹±æ–‡ã€‚åªèƒ½ç¿»è¯‘æˆè‹±æ–‡å¯¹æˆ‘ä»¬æ¥è¯´ç¨å¾®æœ‰äº›å¯æƒœäº†ã€‚å¦‚æœèƒ½å¤ŸæŒ‡å®šç¿»è¯‘çš„è¯­è¨€ï¼Œå¾ˆå¤šè‹±æ–‡æ’­å®¢ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç›´æ¥è½¬å½•æˆä¸­æ–‡æ¥è¯»äº†ã€‚ç°åœ¨æˆ‘ä»¬è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œå°±ä¸å¾—ä¸å†èŠ±ä¸€ä»½é’±ï¼Œè®©ChatGPTæ¥å¸®æˆ‘ä»¬ç¿»è¯‘ã€‚

## é€šè¿‡åˆ†å‰²éŸ³é¢‘æ¥å¤„ç†å¤§æ–‡ä»¶

åˆšæ‰æˆ‘ä»¬åªæ˜¯å°è¯•è½¬å½•äº†ä¸€ä¸ª3åˆ†é’Ÿçš„éŸ³é¢‘ç‰‡æ®µï¼Œé‚£æ¥ä¸‹æ¥æˆ‘ä»¬å°±æ¥è½¬å½•ä¸€ä¸‹æ•´ä¸ªéŸ³é¢‘ã€‚ä¸è¿‡ï¼Œæˆ‘ä»¬æ²¡æ³•æŠŠæ•´ä¸ª150åˆ†é’Ÿçš„æ’­å®¢ä¸€æ¬¡æ€§è½¬å½•å‡ºæ¥ï¼Œå› ä¸ºOpenAIé™åˆ¶Whisperä¸€æ¬¡åªèƒ½è½¬å½•25MBå¤§å°çš„æ–‡ä»¶ã€‚æ‰€ä»¥æˆ‘ä»¬è¦å…ˆæŠŠå¤§çš„æ’­å®¢æ–‡ä»¶åˆ†å‰²æˆä¸€ä¸ªä¸ªå°çš„ç‰‡æ®µï¼Œè½¬å½•å®Œä¹‹åå†æŠŠå®ƒä»¬æ‹¼èµ·æ¥ã€‚æˆ‘ä»¬å¯ä»¥é€‰ç”¨OpenAIåœ¨å®˜æ–¹æ–‡æ¡£é‡Œé¢æä¾›çš„ [PyDub çš„åº“](https://platform.openai.com/docs/guides/speech-to-text/longer-inputs)æ¥åˆ†å‰²æ–‡ä»¶ã€‚

ä¸è¿‡ï¼Œåœ¨åˆ†å‰²ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆè¦é€šè¿‡FFmpegæŠŠä»listennotesä¸‹è½½çš„MP4æ–‡ä»¶è½¬æ¢æˆMP3æ ¼å¼ã€‚ä½ ä¸äº†è§£FFmpegæˆ–è€…æ²¡æœ‰å®‰è£…ä¹Ÿæ²¡æœ‰å…³ç³»ï¼Œå¯¹åº”çš„å‘½ä»¤æˆ‘æ˜¯è®©ChatGPTå†™çš„ã€‚è½¬æ¢åçš„æ–‡ä»¶æˆ‘ä¹Ÿæ”¾åˆ°äº†[è¯¾ç¨‹ Github åº“](https://github.com/xuwenhao/geektime-ai-course)é‡Œçš„ç½‘ç›˜åœ°å€äº†ã€‚

```python
ffmpeg -i ./data/podcast_long.mp4 -vn -c:a libmp3lame -q:a 4 ./data/podcast_long.mp3
```

åˆ†å‰²MP3æ–‡ä»¶çš„ä»£ç ä¹Ÿå¾ˆç®€å•ï¼Œæˆ‘ä»¬æŒ‰ç…§15åˆ†é’Ÿä¸€ä¸ªç‰‡æ®µçš„æ–¹å¼ï¼ŒæŠŠéŸ³é¢‘åˆ‡åˆ†ä¸€ä¸‹å°±å¥½äº†ã€‚é€šè¿‡PyDubçš„AudioSegmentåŒ…ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠæ•´ä¸ªé•¿çš„MP3æ–‡ä»¶åŠ è½½åˆ°å†…å­˜é‡Œé¢æ¥å˜æˆä¸€ä¸ªæ•°ç»„ã€‚é‡Œé¢æ¯1æ¯«ç§’çš„éŸ³é¢‘æ•°æ®å°±æ˜¯æ•°ç»„é‡Œçš„ä¸€ä¸ªå…ƒç´ ï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°å°†æ•°ç»„æŒ‰ç…§æ—¶é—´åˆ‡åˆ†æˆæ¯15åˆ†é’Ÿä¸€ä¸ªç‰‡æ®µçš„æ–°çš„MP3æ–‡ä»¶ã€‚

å…ˆç¡®ä¿æˆ‘ä»¬å®‰è£…äº†PyDubåŒ…ã€‚

```python
%pip install -U pydub
```

ä»£ç ï¼š

```python
from pydub import AudioSegment

podcast = AudioSegment.from_mp3("./data/podcast_long.mp3")

# PyDub handles time in milliseconds
ten_minutes = 15 * 60 * 1000

total_length = len(podcast)

start = 0
index = 0
while start < total_length:
    end = start + ten_minutes
    if end < total_length:
        chunk = podcast[start:end]
    else:
        chunk = podcast[start:]
    with open(f"./data/podcast_clip_{index}.mp3", "wb") as f:
        chunk.export(f, format="mp3")
    start = end
    index += 1
```

åœ¨åˆ‡åˆ†å®Œæˆä¹‹åï¼Œæˆ‘ä»¬å°±ä¸€ä¸ªä¸ªåœ°æ¥è½¬å½•å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶ï¼Œå¯¹åº”çš„ä»£ç å°±åœ¨ä¸‹é¢ã€‚

```python
prompt = "è¿™æ˜¯ä¸€æ®µOnboardæ’­å®¢ï¼Œé‡Œé¢ä¼šèŠåˆ°ChatGPTä»¥åŠPALMè¿™ä¸ªå¤§è¯­è¨€æ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹ä¹Ÿå«åšPathways Language Modelã€‚"
for i in range(index):
    clip = f"./data/podcast_clip_{i}.mp3"
    audio_file= open(clip, "rb")
    transcript = openai.Audio.transcribe("whisper-1", audio_file, 
                                     prompt=prompt)
    # mkdir ./data/transcripts if not exists
    if not os.path.exists("./data/transcripts"):
        os.makedirs("./data/transcripts")
    # write to file
    with open(f"./data/transcripts/podcast_clip_{i}.txt", "w") as f:
        f.write(transcript['text'])
    # get last sentence of the transcript
    sentences = transcript['text'].split("ã€‚")
    prompt = sentences[-1]
```

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯¹æ¯æ¬¡è¿›è¡Œè½¬å½•çš„Promptåšäº†ä¸€ä¸ªå°å°çš„ç‰¹æ®Šå¤„ç†ã€‚æˆ‘ä»¬æŠŠå‰ä¸€ä¸ªç‰‡æ®µè½¬å½•ç»“æœçš„æœ€åä¸€å¥è¯ï¼Œå˜æˆäº†ä¸‹ä¸€ä¸ªè½¬å½•ç‰‡æ®µçš„æç¤ºè¯­ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥è®©åé¢çš„ç‰‡æ®µåœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«çš„æ—¶å€™ï¼ŒçŸ¥é“å‰é¢æœ€åè¯´äº†ä»€ä¹ˆã€‚è¿™æ ·åšï¼Œå¯ä»¥å‡å°‘é”™åˆ«å­—çš„å‡ºç°ã€‚

## é€šè¿‡å¼€æºæ¨¡å‹ç›´æ¥åœ¨æœ¬åœ°è½¬å½•

é€šè¿‡OpenAIçš„Whisper APIæ¥è½¬å½•éŸ³é¢‘æ˜¯æœ‰æˆæœ¬çš„ï¼Œç›®å‰çš„å®šä»·æ˜¯ 0.006 ç¾å…ƒ/åˆ†é’Ÿã€‚æ¯”å¦‚æˆ‘ä»¬ä¸Šé¢çš„150åˆ†é’Ÿçš„éŸ³é¢‘æ–‡ä»¶ï¼Œåªéœ€è¦ä¸åˆ°1ç¾å…ƒï¼Œå…¶å®å·²ç»å¾ˆä¾¿å®œäº†ã€‚ä¸è¿‡ï¼Œå¦‚æœä½ ä¸æƒ³æŠŠå¯¹åº”çš„æ•°æ®å‘é€ç»™OpenAIï¼Œé¿å…ä»»ä½•æ•°æ®æ³„éœ²çš„é£é™©ï¼Œä½ è¿˜æœ‰å¦å¤–ä¸€ä¸ªé€‰æ‹©ï¼Œé‚£å°±æ˜¯ç›´æ¥ä½¿ç”¨OpenAIå¼€æºå‡ºæ¥çš„æ¨¡å‹å°±å¥½äº†ã€‚

ä¸è¿‡ä½¿ç”¨å¼€æºæ¨¡å‹ä½ è¿˜æ˜¯éœ€è¦ä¸€å—GPUï¼Œå¦‚æœæ²¡æœ‰çš„è¯ï¼Œä½ ä»ç„¶å¯ä»¥ä½¿ç”¨å…è´¹çš„Colabçš„Notebookç¯å¢ƒã€‚

å…ˆå®‰è£…openai-whisperçš„ç›¸å…³çš„ä¾èµ–åŒ…ã€‚

```python
%pip install openai-whisper
%pip install setuptools-rust
```

ä»£ç æœ¬èº«å¾ˆç®€å•ï¼Œæˆ‘ä»¬åªæ˜¯æŠŠåŸå…ˆè°ƒç”¨OpenAIçš„APIçš„åœ°æ–¹ï¼Œæ¢æˆäº†åŠ è½½Whisperçš„æ¨¡å‹ï¼Œç„¶ååœ¨transcribeçš„å‚æ•°ä¸Šï¼Œæœ‰ä¸€äº›å°å°çš„å·®å¼‚ã€‚å…¶ä»–éƒ¨åˆ†çš„ä»£ç å’Œå‰é¢æˆ‘ä»¬è°ƒç”¨OpenAIçš„Whisper APIçš„ä»£ç åŸºæœ¬ä¸Šæ˜¯ä¸€è‡´çš„ã€‚

```python
import whisper

model = whisper.load_model("large")
index = 11 # number of fi
  
def transcript(clip, prompt, output):
    result = model.transcribe(clip, initial_prompt=prompt)
    with open(output, "w") as f:
        f.write(result['text'])
    print("Transcripted: ", clip)

original_prompt = "è¿™æ˜¯ä¸€æ®µOnboardæ’­å®¢ï¼Œé‡Œé¢ä¼šèŠåˆ°ChatGPTä»¥åŠPALMè¿™ä¸ªå¤§è¯­è¨€æ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹ä¹Ÿå«åšPathways Language Modelã€‚\n\n"
prompt = original_prompt
for i in range(index):
    clip = f"./drive/MyDrive/colab_data/podcast/podcast_clip_{i}.mp3"
    output = f"./drive/MyDrive/colab_data/podcast/transcripts/local_podcast_clip_{i}.txt"
    transcript(clip, prompt, output)
    # get last sentence of the transcript
    with open(output, "r") as f:
        transcript = f.read()
    sentences = transcript.split("ã€‚")
    prompt = original_prompt + sentences[-1]
```

æœ‰ä¸€ä¸ªç‚¹ä½ å¯ä»¥æ³¨æ„ä¸€ä¸‹ï¼ŒWhisperçš„æ¨¡å‹å’Œæˆ‘ä»¬ä¹‹å‰çœ‹è¿‡çš„å…¶ä»–å¼€æºæ¨¡å‹ä¸€æ ·ï¼Œæœ‰å¥½å‡ ç§ä¸åŒå°ºå¯¸ã€‚ä½ å¯ä»¥é€šè¿‡ load\_model é‡Œé¢çš„å‚æ•°æ¥å†³å®šåŠ è½½ä»€ä¹ˆæ¨¡å‹ã€‚è¿™é‡Œæˆ‘ä»¬é€‰ç”¨çš„æ˜¯æœ€å¤§çš„ large æ¨¡å‹ï¼Œå®ƒå¤§çº¦éœ€è¦10GBçš„æ˜¾å­˜ã€‚å› ä¸ºColabæä¾›çš„GPUæ˜¯è‹±ä¼Ÿè¾¾çš„T4ï¼Œæœ‰16Gæ˜¾å­˜ï¼Œæ‰€ä»¥æ˜¯å®Œå…¨å¤Ÿç”¨çš„ã€‚

å¦‚æœä½ æ˜¯ä½¿ç”¨è‡ªå·±ç”µè„‘ä¸Šçš„æ˜¾å¡ï¼Œæ˜¾å­˜æ²¡æœ‰é‚£ä¹ˆå¤§ï¼Œä½ å¯ä»¥é€‰ç”¨å°ä¸€äº›çš„æ¨¡å‹ï¼Œæ¯”å¦‚smallæˆ–è€…baseã€‚å¦‚æœä½ è¦è½¬å½•çš„å†…å®¹éƒ½æ˜¯è‹±è¯­çš„ï¼Œè¿˜å¯ä»¥ç›´æ¥ä½¿ç”¨small.enè¿™æ ·ä»…é™äºè‹±è¯­çš„æ¨¡å‹ã€‚è¿™ç§å°çš„æˆ–è€…é™åˆ¶è¯­è¨€çš„æ¨¡å‹ï¼Œé€Ÿåº¦è¿˜æ›´å¿«ã€‚ä¸è¿‡ï¼Œå¦‚æœæ˜¯åƒæˆ‘ä»¬è¿™æ ·è½¬å½•ä¸­æ–‡ä¸ºä¸»ï¼Œæ··æ‚äº†è‹±æ–‡çš„å†…å®¹ï¼Œé‚£ä¹ˆå°½å¯èƒ½é€‰å–å¤§ä¸€äº›çš„æ¨¡å‹ï¼Œè½¬å½•çš„å‡†ç¡®ç‡æ‰ä¼šæ¯”è¾ƒé«˜ã€‚

![](https://static001.geekbang.org/resource/image/7a/3d/7a36faf9bb3f023714dea7e24a86653d.png?wh=1928x1076 "Whisperé¡¹ç›®çš„æ¨¡å‹å‚æ•°å’Œå°ºå¯¸è¯´æ˜")

Whisperé¡¹ç›®ï¼š[https://github.com/openai/whisper](https://github.com/openai/whisper)

## ç»“åˆChatGPTåšå†…å®¹å°ç»“

æ— è®ºæ˜¯ä½¿ç”¨APIè¿˜æ˜¯é€šè¿‡æœ¬åœ°çš„GPUè¿›è¡Œæ–‡æœ¬è½¬å½•ï¼Œæˆ‘ä»¬éƒ½ä¼šè·å¾—è½¬å½•ä¹‹åçš„æ–‡æœ¬ã€‚è¦ç»™è¿™äº›æ–‡æœ¬åšä¸ªå°ç»“ï¼Œå…¶å®æˆ‘ä»¬åœ¨[ç¬¬ 10 è®²](https://time.geekbang.org/column/article/645305)è®²è§£llama-indexçš„æ—¶å€™å°±ç»™è¿‡ç¤ºä¾‹äº†ã€‚æˆ‘ä»¬æŠŠé‚£ä¸ªä»£ç ç¨å¾®æ”¹å†™ä¸€ä¸‹ï¼Œå°±èƒ½å¾—åˆ°å¯¹åº”æ’­å®¢çš„å°ç»“ã€‚

```python
from langchain.chat_models import ChatOpenAI
from langchain.text_splitter import SpacyTextSplitter
from llama_index import GPTListIndex, LLMPredictor, ServiceContext, SimpleDirectoryReader
from llama_index.node_parser import SimpleNodeParser

# define LLM
llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name="gpt-3.5-turbo", max_tokens=1024))

text_splitter = SpacyTextSplitter(pipeline="zh_core_web_sm", chunk_size = 2048)
parser = SimpleNodeParser(text_splitter=text_splitter)
documents = SimpleDirectoryReader('./data/transcripts').load_data()
nodes = parser.get_nodes_from_documents(documents)

service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)

list_index = GPTListIndex(nodes=nodes, service_context=service_context)
response = list_index.query("è¯·ä½ ç”¨ä¸­æ–‡æ€»ç»“ä¸€ä¸‹æˆ‘ä»¬çš„æ’­å®¢å†…å®¹:", response_mode="tree_summarize")
print(response)
```

è¾“å‡ºç»“æœï¼š

```python
è¿™ä¸ªæ’­å®¢è®¨è®ºäº†äººå·¥æ™ºèƒ½å’Œæ·±åº¦å­¦ä¹ é¢†åŸŸçš„é«˜çº§æŠ€æœ¯å’Œæœ€æ–°å‘å±•ï¼ŒåŒ…æ‹¬ç¨³å®šæ€§äººå·¥æ™ºèƒ½ã€è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒæ–¹æ³•ã€å›¾åƒç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒå’Œä¼˜åŒ–ï¼Œä»¥åŠå„ç§æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ¯”è¾ƒå’Œåº”ç”¨åœºæ™¯ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬æ¢è®¨äº†å¼€æºç¤¾åŒºçš„ä½œç”¨å’Œè¶‹åŠ¿ï¼Œä»¥åŠå¼€æºå•†ä¸šåŒ–çš„ä¼˜ç¼ºç‚¹åŠå¦‚ä½•åº”å¯¹ã€‚æˆ‘ä»¬è¿˜è®¨è®ºäº†äººå·¥æ™ºèƒ½åœ¨å„ä¸ªé¢†åŸŸçš„åº”ç”¨å’Œæœªæ¥å‘å±•è¶‹åŠ¿ï¼Œå¹¶å¼ºè°ƒäº†æ‰¾åˆ°å®é™…åº”ç”¨åœºæ™¯å’Œè§£å†³å®é™…é—®é¢˜çš„é‡è¦æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬æé†’è¯´ï¼Œæœªæ¥å€¼å¾—æœŸå¾…çš„AIåº”ç”¨å°†æ˜¯èƒ½å¤ŸçœŸæ­£è·Ÿäººäº¤äº’çš„äº§å“ï¼Œå¯¹äºåˆ›ä¸šå…¬å¸æ¥è¯´ï¼Œéœ€è¦ä»ç”¨æˆ·å®é™…çš„ç—›ç‚¹å‡ºå‘å»è€ƒè™‘å¦‚ä½•æ›´å¥½åœ°åº”ç”¨AIæŠ€æœ¯ã€‚
```

åŸºäºè¿™é‡Œçš„ä»£ç ï¼Œä½ å®Œå…¨å¯ä»¥å¼€å‘ä¸€ä¸ªè‡ªåŠ¨æŠ“å–å¹¶å°ç»“ä½ è®¢é˜…çš„æ’­å®¢å†…å®¹çš„å°åº”ç”¨ã€‚ä¸€èˆ¬çš„æ’­å®¢ä¹Ÿå°±æ˜¯40-50åˆ†é’Ÿä¸€æœŸï¼Œè½¬å½•å¹¶å°ç»“ä¸€æœŸçš„æˆæœ¬ä¹Ÿå°±åœ¨5å—äººæ°‘å¸ä¸Šä¸‹ã€‚

## å°ç»“

å¥½äº†ï¼Œè¿™ä¸€è®²åˆ°è¿™é‡Œä¹Ÿå°±ç»“æŸäº†ã€‚

OpenAIçš„Whisperæ¨¡å‹ï¼Œä½¿ç”¨èµ·æ¥éå¸¸ç®€å•æ–¹ä¾¿ã€‚æ— è®ºæ˜¯é€šè¿‡APIè¿˜æ˜¯ä½¿ç”¨å¼€æºçš„æ¨¡å‹ï¼Œåªè¦ä¸€è¡Œä»£ç è°ƒç”¨ä¸€ä¸ªtranscribeå‡½æ•°ï¼Œå°±èƒ½æŠŠä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶è½¬å½•æˆå¯¹åº”çš„æ–‡æœ¬ã€‚è€Œä¸”å³ä½¿å¯¹äºå¤šè¯­è¨€æ··æ‚çš„å†…å®¹ï¼Œå®ƒä¹Ÿèƒ½è½¬å½•å¾—å¾ˆå¥½ã€‚è€Œé€šè¿‡ä¼ å…¥ä¸€ä¸ªPromptï¼Œå®ƒä¸ä»…èƒ½å¤Ÿåœ¨æ•´ä¸ªæ–‡æœ¬é‡Œï¼ŒåŠ ä¸Šåˆé€‚çš„æ ‡ç‚¹ç¬¦å·ï¼Œè¿˜èƒ½å¤Ÿæ ¹æ®Prompté‡Œé¢çš„ä¸“æœ‰åè¯ï¼Œå‡å°‘è½¬å½•ä¸­è¿™äº›å†…å®¹çš„é”™æ¼ã€‚è™½ç„¶OpenAIçš„APIæ¥å£é™åˆ¶äº†å•ä¸ªè½¬å½•æ–‡ä»¶çš„å¤§å°ï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥å¾ˆæ–¹ä¾¿åœ°é€šè¿‡PyDubè¿™æ ·çš„PythonåŒ…ï¼ŒæŠŠéŸ³é¢‘æ–‡ä»¶åˆ‡åˆ†æˆå¤šä¸ªå°çš„ç‰‡æ®µæ¥è§£å†³é—®é¢˜ã€‚

å¯¹äºè½¬å½•åçš„ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°ä½¿ç”¨ä¹‹å‰å­¦ä¹ è¿‡çš„ChatGPTå’Œllama-indexæ¥è¿›è¡Œç›¸åº”çš„æ–‡æœ¬å°ç»“ã€‚é€šè¿‡ç»„åˆWhisperå’ŒChatGPTï¼Œæˆ‘ä»¬å°±å¯ä»¥å¿«é€Ÿåœ°è®©æœºå™¨è‡ªåŠ¨å¸®åŠ©æˆ‘ä»¬å°†æ’­å®¢ã€Youtubeè®¿è°ˆï¼Œå˜æˆä¸€æ®µæ–‡æœ¬å°ç»“ï¼Œèƒ½å¤Ÿè®©æˆ‘ä»¬å¿«é€Ÿæµè§ˆå¹¶åˆ¤å®šæ˜¯å¦æœ‰å¿…è¦æ·±å…¥å»å¬ä¸€ä¸‹åŸå§‹çš„å†…å®¹ã€‚

## æ€è€ƒé¢˜

æˆ‘ä»¬åœ¨å°†é•¿éŸ³é¢‘åˆ†ç‰‡è¿›è¡Œè½¬å½•çš„è¿‡ç¨‹é‡Œï¼Œæ˜¯å®Œå…¨æŒ‰ç…§ç²¾ç¡®çš„æ—¶é—´å»åˆ‡å‰²éŸ³é¢‘æ–‡ä»¶çš„ã€‚ä½†æ˜¯å®é™…ä¸ŠéŸ³é¢‘çš„æ–­å¥å…¶å®å¹¶ä¸åœ¨é‚£ä¸€æ¯«ç§’ã€‚æ‰€ä»¥è½¬å½•çš„æ—¶å€™ï¼Œæ•ˆæœä¹Ÿä¸ä¸€å®šå¥½ï¼Œç‰¹åˆ«æ˜¯åœ¨å½•éŸ³çš„å¼€å¤´å’Œç»“å°¾éƒ¨åˆ†ï¼Œå¾ˆæœ‰å¯èƒ½ä¸æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­ï¼Œä¹Ÿå®¹æ˜“å‡ºç°ä¸€äº›é”™æ¼çš„æƒ…å†µã€‚ä½ èƒ½æƒ³æƒ³æœ‰ä»€ä¹ˆå¥½åŠæ³•å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜å—ï¼Ÿæˆ‘ä»¬æ˜¯å¦å¯ä»¥åˆ©ç”¨SRTæˆ–VTTæ–‡ä»¶é‡Œé¢æ–‡æœ¬å¯¹åº”çš„æ—¶é—´æ ‡æ³¨ä¿¡æ¯ï¼Ÿ

æ¬¢è¿ä½ æŠŠä½ æ€è€ƒçš„ç»“æœåˆ†äº«åˆ°ç•™è¨€åŒºï¼Œä¹Ÿæ¬¢è¿ä½ æŠŠè¿™ä¸€è®²åˆ†äº«ç»™éœ€è¦çš„æœ‹å‹ï¼Œæˆ‘ä»¬ä¸‹ä¸€è®²å†è§ï¼

## æ¨èé˜…è¯»

ææ²è€å¸ˆåœ¨ä»–çš„è®ºæ–‡ç²¾è¯»ç³»åˆ—è§†é¢‘é‡Œé¢ï¼Œæœ‰ä¸“é—¨è®²è§£è¿‡ [OpenAI Whisper çš„ç›¸å…³è®ºæ–‡](https://www.bilibili.com/video/BV1VG4y1t74x/)ã€‚ä»–è¿˜ä¸“é—¨åŸºäºWhisperçš„å¼€æºä»£ç åšäº†ä¸€ä¸ªç”¨æ¥å‰ªè¾‘è§†é¢‘çš„å°å·¥å…· [AutoCut](https://www.bilibili.com/video/BV1Pe4y1t7de/?spm_id_from=333.788.recommend_more_video.2&vd_source=dd7dfb298255b22a34220853aab4f816)ã€‚ä½ æœ‰å…´è¶£çš„è¯ï¼Œå¯ä»¥å»çœ‹ä¸€çœ‹ã€‚
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ15ï¼‰</strong></div><ul>
<li><span>Toni</span> ğŸ‘ï¼ˆ32ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>å°†é•¿éŸ³é¢‘åˆ†ç‰‡è½¬å½•æ—¶ï¼Œå¦‚æœå®Œå…¨æŒ‰ç…§ç²¾ç¡®çš„æ—¶é—´å»åˆ‡å‰²éŸ³é¢‘æ–‡ä»¶ï¼Œå¾ˆæœ‰å¯èƒ½åœ¨ç»“å°¾å¤„è£å‡ºä¸€ä¸ªä¸å®Œæ•´çš„å¥å­ï¼Œè€Œä¸‹ä¸€æ®µçš„å¼€å¤´ä¹Ÿå¯èƒ½ä¼šæ˜¯åŠå¥è¯ã€‚å¦‚ä½•è§£å†³ï¼Œæ€è€ƒé¢˜å¾ˆå®ç”¨ã€‚

ä¸‹é¢æ˜¯ä¸€ç§æ€è·¯:

1.  ä»è®¡åˆ’åˆ‡å‰²çš„ä½ç½®ä¸Šå–å‡ºä¸€å°ç‰‡ã€‚æ¯”å¦‚éŸ³é¢‘æ–‡ä»¶é•¿çº¦2å°æ—¶ï¼Œåˆæ­¥è®¡åˆ’åˆ†æˆå››ä¸ªæ–‡ä»¶ï¼Œæ¯ä»½çº¦é•¿30åˆ†é’Ÿï¼Œå°†30åˆ†åˆ°30åˆ†10ç§’çš„éŸ³é¢‘åˆ‡å‡ºæ¥ã€‚å®ç°æ–¹æ³•
extract = audio_long[StartTime:EndTime]
extract.export(&quot;cutat30mins.mp3&quot;, format=&quot;mp3&quot;)

2. æ‰¾å‡ºè¿™ä¸ª10ç§’åˆ‡ç‰‡ä¸­çš„æ–­å¥ä½ç½®ï¼Œå®ç°æ–¹æ³•
from pydub.silence import detect_silence
piece = AudioSegment.from_mp3(&quot;cutat30mins.mp3&quot;)
silent_ranges = detect_silence(piece, min_silence_len=500, silence_thresh=-40)
å‚æ•°ä»£è¡¨é™éŸ³æ—¶é•¿å’Œåˆ†è´

3. é€‰ä¸Šé¢æ–­å¥ä½ç½®ä¸­çš„ç¬¬ä¸€ä¸ªçš„èµ·ç‚¹ä½œä¸ºç¬¬ä¸€æ®µåŠå°æ—¶éŸ³é¢‘æ–‡ä»¶çš„ç»“å°¾ã€‚è¿™æ ·å°±å¾—åˆ° 1. ä¸­çš„EndTime å‡†ç¡®å€¼ï¼Œè€Œä¸æ˜¯åœ¨ä¸€å¥è¯çš„ä¸­é—´ã€‚

æµ‹è¯•: é€‰ podcast_clip.mp3 ä½œä¸ºæµ‹è¯•æ–‡ä»¶ï¼Œæ—¶é•¿3åˆ†é’Ÿã€‚åˆé€‰2åˆ†é’Ÿå¤„åˆ†å‰²ã€‚

å– 2 åˆ†é’Ÿåˆ° 2 åˆ†é’Ÿ10ç§’ çš„ä¸€ä¸ªå°ç‰‡æ®µï¼Œå¾—å‡ºé™éŸ³æ•°åˆ— [[793, 1803], [4991, 5813]]

file =  = AudioSegment.from_mp3(&quot;podcast_clip.mp3&quot;)
EndTime = 2*60*1000 + 793 = 120793
part_1 = file[:EndTime]
StartTime = 2*60*1000 + 1803 = 121803
part_2 = file[StartTime:]

ç»“æœ:
part_1 ç»“æŸå¥ &#39;è¯å®å‘å¸ƒåä¼šæœ‰æ€æ ·çš„æƒŠå–œ,æˆ‘ä»¬éƒ½æ‹­ç›®ä»¥å¾…ã€‚&#39;
part_2 å¼€å§‹å¥ &#39;AIæ— ç–‘æ˜¯æœªæ¥å‡ å¹´æœ€ä»¤äººå…´å¥‹çš„å˜é‡ä¹‹ä¸€ã€‚&#39;

è¿˜ä¼šæœ‰å…¶å®ƒçš„è§£å†³æ–¹æ³•ã€‚</p>2023-04-20</li><br/><li><span>Toni</span> ğŸ‘ï¼ˆ12ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<p>å°è¯•ç€å°†ææ²è€å¸ˆè§†é¢‘ &#39;AutoCut--å¦‚ä½•ç”¨ Whisper æ¥å‰ªè¾‘è§†é¢‘&#39; çš„å†…å®¹è¿›è¡Œäº†æ¦‚è¦ä¿¡æ¯æå–ã€‚åˆ†ä¸‰æ­¥ï¼Œ1 è§†é¢‘è¯»å–å’Œè¯­éŸ³è¯†åˆ«ï¼Œ2 å°†å¤§å—æ–‡ä»¶è£æˆå°å—ï¼Œä½¿å¾—è¾“å…¥çš„ Token æ•°èƒ½æ»¡è¶³ OpenAI çš„è¦æ±‚ï¼Œ3 åˆ†å—æ€»ç»“ã€‚

1. ä» B ç«™è¯»å–è§†é¢‘ (Bilibili Video)ï¼Œå®ç°ä»£ç å¦‚ä¸‹:

!pip install bilibili-api
from langchain.document_loaders.bilibili import BiliBiliLoader
loader_bi = BiliBiliLoader([&quot;https:&#47;&#47;www.bilibili.com&#47;video&#47;BV1Pe4y1t7de&#47;&quot;])
result_bi = loader_bi.load()

2. æ•°æ®åˆ†å‰²ï¼Œå®ç°ä»£ç å¦‚ä¸‹:

from langchain.text_splitter import RecursiveCharacterTextSplitter
text_splitter_bi = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=20)
texts_bi = text_splitter_bi.split_documents(result_bi)

è°ƒæ•´å‚æ•° chunk_size å†³å®šåˆ‡å‰²çš„å¤§å°ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œè£æˆäº†6æ®µï¼ŒæŸ¥çœ‹ä»£ç å¦‚ä¸‹:

len(texts_bi)
6

3. ç»™å‡ºè§†é¢‘å†…å®¹æè¦ï¼Œå®ç°ä»£ç å¦‚ä¸‹:

from langchain.prompts import PromptTemplate
llm = OpenAI(temperature=0)
prompt_template = &quot;&quot;&quot;Answer in Chinese. Summarize this conversation {text}. Do NOT write sentences that has no sense.&quot;&quot;&quot;
prompt_template2 = &quot;&quot;&quot;Answer in Chinese. Choose the more relevant phrases of the following text and summarize them {text}.&quot;&quot;&quot;
PROMPT = PromptTemplate(
    template=prompt_template,
    input_variables=[&quot;text&quot;]       
)
PROMPT2 = PromptTemplate(
    template=prompt_template2,
    input_variables=[&quot;text&quot;]       
)
overall_bi = load_summarize_chain(llm, chain_type=&quot;map_reduce&quot;, map_prompt=PROMPT, combine_prompt=PROMPT2, return_intermediate_steps=True, verbose=True)

summarize_bi = overall_bi( {&quot;input_documents&quot;: texts_bi},return_only_outputs=True)

è¾“å‡ºç»“æœå¦‚ä¸‹:

è¿™æ®µè§†é¢‘ä»‹ç»äº†ä¸€ä¸ªå«OpenAI Whisperçš„å‰ªè§†é¢‘å°å·¥å…·ï¼Œå¹¶é™„ä¸Šäº†ä¸€ä¸ªGitHubé“¾æ¥ï¼Œ...
æˆ‘ä»¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨OpenAIçš„Whisperæ¨¡å‹æ¥è¯†åˆ«è§†é¢‘ä¸­çš„å­—å¹•ï¼Œå¹¶ä¸”å¯ä»¥é€‰æ‹©ä¸åŒçš„æ¨¡å‹ï¼Œä»tinyåˆ°large ... ä»¥æé«˜è¯†åˆ«ç²¾åº¦ã€‚
é€‰æ‹©Smallæ¨¡å‹å¯ä»¥æ»¡è¶³å¤§éƒ¨åˆ†éœ€æ±‚ï¼Œ...å¯ä»¥èŠ‚çœæ—¶é—´ã€‚
...
è¿™æ¬¡è®¨è®ºçš„ä¸»è¦å†…å®¹æ˜¯Whisperè¿™ä¸ªæ¨¡å‹çš„ä½¿ç”¨ï¼Œå®ƒåœ¨ä¸­æ–‡è¯­è°…ä¸Šçš„è¡¨ç°ä¸æ˜¯å¾ˆå¥½ï¼Œä½†æ˜¯åœ¨å¸¦æœ‰è‹±æ–‡è¯æ±‡çš„è§†é¢‘ä¸­ï¼Œå®ƒçš„è¯†åˆ«èƒ½åŠ›è¿˜æ˜¯å¾ˆå¼ºçš„ï¼Œ ...

---
ä¸Šé¢æä¾›äº†ä¸€ç§æå–è§†é¢‘æ ¸å¿ƒæ€æƒ³çš„æ–¹æ³•ï¼Œè¿˜ä¼šæœ‰æ›´å¥½çš„ã€‚</p>2023-04-23</li><br/><li><span>è©¹æ°</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è€å¸ˆï¼Œwhisperå¼€æºæ¨¡å‹æœ¬åœ°éƒ¨ç½²æ”¯æŒæ‰¹é‡æ¨ç†ä¸ï¼Ÿæ€ä¹ˆæ‰¹é‡æ¨ç†å‘¢ï¼Ÿç›®å‰å°±æ˜¯éœ€è¦å®Œæˆå¾ˆå¤šå¾ˆå¤šçš„è¯­è¨€è¯†åˆ«ä»»åŠ¡ï¼Œæ•ˆç‡è·Ÿä¸ä¸Šï¼Œæƒ³è¯·æ•™è€å¸ˆæ€ä¹ˆè§£å†³å‘¢</p>2023-04-25</li><br/><li><span>Geek_00eb03</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>è€å¸ˆï¼Œè¿è¡Œä»£ç æŠ¥é”™ï¼Œ èƒ½å¸®å¿™çœ‹çœ‹ä»€ä¹ˆåŸå› å—ï¼Ÿ
--&gt; 157     raise ValueError(
    158         &quot;A single term is larger than the allowed chunk size.\n&quot;
    159         f&quot;Term size: {num_cur_tokens}\n&quot;
    160         f&quot;Chunk size: {self._chunk_size}&quot;
    161         f&quot;Effective chunk size: {effective_chunk_size}&quot;
    162     )
    163 # If adding token to current_doc would exceed the chunk size:
    164 # 1. First verify with tokenizer that current_doc
    165 # 1. Update the docs list
    166 if cur_total + num_cur_tokens &gt; effective_chunk_size:
    167     # NOTE: since we use a proxy for counting tokens, we want to
    168     # run tokenizer across all of current_doc first. If
    169     # the chunk is too big, then we will reduce text in pieces

ValueError: A single term is larger than the allowed chunk size.
Term size: 414
Chunk size: 357Effective chunk size: 357</p>2023-04-20</li><br/><li><span>èƒ¡èåœ</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>èƒ½åšæˆæµå¼çš„éŸ³è½¬æ–‡å—ï¼Ÿ</p>2023-04-19</li><br/><li><span>å­è¾°</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>é»˜è®¤å°±æ˜¯è·‘GPUçš„å—ï¼Ÿæˆ‘ç”¨ mac çœ‹æ´»åŠ¨ç›‘è§†å™¨å¥½åƒæ˜¯è·‘åœ¨ CPU ä¸Šçš„ã€‚ã€‚ã€‚</p>2023-04-27</li><br/><li><span>è©¹æ°</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>å¾è€å¸ˆï¼Œæˆ‘æƒ³é—®ä¸€ä¸ªæé«˜å¼€æºwhisperæ¨¡å‹è®¡ç®—æ•ˆç‡çš„é—®é¢˜ï¼Œæˆ‘ç”¨å¤šçº¿ç¨‹å»è°ƒåº¦è§£æä¼šæŠ¥é”™ï¼Œè¯·é—®å¦‚ä½•æé«˜æ•ˆç‡å‘¢ï¼Œæˆ‘åªèƒ½å†ä¹°æ˜¾å¡ï¼Œå¤šéƒ¨ç½²å‡ å°æœåŠ¡å˜›ï¼Ÿ</p>2023-04-25</li><br/><li><span>Geek_00eb03</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>æ™®é€šæœåŠ¡å™¨çš„CPU èƒ½ä¸èƒ½è·‘èµ·æ¥whisper å¼€æºæ¨¡å‹ï¼Ÿ</p>2023-04-20</li><br/><li><span>å®‰è²å°”å¾·</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è€å¸ˆï¼Œè¯·æ•™ä¸€ä¸ªéæŠ€æœ¯é—®é¢˜ï¼Œpeo.comè¿™ä¸ªç½‘ç«™æ˜¯æ”¶è´¹çš„ä¹ˆï¼Œå¦‚æœä¸æ”¶è´¹çš„è¯ï¼Œä»–ä»¬é‡Œé¢chatgptåŠŸèƒ½è°ƒç”¨çš„æ˜¯openaiçš„æ¥å£å®ç°çš„ä¹ˆï¼Œå¦‚æœæ˜¯çš„è¯ï¼Œé‚£å²‚ä¸æ˜¯å¾ˆè´¹é’±ï¼Œä»–ä»¬æ€ä¹ˆèµšé’±å‘¢ï¼Ÿ</p>2023-04-20</li><br/><li><span>å¼ å¼›</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>è‡ªå·±å°è¯•è½¬å½•äº†ä¸€ä¸ªæ’­å®¢ï¼ŒæˆåŠŸç”¨Colabè¿›è¡Œäº†è¯­éŸ³è½¬æ–‡å­—ï¼Œä¸€å…±ç”Ÿæˆäº†4ä¸ª12kbçš„æ–‡æœ¬æ–‡ä»¶ï¼Œå»ºç´¢å¼•ä¹Ÿæ²¡é—®é¢˜ï¼Œä½†æ˜¯åˆ°æœ€åè°ƒæ¨¡å‹æ€»ç»“å°±ä¼šå‡ºé”™ã€‚ç”¨GPTå’ŒgoogleæŸ¥äº†åŠå¤©ï¼Œä¹Ÿå°è¯•è‡ªå·±å¯¹æ¯”è½¬å½•çš„æ–‡æœ¬å’Œæ‚¨ä¹‹å‰çš„æ¡ˆä¾‹ä¸­ä½¿ç”¨çš„æœèŠ±å¤•æ‹¾çš„æ–‡æœ¬ï¼Œç¡®å®æ²¡çœ‹å‡ºå·®åˆ«ï¼Œæœ€ç»ˆä¹Ÿæ²¡èƒ½è§£å†³ï¼Œåªå¥½æ¥æ±‚åŠ©è€å¸ˆäº†ï¼Œè°¢è°¢ï¼

&#47;usr&#47;local&#47;lib&#47;python3.9&#47;dist-packages&#47;llama_index&#47;langchain_helpers&#47;text_splitter.py in split_text_with_overlaps(self, text, extra_info_str)
    155             num_cur_tokens = max(len(self.tokenizer(cur_token)), 1)
    156             if num_cur_tokens &gt; effective_chunk_size:
--&gt; 157                 raise ValueError(
    158                     &quot;A single term is larger than the allowed chunk size.\n&quot;
    159                     f&quot;Term size: {num_cur_tokens}\n&quot;

ValueError: A single term is larger than the allowed chunk size.
Term size: 683
Chunk size: 358Effective chunk size: 358</p>2023-04-20</li><br/><li><span>æå®¢ç”¨æˆ·</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>vadæ¨¡å‹å¯ä»¥åšåˆ†å‰²</p>2024-11-24</li><br/><li><span>æ–¹æ¢</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>å¾ˆå¥½</p>2024-02-19</li><br/><li><span>å°é›¨é’é’</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è€å¸ˆï¼Œæˆ‘çš„è¯·æ±‚è¢«æ‹’ç»äº†ï¼Œè¿™ç§æ€ä¹ˆåŠå‘¢ï¼Ÿ openai.RateLimitError: Error code: 429 - {&#39;error&#39;: {&#39;message&#39;: &#39;Your access was terminated due to violation of our policies, please check your email for more information. If you believe this is in error and would like to appeal, please contact us through our help center at help.openai.com.&#39;, &#39;type&#39;: &#39;access_terminated&#39;, &#39;param&#39;: None, &#39;code&#39;: &#39;access_terminated&#39;}}</p>2023-12-09</li><br/><li><span>Mr.wu</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>è¯·æ•™ä¸€ä¸‹whisperèƒ½è¯»å–æµå¼æ–‡æœ¬è¾“å‡ºè¯­éŸ³ä¹ˆï¼Œæ¥gptè¦ç­‰å¾…è¾“å‡ºå®Œæ¯•åå†è½¬æ–‡æœ¬å»¶è¿Ÿå¤ªä¹…äº†ï¼Œå®æ—¶äº¤äº’ä½“éªŒä¸å¥½</p>2023-07-04</li><br/><li><span>ç¥æ¯“é€é¥</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è¯­éŸ³è½¬æ–‡æœ¬ï¼Œç„¶åæœ¬åœ°è½¬å½•çš„å¼€æºæ¨¡å‹æœ‰æ¨èå—</p>2023-06-26</li><br/>
</ul>