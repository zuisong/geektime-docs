ä½ å¥½ï¼Œæˆ‘æ˜¯é»„ä½³ã€‚ä»ä»Šå¤©èµ·ï¼Œæˆ‘ä»¬å°†æ­£å¼è¿›å…¥å¤§æ¨¡å‹å¾®è°ƒå®æˆ˜ã€‚

å¤§æ¨¡å‹çš„å¾®è°ƒï¼Œæ˜¯ä¸€ä¸ªå¯¹å¤§æ¨¡å‹çš„åŸç†å’Œå®è·µç»éªŒè¦æ±‚éƒ½éå¸¸é«˜çš„é¢†åŸŸã€‚åˆå­¦è€…æƒ³æŠŠå¾®è°ƒæŠ€æœ¯æŒæ¡æ¸…æ™°ï¼Œåœ¨æˆ‘çœ‹æ¥ï¼Œè‡³å°‘é¢ä¸´ä¸‰ä¸ªå¾ˆå¤§çš„éšœç¢ã€‚

1. ä¼˜ç§€èµ„æ–™çš„åŒ®ä¹ï¼Œå› ä¸ºæœ‰æˆåŠŸå¾®è°ƒå¤§æ¨¡å‹ç»éªŒçš„äººå¾€å¾€éƒ½æ˜¯å¥½çš„ç ”ç©¶è€…å’Œä¼ä¸šä¸­çš„éª¨å¹²ï¼Œè¿™äº›äººå¾ˆå°‘æœ‰æ—¶é—´å’Œç²¾åŠ›åˆ¶ä½œå®Œå–„çš„æ–‡æ¡£ï¼ŒæŠŠå…·ä½“çš„å¾®è°ƒç»†èŠ‚è®²æ¸…æ¥šã€‚
2. å¯¹å¤§æ¨¡å‹æ•´ä½“çŸ¥è¯†ä½“ç³»çš„å­¦ä¹ è¦æ±‚é«˜ï¼Œæ‡‚å¾®è°ƒï¼Œåˆæ‡‚å¦‚ä½•å¾®è°ƒæ˜¯æœ€æœ‰æ•ˆçš„ï¼Œéœ€è¦ä½ å¯¹æ•´ä¸ªå¤§æ¨¡å‹æŠ€æœ¯æ ˆæœ‰ä¸€ä¸ªå®è§‚ä¸”æ·±å…¥çš„è®¤çŸ¥ã€‚
3. å¾®è°ƒæŠ€æœ¯ä¸ä»…å†…å®¹å¤šï¼Œè€Œä¸”è¿›åŒ–å¾—å¾ˆå¿«ã€‚å¾®è°ƒè¿™ä¸ªæŠ€æœ¯æ ˆçš„åè¯ä¼—å¤šï¼ŒåŒ…æ‹¬å…¨é‡å¾®è°ƒï¼ˆFull Fine-tuningï¼‰ã€æŒ‡ä»¤å¾®è°ƒï¼ˆInstruction Tuningï¼‰ã€åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰ã€å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼ŒParameter-Efficient Fine-Tuningï¼‰ç­‰ç­‰ã€‚è€Œå‚æ•°é«˜æ•ˆå¾®è°ƒä¸­ï¼ŒåˆåŒ…æ‹¬åŸºäºæç¤ºçš„å¾®è°ƒæ–¹æ³•ï¼ˆå¦‚Prompt Tuning / Prefix Tuning / P-Tuningï¼‰ä»¥åŠåŸºäºä½ç§©åˆ†è§£çš„å¾®è°ƒæ–¹æ³•ï¼ˆLoRA / LoHA / LoKrï¼‰ç­‰ã€‚

è¿™ä¹ˆå¤šçš„æ–°åè¯ï¼ŒåŠ ä¸Šè¿™ä¹ˆå¤æ‚çš„æŠ€æœ¯æ ˆï¼Œè®©äººçœ¼èŠ±ç¼­ä¹±ï¼Œä¸çŸ¥é“ä»ä½•ä¸‹æ‰‹ï¼Œå½“ç„¶ä¹Ÿç»™äº†åˆå­¦è€…å¾ˆå¤§çš„éœ‡æ’¼ã€‚ä¸è¿‡ï¼Œä¸‡ä¸ˆé«˜æ¥¼å¹³åœ°èµ·ï¼Œæˆ‘ä»¬å¯ä»¥ä»ç®€å•å¼€å§‹å­¦èµ·ã€‚

ä»Šå¤©è¿™èŠ‚è¯¾ï¼Œå¯ä»¥ä¸ºæˆ‘ä»¬å¯¹æ‰€è°“çš„å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒå’Œ LoRA æŠ€æœ¯è¿›è¡Œä¸€ä¸ªç¥›é­…ã€‚è™½ç„¶ä¸€èŠ‚è¯¾æ— æ³•è¯¦å°½æ·±å…¥åœ°æ¢è®¨æ‰€æœ‰ç»†èŠ‚ï¼Œä½†å®ƒå°†å¸®åŠ©ä½ æ¢³ç†æ•´ä¸ªè¿‡ç¨‹çš„è„‰ç»œã€‚é€šè¿‡è¿™èŠ‚è¯¾ï¼Œä½ å°†äº†è§£å¹¶æŒæ¡åŸºæœ¬çš„å¾®è°ƒæµç¨‹ï¼Œæœ€ç»ˆæˆåŠŸå¾®è°ƒä¸€ä¸ªå¤§æ¨¡å‹ã€‚è¿™å°†ä¸ºä½ åç»­æ›´æ·±å…¥çš„å­¦ä¹ å’Œåº”ç”¨æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚

## Qwen ä¸­æ–‡å¼€æºæ¨¡å‹ä»‹ç»

åœ¨å¾ˆå¤šLLMæ’è¡Œæ¦œä¸Šï¼ŒQwenï¼Œä¹Ÿå°±æ˜¯é€šä¹‰åƒé—®çš„å¼€æºç‰ˆï¼Œæ— ç–‘æ˜¯å½“å‰æœ€ç«çš„å¼€æºä¸­æ–‡å¯¹è¯æ¨¡å‹ä¹‹ä¸€ï¼Œå®ƒæ˜¯ä¸€ä¸ªåŸºäºTransformerèŒƒå¼çš„å¼€æºä¸­è‹±åŒè¯­å¯¹è¯æ¨¡å‹ï¼Œç”±é˜¿é‡Œé›†å›¢å¼€å‘ã€‚ç›®å‰ï¼ŒQwenå®¶æ—åœ¨ä¸­æ–‡å¼€æºæ¨¡å‹ä¸­é«˜å±…æ¦œé¦–ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/5c/2a/5cc2869866648a9a161acb5b80dd212a.png?wh=632x607)

æ’åæˆªè‡³2024å¹´5æœˆï¼Œæ¥è‡ª[è¿™ä¸ª](https://github.com/jeinlee1991/chinese-llm-benchmark)é¡¹ç›®

å®ƒä½¿ç”¨äº†ç›‘ç£å¾®è°ƒã€åé¦ˆå¼•å¯¼å’Œäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ç­‰æ–¹æ³•è¿›è¡Œè®­ç»ƒï¼Œä»¥æé«˜æ¨¡å‹çš„å›ç­”ä¸€è‡´æ€§å’Œè´¨é‡ï¼Œæ—¨åœ¨å®ç°æµç•…çš„å¤šè½®å¯¹è¯ï¼Œå¹¶åœ¨æ¶ˆè´¹çº§æ˜¾å¡ä¸Šæä¾›ä½é—¨æ§›çš„æœ¬åœ°éƒ¨ç½²ã€‚é‚£ä¹ˆåœ¨æœ¬èŠ‚è¯¾ä¸­ï¼Œæˆ‘ä»¬å°±æ¥å­¦ä¹ å¦‚ä½•å¾®è°ƒQwenï¼Œè®©å®ƒæ›´ç¬¦åˆæˆ‘ä»¬çš„åº”ç”¨åœºæ™¯éœ€æ±‚ã€‚

Qwen-1.8B æ˜¯ Qwen ç³»åˆ—çš„ä¸€ä¸ªæœ€å°çš„ç‰ˆæœ¬ï¼Œå…·æœ‰ 18 äº¿å‚æ•°ã€‚è¿™ä¸ªæ¨¡å‹è™½ç„¶åœ¨å¤§æ¨¡å‹å®¶æ—ä¸­é‡çº§è¾ƒå°ï¼Œä½†ä¹Ÿèƒ½å¤Ÿå¤„ç†ä¸­è‹±åŒè¯­çš„è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆä»»åŠ¡ã€‚é€šè¿‡é‡åŒ–æŠ€æœ¯ï¼ŒQwen-1.8B å¯ä»¥åœ¨ä½è‡³ 4GB æ˜¾å­˜çš„æ¶ˆè´¹çº§æ˜¾å¡ä¸Šè¿è¡Œï¼ˆINT4 é‡åŒ–çº§åˆ«ï¼‰ã€‚

Qwen-1.8B åœ¨æ€§èƒ½å’Œå¼€æ”¾æ€§ä¹‹é—´è¿›è¡Œäº†è‰¯å¥½çš„å¹³è¡¡ï¼Œæ—¨åœ¨ä¸ºå¼€å‘è€…æä¾›ä¸€ä¸ªå¼ºå¤§ä¸”æ˜“ç”¨çš„å¯¹è¯äº¤äº’åŸºåº§ï¼ŒåŠ é€Ÿå¤§æ¨¡å‹åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨è½åœ°ï¼Œå¾ˆå—ä¸­æ–‡ä¸–ç•Œç”¨æˆ·çš„æ¬¢è¿ã€‚è¿™ä¸ªæ¨¡å‹çš„å¤§å°ï¼Œä¹Ÿæ¯”è¾ƒé€‚åˆæˆ‘ä»¬å­¦ä¹ ã€‚æˆ‘æ˜¯åœ¨ NVIDIA A100-SXM4-40GB æ˜¾å¡å’Œ NVIDIA GeForce RTX 3090-24GB æ˜¾å¡æœºå™¨ä¸Šéƒ½è·‘é€šäº†è¿™ä¸ªæ¨¡å‹çš„å¾®è°ƒï¼Œä½ å¦‚æœæœ‰ç±»ä¼¼çš„èµ„æºï¼Œå°±å¯ä»¥å°è¯•ã€‚ï¼ˆä¹Ÿå¯ä»¥ä½¿ç”¨Colabã€é˜¿é‡Œäº‘ã€AWSã€Azureç­‰äº‘èµ„æºï¼‰

## å¦‚ä½•ç†è§£å¤§æ¨¡å‹å¾®è°ƒ

è¯´å›å¾®è°ƒã€‚é¦–å…ˆï¼Œä½ å¾—æ¸…æ¥šï¼Œä¸ºä»€ä¹ˆè¦åšå¤§æ¨¡å‹çš„å¾®è°ƒï¼Ÿä¸¤ä¸ªç›®æ ‡ï¼Œç¬¬ä¸€ä¸ªæ˜¯è®©æ¨¡å‹æ›´åˆ‡åˆè‡ªå·±çš„åº”ç”¨åœºæ™¯ï¼Œæ›´åŠ é€‚åº”ç‰¹å®šçš„ä¸‹æ¸¸ä»»åŠ¡ï¼›ç¬¬äºŒä¸ªæ˜¯æ¨¡å‹èƒ½å¤Ÿå˜å¾—æ›´åŠ è½»ä¾¿ï¼ŒèŠ‚çœèµ„æºã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/7c/75/7c7e08564a962bcyyab6371a10b8f975.jpg?wh=2258x1130)

é’ˆå¯¹è¿™ä¸¤ä¸ªç›®æ ‡ï¼Œä¸šç•Œä¸»è¦é‡‡ç”¨ä»¥ä¸‹å‡ ç§å¾®è°ƒæ–¹å¼ã€‚

- å…¨é‡å¾®è°ƒï¼ˆFull Fine-tuningï¼‰ï¼šè¿™æ˜¯æœ€ç›´æ¥çš„å¾®è°ƒæ–¹æ³•ã€‚å³åœ¨ä¸‹æ¸¸ä»»åŠ¡çš„è®­ç»ƒæ•°æ®ä¸Šï¼Œå¯¹é¢„è®­ç»ƒæ¨¡å‹çš„æ‰€æœ‰å‚æ•°è¿›è¡Œè®­ç»ƒå’Œæ›´æ–°ã€‚å…¨é‡å¾®è°ƒå¯ä»¥è®©æ¨¡å‹å……åˆ†é€‚åº”æ–°çš„ä»»åŠ¡ï¼Œä½†éœ€è¦æ›´æ–°çš„å‚æ•°é‡å·¨å¤§ï¼Œå¯¹ç®—åŠ›è¦æ±‚å¾ˆé«˜ï¼Œè€Œä¸”æœ‰å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆã€é—å¿˜é¢„è®­ç»ƒçŸ¥è¯†ç­‰é—®é¢˜ã€‚
- éƒ¨åˆ†å¾®è°ƒï¼ˆPartial Fine-tuningï¼‰ï¼šæœ‰é€‰æ‹©åœ°å†»ç»“ä¸€éƒ¨åˆ†æ¨¡å‹å‚æ•°ï¼Œåªå¾®è°ƒå…¶ä¸­çš„ä¸€å°éƒ¨åˆ†å‚æ•°ï¼ˆå¦‚æœ€åå‡ å±‚ï¼‰ã€‚è¿™ç§æ–¹æ³•å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šå‡å°‘æ‰€éœ€çš„è®¡ç®—èµ„æºï¼Œä½†ç”±äºå¤§éƒ¨åˆ†å‚æ•°æ²¡æœ‰æ›´æ–°ï¼Œæ¨¡å‹çš„é€‚åº”èƒ½åŠ›ä¹Ÿç›¸å¯¹æœ‰é™ã€‚
- æç¤ºå¾®è°ƒï¼ˆPrompt-tuningï¼‰ï¼šé€šè¿‡å­¦ä¹ è¾“å…¥æ–‡æœ¬çš„â€œè½¯æç¤ºâ€ï¼ˆå¯è®­ç»ƒçš„è¿ç»­å‘é‡ï¼‰æ¥å¼•å¯¼é¢„è®­ç»ƒæ¨¡å‹æ‰§è¡Œç›®æ ‡ä»»åŠ¡ï¼Œè€Œæ— éœ€æ”¹å˜åŸæ¨¡å‹çš„å‚æ•°ã€‚æç¤ºå¾®è°ƒåªéœ€è®­ç»ƒè½¯æç¤ºå‚æ•°ï¼Œå¤§å¤§å‡å°‘äº†è®­ç»ƒå¼€é”€ã€‚ä½†ç”Ÿæˆçš„æç¤ºå‘é‡ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œæ³›åŒ–èƒ½åŠ›ä¹Ÿæœ‰å¾…è¿›ä¸€æ­¥ç ”ç©¶ã€‚
- Adapter å¾®è°ƒï¼šåœ¨é¢„è®­ç»ƒæ¨¡å‹çš„æ¯ä¸€å±‚ï¼ˆæˆ–éƒ¨åˆ†å±‚ï¼‰æ³¨å…¥è½»é‡çº§çš„Adapteræ¨¡å—ã€‚å¾®è°ƒæ—¶åªè®­ç»ƒè¿™äº›æ–°åŠ å…¥çš„Adapterå‚æ•°ï¼Œå†»ç»“åŸæ¨¡å‹å‚æ•°ã€‚Adapterå……å½“äº†ä»»åŠ¡é€‚é…å™¨çš„è§’è‰²ï¼Œä»¥è¾ƒå°çš„å‚æ•°é‡å’Œè®¡ç®—ä»£ä»·å®ç°äº†æ¨¡å‹é€‚é…ã€‚
- LoRAå¾®è°ƒï¼šä»¥ä½ç§©åˆ†è§£çš„æ€æƒ³å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚åœ¨æ¯ä¸ªæ³¨æ„åŠ›æ¨¡å—ä¸­å¼•å…¥ä½ç§©çŸ©é˜µï¼Œåœ¨å‰å‘ä¼ æ’­æ—¶ä¸åŸçŸ©é˜µç›¸åŠ å¾—åˆ°é€‚é…åçš„æƒé‡ã€‚LoRAåªéœ€è®­ç»ƒæ–°å¼•å…¥çš„ä½ç§©çŸ©é˜µï¼Œå‚æ•°å¼€é”€å¾ˆå°ï¼Œä½†èƒ½åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šå–å¾—ä¸é”™çš„æ•ˆæœã€‚
- P-tuning v2ï¼šå°†è¿ç»­çš„æç¤ºå‘é‡å’ŒAdapterçš„æ€æƒ³ç›¸ç»“åˆï¼Œåœ¨æ¯ä¸ªTransformerå±‚åŸºç¡€ä¸Šå¼•å…¥å¯è®­ç»ƒçš„æç¤ºåµŒå…¥ã€‚è¿™äº›æç¤ºåµŒå…¥åœ¨å‰å‘ä¼ æ’­æ—¶ä¼šæ³¨å…¥åˆ°æ³¨æ„åŠ›çŸ©é˜µå’Œå‰é¦ˆå±‚ä¸­ã€‚P-tuning v2 åœ¨ä¿ç•™é¢„è®­ç»ƒçŸ¥è¯†çš„åŒæ—¶ï¼Œä¹Ÿèƒ½æœ‰æ•ˆåœ°è¿›è¡Œä»»åŠ¡é€‚é…ã€‚

ä¸åŒçš„å¾®è°ƒæ–¹æ³•åœ¨å‚æ•°æ•ˆç‡ã€ä»»åŠ¡é€‚åº”èƒ½åŠ›ã€å®ç°éš¾æ˜“åº¦ç­‰æ–¹é¢å„æœ‰ä¼˜åŠ£ã€‚é’ˆå¯¹å…·ä½“ä»»åŠ¡ï¼Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µï¼ˆå¦‚ä»»åŠ¡å¤æ‚åº¦ã€è®­ç»ƒæ•°æ®è§„æ¨¡ã€å¯ç”¨ç®—åŠ›ç­‰ï¼‰æ¥é€‰æ‹©åˆé€‚çš„å¾®è°ƒç­–ç•¥ã€‚

æ­¤å¤–ï¼ŒåŸºäºæ¨¡å‹éƒ¨ç½²çš„éœ€æ±‚ï¼Œæ¨¡å‹è’¸é¦ã€é‡åŒ–ã€å‰ªæç­‰æ¨¡å‹å‹ç¼©æ–¹æ³•ï¼Œä¹Ÿå¸¸å¸¸ä¸å¾®è°ƒæ–¹æ³•é…åˆä½¿ç”¨ï¼Œä»¥è¿›ä¸€æ­¥å‡å°æ¨¡å‹ä½“ç§¯ã€åŠ é€Ÿæ¨ç†é€Ÿåº¦ï¼Œä½¿å¤§æ¨¡å‹æ›´å®¹æ˜“åœ¨å®é™…åº”ç”¨ä¸­è½åœ°ã€‚è¿™ä¸ªæˆ‘ä»¬è¦åœ¨ä¸‹èŠ‚è¯¾ä¸­æ¥ç€è°ˆã€‚

## ä»€ä¹ˆæ˜¯å‚æ•°é«˜æ•ˆå¾®è°ƒ PEFT

ä¸Šé¢ç½—åˆ—çš„å„ç§ä¸»æµå¾®è°ƒæ–¹æ³•ï¼Œé™¤å»å…¨é‡å¾®è°ƒä¹‹å¤–ï¼Œå…¶å®éƒ½å¯ä»¥ç§°ä¹‹ä¸º**å‚æ•°é«˜æ•ˆå¾®è°ƒ**ï¼Œä¹Ÿå°±æ˜¯PEFTï¼Œæ˜¯é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹æ¥è¯´ï¼Œæœ€ä¸ºå®ç”¨çš„æ–¹æ³•ã€‚æ¯•ç«Ÿå¤§è¯­è¨€æ¨¡å‹çš„ä¸»è¦é—®é¢˜æ˜¯å‚æ•°æ•°é‡è¿‡å¤§ï¼Œåšå…¨é‡å¾®è°ƒå®åœ¨å¯¹èµ„æºçš„æ¶ˆè€—å¤ªå¤§ï¼Œå·²ç»ä¸æ˜¯ä¸€èˆ¬ç ”ç©¶äººå‘˜æˆ–è€…æ™®é€šä¼ä¸šæ‰€èƒ½åšçš„äº†ã€‚

PEFTçš„å…·ä½“æ–¹æ³•éå¸¸å¤šï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå®ƒä»¬åˆ†æˆä¸‹é¢å‡ å¤§ç±»ã€‚

### åŸºäºæç¤ºçš„æ–¹æ³•

é¦–å…ˆæ˜¯åŸºäºæç¤ºçš„æ–¹æ³•ï¼ˆPrompt-based methodsï¼‰ï¼Œè¿™ä¸€ç±»æ–¹æ³•çš„ä»£è¡¨æœ‰ï¼š

- Prompt Tuningï¼šåœ¨è¾“å…¥åµŒå…¥ä¸­æ·»åŠ å¯å­¦ä¹ çš„è½¯æç¤ºå‘é‡ã€‚
- Prefix Tuningï¼šåœ¨æ¯ä¸ªTransformerå±‚çš„ Key/Value çŸ©é˜µå‰æ‹¼æ¥å¯å­¦ä¹ çš„å‰ç¼€çŸ©é˜µã€‚
- P-Tuningï¼šå°†æ¯ä¸ªTransformerå±‚çš„å‰é¦ˆç½‘ç»œMLPæ›¿æ¢ä¸ºå¯å­¦ä¹ çš„æç¤ºåµŒå…¥ã€‚

åŸºäºæç¤ºçš„æ–¹æ³•ï¼Œåªéœ€è¦è®­ç»ƒæ–°å¼•å…¥çš„æç¤ºå‚æ•°ï¼Œä¿æŒé¢„è®­ç»ƒæ¨¡å‹å›ºå®šã€‚å®ƒä»¬å€ŸåŠ©å¯å­¦ä¹ çš„æç¤ºæ¥å¼•å¯¼æ¨¡å‹æ‰§è¡Œç‰¹å®šä»»åŠ¡ï¼Œä¸€å®šç¨‹åº¦ä¸Šç¼“è§£äº†ç›´æ¥å¾®è°ƒå¸¦æ¥çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚

### åŸºäº LoRA çš„æ–¹æ³•

ç¬¬äºŒç±»ï¼Œæ˜¯åŸºäºä½ç§©åˆ†è§£çš„æ–¹æ³•ï¼ˆLoRA methodsï¼‰ï¼Œè¿™ä¸€ç±»æ–¹æ³•é€šè¿‡ä½ç§©åˆ†è§£æ¥è¿‘ä¼¼è¡¨ç¤ºè¦å­¦ä¹ çš„å¢é‡æƒé‡çŸ©é˜µï¼Œä»£è¡¨æ–¹æ³•æœ‰ï¼š

- LoRAï¼šåœ¨æ³¨æ„åŠ›çŸ©é˜µä¸Šæ·»åŠ ä½ç§©åˆ†è§£çŸ©é˜µã€‚
- LoHAï¼šåœ¨æ³¨æ„åŠ›çŸ©é˜µä¸Šæ·»åŠ åŸºäºHadamardä¹˜ç§¯çš„ä½ç§©åˆ†è§£ã€‚
- LoKRï¼šåœ¨æ³¨æ„åŠ›çŸ©é˜µä¸Šæ·»åŠ åŸºäºKroneckerä¹˜ç§¯çš„ä½ç§©åˆ†è§£ã€‚
- AdaLoRAï¼šè‡ªé€‚åº”è°ƒæ•´è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç§©å’Œçº¦æŸåŠ›åº¦ã€‚

åŸºäºä½ç§©åˆ†è§£çš„æ€æƒ³ï¼Œå¯ä»¥ç”¨éå¸¸å°çš„å‚æ•°å¼€é”€ï¼ˆæ–°å¢å‚æ•°é‡é€šå¸¸åªæœ‰åŸæ¨¡å‹çš„0.1%~3%ï¼‰æ¥é€‚é…æ¨¡å‹ï¼Œåœ¨å‚æ•°æ•ˆç‡ä¸Šéå¸¸æœ‰ä¼˜åŠ¿ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/32/7c/3290f365bc14846f46da62b46f6f1e7c.png?wh=624x370)

LoRA çš„æ›´å¤šæŠ€æœ¯ç»†èŠ‚ï¼Œè¯·å‚è§[è®ºæ–‡](https://arxiv.org/pdf/2106.09685)ï¼šLoRA: Low-Rank Adaptation of Large Language Models

LoRA è¿™ç§æ–¹æ³•æœ‰è®¸å¤šä¼˜ç‚¹ï¼š

- LoRA é€šè¿‡å¤§å¹…å‡å°‘å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ï¼Œä½¿å¾®è°ƒæ›´åŠ é«˜æ•ˆã€‚
- åŸå§‹é¢„è®­ç»ƒæƒé‡ä¿æŒå†»ç»“ï¼Œè¿™æ„å‘³ç€ä½ å¯ä»¥æ‹¥æœ‰å¤šä¸ªè½»é‡çº§å’Œä¾¿æºå¼çš„ LoRA æ¨¡å‹ï¼Œä»¥ä¾¿åœ¨å…¶åŸºç¡€ä¸Šæ„å»ºå„ç§ä¸‹æ¸¸ä»»åŠ¡ã€‚
- LoRA ä¸å…¶ä»–å‚æ•°é«˜æ•ˆæ–¹æ³•æ­£äº¤ï¼Œå¹¶ä¸”å¯ä»¥ä¸å…¶ä¸­è®¸å¤šæ–¹æ³•ç›¸ç»“åˆã€‚
- ä½¿ç”¨ LoRA å¾®è°ƒçš„æ¨¡å‹çš„æ€§èƒ½ï¼Œä¸å®Œå…¨å¾®è°ƒçš„æ¨¡å‹çš„æ€§èƒ½ç›¸å½“ã€‚

å‡­å€Ÿå‚æ•°å°‘ã€è®¡ç®—å¿«ã€æ•ˆæœå¥½ã€æ˜“å®ç°ç­‰ä¼˜åŠ¿ï¼ŒLoRAæˆä¸ºäº†è¿‘å¹´æ¥æœ€å—æ¬¢è¿çš„PEFTæŠ€æœ¯ä¹‹ä¸€ã€‚åŒ…æ‹¬ChatGPTåœ¨å†…çš„ä¼—å¤šä¸šç•Œå¤§æ¨¡å‹ï¼Œéƒ½é‡‡ç”¨äº†LoRAè¿›è¡Œä¸‹æ¸¸ä»»åŠ¡é€‚é…ã€‚æˆ‘ä»¬ä»Šå¤©ä¹Ÿé€šè¿‡LoRAæ–¹æ³•ï¼Œæ¥å°è¯•å¾®è°ƒ Qwen-1.8B æ¨¡å‹ã€‚

### å…¶ä»–è½»é‡çº§çš„å‚æ•°åŒ–æ–¹æ³•

é™¤äº†ä»¥ä¸Šä¸¤å¤§ç±»ï¼Œè¿˜æœ‰ä¸€äº›å…¶ä»–çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ€è·¯ï¼Œæ¯”å¦‚ï¼š

- Adapterï¼šåœ¨Transformerå±‚ä¸­æ’å…¥è½»é‡çº§çš„ä»»åŠ¡é€‚é…æ¨¡å—ã€‚
- Diff Pruningï¼šå¯¹å¾®è°ƒåæ¨¡å‹å’ŒåŸæ¨¡å‹çš„å‚æ•°å·®å€¼è¿›è¡Œå‰ªæã€‚
- BitFitï¼šåªå¾®è°ƒåç½®å‚æ•°ï¼Œå†»ç»“å…¶ä½™éƒ¨åˆ†ã€‚
- IA3ï¼šç”¨å°‘é‡å¯å­¦ä¹ å‘é‡å¯¹æ¨¡å‹çš„æ¿€æ´»å€¼ï¼ˆkeyã€valueã€å‰é¦ˆçš„ä¸­é—´æ¿€æ´»ï¼‰è¿›è¡Œç¼©æ”¾ã€‚

è¿™äº›æ–¹æ³•æˆ–é€šè¿‡å¼•å…¥è½»é‡çº§æ¨¡å—ï¼Œæˆ–é€šè¿‡åªè°ƒæ•´ä¸€å°éƒ¨åˆ†åŸæœ‰å‚æ•°ï¼Œéƒ½å¯ä»¥ç”¨è¾ƒå°ä»£ä»·å®Œæˆæ¨¡å‹é€‚é…ã€‚

## HuggingFace çš„ PEFT æ¡†æ¶

è¦ä»é›¶å¼€å§‹æ‰‹åŠ¨å®ç°ä¸Šé¢çš„å„ç§å¾®è°ƒæ–¹æ³•ï¼Œå½“ç„¶ä¸ç°å®ï¼Œå¥½åœ¨æˆ‘ä»¬æœ‰Hugging Face çš„ PEFT æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç»„å·¥å…·å’Œæ–¹æ³•ï¼Œæ—¨åœ¨ä½¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¾®è°ƒè¿‡ç¨‹æ›´åŠ é«˜æ•ˆå’Œèµ„æºå‹å¥½ã€‚è¿™ä¸ªæ¡†æ¶æä¾›äº†ä¸€äº›ä¸»è¦çš„æŠ€æœ¯ï¼Œä»¥å‡å°‘å¾®è°ƒæ‰€éœ€çš„å‚æ•°é‡å’Œè®¡ç®—èµ„æºï¼ŒåŒæ—¶ä»ä¿æŒæ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„é«˜æ€§èƒ½ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/25/f0/251f2e16973e3be698467755d89022f0.png?wh=1359x1106)

è¯¦ç»†æ–‡æ¡£[åœ¨æ­¤](https://huggingface.co/docs/peft/en/index)ã€‚

å®‰è£…å¾ˆç®€å•ã€‚

```plain
pip install peft 
```

ä¸è¿‡ï¼Œè¦å®Œå…¨å®ç°å¾®è°ƒï¼Œè¿˜éœ€è¦å®‰è£…å…¶ä»–ä¸€äº›æ”¯æŒåº“ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/1e/02/1e081d6c154de4f3f47a25ece88c4e02.jpg?wh=1476x948)

å®‰è£…å¥½äº†æ‰€éœ€è¦çš„åŒ…ä¹‹åï¼Œå°±åŠ è½½æ¨¡å‹å’Œ PEFT é…ç½®ï¼Œä¼ªä»£ç å¦‚ä¸‹ï¼š

```plain
from transformers import AutoModelForCausalLM, AutoTokenizer from peft import get_peft_config, get_peft_model  
model_name = "ä½ è¦å¾®è°ƒçš„æ¨¡å‹åç§°" 
model = AutoModelForCausalLM.from_pretrained(model_name) 
tokenizer = AutoTokenizer.from_pretrained(model_name)  
peft_config = get_peft_config('è¿™é‡Œä¼šæœ‰å¾ˆå¤šå…·ä½“çš„å†…å®¹') 
peft_model = get_peft_model(model, peft_config) 
```

ä¸Šé¢è¿™ä¸ªè¿‡ç¨‹ï¼Œå’Œæˆ‘ä»¬ä¸‹è½½å¼€æºæ¨¡å‹ï¼Œç„¶ååšåšå…¨å±€å¾®è°ƒï¼Œæˆ–è€…ç›´æ¥åšæ¨ç†ï¼Œåªæœ‰ä¸€ä¸ªä¸åŒï¼Œå°±æ˜¯è¿›è¡Œ peft\_configï¼Œä¹Ÿå°±æ˜¯å„ç§å¾®è°ƒé…ç½®ã€‚é…ç½®å¥½äº†ä¹‹åï¼Œå°±å¯ä»¥å¼€å§‹å¾®è°ƒ peft\_model äº†ã€‚å½“ç„¶ä¸åŒå‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Œæœ‰ä¸åŒçš„é…ç½®ï¼Œå„ç§é…ç½®çš„å…·ä½“æ–‡æ¡£ï¼Œå‚è€ƒ [HuggingFace å®˜ç½‘](https://huggingface.co/docs/peft/en/tutorial/peft_model_config)ã€‚

## ç”¨ LoRA è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒ

åˆšæ‰è¯´äº†ï¼Œåœ¨ä¸Šé¢è¿™ä¹ˆå¤šäº”èŠ±å…«é—¨çš„PEFTæŠ€å·§ä¸­ï¼Œç›®å‰ä¸šç•Œæœ€ä¸ºå¸¸ç”¨çš„ä¸»æµå¾®è°ƒæ–¹å¼æ˜¯LoRAã€‚

ä¸‹é¢æˆ‘ä»¬å°±ç”¨å®ƒæ¥å¼€å§‹å…·ä½“çš„å¾®è°ƒå®æˆ˜ï¼

### **Alpaca** **æ•°æ®æ ¼å¼**

å¾®è°ƒçš„ç¬¬ä¸€æ­¥ï¼Œå…¶å®æ˜¯å‡†å¤‡æ•°æ®ã€‚

è¯´åˆ°æ•°æ®ï¼Œè¿™é‡Œæˆ‘è¦ä»‹ç»ä¸€ä¸‹ Alpaca æ•°æ®æ ¼å¼ã€‚è¿™ç§æ•°æ®æ˜¯ç”± Meta AI åœ¨å‘å¸ƒ Llama æ¨¡å‹æ—¶ä¸€åŒæå‡ºçš„ã€‚Alpaca æ•°æ®é›†åŒ…å«äº† 52K ä¸ªç”± Llama æ¨¡å‹ç”Ÿæˆçš„æŒ‡ä»¤-è¾“å‡ºå¯¹ï¼Œæ¶µç›–äº†é—®ç­”ã€æ€»ç»“ã€åˆ›æ„å†™ä½œç­‰å¤šç§ä»»åŠ¡ç±»å‹ã€‚è¿™ä¸ªæ•°æ®é›†çš„æ ¼å¼å¯¹äºåç»­çš„æŒ‡ä»¤å¾®è°ƒä»»åŠ¡å…·æœ‰é‡è¦æ„ä¹‰ï¼Œæˆä¸ºäº†è®¸å¤šå¼€æºé¡¹ç›®çš„åŸºçŸ³ã€‚

> å†·çŸ¥è¯†ï¼šAlpacaå’ŒLlamaä¸€æ ·ï¼Œä¸­æ–‡éƒ½è¯‘ä¸ºç¾Šé©¼ï¼Œä½†å¹¶ä¸æ˜¯åŒä¸€ç§åŠ¨ç‰©ï¼ŒAlpacaè¾ƒå°ï¼Œè€³æœµçŸ­è€Œåœ†ï¼Œç¾Šæ¯›æ›´ä¸°å¯Œï¼Œè¢«ç”¨æ¥åˆ¶ä½œé«˜è´¨é‡çš„çººç»‡å“ã€‚Llamaè¾ƒå¤§ï¼Œè€³æœµé•¿è€Œå°–ï¼Œæ›´åƒéª†é©¼ï¼Œç”¨æ¥å¸®äººç±»è¿è´§ã€‚

è¿™äº›æ•°æ®æ˜¯é€šè¿‡è‡ªæŒ‡ä»¤ç”ŸæˆæŠ€æœ¯ï¼ˆSelf-Instructï¼‰ç”Ÿæˆçš„ã€‚æ¯æ¡æ•°æ®éƒ½æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

- instructionï¼šæè¿°æ¨¡å‹éœ€è¦æ‰§è¡Œçš„ä»»åŠ¡ã€‚
- inputï¼šä»»åŠ¡çš„ä¸Šä¸‹æ–‡æˆ–è¾“å…¥ï¼Œçº¦40%çš„ä¾‹å­åŒ…å«æ­¤å­—æ®µã€‚
- outputï¼šç”± text-davinci-003 ç”Ÿæˆçš„æŒ‡ä»¤ç­”æ¡ˆã€‚

å› ä¸ºè¿™ç§æ ¼å¼çš„æŒ‡ä»¤æ•°æ®å¾®è°ƒå¤§æ¨¡å‹å¾ˆæœ‰æ•ˆï¼Œç½‘ç»œä¸Šå°±å‡ºç°äº†å¾ˆå¤šç±»ä¼¼çš„æ•°æ®é›†å’Œå¾®è°ƒé¡¹ç›®ï¼Œæˆ‘åœ¨ç½‘ç»œä¸Šæ‰¾åˆ°äº†ä¸€ä¸ªéå¸¸ç¬¦åˆAlpacaé£æ ¼çš„[ä¸­è¯æ•°æ®é›†](https://github.com/liucann/CPMI-ChatGLM)ã€‚æˆ‘ä»¬å°±ç”¨å®ƒæ¥å¼€å±•åç»­çš„å¾®è°ƒï¼Œåœ¨æ­¤å¯¹æ•°æ®é›†çš„åˆ¶ä½œè€…è¡¨ç¤ºæ„Ÿè°¢ï¼

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/b5/c4/b5206680771d7b2395e305c6512c61c4.png?wh=1067x375 "æŒ‡ä»¤å¾®è°ƒä¸­è¯æ•°æ®é›†")

è¿™ä¸ªæ•°æ®ï¼Œæˆ‘æŠŠå®ƒä¿å­˜åœ¨dataç›®å½•ä¸­ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/fe/45/feb71a8yy7bcdf9c702e641080148645.png?wh=249x71)

### **åœ¨å¾®è°ƒä¹‹å‰å…ˆæµ‹è¯•æ¨¡å‹**

åœ¨å¼€å§‹PEFTå¾®è°ƒä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆç®€å•çš„æµ‹è¯•ä¸€ä¸‹Qwenè¿™ä¸ªæ¨¡å‹ï¼Œçœ‹çœ‹å®ƒæ¥å—æŒ‡ä»¤åï¼Œä¼šç»™å‡ºä»€ä¹ˆå›ç­”ã€‚

```plain
# å¯¼å…¥æ‰€éœ€è¦çš„åº“
from transformers import AutoModelForCausalLM, AutoTokenizer

# æŒ‡å®šæ¨¡å‹
MODEL = 'Qwen/Qwen1.5-1.8B-Chat'

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œåˆ†è¯å™¨
tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(MODEL, trust_remote_code=True, device_map='auto')

# æ¨¡å‹è®¾ä¸ºè¯„ä¼°çŠ¶æ€
model.eval()

# å®šä¹‰æµ‹è¯•ç¤ºä¾‹
test_examples = [
Â  Â  {
Â  Â  Â  Â  "instruction": "ä½¿ç”¨ä¸­åŒ»çŸ¥è¯†æ­£ç¡®å›ç­”é€‚åˆè¿™ä¸ªç—…ä¾‹çš„ä¸­æˆè¯ã€‚",
Â  Â  Â  Â  "input": "è‚›é—¨ç–¼ç—›ï¼Œç—”ç–®ï¼Œè‚›è£‚ã€‚"
Â  Â  },
Â  Â  {
Â  Â  Â  Â  "instruction": "ä½¿ç”¨ä¸­åŒ»çŸ¥è¯†æ­£ç¡®å›ç­”é€‚åˆè¿™ä¸ªç—…ä¾‹çš„ä¸­æˆè¯ã€‚",
Â  Â  Â  Â  "input": "æœ‰æ²¡æœ‰èƒ½å¤Ÿæ»‹å…»è‚è‚¾ã€æ¸…çƒ­æ˜ç›®çš„ä¸­è¯ã€‚"
Â  Â  }
]

# ç”Ÿæˆå›ç­”
for example in test_examples:
Â  Â  context = f"Instruction: {example['instruction']}\nInput: {example['input']}\nAnswer: "
Â  Â  inputs = tokenizer(context, return_tensors="pt")
Â  Â  outputs = model.generate(inputs.input_ids.to(model.device), max_length=512, num_return_sequences=1, no_repeat_ngram_size=2)
Â  Â  answer = tokenizer.decode(outputs[0], skip_special_tokens=True)
Â  Â  print(f"Input: {example['input']}")
Â  Â  print(f"Output: {answer}\n")
```

æ¨¡å‹é¦–å…ˆè¢«ä¸‹è½½åˆ°æœ¬æœºçš„Cacheç›®å½•ï¼Œä¹‹åå¤§æ¨¡å‹å½“ç„¶å¯ä»¥æ ¹æ®è‡ªå·±å·²æœ‰çš„çŸ¥è¯†ï¼Œå¯¹ä»»ä½•ä¸­åŒ»ä¸­è¯ç›¸å…³çš„é—®é¢˜è¿›è¡Œå›ç­”ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/79/99/793399820d151da4e01b4630167b6499.png?wh=696x220)

æ³¨æ„ï¼Œè¿™ä¸ªè¾“å‡ºä¸­å¹¶ä¸åŒ…å«æˆ‘ä»¬æ•°æ®é›†ä¸­æœ‰æ•ˆæ²»ç–—è‚›è£‚çš„çš„åœ°æ¦†æ§è§’ä¸¸ï¼Œå› ä¸ºè¿™ä¸ªç­”æ¡ˆæ˜¯ç›®å‰é€šä¹‰åƒé—®æ¨¡å‹æ ¹æ®è‡ªå·±çš„è®­ç»ƒæƒ…å†µæä¾›çš„ï¼Œå¹¶ä¸ä¸€å®šçœŸå®æœ‰æ•ˆã€‚

### å®šåˆ¶å¯ä»¥è¢«æ¨¡å‹è¯»å…¥çš„æ•°æ®é›†

åˆšæ‰ä¸‹è½½çš„ä¸­è¯æŒ‡ä»¤å¾®è°ƒæ•°æ®ï¼Œéœ€è¦è½¬æ¢æˆå¤§æ¨¡å‹èƒ½å¤Ÿè¯»å…¥çš„æ ¼å¼ã€‚ä»£ç å¦‚ä¸‹ï¼š

```plain
# å¯¼å…¥Dataset
from torch.utils.data import Dataset
import json

# è‡ªå®šä¹‰æ•°æ®é›†ç±»
class CustomDataset(Dataset):
Â  Â  def __init__(self, data_path, tokenizer, device):
Â  Â  Â  Â  self.data = json.load(open(data_path))
Â  Â  Â  Â  self.tokenizer = tokenizer
Â  Â  Â  Â  self.device = device

Â  Â  def __len__(self):
Â  Â  Â  Â  return len(self.data)

Â  Â  def __getitem__(self, idx):
Â  Â  Â  Â  example = self.data[idx]
Â  Â  Â  Â  formatted_example = self.format_example(example)
Â  Â  Â  Â  inputs = self.tokenizer(
Â  Â  Â  Â  Â  Â  formatted_example["context"],
Â  Â  Â  Â  Â  Â  max_length=512,
Â  Â  Â  Â  Â  Â  truncation=True,
Â  Â  Â  Â  Â  Â  padding='max_length',
Â  Â  Â  Â  Â  Â  return_tensors="pt"
Â  Â  Â  Â  )
Â  Â  Â  Â  labels = self.tokenizer(
Â  Â  Â  Â  Â  Â  formatted_example["target"],
Â  Â  Â  Â  Â  Â  max_length=512,
Â  Â  Â  Â  Â  Â  truncation=True,
Â  Â  Â  Â  Â  Â  padding='max_length',
Â  Â  Â  Â  Â  Â  return_tensors="pt"
Â  Â  Â  Â  )
Â  Â  Â  Â  inputs['labels'] = labels['input_ids']
Â  Â  Â  Â  # ç¡®ä¿æ‰€æœ‰å¼ é‡åœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Š
Â  Â  Â  Â  return {key: val.squeeze().to(self.device) for key, val in inputs.items()}

Â  Â  def format_example(self, example: dict) -> dict:
Â  Â  Â  Â  context = f"Instruction: {example['instruction']}\n"
Â  Â  Â  Â  if example.get("input"):
Â  Â  Â  Â  Â  Â  context += f"Input: {example['input']}\n"
Â  Â  Â  Â  context += "Answer: "
Â  Â  Â  Â  target = example["output"]
Â  Â  Â  Â  return {"context": context, "target": target}



```

è‡ªå®šä¹‰çš„æ•°æ®é›†ç±» CustomDataset ç»§æ‰¿è‡ª Datasetï¼Œä»¥ä¸‹æ˜¯å¯¹ç±»çš„å®ç°ä»£ç çš„ç®€å•è¯´æ˜ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/fe/1b/fef86876dd379a102fd29826b34e9d1b.jpg?wh=1268x1193)

ä¸¾ä¾‹æ¥è¯´ï¼Œå¯¹äºä¸‹é¢çš„æ•°æ®ï¼š

> [  
> Â  {  
> Â  Â  â€œinstructionâ€: â€œTranslate the following sentence to French.â€,  
> Â  Â  â€œinputâ€: â€œHello, how are you?â€,  
> Â  Â  â€œoutputâ€: â€œBonjour, comment Ã§a va?â€  
> Â  }  
> ]

\_*init*_ æ–¹æ³•ä¼šåŠ è½½ JSON æ–‡ä»¶ï¼Œå¹¶åˆå§‹åŒ–åˆ†è¯å™¨å’Œè®¾å¤‡ã€‚

\_*getitem*_ æ–¹æ³•ä¼šè·å–å¹¶æ ¼å¼åŒ–è¿™ä¸ªæ•°æ®æ ·æœ¬ï¼Œä½¿ç”¨åˆ†è¯å™¨å°†å…¶è½¬æ¢ä¸ºå¼ é‡æ ¼å¼ï¼Œå¹¶è¿”å›åŒ…å«è¾“å…¥å’Œæ ‡ç­¾çš„å­—å…¸ã€‚

format\_example æ–¹æ³•ä¼šç”Ÿæˆä¸Šä¸‹æ–‡å’Œç›®æ ‡æ–‡æœ¬ï¼š

- contextï¼š"Instruction: Translate the following sentence to French.\\nInput: Hello, how are you?\\nAnswer: "
- targetï¼šâ€œBonjour, comment Ã§a va?â€

### **å‡†å¤‡å¾®è°ƒæ¨¡å‹**

ä¸‹é¢ï¼ŒæŒ‡å®šæ¨¡å‹ï¼Œå¹¶å‡†å¤‡å¼€å§‹å¾®è°ƒã€‚

```plain
# å¯¼å…¥å¾®è°ƒæ¨¡å‹æ‰€éœ€çš„åº“
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# æŒ‡å®šæ¨¡å‹
MODEL = 'Qwen/Qwen1.5-1.8B-Chat'

# ç¡®å®šè®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹
tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(MODEL, trust_remote_code=True)
model = model.to(device) # æŠŠæ¨¡å‹ç§»åˆ°è®¾å¤‡ä¸Š

# èŠ‚çœå†…å­˜çš„ä¸€äº›é…ç½®
model.supports_gradient_checkpointing = True Â # æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹åŠŸèƒ½ï¼Œå‡å°‘æ˜¾å­˜ä½¿ç”¨
model.gradient_checkpointing_enable() Â # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹åŠŸèƒ½ï¼Œå‡å°‘è®­ç»ƒæ—¶çš„æ˜¾å­˜å ç”¨
model.enable_input_require_grads() Â # å…è®¸æ¨¡å‹è¾“å…¥çš„å¼ é‡éœ€è¦æ¢¯åº¦ï¼Œæ”¯æŒæ›´çµæ´»çš„æ¢¯åº¦è®¡ç®—
model.is_parallelizable = True Â # æŒ‡å®šæ¨¡å‹å¯ä»¥å¹¶è¡ŒåŒ–å¤„ç†
model.model_parallel = True Â # å¯ç”¨æ¨¡å‹å¹¶è¡ŒåŒ–ï¼Œåœ¨å¤šè®¾å¤‡ï¼ˆå¦‚å¤šGPUï¼‰ä¸Šåˆ†å¸ƒè®¡ç®—
```

æ­¤å¤„ï¼Œæˆ‘ä»¬ä¸ºæ¨¡å‹è®¾å®šäº†ä¸€ç³»åˆ—èŠ‚çº¦å†…å­˜ã€åŠ å¿«å¾®è°ƒé€Ÿåº¦å¹¶å¯ç”¨å¤šå¡å¹¶è¡Œçš„è®¾ç½®ï¼Œå‚è§ç¨‹åºä¸­çš„æ³¨é‡Šå°±å¥½ã€‚

### è®¾ç½® LoRA é…ç½®é¡¹

è¿™äº›é…ç½®é¡¹å¸®åŠ©ç”¨æˆ·åœ¨è®­ç»ƒè¯­è¨€æ¨¡å‹æ—¶åº”ç”¨ LoRA æŠ€æœ¯ï¼Œé€šè¿‡ä½ç§©åˆ†è§£ï¼Œå‡å°‘æ¨¡å‹å‚æ•°å’Œå†…å­˜å ç”¨ï¼Œå¹¶ä½¿ç”¨ dropout æŠ€æœ¯é˜²æ­¢è¿‡æ‹Ÿåˆï¼ŒåŒæ—¶ä»…åœ¨ç‰¹å®šæ¨¡å—ä¸Šåº”ç”¨ LoRAï¼Œä»è€Œåœ¨è®¡ç®—æ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

```plain
# å¯¼å…¥peftåº“
from peft import get_peft_model, LoraConfig, TaskType

# é…ç½®å¹¶åº”ç”¨ LoRA
peft_config = LoraConfig(
Â  Â  task_type=TaskType.CAUSAL_LM, # ä»»åŠ¡ç±»å‹ï¼šå› æœè¯­è¨€æ¨¡å‹ (Causal LM)
Â  Â  inference_mode=False, # æ¨¡å¼ï¼šè®­ç»ƒæ¨¡å¼ (inference_mode=False)
Â  Â  r=8, # ä½ç§©åˆ†è§£çš„ç§©ï¼š8 (r=8)
Â  Â  lora_alpha=32, # ç¼©æ”¾å› å­ï¼š32 (lora_alpha=32)
Â  Â  lora_dropout=0.1, # dropout æ¦‚ç‡ï¼š0.1 (lora_dropout=0.1)
Â  Â  target_modules=["q_proj", "v_proj"] Â # æŸ¥è¯¢æŠ•å½±å’Œå€¼æŠ•å½±æ¨¡å—
)
model = get_peft_model(model, peft_config) # åº”ç”¨LoRAé…ç½®
```

æ­¤å¤„LoRAå¾®è°ƒé…ç½®é¡¹çš„å…·ä½“è¯´æ˜å¦‚ä¸‹ï¼š

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/51/9d/51b023d9eb96a4f27dd24dee22dc9f9d.jpg?wh=1890x1088)

### å¼€å¯ LoRA è®­ç»ƒ

ä¸‹é¢å°±æ­£å¼å¼€å§‹è®­ç»ƒã€‚

```plain
# å‡†å¤‡æ•°æ®é›†
train_dataset = CustomDataset("data/chinese_med.json", tokenizer, device)

# å¯¼å…¥è®­ç»ƒç›¸å…³çš„åº“
from transformers import TrainingArguments, Trainer

# å®šä¹‰è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
Â  Â  output_dir='./results', Â # è®­ç»ƒç»“æœä¿å­˜çš„ç›®å½•
Â  Â  num_train_epochs=50, Â # è®­ç»ƒçš„æ€»è½®æ•°
Â  Â  per_device_train_batch_size=4, Â # æ¯ä¸ªè®¾å¤‡ä¸Šçš„è®­ç»ƒæ‰¹æ¬¡å¤§å°
Â  Â  gradient_accumulation_steps=8, Â # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼Œåœ¨è¿›è¡Œåå‘ä¼ æ’­å‰ç´¯ç§¯å¤šå°‘æ­¥
Â  Â  evaluation_strategy="no", Â # è¯„ä¼°ç­–ç•¥ï¼Œè¿™é‡Œè®¾ç½®ä¸ºä¸è¯„ä¼°
Â  Â  save_strategy="epoch", Â # ä¿å­˜ç­–ç•¥ï¼Œæ¯ä¸ª epoch ä¿å­˜ä¸€æ¬¡æ¨¡å‹
Â  Â  learning_rate=5e-5, Â # å­¦ä¹ ç‡
Â  Â  fp16=True, Â # å¯ç”¨ 16 ä½æµ®ç‚¹æ•°è®­ç»ƒï¼Œæé«˜è®­ç»ƒé€Ÿåº¦å¹¶å‡å°‘æ˜¾å­˜ä½¿ç”¨
Â  Â  logging_dir='./logs', Â # æ—¥å¿—ä¿å­˜ç›®å½•
Â  Â  dataloader_pin_memory=False, Â # ç¦ç”¨ pin_memory ä»¥èŠ‚çœå†…å­˜
)

# è‡ªå®šä¹‰ Trainer
class CustomTrainer(Trainer):
Â  Â  def compute_loss(self, model, inputs, return_outputs=False):
Â  Â  Â  Â  labels = inputs.pop("labels") Â # ä»è¾“å…¥ä¸­å–å‡ºæ ‡ç­¾
Â  Â  Â  Â  outputs = model(**inputs) Â # è·å–æ¨¡å‹è¾“å‡º
Â  Â  Â  Â  logits = outputs.logits Â # è·å–æ¨¡å‹è¾“å‡ºçš„logits
Â  Â  Â  Â  shift_logits = logits[..., :-1, :].contiguous() Â # å¯¹logitsè¿›è¡Œåç§»ï¼Œå‡†å¤‡è®¡ç®—äº¤å‰ç†µæŸå¤±
Â  Â  Â  Â  shift_labels = labels[..., 1:].contiguous() Â # å¯¹æ ‡ç­¾è¿›è¡Œåç§»ï¼Œå‡†å¤‡è®¡ç®—äº¤å‰ç†µæŸå¤±
Â  Â  Â  Â  loss_fct = torch.nn.CrossEntropyLoss() Â # å®šä¹‰äº¤å‰ç†µæŸå¤±å‡½æ•°
Â  Â  Â  Â  loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1)) Â # è®¡ç®—æŸå¤±
Â  Â  Â  Â  return (loss, outputs) if return_outputs else loss Â # æ ¹æ®å‚æ•°è¿”å›æŸå¤±å’Œè¾“å‡º

# å®šä¹‰ Trainer
trainer = CustomTrainer(
Â  Â  model=model, Â # è®­ç»ƒçš„æ¨¡å‹
Â  Â  args=training_args, Â # è®­ç»ƒå‚æ•°
Â  Â  train_dataset=train_dataset, Â # è®­ç»ƒæ•°æ®é›†
)

# å¼€å§‹è®­ç»ƒ
trainer.train()
```

æ­¤å¤„ï¼Œè®­ç»ƒå‚æ•°ä¹Ÿåˆ—è¡¨è¯´æ˜å¦‚ä¸‹ï¼š

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/72/ec/721567afdc328c542abbdcd33e68a7ec.jpg?wh=1258x1172)

500 è½®æ¬¡çš„è®­ç»ƒå¼€å§‹ï¼Œå¦‚å›¾æ‰€ç¤ºï¼ŒæŸå¤±å°†é€æ¸ç¼©å°ã€‚(å¦‚æœæ—¶é—´éœ€æ±‚å¤ªä¹…ï¼Œä½ å¯ä»¥åªé€‰å–å‡ ä¸ªæ•°æ®æ¥è¿›è¡Œå¾®è°ƒçš„å°è¯•ã€‚)

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/19/e7/19aeb607ef9db33c630924fd35abcfe7.png?wh=1225x326)

### ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹

è·‘500è½®åï¼Œæ¨¡å‹æˆåŠŸä¿å­˜è‡³æœ¬æœºç›®å½•ã€‚

```plain
# åˆ›å»ºä¿å­˜æ¨¡å‹çš„ç›®å½•
import os
save_directory = 'Qwen1.5-1.8B-Chat'
os.makedirs(save_directory, exist_ok=True)

# ä¿å­˜è®­ç»ƒåçš„æ¨¡å‹å’Œé…ç½®æ–‡ä»¶
model.save_pretrained(save_directory)
tokenizer.save_pretrained(save_directory)

# å°†é…ç½®æ–‡ä»¶ä¸‹è½½åˆ°æ¨¡å‹ç›®å½•ä¸­
config = model.config.to_dict()
config_path = os.path.join(save_directory, 'config.json')
with open(config_path, 'w') as f:
Â  Â  json.dump(config, f, ensure_ascii=False, indent=4)

print(f"Model and configuration saved to {save_directory}")
```

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/df/72/df99a6fc6f3bb22b36aaf9453c635172.png?wh=530x438)

### **åœ¨å¾®è°ƒä¹‹åå†æ¬¡æµ‹è¯•æ¨¡å‹**

é‡æ–°ç”¨æœ¬åœ°ç›®å½•åŠ è½½å¾®è°ƒåçš„Qwenæ¨¡å‹ï¼Œå†æ¬¡æµ‹è¯•åŒæ ·çš„é—®é¢˜ã€‚

ä¸‹é¢æŒ‡å®šæ¨¡å‹çš„ ./ å°±ä»£è¡¨å½“å‰ç›®å½•ï¼Œè€Œä¸æ˜¯åœ¨HuggingFaceä¸Šä¸‹è½½åŸå§‹çš„Qwenã€‚

```plain
# å¯¼å…¥æ‰€éœ€è¦çš„åº“
from transformers import AutoModelForCausalLM, AutoTokenizer

# æŒ‡å®šæ¨¡å‹
MODEL = './Qwen1.5-1.8B-Chat'

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œåˆ†è¯å™¨
tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(MODEL, trust_remote_code=True, device_map='auto')

# æ¨¡å‹è®¾ä¸ºè¯„ä¼°çŠ¶æ€
model.eval()

# å®šä¹‰æµ‹è¯•ç¤ºä¾‹
test_examples = [
Â  Â  {
Â  Â  Â  Â  "instruction": "ä½¿ç”¨ä¸­åŒ»çŸ¥è¯†æ­£ç¡®å›ç­”é€‚åˆè¿™ä¸ªç—…ä¾‹çš„ä¸­æˆè¯ã€‚",
Â  Â  Â  Â  "input": "è‚›é—¨ç–¼ç—›ï¼Œç—”ç–®ï¼Œè‚›è£‚ã€‚"
Â  Â  },
Â  Â  {
Â  Â  Â  Â  "instruction": "ä½¿ç”¨ä¸­åŒ»çŸ¥è¯†æ­£ç¡®å›ç­”é€‚åˆè¿™ä¸ªç—…ä¾‹çš„ä¸­æˆè¯ã€‚",
Â  Â  Â  Â  "input": "æœ‰æ²¡æœ‰èƒ½å¤Ÿæ»‹å…»è‚è‚¾ã€æ¸…çƒ­æ˜ç›®çš„ä¸­è¯ã€‚"
Â  Â  }
]

# ç”Ÿæˆå›ç­”
for example in test_examples:
Â  Â  context = f"Instruction: {example['instruction']}\nInput: {example['input']}\nAnswer: "
Â  Â  inputs = tokenizer(context, return_tensors="pt")
Â  Â  outputs = model.generate(inputs.input_ids.to(model.device), max_length=512, num_return_sequences=1, no_repeat_ngram_size=2)
Â  Â  answer = tokenizer.decode(outputs[0], skip_special_tokens=True)
Â  Â  print(f"Input: {example['input']}")
Â  Â  print(f"Output: {answer}\n")
```

è¾“å‡ºå¦‚ä¸‹ï¼š

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/1e/2e/1efec796b049d411b04eb42c356b572e.png?wh=509x101)

æ­¤æ—¶ï¼Œæˆ‘ä»¬æ¬£å–œçš„çœ‹åˆ°äº†æ§è§’ä¸¸çš„ä¿¡æ¯ï¼Œä¹ŸåŒ…å«åœ°æ¦†æ§è§’ä¸¸ä¸­çš„å…¶ä»–ä¸€äº›æœ‰æ•ˆæˆåˆ†ã€‚è™½ç„¶ä¸æ˜¯ç™¾åˆ†ä¹‹ç™¾å‡†ç¡®ï¼Œä½†æ˜¯å¾ˆæ˜æ˜¾æˆ‘ä»¬æ•°æ®é›†ä¸­çš„çŸ¥è¯†ï¼Œå·²ç»è¢«çº³å…¥äº†Qwenæ¨¡å‹çš„çŸ¥è¯†ä½“ç³»ä¸­ã€‚

## æ€»ç»“æ—¶åˆ»

æœ¬èŠ‚è¯¾æˆ‘ä»¬å­¦ä¹ äº†å‚æ•°é«˜æ•ˆå¾®è°ƒçš„åŸºæœ¬åŸç†ï¼Œä»‹ç»äº†PEFTæ¡†æ¶ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬åŸºäº LoRA å¯¹ Qwenæ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œä½¿å…¶åœ¨ä¸­åŒ»é¢†åŸŸé—®ç­”ä»»åŠ¡ä¸Šå–å¾—äº†åŸºäºæˆ‘ä»¬çŸ¥è¯†åº“çš„ç»“æœï¼Œè€Œä¸æ˜¯å®ƒåŸæœ‰çš„è®¤çŸ¥ã€‚

åˆ©ç”¨LoRAç­‰å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨è¾ƒå°çš„è®¡ç®—å¼€é”€ï¼Œå¿«é€Ÿé€‚é…é¢„è®­ç»ƒæ¨¡å‹åˆ°ç‰¹å®šä»»åŠ¡ï¼Œè®©æ¨¡å‹è·å¾—æ–°çš„é¢†åŸŸçŸ¥è¯†ï¼ŒåŒæ—¶åˆèƒ½ä¿ç•™åŸæœ‰çš„è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œè¿™ä¸ºå¤§è¯­è¨€æ¨¡å‹åœ¨å‚ç›´é¢†åŸŸçš„åº”ç”¨æä¾›äº†æ–°çš„æ€è·¯ï¼Œä¹Ÿé™ä½äº†å¤§æ¨¡å‹åº”ç”¨è½åœ°çš„é—¨æ§›ã€‚

åœ¨æœ¬è¯¾ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿæ¶‰åŠåˆ°äº†ä¸€äº›å¦‚ä½•æœ‰æ•ˆåˆ©ç”¨å½“å‰GPUå†…å­˜çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬æ¢¯åº¦æ£€æŸ¥ç‚¹ã€å¤šå¡å¹¶è¡Œç­‰ç­‰ã€‚å…¶å®ï¼Œåœ¨å¾®è°ƒçš„åŒæ—¶ï¼Œå¦‚ä½•ä¸ºå¤§æ¨¡å‹åšè¿›ä¸€æ­¥çš„ç˜¦èº«ï¼Œéå¸¸å€¼å¾—è®¨è®ºã€‚æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚è¯¾ç»§ç»­è¿™ä¸€éƒ¨åˆ†çš„å­¦ä¹ ä¹‹æ—…ã€‚

## æ€è€ƒé¢˜

1. é™¤äº†åŒ»ç–—é¢†åŸŸï¼Œä½ è¿˜èƒ½æ‰¾åˆ°å“ªäº›åœºæ™¯çš„æ•°æ®é›†ï¼Ÿå°è¯•æ”¶é›†ç›¸å…³æ•°æ®ï¼Œå¹¶å®Œæˆæ¨¡å‹å¾®è°ƒã€‚
2. åœ¨ LoRA ä»¥å¤–ï¼Œè¿˜æœ‰å“ªäº›å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Ÿå®ƒä»¬ä¹‹é—´æœ‰ä½•å¼‚åŒï¼Ÿ
3. æˆ‘ä»¬å·²ç»ç”¨PEFTæ¡†æ¶åšäº†LoRAå¾®è°ƒï¼Œé‚£ä¹ˆç°åœ¨ä½ å¯¹å¾®è°ƒçš„æ•´ä½“æµç¨‹å°±æœ‰äº†æ¸…æ¥šçš„è®¤çŸ¥ï¼Œé™¤äº†LoRAä¹‹å¤–ï¼Œä½ å¯å¦å°è¯•å…¶ä»–çš„PEFTå¾®è°ƒæ–¹æ³•ï¼Ÿ

æœŸå¾…ä½ çš„åˆ†äº«ï¼Œæ¬¢è¿ä¸æˆ‘äº¤æµã€‚å¦‚æœä»Šå¤©çš„å†…å®¹è®©ä½ æœ‰æ‰€æ”¶è·ï¼Œä¹Ÿæ¬¢è¿ä½ æŠŠè¿™èŠ‚è¯¾è½¬å‘ç»™æœ‰éœ€è¦çš„æœ‹å‹ï¼æˆ‘ä»¬ä¸‹èŠ‚è¯¾å†è§ï¼
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ3ï¼‰</strong></div><ul>
<li><span>coderlee</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>è¿™èŠ‚è¯¾ï¼Œæ¯”è¾ƒå°´å°¬ï¼Œwindowè¿è¡Œï¼Œä¸€ç›´æç¤º
Traceback (most recent call last):
  File &quot;D:\Workspace\AI\pwerfull_llm\13_FinetuneQwenPEFT\02_finetune_qwen_1b_lora_ok.py&quot;, line 123, in &lt;module&gt;
    trainer.train()
  File &quot;D:\ProgramData\anaconda3\envs\langchain-test-v2\Lib\site-packages\transformers\trainer.py&quot;, line 1539, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File &quot;D:\ProgramData\anaconda3\envs\langchain-test-v2\Lib\site-packages\transformers\trainer.py&quot;, line 1944, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File &quot;D:\ProgramData\anaconda3\envs\langchain-test-v2\Lib\site-packages\transformers\trainer.py&quot;, line 2300, in _maybe_log_save_evaluate
    self._save_checkpoint(model, trial, metrics=metrics)
  File &quot;D:\ProgramData\anaconda3\envs\langchain-test-v2\Lib\site-packages\transformers\trainer.py&quot;, line 2418, in _save_checkpoint
    fd = os.open(output_dir, os.O_RDONLY)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
PermissionError: [Errno 13] Permission denied: &#39;D:\\Workspace\\AI\\pwerfull_llm\\13_FinetuneQwenPEFT\\results\\checkpoint-1&#39;
 10%|â–ˆ         | 1&#47;10 [00:17&lt;02:39, 17.71s&#47;it]
æ‰€ä»¥ï¼Œæˆ‘æ‰“ç®—ç­‰åç»­æ‰¾ä¸ªlinuxç¯å¢ƒï¼Œå†å®é™…æ“ä½œä¸‹ã€‚</p>2024-11-18</li><br/><li><span>åœ¨è·¯ä¸Š</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>ä½³å“¥å¥½ï¼Œä»€ä¹ˆæ—¶å€™åº”è¯¥ä½¿ç”¨å¾®è°ƒï¼Œä»€ä¹ˆæ—¶å€™åº”è¯¥ç”¨RAGæˆ–sql agentå•Šï¼Ÿ</p>2024-06-26</li><br/><li><span>ArtistLu</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>è€å¸ˆï¼Œæˆ‘ç”¨ Qwen2-0.5B è®­ç»ƒå‡ºæ¥çš„æ•ˆæœä¸è¡Œã€‚ç»“æœå¦‚ä¸‹ï¼š
---------------------------------------------------------
Input: è‚›é—¨ç–¼ç—›ï¼Œç—”ç–®ï¼Œè‚›è£‚ã€‚
Output: Instruction: ä½¿ç”¨ä¸­åŒ»çŸ¥è¯†æ­£ç¡®å›ç­”é€‚åˆè¿™ä¸ªç—…ä¾‹çš„ä¸­æˆè¯ã€‚
Input: è‚›é—¨ç–¼ç—›ï¼Œç—”ç–®ï¼Œè‚›è£‚ã€‚
Answer: ã€ã€ã€‚ã€é»„ã€ï¼Œã€åˆ¶ã€ç‰‡ã€å“ã€çŠ¶ã€å‰‚ã€æ€§ã€ç‚’ã€ï¼›ã€é†‹ã€.ã€ï¼‰ã€‚å“ã€‚
----------------------------------------------------------
èƒ½å¸®å¿™è§£ç­”å‡ ä¸ªé—®é¢˜å—ï¼Ÿ
1.å‡ºç°è¿™ç§æƒ…å†µæ˜¯ä¸æ˜¯é¢„è®­ç»ƒæ¨¡å‹å¤ªå°å¯¼è‡´ï¼Ÿ
2.è®­ç»ƒçš„ç»“æœæ–‡ä»¶æ€»å¤§å°åªæœ‰åå‡ Mï¼Œä¸ºå•¥è®­ç»ƒåè¿™ä¹ˆå°å‹’ï¼Ÿ
3.å¦‚æœåªéœ€è¦å¤§æ¨¡å‹å›ç­”å¾ˆå°é¢†åŸŸé—®é¢˜ï¼Œé€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹å¤§å°æœ‰å•¥ä¼˜åŠ£ï¼Ÿï¼ˆæ¯”å¦‚æˆ‘åªæƒ³ç”¨å¤§æ¨¡å‹ç»™ k8s èŠ‚ç‚¹æ‰“åˆ†ï¼Œç”¨äºè°ƒåº¦ï¼‰ğŸ™</p>2024-06-25</li><br/>
</ul>