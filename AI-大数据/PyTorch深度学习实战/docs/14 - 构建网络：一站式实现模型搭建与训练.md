ä½ å¥½ï¼Œæˆ‘æ˜¯æ–¹è¿œã€‚

å‰é¢æˆ‘ä»¬èŠ±äº†ä¸å°‘æ—¶é—´ï¼Œæ—¢å­¦ä¹ äº†æ•°æ®éƒ¨åˆ†çš„çŸ¥è¯†ï¼Œè¿˜ç ”ç©¶äº†æ¨¡å‹çš„ä¼˜åŒ–æ–¹æ³•ã€æŸå¤±å‡½æ•°ä»¥åŠå·ç§¯è®¡ç®—ã€‚ä½ å¯èƒ½æ„Ÿè§‰è¿™äº›çŸ¥è¯†è¿˜æœ‰äº›é›¶é›¶æ•£æ•£ï¼Œä½†å…¶å®æˆ‘ä»¬ä¸çŸ¥ä¸è§‰ä¸­ï¼Œå·²ç»æ‹¿ä¸‹äº†æ¨¡å‹è®­ç»ƒçš„å¿…å­¦å†…å®¹ã€‚

ä»Šå¤©è¿™èŠ‚è¯¾ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªä¸­æœŸå°ç»ƒä¹ ï¼Œæ˜¯æˆ‘ä»¬æ£€éªŒè‡ªå·±å­¦ä¹ æ•ˆæœçš„å¥½æ—¶æœºã€‚æˆ‘ä¼šå¸¦ä½ ä½¿ç”¨PyTorchæ„å»ºå’Œè®­ç»ƒä¸€ä¸ªè‡ªå·±çš„æ¨¡å‹ã€‚

å…·ä½“æˆ‘æ˜¯è¿™ä¹ˆå®‰æ’çš„ï¼Œé¦–å…ˆè®²è§£æ­å»ºç½‘ç»œå¿…å¤‡çš„åŸºç¡€æ¨¡å—â€”â€”nn.Moduleæ¨¡å—ï¼Œä¹Ÿå°±æ˜¯å¦‚ä½•è‡ªå·±æ„å»ºä¸€ä¸ªç½‘ç»œï¼Œå¹¶ä¸”è®­ç»ƒå®ƒï¼Œæ¢å¥è¯è¯´ï¼Œå°±æ˜¯ææ¸…æ¥šVGGã€Inceptioné‚£äº›ç½‘ç»œæ˜¯æ€ä¹ˆè®­ç»ƒå‡ºæ¥çš„ã€‚ç„¶åæˆ‘ä»¬å†çœ‹çœ‹å¦‚ä½•å€ŸåŠ©Torchvisionçš„æ¨¡å‹ä½œä¸ºé¢„è®­ç»ƒæ¨¡å‹ï¼Œæ¥è®­ç»ƒæˆ‘ä»¬è‡ªå·±çš„æ¨¡å‹ã€‚

## æ„å»ºè‡ªå·±çš„æ¨¡å‹

è®©æˆ‘ä»¬ç›´æ¥åˆ‡å…¥ä¸»é¢˜ï¼Œä½¿ç”¨PyTorchï¼Œè‡ªå·±æ„å»ºå¹¶è®­ç»ƒä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ï¼Œæ¥æ‹Ÿåˆå‡ºè®­ç»ƒé›†ä¸­çš„èµ°åŠ¿åˆ†å¸ƒã€‚

æˆ‘ä»¬å…ˆéšæœºç”Ÿæˆè®­ç»ƒé›†Xä¸å¯¹åº”çš„æ ‡ç­¾Yï¼Œå…·ä½“ä»£ç å¦‚ä¸‹ï¼š

```python
import numpy as np
import random
from matplotlib import pyplot as plt

w = 2
b = 3
xlim = [-10, 10]
x_train = np.random.randint(low=xlim[0], high=xlim[1], size=30)

y_train = [w * x + b + random.randint(0,2) for x in x_train]

plt.plot(x_train, y_train, 'bo')
```

ä¸Šè¿°ä»£ç ä¸­ç”Ÿæˆçš„æ•°æ®ï¼Œæ•´ç†æˆæ•£ç‚¹å›¾ä»¥åï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š  
![å›¾ç‰‡](https://static001.geekbang.org/resource/image/f2/11/f2d24e9e7ea5737a78032b686282ca11.jpg?wh=900x621)

ç†Ÿæ‚‰å›å½’çš„åŒå­¦åº”è¯¥çŸ¥é“ï¼Œæˆ‘ä»¬çš„å›å½’æ¨¡å‹ä¸ºï¼š$y = wx+b$ã€‚è¿™é‡Œçš„xä¸yï¼Œå…¶å®å°±å¯¹åº”ä¸Šè¿°ä»£ç ä¸­çš„x\_trainä¸y\_trainï¼Œè€Œwä¸bæ­£æ˜¯æˆ‘ä»¬è¦å­¦ä¹ çš„å‚æ•°ã€‚

å¥½ï¼Œé‚£ä¹ˆæˆ‘ä»¬çœ‹çœ‹å¦‚ä½•æ„å»ºè¿™ä¸ªæ¨¡å‹ã€‚æˆ‘ä»¬è¿˜æ˜¯å…ˆçœ‹ä»£ç ï¼Œå†å…·ä½“è®²è§£ã€‚

```python
import torch
from torch import nn

class LinearModel(nn.Module):
Â  def __init__(self):
Â  Â  super().__init__()
Â  Â  self.weight = nn.Parameter(torch.randn(1))
Â  Â  self.bias = nn.Parameter(torch.randn(1))

Â  def forward(self, input):
Â  Â  return (input * self.weight) + self.bias
```

é€šè¿‡ä¸Šé¢è¿™ä¸ªçº¿æ€§å›å½’æ¨¡å‹çš„ä¾‹å­ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å‡ºæ„å»ºç½‘ç»œæ—¶çš„é‡è¦å‡ ä¸ªçŸ¥è¯†ç‚¹ã€‚

1.**å¿…é¡»ç»§æ‰¿nn.Moduleç±»**ã€‚

2.**é‡å†™\_\_init\_\_()æ–¹æ³•**ã€‚é€šå¸¸æ¥è¯´è¦æŠŠæœ‰éœ€è¦å­¦ä¹ çš„å‚æ•°çš„å±‚æ”¾åˆ°æ„é€ å‡½æ•°ä¸­ï¼Œä¾‹å¦‚ï¼Œä¾‹å­ä¸­çš„weightä¸biasï¼Œè¿˜æœ‰æˆ‘ä»¬ä¹‹å‰å­¦ä¹ çš„å·ç§¯å±‚ã€‚æˆ‘ä»¬åœ¨ä¸Šè¿°çš„\_\_init\_\_()ä¸­ä½¿ç”¨äº†nn.Parameter()ï¼Œå®ƒä¸»è¦çš„ä½œç”¨å°±æ˜¯ä½œä¸ºnn.Moduleä¸­å¯è®­ç»ƒçš„å‚æ•°ä½¿ç”¨ã€‚

3.**forward()æ˜¯å¿…é¡»é‡å†™çš„æ–¹æ³•**ã€‚çœ‹å‡½æ•°åä¹Ÿå¯ä»¥çŸ¥é“ï¼Œå®ƒæ˜¯ç”¨æ¥å®šä¹‰è¿™ä¸ªæ¨¡å‹æ˜¯å¦‚ä½•è®¡ç®—è¾“å‡ºçš„ï¼Œä¹Ÿå°±æ˜¯å‰å‘ä¼ æ’­ã€‚å¯¹åº”åˆ°æˆ‘ä»¬çš„ä¾‹å­ï¼Œå°±æ˜¯è·å¾—æœ€ç»ˆè¾“å‡ºy=weight * x+biasçš„è®¡ç®—ç»“æœã€‚å¯¹äºä¸€äº›ä¸éœ€è¦å­¦ä¹ å‚æ•°çš„å±‚ï¼Œä¸€èˆ¬æ¥è¯´å¯ä»¥æ”¾åœ¨è¿™é‡Œã€‚ä¾‹å¦‚ï¼ŒBNå±‚ï¼Œæ¿€æ´»å‡½æ•°è¿˜æœ‰Dropoutã€‚

### nn.Moduleæ¨¡å—

nn.Moduleæ˜¯æ‰€æœ‰ç¥ç»ç½‘ç»œæ¨¡å—çš„åŸºç±»ã€‚å½“æˆ‘ä»¬è‡ªå·±è¦è®¾è®¡ä¸€ä¸ªç½‘ç»œç»“æ„çš„æ—¶å€™ï¼Œå°±è¦ç»§æ‰¿è¯¥ç±»ã€‚ä¹Ÿå°±è¯´ï¼Œå…¶å®Torchvisonä¸­çš„é‚£äº›æ¨¡å‹ï¼Œä¹Ÿéƒ½æ˜¯é€šè¿‡ç»§æ‰¿nn.Moduleæ¨¡å—æ¥æ„å»ºç½‘ç»œæ¨¡å‹çš„ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ**æ¨¡å—æœ¬èº«æ˜¯callableçš„ï¼Œå½“è°ƒç”¨å®ƒçš„æ—¶å€™ï¼Œå°±æ˜¯æ‰§è¡Œforwardå‡½æ•°ï¼Œä¹Ÿå°±æ˜¯å‰å‘ä¼ æ’­**ã€‚

æˆ‘ä»¬è¿˜æ˜¯ç»“åˆä»£ç ä¾‹å­ç›´è§‚æ„Ÿå—ä¸€ä¸‹ã€‚è¯·çœ‹ä¸‹é¢çš„ä»£ç ï¼Œå…ˆåˆ›å»ºä¸€ä¸ªLinearModelçš„å®ä¾‹modelï¼Œç„¶åmodel(x)å°±ç›¸å½“äºè°ƒç”¨LinearModelä¸­çš„forwardæ–¹æ³•ã€‚

```python
model = LinearModel()
x = torch.tensor(3)
y = model(x)
```

åœ¨æˆ‘ä»¬ä¹‹å‰çš„è¯¾ç¨‹é‡Œå·²ç»è®²è¿‡ï¼Œæ¨¡å‹æ˜¯é€šè¿‡å‰å‘ä¼ æ’­ä¸åå‘ä¼ æ’­æ¥è®¡ç®—æ¢¯åº¦ï¼Œç„¶åæ›´æ–°å‚æ•°çš„ã€‚æˆ‘æƒ³å­¦åˆ°è¿™é‡Œï¼Œåº”è¯¥æ²¡æœ‰å‡ ä¸ªäººä¼šæ„¿æ„å»å†™åå‘ä¼ æ’­å’Œæ¢¯åº¦æ›´æ–°ä¹‹ç±»çš„ä»£ç å§ã€‚

è¿™ä¸ªæ—¶å€™PyTorchçš„ä¼˜ç‚¹å°±ä½“ç°å‡ºæ¥äº†ï¼Œå½“ä½ è®­ç»ƒæ—¶ï¼ŒPyTorchçš„æ±‚å¯¼æœºåˆ¶ä¼šå¸®ä½ è‡ªåŠ¨å®Œæˆè¿™äº›ä»¤äººå¤´å¤§çš„è®¡ç®—ã€‚

é™¤äº†åˆšæ‰è®²è¿‡çš„å†…å®¹ï¼Œå…³äºåˆå§‹åŒ–æ–¹æ³•\_\_init\_\_ï¼Œä½ è¿˜éœ€è¦å…³æ³¨çš„æ˜¯ï¼Œ**å¿…é¡»è°ƒç”¨çˆ¶ç±»çš„æ„é€ æ–¹æ³•æ‰å¯ä»¥**ï¼Œä¹Ÿå°±æ˜¯è¿™è¡Œä»£ç ï¼š

```python
super().__init__()
```

å› ä¸ºåœ¨nn.Moduleçš„\_\_init\_\_()ä¸­ï¼Œä¼šåˆå§‹åŒ–ä¸€äº›æœ‰åºçš„å­—å…¸ä¸é›†åˆã€‚è¿™äº›é›†åˆç”¨æ¥å­˜å‚¨ä¸€äº›æ¨¡å‹è®­ç»ƒè¿‡ç¨‹çš„ä¸­é—´å˜é‡ï¼Œå¦‚æœä¸åˆå§‹åŒ–nn.Moduleä¸­çš„è¿™äº›å‚æ•°çš„è¯ï¼Œæ¨¡å‹å°±ä¼šæŠ¥ä¸‹é¢çš„é”™è¯¯ã€‚

```python
AttributeError: cannot assign parameters before Module.__init__() call
```

### æ¨¡å‹çš„è®­ç»ƒ

æˆ‘ä»¬çš„æ¨¡å‹å®šä¹‰å¥½ä¹‹åï¼Œè¿˜æ²¡æœ‰è¢«è®­ç»ƒã€‚è¦æƒ³è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œå°±éœ€è¦ç”¨åˆ°æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–æ–¹æ³•ï¼Œè¿™ä¸€éƒ¨åˆ†å‰é¢è¯¾é‡Œï¼ˆå¦‚æœä½ æ„Ÿè§‰é™Œç”Ÿçš„è¯ï¼Œå¯ä»¥å›é¡¾11ï½13èŠ‚è¯¾ï¼‰å·²ç»å­¦è¿‡äº†ï¼Œæ‰€ä»¥ç°åœ¨æˆ‘ä»¬ç›´æ¥çœ‹ä»£ç å°±å¯ä»¥äº†ã€‚

è¿™é‡Œé€‰æ‹©çš„æ˜¯MSEæŸå¤±ä¸SGDä¼˜åŒ–æ–¹æ³•ã€‚

```python
model = LinearModel()
# å®šä¹‰ä¼˜åŒ–å™¨
optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

y_train = torch.tensor(y_train, dtype=torch.float32)
for _ in range(1000):
    input = torch.from_numpy(x_train)
    output = model(input)
    loss = nn.MSELoss()(output, y_train)
    model.zero_grad()
    loss.backward()
    optimizer.step()
```

ç»è¿‡1000ä¸ªEpochçš„è®­ç»ƒä»¥åï¼Œæˆ‘ä»¬å¯ä»¥æ‰“å°å‡ºæ¨¡å‹çš„weightä¸biasï¼Œçœ‹çœ‹æ˜¯å¤šå°‘ã€‚

å¯¹äºä¸€ä¸ªæ¨¡å‹çš„**å¯è®­ç»ƒ**çš„å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡named\_parameters()æ¥æŸ¥çœ‹ï¼Œè¯·çœ‹ä¸‹é¢ä»£ç ã€‚

```python
for parameter in model.named_parameters():
Â  print(parameter)
# è¾“å‡ºï¼š
('weight', Parameter containing:
tensor([2.0071], requires_grad=True))
('bias', Parameter containing:
tensor([3.1690], requires_grad=True))
```

å¯ä»¥çœ‹åˆ°ï¼Œweightæ˜¯2.0071ï¼Œbiasæ˜¯3.1690ï¼Œä½ å†å›å¤´å¯¹ä¸€ä¸‹æˆ‘ä»¬åˆ›å»ºè®­ç»ƒæ•°æ®çš„wä¸bï¼Œå®ƒä»¬æ˜¯ä¸æ˜¯ä¸€æ ·å‘¢ï¼Ÿ

æˆ‘ä»¬åˆšæ‰è¯´è¿‡ï¼Œç»§æ‰¿ä¸€ä¸ªnn.Moduleä¹‹åï¼Œå¯ä»¥å®šä¹‰è‡ªå·±çš„ç½‘ç»œæ¨¡å‹ã€‚ModuleåŒæ ·å¯ä»¥ä½œä¸ºå¦å¤–ä¸€ä¸ªModuleçš„ä¸€éƒ¨åˆ†ï¼Œè¢«åŒ…å«åœ¨ç½‘ç»œä¸­ã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬è¦è®¾è®¡ä¸‹é¢è¿™æ ·çš„ä¸€ä¸ªç½‘ç»œï¼š

![](https://static001.geekbang.org/resource/image/25/c6/2574b93463fd3dbd0e97661d6a06ffc6.jpg?wh=1372x689)

è§‚å¯Ÿå›¾ç‰‡å¾ˆå®¹æ˜“å°±ä¼šå‘ç°ï¼Œåœ¨è¿™ä¸ªç½‘ç»œä¸­æœ‰å¤§é‡é‡å¤çš„ç»“æ„ã€‚ä¸Šå›¾ä¸­çš„3x3ä¸2x2çš„å·ç§¯ç»„åˆï¼ŒæŒ‰ç…§æˆ‘ä»¬å¼€ç¯‡çš„è®²è§£çš„è¯ï¼Œæˆ‘ä»¬éœ€è¦æŠŠæ¯ä¸€å±‚å·ç§¯éƒ½å®šä¹‰åˆ°\_\_init\_\_()ï¼Œç„¶åå†åœ¨forwardä¸­å®šä¹‰å¥½æ‰§è¡Œæ–¹æ³•å°±å¯ä»¥äº†ï¼Œä¾‹å¦‚ä¸‹é¢çš„ä¼ªä»£ç ï¼š

```python
class CustomModel(nn.Module):
Â  def __init__(self):
Â  Â  super().__init__()
Â  Â  self.conv1_1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, padding='same')
Â  Â  self.conv1_2 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=2, padding='same')
Â  Â  ...
Â  Â  self.conv_m_1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, padding='same')
Â  Â  self.conv_m_2 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=2, padding='same')
Â  Â  ...
Â  Â  self.conv_n_1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, padding='same')
Â  Â  self.conv_n_2 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=2, padding='same')

Â  def forward(self, input):
Â  Â  x = self.conv1_1(input)
Â  Â  x = self.conv1_2(x)
Â  Â  ...
Â  Â  x = self.conv_m_1(x)
Â  Â  x = self.conv_m_2(x)
Â  Â  ...Â  Â Â 
Â  Â  x = self.conv_n_1(x)
Â  Â  x = self.conv_n_2(x)
Â  Â  ...
Â  Â  return x
```

å…¶å®è¿™éƒ¨åˆ†é‡å¤çš„ç»“æ„å®Œå…¨å¯ä»¥æ”¾åœ¨ä¸€ä¸ªå•ç‹¬çš„moduleä¸­ï¼Œç„¶åï¼Œåœ¨æˆ‘ä»¬æ¨¡å‹ä¸­ç›´æ¥è°ƒç”¨è¿™éƒ¨åˆ†å³å¯ï¼Œå…·ä½“å®ç°ä½ å¯ä»¥å‚è€ƒä¸‹é¢çš„ä»£ç ï¼š

```python
class CustomLayer(nn.Module):
  def __init__(self, input_channels, output_channels):
    super().__init__()
    self.conv1_1 = nn.Conv2d(in_channels=input_channels, out_channels=3, kernel_size=3, padding='same')
    self.conv1_2 = nn.Conv2d(in_channels=3, out_channels=output_channels, kernel_size=2, padding='same')
    
  def forward(self, input):
    x = self.conv1_1(input)
    x = self.conv1_2(x)
    return x
    
```

ç„¶åå‘¢ï¼ŒCustomModelå°±å˜æˆä¸‹é¢è¿™æ ·äº†ï¼š

```python
class CustomModel(nn.Module):
  def __init__(self):
    super().__init__()
    self.layer1 = CustomLayer(1ï¼Œ1)
    ...
    self.layerm = CustomLayer(1ï¼Œ1)
    ...
    self.layern = CustomLayer(1ï¼Œ1)
  
  def forward(self, input):
    x = self.layer1(input)
    ...
    x = self.layerm(x)
    ...    
    x = self.layern(x)
    ...
    return x
```

ç†Ÿæ‚‰æ·±åº¦å­¦ä¹ çš„åŒå­¦ï¼Œä¸€å®šå¬è¿‡æ®‹å·®å—ã€Inceptionå—è¿™æ ·çš„å¤šå±‚çš„ä¸€ä¸ªç»„åˆã€‚ä½ æ²¡å¬è¿‡ä¹Ÿæ²¡å…³ç³»ï¼Œåœ¨å›¾åƒåˆ†ç±»ä¸­æˆ‘è¿˜ä¼šè®²åˆ°ã€‚è¿™é‡Œä½ åªéœ€è¦çŸ¥é“ï¼Œè¿™ç§å¤šå±‚ç»„åˆçš„ç»“æ„æ˜¯ç±»ä¼¼çš„ï¼Œå¯¹äºè¿™ç§ç»„åˆï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”¨ä¸Šé¢çš„ä»£ç çš„æ–¹å¼å®ç°ã€‚

### æ¨¡å‹ä¿å­˜ä¸åŠ è½½

æˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹æœ€ç»ˆçš„ç›®çš„ï¼Œå°±æ˜¯è¦ä¸ºå…¶ä»–åº”ç”¨æä¾›æœåŠ¡çš„ï¼Œè¿™å°±æ¶‰åŠåˆ°äº†æ¨¡å‹çš„ä¿å­˜ä¸åŠ è½½ã€‚

æ¨¡å‹ä¿å­˜ä¸åŠ è½½çš„è¯æœ‰ä¸¤ç§æ–¹å¼ã€‚PyTorchæ¨¡å‹çš„åç¼€åä¸€èˆ¬æ˜¯ptæˆ–pthï¼Œè¿™éƒ½æ²¡æœ‰å…³ç³»ï¼Œåªæ˜¯ä¸€ä¸ªåç¼€åè€Œå·²ã€‚æˆ‘ä»¬æ¥ç€ä¸Šé¢çš„å›å½’æ¨¡å‹ç»§ç»­è®²æ¨¡å‹çš„ä¿å­˜ä¸åŠ è½½ã€‚

#### æ–¹å¼ä¸€ï¼šåªä¿å­˜è®­ç»ƒå¥½çš„å‚æ•°

ç¬¬ä¸€ç§æ–¹å¼å°±æ˜¯åªä¿å­˜è®­ç»ƒå¥½çš„å‚æ•°ã€‚ç„¶ååŠ è½½æ¨¡å‹çš„æ—¶å€™ï¼Œä½ éœ€è¦é€šè¿‡ä»£ç åŠ è½½ç½‘ç»œç»“æ„ï¼Œç„¶åå†å°†å‚æ•°èµ‹äºˆç½‘ç»œã€‚

åªä¿å­˜å‚æ•°çš„ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
torch.save(model.state_dict(), './linear_model.pth')
```

ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ¨¡å‹çš„state\_dictï¼Œè€Œç¬¬äºŒä¸ªå‚æ•°è¦ä¿å­˜çš„ä½ç½®ã€‚

ä»£ç ä¸­çš„state\_dictæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œåœ¨æ¨¡å‹è¢«å®šä¹‰ä¹‹åä¼šè‡ªåŠ¨ç”Ÿæˆï¼Œå­˜å‚¨çš„æ˜¯æ¨¡å‹**å¯è®­ç»ƒ**çš„å‚æ•°ã€‚æˆ‘ä»¬å¯ä»¥æ‰“å°å‡ºçº¿æ€§å›å½’æ¨¡å‹çš„state\_dictï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```python
model.state_dict()
è¾“å‡ºï¼šOrderedDict([('weight', tensor([[2.0071]])), ('bias', tensor([3.1690]))])
```

åŠ è½½æ¨¡å‹çš„æ–¹å¼å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
# å…ˆå®šä¹‰ç½‘ç»œç»“æ„
linear_model = LinearModel()
# åŠ è½½ä¿å­˜çš„å‚æ•°
linear_model.load_state_dict(torch.load('./linear_model.pth'))
linear_model.eval()
for parameter in linear_model.named_parameters():
Â  print(parameter)
è¾“å‡ºï¼š
('weight', Parameter containing:
tensor([[2.0071]], requires_grad=True))
('bias', Parameter containing:
tensor([3.1690], requires_grad=True))
```

è¿™é‡Œæœ‰ä¸ªmodel.eval()éœ€è¦ä½ æ³¨æ„ä¸€ä¸‹ï¼Œå› ä¸ºæœ‰äº›å±‚ï¼ˆä¾‹å¦‚ï¼ŒDropoutä¸BNï¼‰åœ¨è®­ç»ƒæ—¶ä¸è¯„ä¼°æ—¶çš„çŠ¶æ€æ˜¯ä¸ä¸€æ ·çš„ï¼Œå½“è¿›å…¥è¯„ä¼°æ—¶è¦æ‰§è¡Œmodel.eval()ï¼Œæ¨¡å‹æ‰èƒ½è¿›å…¥è¯„ä¼°çŠ¶æ€ã€‚è¿™é‡Œè¯´çš„è¯„ä¼°ä¸å…‰å…‰æŒ‡ä»£è¯„ä¼°æ¨¡å‹ï¼Œä¹ŸåŒ…æ‹¬æ¨¡å‹ä¸Šçº¿æ—¶å€™æ—¶çš„çŠ¶æ€ã€‚

#### æ–¹å¼äºŒï¼šä¿å­˜ç½‘ç»œç»“æ„ä¸å‚æ•°

ç›¸æ¯”ç¬¬ä¸€ç§æ–¹å¼ï¼Œè¿™ç§æ–¹å¼åœ¨åŠ è½½æ¨¡å‹çš„æ—¶å€™ï¼Œä¸éœ€è¦åŠ è½½ç½‘ç»œç»“æ„äº†ã€‚å…·ä½“ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
# ä¿å­˜æ•´ä¸ªæ¨¡å‹
torch.save(model, './linear_model_with_arc.pth')
# åŠ è½½æ¨¡å‹ï¼Œä¸éœ€è¦åˆ›å»ºç½‘ç»œäº†
linear_model_2 = torch.load('./linear_model_with_arc.pth')
linear_model_2.eval()
for parameter in linear_model_2.named_parameters():
Â  print(parameter)
# è¾“å‡ºï¼š
('weight', Parameter containing:
tensor([[2.0071]], requires_grad=True))
('bias', Parameter containing:
tensor([3.1690], requires_grad=True))
```

è¿™æ ·æ“ä½œä»¥åï¼Œå¦‚æœä½ æˆåŠŸè¾“å‡ºäº†ç›¸åº”æ•°å€¼ï¼Œè€Œä¸”è·Ÿä¹‹å‰ä¿å­˜çš„æ¨¡å‹çš„å‚æ•°ä¸€è‡´ï¼Œå°±è¯´æ˜åŠ è½½å¯¹äº†ã€‚

## ä½¿ç”¨Torchvisonä¸­çš„æ¨¡å‹è¿›è¡Œè®­ç»ƒ

æˆ‘ä»¬å‰é¢è¯´è¿‡ï¼ŒTorchvisionæä¾›äº†ä¸€äº›å°è£…å¥½çš„ç½‘ç»œç»“æ„ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥æ‹¿è¿‡æ¥ä½¿ç”¨ã€‚ä½†æ˜¯å¹¶æ²¡æœ‰ç»†è¯´å¦‚ä½•ä½¿ç”¨å®ƒä»¬åœ¨æˆ‘ä»¬çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°±æ¥çœ‹çœ‹å¦‚ä½•ä½¿ç”¨è¿™äº›ç½‘ç»œç»“æ„ï¼Œåœ¨æˆ‘ä»¬è‡ªå·±çš„æ•°æ®ä¸Šè®­ç»ƒæˆ‘ä»¬è‡ªå·±çš„æ¨¡å‹ã€‚

### å†è¯´å¾®è°ƒ

å…¶å®ï¼ŒTorchvisionæä¾›çš„æ¨¡å‹æœ€å¤§çš„ä½œç”¨å°±æ˜¯å½“ä½œæˆ‘ä»¬è®­ç»ƒæ—¶çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç”¨æ¥åŠ é€Ÿæˆ‘ä»¬æ¨¡å‹æ”¶æ•›çš„é€Ÿåº¦ï¼Œè¿™å°±æ˜¯æ‰€è°“çš„å¾®è°ƒã€‚

å¯¹äºå¾®è°ƒï¼Œæœ€å…³é”®çš„ä¸€æ­¥å°±æ˜¯ä¹‹å‰è®²çš„**è°ƒæ•´æœ€åå…¨è¿æ¥å±‚è¾“å‡ºçš„æ•°ç›®**ã€‚Torchvisionä¸­åªæ˜¯å¯¹å„å¤§ç½‘ç»œç»“æ„çš„å¤ç°ï¼Œè€Œä¸æ˜¯å¯¹å®ƒä»¬è¿›è¡Œäº†ç»Ÿä¸€çš„å°è£…ï¼Œæ‰€ä»¥åœ¨ä¿®æ”¹å…¨è¿æ¥å±‚æ—¶ï¼Œä¸åŒçš„ç½‘ç»œæœ‰ä¸åŒçš„ä¿®æ”¹æ–¹æ³•ã€‚

ä¸è¿‡ä½ ä¹Ÿåˆ«æ‹…å¿ƒï¼Œè¿™ä¸ªä¿®æ”¹å¹¶ä¸å¤æ‚ï¼Œä½ åªéœ€è¦æ‰“å°å‡ºç½‘ç»œç»“æ„ï¼Œå°±å¯ä»¥çŸ¥é“å¦‚ä½•ä¿®æ”¹äº†ã€‚æˆ‘ä»¬æ¥ä¸‹æ¥ä»¥AlexNetä¸ºä¾‹å¸¦ä½ å°è¯•ä¸€ä¸‹å¦‚ä½•å¾®è°ƒã€‚

å‰é¢è®²Torchvisionçš„æ—¶å€™å…¶å®æåˆ°è¿‡ä¸€æ¬¡å¾®è°ƒï¼Œé‚£ä¸ªæ—¶å€™è¯´çš„æ˜¯å›ºå®šæ•´ä¸ªç½‘ç»œçš„å‚æ•°ï¼Œåªè®­ç»ƒæœ€åçš„å…¨è¿æ¥å±‚ã€‚ä»Šå¤©æˆ‘å†ç»™ä½ ä»‹ç»å¦å¤–ä¸€ç§å¾®è°ƒçš„æ–¹å¼ï¼Œé‚£å°±æ˜¯ä¿®æ”¹å…¨è¿æ¥å±‚ä¹‹åï¼Œæ•´ä¸ªç½‘ç»œéƒ½é‡æ–°å¼€å§‹è®­ç»ƒã€‚åªä¸è¿‡ï¼Œè¿™æ—¶å€™è¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•°ä½œä¸ºåˆå§‹åŒ–çš„å‚æ•°ï¼Œè¿™ç§æ–¹å¼æ›´ä¸ºå¸¸ç”¨ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±çœ‹çœ‹å¦‚ä½•ä½¿ç”¨Torchvisionä¸­æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚

é¦–å…ˆï¼Œå¯¼å…¥æ¨¡å‹ã€‚ä»£ç å¦‚ä¸‹ï¼š

```python
import torchvision.models as models
alexnet = models.alexnet(pretrained=True)
```

è¿™ä¸€æ­¥å¦‚æœä½ ä¸èƒ½â€œç§‘å­¦ä¸Šç½‘â€çš„è¯ï¼Œå¯èƒ½ä¼šæ¯”è¾ƒæ…¢ã€‚ä½ å¯ä»¥å…ˆæ ¹æ®å‘½ä»¤ä¸­æç¤ºçš„urlæ‰‹åŠ¨ä¸‹è½½ï¼Œç„¶åä½¿ç”¨ä»Šå¤©è®²çš„æ¨¡å‹åŠ è½½çš„æ–¹å¼åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
import torchvision.models as models
alexnet = models.alexnet()
alexnet.load_state_dict(torch.load('./model/alexnet-owt-4df8aa71.pth'))
```

ä¸ºäº†éªŒè¯åŠ è½½æ˜¯å¦æˆåŠŸï¼Œæˆ‘ä»¬è®©å®ƒå¯¹ä¸‹å›¾è¿›è¡Œé¢„æµ‹ï¼š  
![å›¾ç‰‡](https://static001.geekbang.org/resource/image/66/20/666181b44c23e9075debe0daf6126b20.jpg?wh=1920x1867)

ä»£ç å¦‚ä¸‹ï¼š

```python
from PIL import Image
import torchvision
import torchvision.transforms as transforms

im = Image.open('dog.jpg')

transform = transforms.Compose([
Â  Â  transforms.RandomResizedCrop((224,224)),
Â  Â  transforms.ToTensor(),
Â  Â  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
Â  Â  ])

input_tensor = transform(im).unsqueeze(0)
alexnet(input_tensor).argmax()
è¾“å‡ºï¼š263
```

è¿è¡Œäº†å‰é¢çš„ä»£ç ä¹‹åï¼Œå¯¹åº”åˆ°ImageNetçš„ç±»åˆ«æ ‡ç­¾ä¸­å¯ä»¥æ‰¾åˆ°ï¼Œ263å¯¹åº”çš„æ˜¯Pembrokeï¼ˆæŸ¯åŸºç‹—ï¼‰ï¼Œè¿™å°±è¯æ˜æ¨¡å‹å·²ç»åŠ è½½æˆåŠŸäº†ã€‚  
è¿™ä¸ªè¿‡ç¨‹ä¸­æœ‰ä¸¤ä¸ªé‡ç‚¹ä½ è¦ç•™æ„ã€‚

é¦–å…ˆï¼Œå› ä¸ºTorchvisionä¸­æ‰€æœ‰å›¾åƒåˆ†ç±»çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå®ƒä»¬éƒ½æ˜¯åœ¨ImageNetä¸Šè®­ç»ƒçš„ã€‚æ‰€ä»¥ï¼Œè¾“å…¥æ•°æ®éœ€è¦æ˜¯3é€šé“çš„æ•°æ®ï¼Œä¹Ÿå°±æ˜¯shapeä¸º(B, 3, H, W)çš„Tensorï¼ŒBä¸ºbatchsizeã€‚æˆ‘ä»¬éœ€è¦ä½¿ç”¨å‡å€¼ä¸º\[0.485, 0.456, 0.406]ï¼Œæ ‡å‡†å·®ä¸º\[0.229, 0.224, 0.225]å¯¹æ•°æ®è¿›è¡Œæ­£è§„åŒ–ã€‚

å¦å¤–ï¼Œä»ç†è®ºä¸Šè¯´ï¼Œå¤§éƒ¨åˆ†çš„ç»å…¸å·ç§¯ç¥ç»æœ€åé‡‡ç”¨å…¨è¿æ¥å±‚ï¼ˆä¹Ÿå°±æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„æ„ŸçŸ¥æœºï¼‰è¿›è¡Œåˆ†ç±»ï¼Œè¿™ä¹Ÿå¯¼è‡´äº†ç½‘ç»œçš„è¾“å…¥å°ºå¯¸æ˜¯å›ºå®šçš„ã€‚ä½†æ˜¯ï¼Œåœ¨Torchvisionçš„æ¨¡å‹å¯ä»¥æ¥å—ä»»æ„å°ºå¯¸çš„è¾“å…¥çš„ã€‚

è¿™æ˜¯å› ä¸ºTorchvisionå¯¹æ¨¡å‹åšäº†ä¼˜åŒ–ï¼Œæœ‰çš„ç½‘ç»œæ˜¯åœ¨æœ€åçš„å·ç§¯å±‚é‡‡ç”¨äº†å…¨å±€å¹³å‡ï¼Œæˆ–è€…é‡‡ç”¨çš„æ˜¯å…¨å·ç§¯ç½‘ç»œã€‚è¿™ä¸¤ç§æ–¹å¼éƒ½å¯ä»¥è®©ç½‘ç»œæ¥å—åœ¨æœ€å°è¾“å…¥å°ºå¯¸åŸºç¡€ä¹‹ä¸Šï¼Œä»»æ„å°ºåº¦çš„è¾“å…¥ã€‚è¿™ä¸€ç‚¹ï¼Œä½ ç°åœ¨å¯èƒ½è®¤è¯†å¾—è¿˜ä¸å¤Ÿæ¸…æ¥šï¼Œä¸è¿‡åˆ«æ‹…å¿ƒï¼Œä»¥åæˆ‘ä»¬å­¦ä¹ å®Œå›¾åƒåˆ†ç±»ç†è®ºä¹‹åï¼Œä½ ä¼šç†è§£å¾—æ›´åŠ é€å½»ã€‚

æˆ‘ä»¬å›åˆ°å¾®è°ƒè¿™ä¸ªä¸»é¢˜ã€‚æ­£å¦‚åˆšæ‰æ‰€è¯´ï¼Œè®­ç»ƒä¸€ä¸ªAlexNetéœ€è¦çš„æ•°æ®å¿…é¡»æ˜¯ä¸‰é€šé“æ•°æ®ã€‚æ‰€ä»¥ï¼Œåœ¨è¿™é‡Œæˆ‘ä½¿ç”¨äº†CIFAR-10å…¬å¼€æ•°æ®é›†ä¸¾ä¾‹ã€‚

CIFAR-10æ•°æ®é›†ä¸€å…±æœ‰60000å¼ å›¾ç‰‡æ„æˆï¼Œå…±10ä¸ªç±»åˆ«ï¼Œæ¯ä¸€ç±»åŒ…å«6000å›¾ç‰‡ã€‚æ¯å¼ å›¾ç‰‡ä¸º32x32çš„RGBå›¾ç‰‡ã€‚å…¶ä¸­50000å¼ å›¾ç‰‡ä½œä¸ºè®­ç»ƒé›†ï¼Œ10000å¼ å›¾ç‰‡ä½œä¸ºæµ‹è¯•é›†ã€‚

å¯ä»¥è¯´CIFAR-10æ˜¯éå¸¸æ¥è¿‘çœŸå®é¡¹ç›®æ•°æ®çš„æ•°æ®é›†äº†ï¼Œå› ä¸ºçœŸå®é¡¹ç›®ä¸­çš„æ•°æ®é€šå¸¸æ˜¯RGBä¸‰é€šé“æ•°æ®ï¼Œè€ŒCIFAR-10åŒæ ·æ˜¯ä¸‰é€šé“æ•°æ®ã€‚

æˆ‘ä»¬ç”¨ä¹‹å‰è®²çš„make\_gridæ–¹æ³•ï¼Œå°†CIFAR-10çš„æ•°æ®æ‰“å°å‡ºæ¥ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
cifar10_dataset = torchvision.datasets.CIFAR10(root='./data',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â train=False,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â transform=transforms.ToTensor(),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â target_transform=None,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â download=True)
# å–32å¼ å›¾ç‰‡çš„tensor
tensor_dataloader = DataLoader(dataset=cifar10_dataset,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â batch_size=32)
data_iter = iter(tensor_dataloader)
img_tensor, label_tensor = data_iter.next()
print(img_tensor.shape)
grid_tensor = torchvision.utils.make_grid(img_tensor, nrow=16, padding=2)
grid_img = transforms.ToPILImage()(grid_tensor)
display(grid_img)
```

è¯·æ³¨æ„ï¼Œä¸Šè¿°ä»£ç ä¸­çš„transformï¼Œæˆ‘ä¸ºäº†æ‰“å°å›¾ç‰‡åªä½¿ç”¨äº†transform.ToTensor()è¾“å‡ºå›¾ç‰‡ï¼Œç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š  
![](https://static001.geekbang.org/resource/image/f0/f2/f0b5f4ed8c24fbb81c7b7c71a907a6f2.jpg?wh=546x546)

è¿™é‡Œæˆ‘ç‰¹åˆ«è¯´æ˜ä¸€ä¸‹ï¼Œå› ä¸ºè¿™ä¸ªè®­ç»ƒé›†çš„æ•°æ®éƒ½æ˜¯32x32çš„ï¼Œæ‰€ä»¥ä½ ç°åœ¨çœ‹åˆ°çš„å°±æ˜¯åŸå›¾æ•ˆæœï¼Œå›¾ç‰‡å¤§å°å¹¶ä¸å½±å“å’±ä»¬çš„å­¦ä¹ ã€‚

ä¸‹é¢æˆ‘ä»¬è¦åšçš„æ˜¯ä¿®æ”¹å…¨è¿æ¥å±‚ï¼Œç›´æ¥printå°±å¯ä»¥æ‰“å°å‡ºç½‘ç»œç»“æ„ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
print(alexnet)
è¾“å‡ºï¼š
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
```

å¯ä»¥çœ‹åˆ°ï¼Œæœ€åå…¨è¿æ¥å±‚è¾“å…¥æ˜¯4096ä¸ªå•å…ƒï¼Œè¾“å‡ºæ˜¯1000ä¸ªå•å…ƒï¼Œæˆ‘ä»¬è¦æŠŠå®ƒä¿®æ”¹ä¸ºè¾“å‡ºæ˜¯10ä¸ªå•å…ƒçš„å…¨è¿æ¥å±‚ï¼ˆCIFR10æœ‰10ç±»ï¼‰ã€‚ä»£ç å¦‚ä¸‹ï¼š

```python
# æå–åˆ†ç±»å±‚çš„è¾“å…¥å‚æ•°
fc_in_features = alexnet.classifier[6].in_features

# ä¿®æ”¹é¢„è®­ç»ƒæ¨¡å‹çš„è¾“å‡ºåˆ†ç±»æ•°
alexnet.classifier[6] = torch.nn.Linear(fc_in_features, 10)
print(alexnet)
è¾“å‡ºï¼š
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
```

è¿™æ—¶ï¼Œä½ å¯ä»¥å‘ç°è¾“å‡ºå°±å˜ä¸º10ä¸ªå•å…ƒäº†ã€‚

æ¥ä¸‹æ¥å°±æ˜¯åœ¨CIFAR-10ä¸Šï¼Œä½¿ç”¨AlexNetä½œä¸ºé¢„è®­ç»ƒæ¨¡å‹è®­ç»ƒæˆ‘ä»¬è‡ªå·±çš„æ¨¡å‹äº†ã€‚é¦–å…ˆæ˜¯æ•°æ®è¯»å…¥ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
transform = transforms.Compose([
Â  Â  transforms.RandomResizedCrop((224,224)),
Â  Â  transforms.ToTensor(),
Â  Â  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
Â  Â  ])
cifar10_dataset = torchvision.datasets.CIFAR10(root='./data',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â train=False,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â transform=transform,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â target_transform=None,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â download=True)
dataloader = DataLoader(dataset=cifar10_dataset, # ä¼ å…¥çš„æ•°æ®é›†, å¿…é¡»å‚æ•°
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â batch_size=32,Â  Â  Â  Â # è¾“å‡ºçš„batchå¤§å°
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â shuffle=True,Â  Â  Â  Â # æ•°æ®æ˜¯å¦æ‰“ä¹±
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â num_workers=2)Â  Â  Â  # è¿›ç¨‹æ•°, 0è¡¨ç¤ºåªæœ‰ä¸»è¿›ç¨‹
```

è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘æ›´æ”¹äº†transformï¼Œå¹¶ä¸”å°†å›¾ç‰‡resizeåˆ°224x224å¤§å°ã€‚è¿™ä¸ªå°ºå¯¸æ˜¯Torchvisionä¸­æ¨èçš„ä¸€ä¸ªæœ€å°è®­ç»ƒå°ºå¯¸ã€‚æ¨¡å‹å°±æ˜¯æˆ‘ä»¬ä¿®æ”¹åçš„AlexNetï¼Œä¹‹åçš„è®­ç»ƒè·Ÿæˆ‘ä»¬ä¹‹å‰è®²çš„æ˜¯ä¸€æ ·çš„ã€‚  
å…ˆå®šä¹‰ä¼˜åŒ–å™¨ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
optimizer = torch.optim.SGD(alexnet.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)
```

ç„¶åå¼€å§‹æ¨¡å‹è®­ç»ƒï¼Œæ˜¯ä¸æ˜¯æ„Ÿè§‰åé¢çš„ä»£ç å¾ˆçœ¼ç†Ÿï¼Œæ²¡é”™ï¼Œå®ƒè·Ÿæˆ‘ä»¬ä¹‹å‰è®²çš„ä¸€æ ·ï¼š

```python
# è®­ç»ƒ3ä¸ªEpoch
for epoch in range(3):
Â  Â  for item in dataloader:Â 
Â  Â  Â  Â  output = alexnet(item[0])
Â  Â  Â  Â  target = item[1]
Â  Â  Â  Â  # ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°
Â  Â  Â  Â  loss = nn.CrossEntropyLoss()(output, target)
Â  Â  Â  Â  print('Epoch {}, Loss {}'.format(epoch + 1 , loss))
Â  Â  Â  Â  #ä»¥ä¸‹ä»£ç çš„å«ä¹‰ï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰çš„æ–‡ç« ä¸­å·²ç»ä»‹ç»è¿‡äº†
Â  Â  Â  Â  alexnet.zero_grad()
Â  Â  Â  Â  loss.backward()
Â  Â  Â  Â  optimizer.step()
```

è¿™é‡Œç”¨åˆ°çš„å¾®è°ƒæ–¹å¼ï¼Œå°±æ˜¯æ‰€æœ‰å‚æ•°éƒ½éœ€è¦è¿›è¡Œé‡æ–°è®­ç»ƒã€‚

è€Œç¬¬ä¸€ç§æ–¹å¼ï¼ˆå›ºå®šæ•´ä¸ªç½‘ç»œçš„å‚æ•°ï¼Œåªè®­ç»ƒæœ€åçš„å…¨è¿æ¥å±‚ï¼‰ï¼Œåªéœ€è¦åœ¨è¯»å–å®Œé¢„è®­ç»ƒæ¨¡å‹ä¹‹åï¼Œå°†å…¨è¿æ¥å±‚ä¹‹å‰çš„å‚æ•°å…¨éƒ¨é”æ­»å³å¯ï¼Œä¹Ÿå°±æ˜¯è®©ä»–ä»¬æ— æ³•è®­ç»ƒï¼Œæˆ‘ä»¬æ¨¡å‹è®­ç»ƒæ—¶ï¼Œåªè®­ç»ƒå…¨è¿æ¥å±‚å°±è¡Œäº†ï¼Œå…¶ä½™ä¸€åˆ‡éƒ½ä¸å˜ã€‚ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
alexnet = models.alexnet()
alexnet.load_state_dict(torch.load('./model/alexnet-owt-4df8aa71.pth'))
for param in alexnet.parameters():
    param.requires_grad = False
```

è¯´åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¾®è°ƒå°±è®²å®Œäº†ï¼Œä½ å¯ä»¥è‡ªå·±åŠ¨æ‰‹è¯•è¯•çœ‹ã€‚

## æ€»ç»“

ä»Šå¤©çš„å†…å®¹ï¼Œä¸»è¦æ˜¯å›´ç»•å¦‚ä½•è‡ªå·±æ­å»ºä¸€ä¸ªç½‘ç»œæ¨¡å‹ï¼Œæˆ‘ä»¬ä»‹ç»äº†nn.Moduleæ¨¡å—ä»¥åŠå›´ç»•å®ƒçš„ä¸€äº›æ–¹æ³•ã€‚

æ ¹æ®è¿™è®²æˆ‘åˆ†äº«ç»™ä½ çš„æ€è·¯ï¼Œä¹‹åå¦‚æœä½ æœ‰ä»€ä¹ˆæƒ³æ³•æ—¶ï¼Œå°±å¯ä»¥å¿«é€Ÿæ­å»ºä¸€ä¸ªæ¨¡å‹è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ã€‚

å…¶å®ï¼Œå®é™…çš„å¼€å‘ä¸­ï¼Œæˆ‘ä»¬å¾ˆå°‘ä¼šè‡ªå·±å»æ„å»ºä¸€ä¸ªç½‘ç»œï¼Œç»å¤§å¤šæ•°éƒ½æ˜¯ç›´æ¥ä½¿ç”¨å‰äººå·²ç»æ„å»ºå¥½çš„ä¸€äº›ç»å…¸ç½‘ç»œï¼Œä¾‹å¦‚ï¼ŒTorchvisionä¸­é‚£äº›æ¨¡å‹ã€‚å½“ä½ å»çœ‹ä¸€äº›è¿˜æ²¡æœ‰è¢«å°è£…åˆ°PyTorchçš„æ¨¡å‹çš„æ—¶å€™ï¼Œä»Šå¤©æ‰€å­¦çš„å†…å®¹å°±èƒ½å¤Ÿå¸®ä½ ç›´æ¥å€Ÿé‰´å‰äººçš„å·¥ä½œç»“æœï¼Œè®­ç»ƒå±äºè‡ªå·±çš„æ¨¡å‹ã€‚

æœ€åï¼Œæˆ‘å†ç»“åˆè‡ªå·±çš„å­¦ä¹ ç ”ç©¶ç»éªŒï¼Œç»™æœ‰å…´è¶£äº†è§£æ›´å¤šæ·±åº¦å­¦ä¹ çŸ¥è¯†çš„åŒå­¦æä¾›ä¸€äº›å­¦ä¹ çº¿ç´¢ã€‚ç›®å‰æˆ‘ä»¬åªè®²äº†å·ç§¯å±‚ï¼Œå¯¹äºä¸€ä¸ªç½‘ç»œè¿˜æœ‰å¾ˆå¤šå…¶ä½™å±‚ï¼Œæ¯”å¦‚Dropoutã€Poolingå±‚ã€BNå±‚ã€æ¿€æ´»å‡½æ•°ç­‰ã€‚Dropoutå‡½æ•°ã€Poolingå±‚ã€æ¿€æ´»å‡½æ•°ç›¸å¯¹æ¯”è¾ƒå¥½ç†è§£ï¼ŒBNå±‚å¯èƒ½ç¨å¾®å¤æ‚ä¸€äº›ã€‚

å¦å¤–ï¼Œç»†å¿ƒçš„å°ä¼™ä¼´åº”è¯¥å‘ç°äº†ï¼Œæˆ‘ä»¬åœ¨æ‰“å°AlexNetç½‘ç»œç»“æ„ä¸­çš„æ—¶å€™ï¼Œå®ƒçš„ä¸€éƒ¨åˆ†æ˜¯ä½¿ç”¨nn.Sequentialæ„å»ºçš„ã€‚**nn.Sequentialæ˜¯ä¸€ç§å¿«é€Ÿæ„å»ºç½‘ç»œçš„æ–¹å¼**ï¼Œæœ‰äº†è¿™èŠ‚è¯¾çš„çŸ¥è¯†ä½œå‚¨å¤‡ï¼Œå¼„æ‡‚è¿™ä¸ªæ–¹å¼ä½ ä¼šè§‰å¾—éå¸¸ç®€å•ï¼Œä¹Ÿæ¨èä½ å»çœ‹çœ‹ã€‚

## æ¯è¯¾ä¸€ç»ƒ

è¯·ä½ è‡ªå·±æ„å»ºä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼ŒåŸºäºCIFAR-10ï¼Œè®­ç»ƒä¸€ä¸ªå›¾åƒåˆ†ç±»æ¨¡å‹ã€‚å› ä¸ºè¿˜æ²¡æœ‰å­¦ä¹ å›¾åƒåˆ†ç±»åŸç†ï¼Œæ‰€ä»¥æˆ‘å…ˆå¸®ä½ å†™å¥½äº†ç½‘ç»œçš„ç»“æ„ï¼Œéœ€è¦ä½ è¡¥å…¨æ•°æ®è¯»å–ã€æŸå¤±å‡½æ•°(äº¤å‰ç†µæŸå¤±)ä¸ä¼˜åŒ–æ–¹æ³•ï¼ˆSGDï¼‰ç­‰éƒ¨åˆ†ã€‚

```python
class MyCNN(nn.Module):
Â  Â  def __init__(self):
Â  Â  Â  Â  super().__init__()
Â  Â  Â  Â  self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
Â  Â  Â  Â  # conv1è¾“å‡ºçš„ç‰¹å¾å›¾ä¸º222x222å¤§å°
Â  Â  Â  Â  self.fc = nn.Linear(16 * 222 * 222, 10)

Â  Â  def forward(self, input):
Â  Â  Â  Â  x = self.conv1(input)
Â  Â  Â  Â  # è¿›å»å…¨è¿æ¥å±‚ä¹‹å‰ï¼Œå…ˆå°†ç‰¹å¾å›¾é“ºå¹³
Â  Â  Â  Â  x = x.view(x.shape[0], -1)
Â  Â  Â  Â  x = self.fc(x)
Â  Â  Â  Â  return x
```

æ¬¢è¿ä½ åœ¨ç•™è¨€åŒºå’Œæˆ‘äº¤æµè®¨è®ºã€‚å¦‚æœè¿™èŠ‚è¯¾å¯¹ä½ æœ‰å¸®åŠ©ï¼Œä¹Ÿæ¨èä½ é¡ºæ‰‹åˆ†äº«ç»™æ›´å¤šçš„åŒäº‹ã€æœ‹å‹ï¼Œè·Ÿä»–ä¸€èµ·å­¦ä¹ è¿›æ­¥ã€‚
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ15ï¼‰</strong></div><ul>
<li><span>vcjmhg</span> ğŸ‘ï¼ˆ15ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>class MyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        # conv1è¾“å‡ºçš„ç‰¹å¾å›¾ä¸º222x222å¤§å°
        self.fc = nn.Linear(16 * 222 * 222, 10)

    def forward(self, input):
        x = self.conv1(input)
        # è¿›å»å…¨è¿æ¥å±‚ä¹‹å‰ï¼Œå…ˆå°†ç‰¹å¾å›¾é“ºå¹³
        x = x.view(x.shape[0], -1)
        x = self.fc(x)
        return x
# å°½é‡ä½¿ç”¨gpuè¿›è¡Œè®­ç»ƒ,å¦‚æœæ²¡æœ‰cpuåˆ™ä½¿ç”¨gpuæ¥è®­ç»ƒ
device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
cnn = MyCNN().to(device)
transform = transforms.Compose([
    # ä¿®æ”¹è£å‰ªå›¾ç‰‡çš„å°ºå¯¸
    transforms.RandomResizedCrop((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,
                                               train=False,
                                               transform=transform,
                                               target_transform=None,
                                               download=True)
dataloader = DataLoader(dataset=cifar10_dataset,  # ä¼ å…¥çš„æ•°æ®é›†, å¿…é¡»å‚æ•°
                        batch_size=32,  # è¾“å‡ºçš„batchå¤§å°
                        shuffle=True,  # æ•°æ®æ˜¯å¦æ‰“ä¹±
                        num_workers=2)  # è¿›ç¨‹æ•°, 0è¡¨ç¤ºåªæœ‰ä¸»è¿›ç¨‹
# å®šä¹‰ä¼˜åŒ–å™¨
optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)
steps = 0
for epoch in range(16):
    for item in dataloader:
        steps += 1
        output = cnn(item[0].to(device))
        target = item[1].to(device)
        # ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°
        loss = nn.CrossEntropyLoss()(output, target)
        # æ¯100æ­¥æ‰“å°ä¸€æ¬¡loss
        if steps % 100 == 0:
            print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1, loss))
        cnn.zero_grad()
        loss.backward()
        optimizer.step()
# æµ‹è¯•åˆ†ç±»ç»“æœ
im = Image.open(&#39;data&#47;img.png&#39;)
input_tensor = transform(im).unsqueeze(0)
result = cnn(input_tensor.to(device)).argmax()
print(result)
# tensor(3, device=&#39;cuda:0&#39;)</p>2021-11-16</li><br/><li><span>Mr_æå†²</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ8ï¼‰<p>æˆ‘åœ¨ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„alexnet-owt-7be5be79.pthæ¨¡å‹ï¼Œåå¤æ‰§è¡Œä¸‹é¢è¿™æ®µä»£ç çš„æ—¶å€™
alexnet(input_tensor).argmax()
å¾—åˆ°çš„ç»“æœå¹¶ä¸æ€»æ˜¯263ï¼Œè€Œæœ‰æ—¶å€™ä¼šå¾—åˆ°151å’Œ264æˆ–è€…å…¶ä»–çš„æ•°å€¼ï¼Œè¯·é—®æˆ‘æœ€ç»ˆåº”è¯¥ç›¸ä¿¡å“ªä¸€ä¸ªé¢„æµ‹ç»“æœå‘¢ï¼Œæ˜¯è¿›è¡Œå¤šæ¬¡é¢„æµ‹å–é¢„æµ‹æ¬¡æ•°æœ€å¤šçš„é‚£ä¸ªå—ï¼Ÿè¿˜æ˜¯æœ‰åˆ«çš„ç§‘å­¦çš„æ–¹æ³•å‘¢ï¼Ÿ</p>2022-03-15</li><br/><li><span>clee</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è°ƒæ•´ä¹‹åï¼Œå¯ä»¥æ­£å¸¸è®­ç»ƒäº†ï¼Œä½†æ˜¯æµ‹è¯•æ•°æ®çš„æ—¶å€™æˆ‘å‘ç°æœ‰äº›å›¾ç‰‡åˆ†ç±»ä¼šæœ‰é—®é¢˜ï¼Œæ¯”å¦‚ç‹—å’ŒçŒ«ï¼Œé¹¿å’Œé©¬å°±å®¹æ˜“åˆ†ç±»é”™è¯¯ï¼Œè¿™æ˜¯å› ä¸ºæ¬ æ‹Ÿåˆå—ï¼Ÿåº”è¯¥å¦‚ä½•ä¼˜åŒ–ï¼Ÿ</p>2021-11-16</li><br/><li><span>Monroe  He</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è€å¸ˆè¯·æ•™ä¸€ä¸ªé—®é¢˜ï¼Œåœ¨æ¢¯åº¦æ¸…é›¶ä»£ç ä¸­

13 èŠ‚è¯¾ç”¨çš„æ˜¯ä¼˜åŒ–å™¨
optimizer.zero_grad()

è¿™èŠ‚è¯¾ç”¨çš„æ˜¯æ¨¡å‹
alexnet.zero_grad()

è¿™ä¸¤è¡Œä»£ç æœ‰ä»€ä¹ˆåŒºåˆ«å—ï¼Ÿ
</p>2023-03-19</li><br/><li><span>zhangting</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<p>è€å¸ˆè¯·æ•™ä¸ªé—®é¢˜ï¼Œä¸ºä»€ä¹ˆæ”¹å…¨è¿æ¥åï¼Œè®­ç»ƒå‡ºæ¥çš„æ¨¡å‹ï¼Œæ€»æ˜¯è¾“å‡ºçš„æ˜¯5ã€‚è€Œæœªåšæ”¹åŠ¨å‰ï¼Œé¢„æµ‹å‡ºæ¥çš„æ˜¯263.æºç å¦‚ä¸‹ï¼š

alexnet = models.alexnet()
alexnet.load_state_dict(torch.load(&#39;.&#47;model&#47;alexnet-owt-7be5be79.pth&#39;)) 

fc_in_features = alexnet.classifier[6].in_features

alexnet.classifier[6] = torch.nn.Linear(fc_in_features, 10)
print(alexnet)

transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,                                       
                                               train=False,                                       
                                               transform=transform,                                       
                                               target_transform=None,                                       
                                               download=False)
dataloader = DataLoader(dataset=cifar10_dataset, batch_size=32, shuffle=True, num_workers=4)

optimizer = torch.optim.SGD(alexnet.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

for epoch in range(3):
    for item in dataloader: 
        output = alexnet(item[0])
        target = item[1]
        loss = nn.CrossEntropyLoss()(output, target)
        print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss))
        alexnet.zero_grad()
        loss.backward()
        optimizer.step()
       
im = Image.open(&#39;dog.jpg&#39;)
transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
input_tensor = transform(im).unsqueeze(0)

alexnet.eval()

print(alexnet(input_tensor).argmax())</p>2022-05-12</li><br/><li><span>åˆ˜åˆ©</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ5ï¼‰<p>hiï¼Œè€å¸ˆï¼Œå¾®è°ƒçš„æ—¶å€™ï¼Œå¦‚æœè¿™æ ·å†™ï¼Œå‚æ•°éƒ½ä¸æ›´æ–°äº†ï¼Œé‚£è¿˜æœ‰å“ªéƒ¨åˆ†å‚æ•°ä¼šè¢«è®­ç»ƒå‘¢ï¼Ÿæ˜¯éœ€è¦å†æ¥ä¸€å±‚å…¨è¿æ¥å±‚ä¹ˆï¼Ÿ
alexnet = models.alexnet()
alexnet.load_state_dict(torch.load(&#39;.&#47;model&#47;alexnet-owt-4df8aa71.pth&#39;))
for param in alexnet.parameters(): 
    param.requires_grad = False</p>2022-05-03</li><br/><li><span>é©¬å…‹å›¾å¸ƒ</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>æ€è€ƒï¼š

ä½¿ç”¨ `nn.CrossEntropyLoss` ä½œä¸º loss function æ—¶ï¼Œä¼šè‡ªåŠ¨åœ¨ç½‘ç»œæœ€åæ·»åŠ  `nn.LogSoftmax` å’Œ `nn.nLLLos`ï¼Œå› æ­¤ä¸ç”¨å†åœ¨ fc å±‚åé¢æ‰‹åŠ¨æ·»åŠ  Softmax å±‚ï¼›

é—®é¢˜ï¼š

transform ä¸­ï¼Œæ ‡å‡†åŒ–çš„ mean å’Œ std æ˜¯å¦‚ä½•ç¡®å®šçš„ï¼ˆæˆ‘ä»¬éœ€è¦ä½¿ç”¨å‡å€¼ä¸º[0.485, 0.456, 0.406]ï¼Œæ ‡å‡†å·®ä¸º[0.229, 0.224, 0.225]å¯¹æ•°æ®è¿›è¡Œæ­£è§„åŒ–ï¼‰ï¼Ÿ</p>2021-11-12</li><br/><li><span>æ¨æ°</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>import torchvision.models as models
from PIL import Image
import torchvision
import torchvision.transforms as transforms

alexnet = models.alexnet(pretrained=True)

im = Image.open(&#39;.&#47;data&#47;dog.jpg&#39;)

transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

input_tensor = transform(im).unsqueeze(0)
print(alexnet(input_tensor).argmax())

ä»¥ä¸Šä»£ç è¾“å‡ºçš„ä¸ä¸€å®šæ˜¯264ï¼Œè¿™ä¸ªæ˜¯å•¥æƒ…å†µï¼Ÿ</p>2022-10-04</li><br/><li><span>Geek_827444</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>è€å¸ˆæ‚¨å¥½ï¼šæˆ‘ä¸€æ­¥ä¸€æ­¥æŒ‰ç…§å’±ä»¬é‚£ä¸ªæ­¥éª¤æ¥çš„ï¼Œä¸ºä»€ä¹ˆä»£ç è¿è¡Œä¸äº†é‚£ï¼Ÿè°¢è°¢æ‚¨ï¼

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models

import torchvision.models as models
alexnet = models.alexnet(pretrained=True)


import torchvision.transforms as transforms

transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])
])

import torchvision

cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,#æ³¨ï¼šè¿™é‡Œæ˜¯å­˜åœ¨													pycharmæ–‡ä»¶å½“ä¸­çš„dataæ–‡ä»¶å¤¹é‡Œ
                                              train=False,
                                              transform=transform,
                                              target_transform=None,
                                              download=True)

from torch.utils.data import DataLoader

dataloader = DataLoader(dataset=cifar10_dataset,
                       batch_size=32,
                       shuffle=True,
                       num_workers=2)



fc_in_features = alexnet.classifier[6].in_features
alexnet.classifier[6] = torch.nn.Linear(fc_in_features,10)

optimizer = torch.optim.SGD(alexnet.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

for epoch in range(3):
    # â†“å®šä¹‰æ¯”å¯¹çš„å…ƒç´ 
    for item in dataloader:
        output = alexnet(item[0])
        target = item[1]

        # â†“ä½¿ç”¨æŸå¤±å‡½æ•°
        loss = nn.CrossEntropyLoss()(output, target)
        print(&#39;Epoch{},Loss{}&#39;.format(epoch + 1, loss))

        # â†“æ›´æ–°æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å‡½æ•°
        alexnet.zero_grad()
        loss.backward()
        optimizer.step()

</p>2022-08-09</li><br/><li><span>John(æ˜“ç­‹)</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>å·¨äººè‚©è†€@é©¬å…‹å›¾åº“
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from PIL import Image
transform = transforms.Compose([
    transforms.RandomResizedCrop((224, 224)), 
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

cifar10_train_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,train=True,transform=transform,target_transform=None)
train_loader = torch.utils.data.DataLoader(dataset=cifar10_train_dataset,batch_size=32,shuffle=True,num_workers=2) 
classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;)
n_total_steps = len(train_loader)

class MyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        self.fc = nn.Linear(16 * 222 * 222, 10)
        
    def forward(self, input):
        x = self.conv1(input)
        x = x.view(x.shape[0], -1)
        x = self.fc(x)
        return x
    
device = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
model = MyCNN().to(device)

criterion = nn.CrossEntropyLoss() 
optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

print(&#39;Start training...&#39;)
for epoch in range(4):
    for i, (images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)
        labels_pred = model(images)
        loss = criterion(labels_pred, labels)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step
        
        if (i+1) % 100 == 0:
            print(f&#39;Epoch [{epoch+1}&#47;{4}], Step [{i+1:5d}&#47;{n_total_steps}], Loss={loss.item():.4f}&#39;)

print(&#39;Training complete!&#39;)

with torch.no_grad():
    im = Image.open(&#39;.&#47;images&#47;dog.jpg&#39;)
    input_tensor = transform(im).unsqueeze(0).to(device)
    label_pred = model(input_tensor).argmax()
    print(f&#39;Your label predicted: {classes[label_pred]}&#39;)</p>2022-08-07</li><br/><li><span>Zeurd</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è€å¸ˆï¼Œæƒ³è¯·é—®ä¸€ä¸‹ï¼Œæˆ‘åœ¨æ¢äº†ä¸€ä¸ªæ¨¡å‹InceptionV3ï¼ŒåšæŸå¤±å‡½æ•°çš„æ—¶å€™ï¼Œä¼šæç¤ºæˆ‘argument &#39;input&#39; (position 1) must be Tensor, not InceptionOutputsè¿™æ˜¯ä»€ä¹ˆåŸå› å‘¢ï¼Ÿæˆ‘ç”¨outputé¢„æµ‹å®Œè¾“å‡ºçš„æ˜¯ä¸€ä¸ªInceptionOutPutsçš„é‡ï¼Œè€Œä¸æ˜¯Tensorå½¢å¼çš„ï¼Œå½“æˆ‘æƒ³ç”¨torch.tensoråˆä¼šæç¤ºæˆ‘ä¸æ˜¯ä¸€ç»´çš„ï¼Œä¸èƒ½è½¬åŒ–</p>2022-07-25</li><br/><li><span>ä¸‡åŒ–8af10b</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è€å¸ˆï¼Œè¯·æ•™ä¸€ä¸‹ï¼Œä¸Šé¢çš„ä¾‹å­

# è®­ç»ƒ3ä¸ªEpoch
for epoch in range(3): 
for item in dataloader: 
output = alexnet(item[0]) target = item[1] 
# ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•° loss = nn.CrossEntropyLoss()(output, target) 
print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss)) #ä»¥ä¸‹ä»£ç çš„å«ä¹‰ï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰çš„æ–‡ç« ä¸­å·²ç»ä»‹ç»è¿‡äº† alexnet.zero_grad() 
loss.backward()
 optimizer.step()


æ¯epoché‡Œé¢ä½œçš„æ¬¡æ•°æˆ‘åšäº†è®¡æ•°æ˜¯313æ¬¡backwardsï¼Œä¸ºä»€ä¹ˆä¼šæ˜¯è¿™ä¸ªæ•°å­—ï¼Œæˆ‘è®¡ç®—äº†ä»¥ä¸‹50000å¼ è®­ç»ƒé›†ï¼Œ50000&#47;32&#47;2=781.25æ¬¡æ‰å¯¹é˜¿ã€‚è¯·è€å¸ˆç‚¹æ˜æˆ‘ç®—é”™åœ¨å“ªé‡Œï¼Ÿ</p>2022-06-23</li><br/><li><span>äºšæ—</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>ç…§æŠ„æŠ„å‡ºæ¥äº†ï¼Œä½†æ˜¯å¯¹æŸå¤±å‡½æ•°é€‰å–ï¼Œä¼˜åŒ–å™¨å‚æ•°è®¾ç½®ï¼Œè¿˜æ˜¯ä¸€è„¸æ‡µ</p>2022-05-20</li><br/><li><span>Geek_fc975d</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>or epoch in range(3): for item in dataloader: output = alexnet(item[0]) target = item[1] # ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•° loss = nn.CrossEntropyLoss()(output, target) print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss)) #ä»¥ä¸‹ä»£ç çš„å«ä¹‰ï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰çš„æ–‡ç« ä¸­å·²ç»ä»‹ç»è¿‡äº† alexnet.zero_grad() loss.backward() optimizer.step()

æƒ³è¯·æ•™è€å¸ˆå’Œå„ä½åŒå­¦ï¼Œè¿™ä¸ªitemæ˜¯å¤šå°‘ï¼Œ æ˜¯cifar10çš„æ€»æ•°æ®æ•°&#47;batch_sizeå—ï¼ŸåŸå…ˆæˆ‘ä»¥ä¸ºè¿™ä¸ªå€¼ç­‰äºbatch-sizeï¼Œçœ‹èµ·æ¥è¿™ä¸ªç»“æœä¸å¯¹å‘¢ã€‚

è¿˜æƒ³è¯·æ•™ä¸‹epochè¿™ä¸ªå‚æ•°æ˜¯æŒ‡ä»€ä¹ˆï¼Œ æ˜¯è¯´æŒ‰ç…§è¿™ä¸ªbatch_sizeå°†æ•´ä¸ªæ•°æ®é›†è®­ç»ƒå‡ æ¬¡å—ï¼Ÿ

æˆ‘åœ¨Jupyterä¸­è®­ç»ƒï¼Œè®­ç»ƒçš„é€Ÿåº¦è¶…çº§æ…¢ï¼Œæœ‰ä»€ä¹ˆæå‡çš„æ–¹æ³•å—ï¼Ÿ</p>2022-04-10</li><br/><li><span>ç’ç’æ£’</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>ä½ å¥½ï¼Œè€å¸ˆï¼Œè¯·æ•™ä¸‹ï¼Œæƒ³ç”¨é¢„è®­ç»ƒçš„effientnet b0æ¥è®­ç»ƒè‡ªå·±çš„æ•°æ®ï¼Œè‡ªå·±çš„æ•°æ®æ˜¯pngçš„å›¾ç‰‡ï¼Œè¿™ä¸ªè¡Œçš„é€šå—ï¼Œæ˜¯éœ€è¦ä¿®æ”¹ä¸‹è¾“å…¥é€šé“æ•°å°±å¯ä»¥å—ï¼Œè¿˜æ˜¯è¯´ä¸èƒ½ä½¿ç”¨é¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œå¯ä»¥é‡æ–°è®­ç»ƒä¸€ä¸ªæ–°çš„æ¨¡å‹ï¼Ÿ</p>2021-12-21</li><br/>
</ul>