ä½ å¥½ï¼Œæˆ‘æ˜¯æ–¹è¿œã€‚

å‰é¢æˆ‘ä»¬èŠ±äº†ä¸å°‘æ—¶é—´ï¼Œæ—¢å­¦ä¹ äº†æ•°æ®éƒ¨åˆ†çš„çŸ¥è¯†ï¼Œè¿˜ç ”ç©¶äº†æ¨¡å‹çš„ä¼˜åŒ–æ–¹æ³•ã€æŸå¤±å‡½æ•°ä»¥åŠå·ç§¯è®¡ç®—ã€‚ä½ å¯èƒ½æ„Ÿè§‰è¿™äº›çŸ¥è¯†è¿˜æœ‰äº›é›¶é›¶æ•£æ•£ï¼Œä½†å…¶å®æˆ‘ä»¬ä¸çŸ¥ä¸è§‰ä¸­ï¼Œå·²ç»æ‹¿ä¸‹äº†æ¨¡å‹è®­ç»ƒçš„å¿…å­¦å†…å®¹ã€‚

ä»Šå¤©è¿™èŠ‚è¯¾ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªä¸­æœŸå°ç»ƒä¹ ï¼Œæ˜¯æˆ‘ä»¬æ£€éªŒè‡ªå·±å­¦ä¹ æ•ˆæœçš„å¥½æ—¶æœºã€‚æˆ‘ä¼šå¸¦ä½ ä½¿ç”¨PyTorchæ„å»ºå’Œè®­ç»ƒä¸€ä¸ªè‡ªå·±çš„æ¨¡å‹ã€‚

å…·ä½“æˆ‘æ˜¯è¿™ä¹ˆå®‰æ’çš„ï¼Œé¦–å…ˆè®²è§£æ­å»ºç½‘ç»œå¿…å¤‡çš„åŸºç¡€æ¨¡å—â€”â€”nn.Moduleæ¨¡å—ï¼Œä¹Ÿå°±æ˜¯å¦‚ä½•è‡ªå·±æ„å»ºä¸€ä¸ªç½‘ç»œï¼Œå¹¶ä¸”è®­ç»ƒå®ƒï¼Œæ¢å¥è¯è¯´ï¼Œå°±æ˜¯ææ¸…æ¥šVGGã€Inceptioné‚£äº›ç½‘ç»œæ˜¯æ€ä¹ˆè®­ç»ƒå‡ºæ¥çš„ã€‚ç„¶åæˆ‘ä»¬å†çœ‹çœ‹å¦‚ä½•å€ŸåŠ©Torchvisionçš„æ¨¡å‹ä½œä¸ºé¢„è®­ç»ƒæ¨¡å‹ï¼Œæ¥è®­ç»ƒæˆ‘ä»¬è‡ªå·±çš„æ¨¡å‹ã€‚

## æ„å»ºè‡ªå·±çš„æ¨¡å‹

è®©æˆ‘ä»¬ç›´æ¥åˆ‡å…¥ä¸»é¢˜ï¼Œä½¿ç”¨PyTorchï¼Œè‡ªå·±æ„å»ºå¹¶è®­ç»ƒä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ï¼Œæ¥æ‹Ÿåˆå‡ºè®­ç»ƒé›†ä¸­çš„èµ°åŠ¿åˆ†å¸ƒã€‚

æˆ‘ä»¬å…ˆéšæœºç”Ÿæˆè®­ç»ƒé›†Xä¸å¯¹åº”çš„æ ‡ç­¾Yï¼Œå…·ä½“ä»£ç å¦‚ä¸‹ï¼š

```python
import numpy as np
import random
from matplotlib import pyplot as plt

w = 2
b = 3
xlim = [-10, 10]
x_train = np.random.randint(low=xlim[0], high=xlim[1], size=30)

y_train = [w * x + b + random.randint(0,2) for x in x_train]

plt.plot(x_train, y_train, 'bo')
```
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ30ï¼‰</strong></div><ul>
<li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/j24oyxHcpB5AMR9pMO6fITqnOFVOncnk2T1vdu1rYLfq1cN6Sj7xVrBVbCvHXUad2MpfyBcE4neBguxmjIxyiaQ/132" width="30px"><span>vcjmhg</span> ğŸ‘ï¼ˆ15ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<div>class MyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        # conv1è¾“å‡ºçš„ç‰¹å¾å›¾ä¸º222x222å¤§å°
        self.fc = nn.Linear(16 * 222 * 222, 10)

    def forward(self, input):
        x = self.conv1(input)
        # è¿›å»å…¨è¿æ¥å±‚ä¹‹å‰ï¼Œå…ˆå°†ç‰¹å¾å›¾é“ºå¹³
        x = x.view(x.shape[0], -1)
        x = self.fc(x)
        return x
# å°½é‡ä½¿ç”¨gpuè¿›è¡Œè®­ç»ƒ,å¦‚æœæ²¡æœ‰cpuåˆ™ä½¿ç”¨gpuæ¥è®­ç»ƒ
device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
cnn = MyCNN().to(device)
transform = transforms.Compose([
    # ä¿®æ”¹è£å‰ªå›¾ç‰‡çš„å°ºå¯¸
    transforms.RandomResizedCrop((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,
                                               train=False,
                                               transform=transform,
                                               target_transform=None,
                                               download=True)
dataloader = DataLoader(dataset=cifar10_dataset,  # ä¼ å…¥çš„æ•°æ®é›†, å¿…é¡»å‚æ•°
                        batch_size=32,  # è¾“å‡ºçš„batchå¤§å°
                        shuffle=True,  # æ•°æ®æ˜¯å¦æ‰“ä¹±
                        num_workers=2)  # è¿›ç¨‹æ•°, 0è¡¨ç¤ºåªæœ‰ä¸»è¿›ç¨‹
# å®šä¹‰ä¼˜åŒ–å™¨
optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)
steps = 0
for epoch in range(16):
    for item in dataloader:
        steps += 1
        output = cnn(item[0].to(device))
        target = item[1].to(device)
        # ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°
        loss = nn.CrossEntropyLoss()(output, target)
        # æ¯100æ­¥æ‰“å°ä¸€æ¬¡loss
        if steps % 100 == 0:
            print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1, loss))
        cnn.zero_grad()
        loss.backward()
        optimizer.step()
# æµ‹è¯•åˆ†ç±»ç»“æœ
im = Image.open(&#39;data&#47;img.png&#39;)
input_tensor = transform(im).unsqueeze(0)
result = cnn(input_tensor.to(device)).argmax()
print(result)
# tensor(3, device=&#39;cuda:0&#39;)</div>2021-11-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/e5/76/5d0b66aa.jpg" width="30px"><span>Mr_æå†²</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ8ï¼‰<div>æˆ‘åœ¨ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„alexnet-owt-7be5be79.pthæ¨¡å‹ï¼Œåå¤æ‰§è¡Œä¸‹é¢è¿™æ®µä»£ç çš„æ—¶å€™
alexnet(input_tensor).argmax()
å¾—åˆ°çš„ç»“æœå¹¶ä¸æ€»æ˜¯263ï¼Œè€Œæœ‰æ—¶å€™ä¼šå¾—åˆ°151å’Œ264æˆ–è€…å…¶ä»–çš„æ•°å€¼ï¼Œè¯·é—®æˆ‘æœ€ç»ˆåº”è¯¥ç›¸ä¿¡å“ªä¸€ä¸ªé¢„æµ‹ç»“æœå‘¢ï¼Œæ˜¯è¿›è¡Œå¤šæ¬¡é¢„æµ‹å–é¢„æµ‹æ¬¡æ•°æœ€å¤šçš„é‚£ä¸ªå—ï¼Ÿè¿˜æ˜¯æœ‰åˆ«çš„ç§‘å­¦çš„æ–¹æ³•å‘¢ï¼Ÿ</div>2022-03-15</li><br/><li><img src="" width="30px"><span>clee</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è°ƒæ•´ä¹‹åï¼Œå¯ä»¥æ­£å¸¸è®­ç»ƒäº†ï¼Œä½†æ˜¯æµ‹è¯•æ•°æ®çš„æ—¶å€™æˆ‘å‘ç°æœ‰äº›å›¾ç‰‡åˆ†ç±»ä¼šæœ‰é—®é¢˜ï¼Œæ¯”å¦‚ç‹—å’ŒçŒ«ï¼Œé¹¿å’Œé©¬å°±å®¹æ˜“åˆ†ç±»é”™è¯¯ï¼Œè¿™æ˜¯å› ä¸ºæ¬ æ‹Ÿåˆå—ï¼Ÿåº”è¯¥å¦‚ä½•ä¼˜åŒ–ï¼Ÿ</div>2021-11-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/92/7b/8c7e3e61.jpg" width="30px"><span>Monroe  He</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆè¯·æ•™ä¸€ä¸ªé—®é¢˜ï¼Œåœ¨æ¢¯åº¦æ¸…é›¶ä»£ç ä¸­

13 èŠ‚è¯¾ç”¨çš„æ˜¯ä¼˜åŒ–å™¨
optimizer.zero_grad()

è¿™èŠ‚è¯¾ç”¨çš„æ˜¯æ¨¡å‹
alexnet.zero_grad()

è¿™ä¸¤è¡Œä»£ç æœ‰ä»€ä¹ˆåŒºåˆ«å—ï¼Ÿ
</div>2023-03-19</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/ajNVdqHZLLDm5eHbw1fuicJiaXercgBI48O0Idt2mHUElmZyBM4o119NkndU1SNpsv8rZzKFibj8z1FibFAdNEO3zw/132" width="30px"><span>zhangting</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<div>è€å¸ˆè¯·æ•™ä¸ªé—®é¢˜ï¼Œä¸ºä»€ä¹ˆæ”¹å…¨è¿æ¥åï¼Œè®­ç»ƒå‡ºæ¥çš„æ¨¡å‹ï¼Œæ€»æ˜¯è¾“å‡ºçš„æ˜¯5ã€‚è€Œæœªåšæ”¹åŠ¨å‰ï¼Œé¢„æµ‹å‡ºæ¥çš„æ˜¯263.æºç å¦‚ä¸‹ï¼š

alexnet = models.alexnet()
alexnet.load_state_dict(torch.load(&#39;.&#47;model&#47;alexnet-owt-7be5be79.pth&#39;)) 

fc_in_features = alexnet.classifier[6].in_features

alexnet.classifier[6] = torch.nn.Linear(fc_in_features, 10)
print(alexnet)

transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,                                       
                                               train=False,                                       
                                               transform=transform,                                       
                                               target_transform=None,                                       
                                               download=False)
dataloader = DataLoader(dataset=cifar10_dataset, batch_size=32, shuffle=True, num_workers=4)

optimizer = torch.optim.SGD(alexnet.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

for epoch in range(3):
    for item in dataloader: 
        output = alexnet(item[0])
        target = item[1]
        loss = nn.CrossEntropyLoss()(output, target)
        print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss))
        alexnet.zero_grad()
        loss.backward()
        optimizer.step()
       
im = Image.open(&#39;dog.jpg&#39;)
transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
input_tensor = transform(im).unsqueeze(0)

alexnet.eval()

print(alexnet(input_tensor).argmax())</div>2022-05-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/f2/23/bb13b3ed.jpg" width="30px"><span>åˆ˜åˆ©</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ5ï¼‰<div>hiï¼Œè€å¸ˆï¼Œå¾®è°ƒçš„æ—¶å€™ï¼Œå¦‚æœè¿™æ ·å†™ï¼Œå‚æ•°éƒ½ä¸æ›´æ–°äº†ï¼Œé‚£è¿˜æœ‰å“ªéƒ¨åˆ†å‚æ•°ä¼šè¢«è®­ç»ƒå‘¢ï¼Ÿæ˜¯éœ€è¦å†æ¥ä¸€å±‚å…¨è¿æ¥å±‚ä¹ˆï¼Ÿ
alexnet = models.alexnet()
alexnet.load_state_dict(torch.load(&#39;.&#47;model&#47;alexnet-owt-4df8aa71.pth&#39;))
for param in alexnet.parameters(): 
    param.requires_grad = False</div>2022-05-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8d/8a/ec29ca4a.jpg" width="30px"><span>é©¬å…‹å›¾å¸ƒ</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>æ€è€ƒï¼š

ä½¿ç”¨ `nn.CrossEntropyLoss` ä½œä¸º loss function æ—¶ï¼Œä¼šè‡ªåŠ¨åœ¨ç½‘ç»œæœ€åæ·»åŠ  `nn.LogSoftmax` å’Œ `nn.nLLLos`ï¼Œå› æ­¤ä¸ç”¨å†åœ¨ fc å±‚åé¢æ‰‹åŠ¨æ·»åŠ  Softmax å±‚ï¼›

é—®é¢˜ï¼š

transform ä¸­ï¼Œæ ‡å‡†åŒ–çš„ mean å’Œ std æ˜¯å¦‚ä½•ç¡®å®šçš„ï¼ˆæˆ‘ä»¬éœ€è¦ä½¿ç”¨å‡å€¼ä¸º[0.485, 0.456, 0.406]ï¼Œæ ‡å‡†å·®ä¸º[0.229, 0.224, 0.225]å¯¹æ•°æ®è¿›è¡Œæ­£è§„åŒ–ï¼‰ï¼Ÿ</div>2021-11-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/45/2f/b0b0dd74.jpg" width="30px"><span>æ¨æ°</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>import torchvision.models as models
from PIL import Image
import torchvision
import torchvision.transforms as transforms

alexnet = models.alexnet(pretrained=True)

im = Image.open(&#39;.&#47;data&#47;dog.jpg&#39;)

transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

input_tensor = transform(im).unsqueeze(0)
print(alexnet(input_tensor).argmax())

ä»¥ä¸Šä»£ç è¾“å‡ºçš„ä¸ä¸€å®šæ˜¯264ï¼Œè¿™ä¸ªæ˜¯å•¥æƒ…å†µï¼Ÿ</div>2022-10-04</li><br/><li><img src="" width="30px"><span>Geek_827444</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<div>è€å¸ˆæ‚¨å¥½ï¼šæˆ‘ä¸€æ­¥ä¸€æ­¥æŒ‰ç…§å’±ä»¬é‚£ä¸ªæ­¥éª¤æ¥çš„ï¼Œä¸ºä»€ä¹ˆä»£ç è¿è¡Œä¸äº†é‚£ï¼Ÿè°¢è°¢æ‚¨ï¼

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models

import torchvision.models as models
alexnet = models.alexnet(pretrained=True)


import torchvision.transforms as transforms

transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])
])

import torchvision

cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,#æ³¨ï¼šè¿™é‡Œæ˜¯å­˜åœ¨													pycharmæ–‡ä»¶å½“ä¸­çš„dataæ–‡ä»¶å¤¹é‡Œ
                                              train=False,
                                              transform=transform,
                                              target_transform=None,
                                              download=True)

from torch.utils.data import DataLoader

dataloader = DataLoader(dataset=cifar10_dataset,
                       batch_size=32,
                       shuffle=True,
                       num_workers=2)



fc_in_features = alexnet.classifier[6].in_features
alexnet.classifier[6] = torch.nn.Linear(fc_in_features,10)

optimizer = torch.optim.SGD(alexnet.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

for epoch in range(3):
    # â†“å®šä¹‰æ¯”å¯¹çš„å…ƒç´ 
    for item in dataloader:
        output = alexnet(item[0])
        target = item[1]

        # â†“ä½¿ç”¨æŸå¤±å‡½æ•°
        loss = nn.CrossEntropyLoss()(output, target)
        print(&#39;Epoch{},Loss{}&#39;.format(epoch + 1, loss))

        # â†“æ›´æ–°æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å‡½æ•°
        alexnet.zero_grad()
        loss.backward()
        optimizer.step()

</div>2022-08-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/02/2a/90e38b94.jpg" width="30px"><span>John(æ˜“ç­‹)</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>å·¨äººè‚©è†€@é©¬å…‹å›¾åº“
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from PIL import Image
transform = transforms.Compose([
    transforms.RandomResizedCrop((224, 224)), 
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

cifar10_train_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,train=True,transform=transform,target_transform=None)
train_loader = torch.utils.data.DataLoader(dataset=cifar10_train_dataset,batch_size=32,shuffle=True,num_workers=2) 
classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;)
n_total_steps = len(train_loader)

class MyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        self.fc = nn.Linear(16 * 222 * 222, 10)
        
    def forward(self, input):
        x = self.conv1(input)
        x = x.view(x.shape[0], -1)
        x = self.fc(x)
        return x
    
device = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
model = MyCNN().to(device)

criterion = nn.CrossEntropyLoss() 
optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

print(&#39;Start training...&#39;)
for epoch in range(4):
    for i, (images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)
        labels_pred = model(images)
        loss = criterion(labels_pred, labels)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step
        
        if (i+1) % 100 == 0:
            print(f&#39;Epoch [{epoch+1}&#47;{4}], Step [{i+1:5d}&#47;{n_total_steps}], Loss={loss.item():.4f}&#39;)

print(&#39;Training complete!&#39;)

with torch.no_grad():
    im = Image.open(&#39;.&#47;images&#47;dog.jpg&#39;)
    input_tensor = transform(im).unsqueeze(0).to(device)
    label_pred = model(input_tensor).argmax()
    print(f&#39;Your label predicted: {classes[label_pred]}&#39;)</div>2022-08-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2c/8d/70/b0047299.jpg" width="30px"><span>Zeurd</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆï¼Œæƒ³è¯·é—®ä¸€ä¸‹ï¼Œæˆ‘åœ¨æ¢äº†ä¸€ä¸ªæ¨¡å‹InceptionV3ï¼ŒåšæŸå¤±å‡½æ•°çš„æ—¶å€™ï¼Œä¼šæç¤ºæˆ‘argument &#39;input&#39; (position 1) must be Tensor, not InceptionOutputsè¿™æ˜¯ä»€ä¹ˆåŸå› å‘¢ï¼Ÿæˆ‘ç”¨outputé¢„æµ‹å®Œè¾“å‡ºçš„æ˜¯ä¸€ä¸ªInceptionOutPutsçš„é‡ï¼Œè€Œä¸æ˜¯Tensorå½¢å¼çš„ï¼Œå½“æˆ‘æƒ³ç”¨torch.tensoråˆä¼šæç¤ºæˆ‘ä¸æ˜¯ä¸€ç»´çš„ï¼Œä¸èƒ½è½¬åŒ–</div>2022-07-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/3f/4a/b1c9e5e3.jpg" width="30px"><span>ä¸‡åŒ–8af10b</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆï¼Œè¯·æ•™ä¸€ä¸‹ï¼Œä¸Šé¢çš„ä¾‹å­

# è®­ç»ƒ3ä¸ªEpoch
for epoch in range(3): 
for item in dataloader: 
output = alexnet(item[0]) target = item[1] 
# ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•° loss = nn.CrossEntropyLoss()(output, target) 
print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss)) #ä»¥ä¸‹ä»£ç çš„å«ä¹‰ï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰çš„æ–‡ç« ä¸­å·²ç»ä»‹ç»è¿‡äº† alexnet.zero_grad() 
loss.backward()
 optimizer.step()


æ¯epoché‡Œé¢ä½œçš„æ¬¡æ•°æˆ‘åšäº†è®¡æ•°æ˜¯313æ¬¡backwardsï¼Œä¸ºä»€ä¹ˆä¼šæ˜¯è¿™ä¸ªæ•°å­—ï¼Œæˆ‘è®¡ç®—äº†ä»¥ä¸‹50000å¼ è®­ç»ƒé›†ï¼Œ50000&#47;32&#47;2=781.25æ¬¡æ‰å¯¹é˜¿ã€‚è¯·è€å¸ˆç‚¹æ˜æˆ‘ç®—é”™åœ¨å“ªé‡Œï¼Ÿ</div>2022-06-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8c/5c/3f164f66.jpg" width="30px"><span>äºšæ—</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>ç…§æŠ„æŠ„å‡ºæ¥äº†ï¼Œä½†æ˜¯å¯¹æŸå¤±å‡½æ•°é€‰å–ï¼Œä¼˜åŒ–å™¨å‚æ•°è®¾ç½®ï¼Œè¿˜æ˜¯ä¸€è„¸æ‡µ</div>2022-05-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/25/89/23/e71f180b.jpg" width="30px"><span>Geek_fc975d</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>or epoch in range(3): for item in dataloader: output = alexnet(item[0]) target = item[1] # ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•° loss = nn.CrossEntropyLoss()(output, target) print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss)) #ä»¥ä¸‹ä»£ç çš„å«ä¹‰ï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰çš„æ–‡ç« ä¸­å·²ç»ä»‹ç»è¿‡äº† alexnet.zero_grad() loss.backward() optimizer.step()

æƒ³è¯·æ•™è€å¸ˆå’Œå„ä½åŒå­¦ï¼Œè¿™ä¸ªitemæ˜¯å¤šå°‘ï¼Œ æ˜¯cifar10çš„æ€»æ•°æ®æ•°&#47;batch_sizeå—ï¼ŸåŸå…ˆæˆ‘ä»¥ä¸ºè¿™ä¸ªå€¼ç­‰äºbatch-sizeï¼Œçœ‹èµ·æ¥è¿™ä¸ªç»“æœä¸å¯¹å‘¢ã€‚

è¿˜æƒ³è¯·æ•™ä¸‹epochè¿™ä¸ªå‚æ•°æ˜¯æŒ‡ä»€ä¹ˆï¼Œ æ˜¯è¯´æŒ‰ç…§è¿™ä¸ªbatch_sizeå°†æ•´ä¸ªæ•°æ®é›†è®­ç»ƒå‡ æ¬¡å—ï¼Ÿ

æˆ‘åœ¨Jupyterä¸­è®­ç»ƒï¼Œè®­ç»ƒçš„é€Ÿåº¦è¶…çº§æ…¢ï¼Œæœ‰ä»€ä¹ˆæå‡çš„æ–¹æ³•å—ï¼Ÿ</div>2022-04-10</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIW9p3Q9OuX2kGgroDacib99YvjkichWdl54YBVicno8wNPW9gKibUNb0QPtYvTljSWFdjgXdrGPr7Q5g/132" width="30px"><span>ç’ç’æ£’</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>ä½ å¥½ï¼Œè€å¸ˆï¼Œè¯·æ•™ä¸‹ï¼Œæƒ³ç”¨é¢„è®­ç»ƒçš„effientnet b0æ¥è®­ç»ƒè‡ªå·±çš„æ•°æ®ï¼Œè‡ªå·±çš„æ•°æ®æ˜¯pngçš„å›¾ç‰‡ï¼Œè¿™ä¸ªè¡Œçš„é€šå—ï¼Œæ˜¯éœ€è¦ä¿®æ”¹ä¸‹è¾“å…¥é€šé“æ•°å°±å¯ä»¥å—ï¼Œè¿˜æ˜¯è¯´ä¸èƒ½ä½¿ç”¨é¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œå¯ä»¥é‡æ–°è®­ç»ƒä¸€ä¸ªæ–°çš„æ¨¡å‹ï¼Ÿ</div>2021-12-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/d2/d7/7f00bea1.jpg" width="30px"><span>Hité»æ˜åˆ†æ˜ğŸ©</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<div>
#æ•°æ®åŠ è½½

transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,
                                       train=False,
                                       transform=transform,
                                       target_transform=None,
                                       download=True)
dataloader = DataLoader(dataset=cifar10_dataset, # ä¼ å…¥çš„æ•°æ®é›†, å¿…é¡»å‚æ•°
                               batch_size=32,       # è¾“å‡ºçš„batchå¤§å°
                               shuffle=True,       # æ•°æ®æ˜¯å¦æ‰“ä¹±
                               num_workers=0)      # è¿›ç¨‹æ•°, 0è¡¨ç¤ºåªæœ‰ä¸»è¿›ç¨‹


#å®šä¹‰æ¨¡å‹
class myCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3,16,kernel_size=3)
        self.fc = nn.Linear(16 * 222 *222 ,10)
        
    def forward(self,input):
        x = self.conv1(input)
        # è¿›å»å…¨è¿æ¥å±‚ä¹‹å‰ï¼Œå…ˆå°†ç‰¹å¾å›¾é“ºå¹³
        x = x.view(x.shape[0],-1)
        x = self.fc(x)
        return x

# å°½é‡ä½¿ç”¨gpuè¿›è¡Œè®­ç»ƒ,å¦‚æœæ²¡æœ‰cpuåˆ™ä½¿ç”¨gpuæ¥è®­ç»ƒ
device = torch.device(&quot;cuda:0&quot;if torch.cuda.is_available()else &quot;cpu&quot;)

cnn = myCNN().to(device)


optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)
steps = 0

for epoch in range(30):
    for item in dataloader:
        steps += 1
        output = cnn(item[0])
        target = item[1].to(device)
        loss = nn.CrossEntropyLoss()(output,target)
        print(&#39;Epoch{},Loss{}&#39;.format(epoch + 1 ,loss))
        cnn.zero_grad()
        loss.backward()
        optimizer.step()
im = Image.open(&#39;data&#47;img.png&#39;)
input_tensor = transform(im).unsqueeze(0)
result = cnn(input_tensor.to(device)).argmax()
print(result)
è€å¸ˆæ‚¨å¥½ï¼Œæˆ‘è¿è¡Œä»¥åå‡ºç°æŠ¥é”™ï¼š
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor</div>2021-12-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/fc/de/6e2cb960.jpg" width="30px"><span>autiplex</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<div>from PIL import Image
from torch.utils.data import DataLoader
import torch
from torch import nn
import torchvision.transforms as transforms
import torchvision


#  è¯»å–æ•°æ®
transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,
                                       train=False,
                                       transform=transform,
                                       target_transform=None,
                                       download=True)
dataloader = DataLoader(dataset=cifar10_dataset, # ä¼ å…¥çš„æ•°æ®é›†, å¿…é¡»å‚æ•°
                               batch_size=32,       # è¾“å‡ºçš„batchå¤§å°
                               shuffle=True,       # æ•°æ®æ˜¯å¦æ‰“ä¹±
                               num_workers=2)      # è¿›ç¨‹æ•°, 0è¡¨ç¤ºåªæœ‰ä¸»è¿›ç¨‹


#  ç½‘ç»œç»“æ„
class MyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        # conv1è¾“å‡ºçš„ç‰¹å¾å›¾ä¸º222x222å¤§å°
        self.fc = nn.Linear(16 * 222 * 222, 10)

    def forward(self, input):
        x = self.conv1(input)
        # è¿›å»å…¨è¿æ¥å±‚ä¹‹å‰ï¼Œå…ˆå°†ç‰¹å¾å›¾é“ºå¹³
        x = x.view(x.shape[0], -1)
        x = self.fc(x)
        return x

cnn = MyCNN()
#  æŸå¤±å‡½æ•°
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

#  è®­ç»ƒ10ä¸ªEpoch
for epoch in range(10):
    for item in dataloader: 
        output = cnn(item[0])
        target = item[1]
        loss = criterion(output, target)
        print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss))
        #ä»¥ä¸‹ä»£ç çš„å«ä¹‰ï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰çš„æ–‡ç« ä¸­å·²ç»ä»‹ç»è¿‡äº†
        cnn.zero_grad()
        loss.backward()
        optimizer.step()

#  æµ‹è¯•ç»“æœ
pass

è€å¸ˆä¸Šé¢çš„ä»£ç è¿è¡Œä¼šå‘ç”Ÿä¸‹é¢çš„æŠ¥é”™ï¼Œæˆ‘æŸ¥äº†ä¸€ä¸‹è¯´æ˜¯è¦æ”¾åœ¨__name__==&#39;__main__&#39;é‡Œè¿è¡Œï¼Œæˆ‘æ²¡å¤ªæ˜ç™½

The &quot;freeze_support()&quot; line can be omitted if the program
        is not going to be frozen to produce an executable.
</div>2021-11-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/b5/4c/6b9528f8.jpg" width="30px"><span>zhaobk</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>#å›¾åƒåˆ†ç±»
class MyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        # conv1è¾“å‡ºçš„ç‰¹å¾å›¾ä¸º222x222å¤§å°
        self.fc = nn.Linear(16 * 222 * 222, 10)

    def forward(self, input):
        x = self.conv1(input)
        # è¿›å»å…¨è¿æ¥å±‚ä¹‹å‰ï¼Œå…ˆå°†ç‰¹å¾å›¾é“ºå¹³
        x = x.view(x.shape[0], -1)
        x = self.fc(x)
        return x


#å®šä¹‰è¯»å–æ•°æ®æ ¼å¼ meanå’Œstdæ˜¯ImageNetçš„å‡å€¼ä¸æ ‡å‡†å·®ã€‚torchvisionä¸­çš„æ¨¡å‹éƒ½æ˜¯åœ¨ImageNetä¸Šè®­ç»ƒçš„ã€‚
transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])
#è·å–æ•°æ®

cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,
                                       train=False,
                                       transform=transform,
                                       target_transform=None,
                                       download=True)


#åŠ è½½æ•°æ®
dataloader = DataLoader(
    dataset=cifar10_dataset, # ä¼ å…¥çš„æ•°æ®é›†, å¿…é¡»å‚æ•°
    batch_size=32,       # è¾“å‡ºçš„batchå¤§å°
    shuffle=True,       # æ•°æ®æ˜¯å¦æ‰“ä¹±
    num_workers=0)      # è¿›ç¨‹æ•°, 0è¡¨ç¤ºåªæœ‰ä¸»è¿›ç¨‹

cnn = MyCNN()
#å®šä¹‰ä¼˜åŒ–å™¨
optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

for epoch in range(10):
    for item in dataloader:
        cnt+=1
        output = cnn(item[0])
        target = item[1]
        # ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°
        loss = nn.CrossEntropyLoss()(output, target)
        print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss))
        #é¦–å…ˆè¦é€šè¿‡zero_grad()å‡½æ•°æŠŠæ¢¯åº¦æ¸…é›¶

        cnn.zero_grad()
        # ç®—å®Œlossä¹‹åè¿›è¡Œåå‘ä¼ æ’­ï¼Œè¿™ä¸ªè¿‡ç¨‹ä¹‹åæ¢¯åº¦ä¼šè®°å½•åœ¨å˜é‡ä¸­
        loss.backward()
        # ç”¨è®¡ç®—çš„æ¢¯åº¦å»åšä¼˜åŒ–
        optimizer.step()

im = Image.open(&#39;dog.jpg&#39;)
input_tensor = transform(im).unsqueeze(0)
print(cnn(input_tensor).argmax())

æˆ‘è®­ç»ƒå®Œlossæ€»æ˜¯åœ¨1.8~~2.0ä¹‹é—´éœ‡è¡ï¼Œæœ€åç”¨dog.jpgæµ‹è¯•å‡ºæ¥çš„åˆ†ç±»æ˜¯3ï¼Œcatã€‚è¯·é—®è€å¸ˆï¼Œæˆ‘çš„ä»£ç æœ‰é—®é¢˜ä¹ˆï¼Ÿè¿˜æ˜¯è®­ç»ƒçš„å°‘ï¼Ÿ</div>2021-11-15</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ0F94uoYZQicSOIfEfSr9gH7CTKibNBsS6d9PRDd8cy7bdTCF9jibXYtf0esGqsQAItHnElejIFovxg/132" width="30px"><span>cab</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è¯·é—®ä¸€ä¸‹ä¸ºä»€ä¹ˆPyTorchä¸­çš„AlexNetç½‘ç»œç»“æ„ä¸è®ºæ–‡ä¸­çš„ä¸ä¸€æ ·å‘¢ï¼Ÿ
</div>2021-11-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8d/8a/ec29ca4a.jpg" width="30px"><span>é©¬å…‹å›¾å¸ƒ</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>ä»£ç ï¼š

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from PIL import Image


transform = transforms.Compose([
    transforms.RandomResizedCrop((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

cifar10_train_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;, train=True, transform=transform, target_transform=None, download=True)
train_loader = torch.utils.data.DataLoader(dataset=cifar10_train_dataset, batch_size=32, shuffle=True, num_workers=2)
classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;)
n_total_steps = len(train_loader)


class MyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        self.fc = nn.Linear(16 * 222 * 222, 10)

    def forward(self, input):
        x = self.conv1(input)
        x = x.view(x.shape[0], -1)
        x = self.fc(x)
        return x


device = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
model = MyCNN().to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

print(&#39;Start training...&#39;)
for epoch in range(4):
    for i, (images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)
        labels_pred = model(images)
        loss = criterion(labels_pred, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i+1) % 100 == 0:
            print(f&#39;Epoch [{epoch+1}&#47;{4}], Step [{i+1:5d}&#47;{n_total_steps}], Loss = {loss.item():.4f}&#39;)
print(&#39;Training complete!&#39;)

print(&#39;Start testing...&#39;)
with torch.no_grad():
    im = Image.open(&#39;dog.jpg&#39;)
    input_tensor = my_transform(im).unsqueeze(0).to(device)
    label_pred = model(input_tensor).argmax()
    print(f&#39;Your label predictedï¼š{classes[label_pred]}&#39;)
</div>2021-11-12</li><br/><li><img src="" width="30px"><span>clee</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<div>import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms
import torchvision

transform = transforms.Compose([transforms.RandomResizedCrop((224,224)), 
                                transforms.ToTensor(), 
                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])
cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;, 
                                               train=False, 
                                               transform=transform, 
                                               target_transform=None, 
                                               download=True)
dataloader = DataLoader(dataset=cifar10_dataset, batch_size=32)
class MyCNN(nn.Module): 
  def __init__(self): 
    super().__init__()
    self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
    self.fc = nn.Linear(16 * 222 * 222, 10)
  def forward(self, input):
    x = self.conv1(input)
    # è¿›å»å…¨è¿æ¥å±‚ä¹‹å‰ï¼Œå…ˆå°†ç‰¹å¾å›¾é“ºå¹³
    x = x.view(x.shape[0], -1)
    x = self.fc(x)
    return x

class MyCNN_Model():
  def __init__(self):
    self.learning_rate = 0.001
    self.epoches = 100
    self.model = MyCNN()
    self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate, momentum=0.9)
    self.loss_function = nn.CrossEntropyLoss()

  def train(self):
    for epoch in range(self.epoches):
      for item in dataloader:
        prediction = self.model(item[0])
        loss = self.loss_function(prediction, item[1])
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
      print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss))
    torch.save(self.model.state_dict(), &#39;mycnn.pth&#39;)

ç–‘é—®ä¸€ï¼šLossè¾“å‡ºç‰¹åˆ«å¤§ï¼Œæ˜¯å“ªä¸ªå‚æ•°æ²¡æœ‰é…ç½®æ­£ç¡®å—?
Epoch 1, Loss 44.85285568237305
Epoch 2, Loss 6869.75048828125ï¼Œ
ç–‘é—®äºŒï¼š
loss.backward()ï¼Œoptimizer.step() ä¸¤è¡Œä»£ç éƒ½æ˜¯æ‰§è¡Œäº†æ–¹æ³•è€Œå·²ï¼Œæ²¡æœ‰ä¼ é€’ä»»ä½•å‚æ•°ï¼Œé‚£ä¹ˆæŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨å†…éƒ¨å’Œæ¨¡å‹æ˜¯æ€ä¹ˆå…³è”èµ·æ¥çš„ã€‚
</div>2021-11-12</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q3auHgzwzM7uYZvwhrLHsJICstGXaOvUNZnyq0aO7gF0OLicMyZAZFnRiaDyvM1lGxnEDP2VUMV3m6UjiazMmSNGQ/132" width="30px"><span>Geek_8cfc4c</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>æœ‰ä¸ªç¥å¥‡é—®é¢˜ï¼Œæˆ‘åœ¨macä¸Šè·‘æ¨¡å‹è®­ç»ƒlossæ„Ÿè§‰æ²¡æœ‰æ”¶æ•›çš„è¿¹è±¡
ç”¨linuxæœºå™¨è·‘å°±æ”¶æ•›äº†â€¦â€¦
ç‰ˆæœ¬å·éƒ½æ˜¯ä¸€æ ·çš„â€¦â€¦
è¿™å¯èƒ½æ˜¯ä»€ä¹ˆé—®é¢˜å‘¢ï¼Ÿ</div>2021-11-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2b/13/3e/d028cddd.jpg" width="30px"><span>ç‹ç</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<div>from PIL import Image
import torchvision
import torchvision.transforms as transforms
import torch
from torch.utils.data import DataLoader

# æ•°æ®è¯»å–
transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,
                                       train=False, #ä¸‹è½½æµ‹è¯•é›†
                                       transform=transform,
                                       target_transform=None,
                                       download=True)
dataloader = DataLoader(dataset=cifar10_dataset, # ä¼ å…¥çš„æ•°æ®é›†, å¿…é¡»å‚æ•°
                               batch_size=32,       # è¾“å‡ºçš„batchå¤§å°
                               shuffle=True,       # æ•°æ®æ˜¯å¦æ‰“ä¹±
                               num_workers=2)   # è¿›ç¨‹æ•°, 0è¡¨ç¤ºåªæœ‰ä¸»è¿›ç¨‹

# å®šä¹‰è®¡ç®—è®¾å¤‡
device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) 

# å®ä¾‹åŒ–æ¨¡å‹
cnn = MyCNN().to(device)
# å®šä¹‰ä¼˜åŒ–å™¨
optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

steps = 0
for epoch in range(10):
    for item in dataloader: 
        steps += 1
        output = cnn(item[0].to(device))
        target = item[1].to(device)
        # ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°
        loss = nn.CrossEntropyLoss()(output, target)
        
        if steps % 50 == 0:
            print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss))
        cnn.zero_grad()
        loss.backward()
        optimizer.step()


# ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹
im = Image.open(&#39;dog.jpg&#39;)
input_tensor = transform(im).unsqueeze(0)
cnn(input_tensor.to(device)).argmax()

è¾“å‡ºï¼štensor(5, device=&#39;cuda:0&#39;)

é¢„æµ‹ç±»åˆ«æ˜¯â€œç‹—â€ã€‚

æ˜¯è¿æ°”å¥½å—ï¼Ÿåªè®­ç»ƒäº†10 epochsï¼Œæœ€åæ˜¾ç¤ºçš„loss 1.8å·¦å³
</div>2021-11-12</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q3auHgzwzM7uYZvwhrLHsJICstGXaOvUNZnyq0aO7gF0OLicMyZAZFnRiaDyvM1lGxnEDP2VUMV3m6UjiazMmSNGQ/132" width="30px"><span>Geek_8cfc4c</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<div>å¯¹äºæœ¬èŠ‚è¯¾æœ‰å‡ ä¸ªé—®é¢˜ä¸å¤ªæ˜ç™½è¿˜æœ›èµæ•™ ï¼ˆpytorchç‰ˆæœ¬&#39;1.10.0&#39;ï¼‰

1. æ¨¡å‹è®­ç»ƒé‚£ éƒ¨åˆ†
`y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(0)`
unsqueezeçš„æ„ä¹‰æ˜¯å•¥å‘¢ï¼Ÿ (y_trainæœ¬æ¥sizeæ˜¯Size([30])æ­£å¥½å’Œx_trainåŒ¹é…)
è¿™æ ·åšåè€Œå¾—åˆ°äº†ä¸€ä¸ªwarning
`
UserWarning: Using a target size (torch.Size([1, 30])) that is different to the input size (torch.Size([30])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
`

2. å†è¯´å¾®è°ƒ éƒ¨åˆ†
ä¸€å¼€å§‹ç›´æ¥ä¸‹è½½çš„AlexNetæ¨¡å‹(alexnet-owt-7be5be79.pth), é¢„æµ‹ç»“æœæ˜¯151
åæ¥ä½¿ç”¨äºæ–‡ä¸­ä¸€æ ·çš„ç‰ˆæœ¬æ‰å˜æˆ263

å› ä¸ºtorchvisionçš„ç‰ˆæœ¬ä¸åŒï¼Œé¢„è®­ç»ƒçš„æ¨¡å‹ç»“æœå°±æœ‰äº†å·®å¼‚ä¹ˆï¼Ÿ
å¦‚æœæ˜¯çš„è¯æˆ‘çœ‹åˆ°çš„æ ‡ç­¾åˆ—è¡¨ä¸­151æ˜¯å‰å¨ƒå¨ƒï¼ˆChihuahuaï¼‰â€¦â€¦

è°¢è°¢
</div>2021-11-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/b8/6e/0aae08d6.jpg" width="30px"><span>VincentQ</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>pretrained = Trueä¸èƒ½ç”¨äº†

from torchvision.models import AlexNet_Weights

alexnet = models.alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)</div>2024-06-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/81/e9/d131dd81.jpg" width="30px"><span>Mamba</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>å›ºå®šæ•´ä¸ªç½‘ç»œçš„å‚æ•°ï¼Œåªè®­ç»ƒæœ€åçš„å…¨è¿æ¥å±‚, åœ¨è¯»å–å®Œé¢„è®­ç»ƒæ¨¡å‹ä¹‹åï¼Œå°†å‚æ•°å…¨éƒ¨é”æ­»,ç„¶åæ–°å¢ä¸€ä¸ªå…¨è¿æ¥å±‚

### ä¿®æ”¹ç½‘ç»œç»“æ„
# å¯¼å…¥é¢„è®­ç»ƒçš„AlexNetæ¨¡å‹
alexnet = models.alexnet(pretrained=True)
# å†»ç»“æ‰€æœ‰å±‚
for param in alexnet.features.parameters():
    param.requires_grad = False
# è·å–AlexNetæœ€åä¸€ä¸ªå…¨è¿æ¥å±‚çš„è¾“å‡ºç‰¹å¾æ•°
input_features = alexnet.classifier[-1].out_features

# æ·»åŠ ä¸€ä¸ªæ–°çš„å…¨è¿æ¥å±‚ï¼Œç”¨äº10åˆ†ç±»ä»»åŠ¡
alexnet.classifier.add_module(&#39;fc&#39;, nn.Linear(input_features, 10))

# æ‰“å°æ¨¡å‹ç»“æ„ï¼Œç¡®è®¤æ›´æ”¹
print(alexnet)</div>2024-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>å­¦ä¹ æ‰“å¡</div>2023-12-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/5d/24/ccecf795.jpg" width="30px"><span>benny</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>è¿™ä¸ªè¯¾ç¨‹æœ‰githubåœ°å€å—ï¼Ÿ</div>2023-08-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/02/2a/90e38b94.jpg" width="30px"><span>John(æ˜“ç­‹)</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<div>&#47;&#47; è¿™é‡Œéœ€è¦ import DataLoader
from torch.utils.data import Dataset, DataLoader

cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#47;&#39;,
                                              train=False,
                                              transform=transforms.ToTensor(),
                                              target_transform=None,
                                              download=True)
tensor_dataloader = DataLoader(dataset=cifar10_dataset,                               
                               batch_size=32)
data_iter = iter(tensor_dataloader)
img_tensor, label_tensor = data_iter.next()
print(img_tensor.shape)
grid_tensor = torchvision.utils.make_grid(img_tensor, nrow=16, padding=2)
grid_img = transforms.ToPILImage()(grid_tensor)
display(grid_img)
</div>2022-08-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/f2/23/bb13b3ed.jpg" width="30px"><span>åˆ˜åˆ©</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>hiï¼Œè€å¸ˆï¼Œå¾®è°ƒçš„æ—¶å€™ï¼Œ</div>2022-05-03</li><br/>
</ul>