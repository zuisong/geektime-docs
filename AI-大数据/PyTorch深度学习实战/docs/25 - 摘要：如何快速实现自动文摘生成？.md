ä½ å¥½ï¼Œæˆ‘æ˜¯æ–¹è¿œã€‚

å½“æˆ‘ä»¬æ‰“å¼€æŸä¸ªæ–°é—»APPæˆ–è€…æŸä¸ªç½‘ç«™æ—¶ï¼Œå¸¸å¸¸è¢«è¿™æ ·çš„æ ‡é¢˜æ‰€å¸å¼•ï¼šâ€œéœ‡æƒŠäº†åäº¿äººâ€ã€â€œä¸€å®šè¦è¯»å®Œï¼Œè·Ÿä½ çš„ç”Ÿå‘½æœ‰å…³ï¼â€ç­‰ã€‚ä½†æ˜¯å½“æˆ‘ä»¬ç‚¹è¿›å»å´å‘ç°éƒ½æ˜¯æ ‡é¢˜å…šï¼Œå®é™…å†…å®¹å¤§ç›¸å¾„åº­ï¼è¿™æ—¶å€™ä½ å¯èƒ½ä¼šæƒ³ï¼Œå¦‚æœæœ‰ä¸€ç§å·¥å…·èƒ½å¸®åŠ©æˆ‘ä»¬æç‚¼æ–‡ç« çš„å…³é”®å†…å®¹ï¼Œé‚£æˆ‘ä»¬å°±ä¸ä¼šå†å—åˆ°æ ‡é¢˜å…šçš„å½±å“äº†ã€‚å…¶å®æƒ³è¦å®ç°è¿™ä¸ªå·¥å…·å¹¶ä¸å¤æ‚ï¼Œç”¨è‡ªåŠ¨æ–‡æ‘˜æŠ€æœ¯å°±èƒ½è§£å†³ã€‚

è‡ªåŠ¨æ–‡æ‘˜å……æ–¥ç€æˆ‘ä»¬ç”Ÿæ´»çš„æ–¹æ–¹é¢é¢ï¼Œå®ƒå¯ç”¨äºçƒ­ç‚¹æ–°é—»èšåˆã€æ–°é—»æ¨èã€è¯­éŸ³æ’­æŠ¥ã€APPæ¶ˆæ¯Pushã€æ™ºèƒ½å†™ä½œç­‰åœºæ™¯ã€‚ä»Šå¤©æˆ‘ä»¬è¦è®²çš„è¿™ä¸ªè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œå°±æ˜¯è‡ªåŠ¨æ–‡æ‘˜ç”Ÿæˆã€‚

## é—®é¢˜èƒŒæ™¯

è‡ªåŠ¨æ–‡æ‘˜æŠ€æœ¯ï¼Œå°±æ˜¯è‡ªåŠ¨æç‚¼å‡ºä¸€äº›å¥å­æ¥æ¦‚æ‹¬æ•´ç¯‡æ–‡ç« çš„å¤§æ„ï¼Œç”¨æˆ·é€šè¿‡è¯»æ‘˜è¦å°±å¯ä»¥äº†è§£åˆ°åŸæ–‡è¦è¡¨è¾¾çš„æ„æ€ã€‚

### æŠ½å–ä¸ç”Ÿæˆ

è‡ªåŠ¨æ–‡æ‘˜æœ‰ä¸¤ç§è§£å†³æ–¹æ¡ˆï¼šä¸€ç§æ˜¯æŠ½å–å¼ï¼ˆExtractiveï¼‰çš„ï¼Œå°±æ˜¯ä»åŸæ–‡ä¸­æå–ä¸€äº›å…³é”®çš„å¥å­ï¼Œç»„åˆæˆä¸€ç¯‡æ‘˜è¦ï¼›å¦å¤–ä¸€ç§æ˜¯ç”Ÿæˆå¼ï¼ˆAbstractiveï¼‰çš„ï¼Œä¹Ÿæ˜¯è¿™èŠ‚è¯¾æˆ‘ä»¬é‡ç‚¹è¦è®²çš„å†…å®¹ï¼Œè¿™ç§æ–¹å¼éœ€è¦è®¡ç®—æœºé€šè¯»åŸæ–‡åï¼Œåœ¨ç†è§£æ•´ç¯‡æ–‡ç« å†…å®¹çš„åŸºç¡€ä¸Šï¼Œä½¿ç”¨ç®€çŸ­è¿è´¯çš„è¯­è¨€å°†åŸæ–‡çš„ä¸»è¦å†…å®¹è¡¨è¾¾å‡ºæ¥ï¼Œå³ä¼šäº§ç”ŸåŸæ–‡ä¸­æ²¡æœ‰å‡ºç°çš„è¯å’Œå¥å­ã€‚

ç°é˜¶æ®µï¼ŒæŠ½å–å¼çš„æ‘˜è¦ç›®å‰å·²ç»ç›¸å¯¹æˆç†Ÿï¼Œä½†æ˜¯æŠ½å–è´¨é‡åŠå†…å®¹æµç•…åº¦éƒ½ä¸å¤Ÿç†æƒ³ã€‚éšç€æ·±åº¦å­¦ä¹ çš„ç ”ç©¶ï¼Œç”Ÿæˆå¼æ‘˜è¦çš„è´¨é‡å’Œæµç•…åº¦éƒ½æœ‰å¾ˆå¤§æå‡ï¼Œä½†ç›®å‰ä¹Ÿå—åˆ°åŸæ–‡æœ¬é•¿åº¦è¿‡é•¿ã€æŠ½å–å†…å®¹ä¸ä½³ç­‰é™åˆ¶ï¼Œç”Ÿæˆçš„æ‘˜è¦ä¸äººå·¥æ‘˜è¦ç›¸æ¯”ï¼Œè¿˜æœ‰ç›¸å½“çš„å·®è·ã€‚

è¯­è¨€çš„è¡¨è¾¾æ–¹å¼å¤šç§å¤šæ ·ï¼Œæœºå™¨ç”Ÿæˆçš„æ‘˜è¦å¯èƒ½å’Œäººå·¥æ‘˜è¦å¹¶ä¸ç›¸åŒï¼Œé‚£ä¹ˆå¦‚ä½•è¡¡é‡è‡ªåŠ¨æ‘˜è¦çš„å¥½åå‘¢ï¼Ÿè¿™å°±æ¶‰åŠåˆ°æ‘˜è¦çš„è¯„ä»·æŒ‡æ ‡ã€‚

### è¯„ä»·æŒ‡æ ‡

è¯„ä»·è‡ªåŠ¨æ‘˜è¦çš„æ•ˆæœé€šå¸¸ä½¿ç”¨ **ROUGE**ï¼ˆRecall Oriented Understudy for Gisting Evaluationï¼‰è¯„ä»·ã€‚

ROUGEè¯„ä»·æ³•å‚è€ƒäº†æœºå™¨ç¿»è¯‘è‡ªåŠ¨è¯„ä»·æ–¹æ³•ï¼Œå¹¶ä¸”è€ƒè™‘äº†N-gramå…±åŒå‡ºç°çš„ç¨‹åº¦ã€‚è¿™ä¸ªæ–¹æ³•å…·ä½“æ˜¯è¿™æ ·è®¾è®¡çš„ï¼šé¦–å…ˆç”±å¤šä¸ªä¸“å®¶åˆ†åˆ«ç”Ÿæˆäººå·¥æ‘˜è¦ï¼Œæ„æˆæ ‡å‡†æ‘˜è¦é›†ï¼›ç„¶åå¯¹æ¯”ç³»ç»Ÿç”Ÿæˆçš„è‡ªåŠ¨æ‘˜è¦ä¸äººå·¥ç”Ÿæˆçš„æ ‡å‡†æ‘˜è¦ï¼Œé€šè¿‡ç»Ÿè®¡äºŒè€…ä¹‹é—´é‡å çš„åŸºæœ¬å•å…ƒï¼ˆnå…ƒè¯­æ³•ã€è¯åºæˆ–è¯å¯¹ï¼‰çš„æ•°ç›®ï¼Œæ¥è¯„ä»·æ‘˜è¦çš„è´¨é‡ã€‚é€šè¿‡ä¸å¤šä¸“å®¶äººå·¥æ‘˜è¦çš„å¯¹æ¯”ï¼Œæé«˜è¯„ä»·ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¥å£®æ€§ã€‚

ROUGEä¸»è¦åŒ…æ‹¬ä»¥ä¸‹4ç§è¯„ä»·æŒ‡æ ‡ï¼š

1.ROUGE-Nï¼ŒåŸºäºn-gramçš„å…±ç°ç»Ÿè®¡ï¼›  
2.ROUGE-Lï¼ŒåŸºäºæœ€é•¿å…¬å…±å­ä¸²ï¼›  
3.ROUGE-Sï¼ŒåŸºäºé¡ºåºè¯å¯¹ç»Ÿè®¡ï¼›  
4.ROUGE-Wï¼Œåœ¨ROUGE-Lçš„åŸºç¡€ä¸Šï¼Œè€ƒè™‘ä¸²çš„è¿ç»­åŒ¹é…ã€‚Â   
äº†è§£äº†è‡ªåŠ¨æ–‡æ‘˜çš„ç§ç±»ä¸è¯„ä»·æŒ‡æ ‡ï¼Œä¸‹é¢æˆ‘ä»¬å†æ¥è®¤è¯†ä¸€ä¸ªç”¨äºè‡ªåŠ¨æ–‡æ‘˜ç”Ÿæˆçš„æ¨¡å‹â€”â€”BARTã€‚å®ƒçš„åå­—å’Œä¸ŠèŠ‚è¯¾è®²è¿‡çš„BERTéå¸¸åƒï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹çœ‹å®ƒæœ‰å“ªäº›ç‰¹ç‚¹ã€‚

## BARTåŸç†ä¸ç‰¹ç‚¹åˆ†æ

BARTçš„å…¨ç§°æ˜¯Bidirectional andÂ Auto-RegressiveÂ Transformersï¼ˆåŒå‘è‡ªå›å½’å˜å‹å™¨ï¼‰ã€‚å®ƒæ˜¯ç”± Facebook AI åœ¨2019å¹´æå‡ºçš„ä¸€ä¸ªæ–°çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç»“åˆäº†åŒå‘Transformerå’Œè‡ªå›å½’Transformerï¼Œåœ¨æ–‡æœ¬ç”Ÿæˆç›¸å…³ä»»åŠ¡ä¸­è¾¾åˆ°äº†SOTAçš„ç»“æœã€‚ä½ å¯ä»¥é€šè¿‡è¿™ä¸ªé“¾æ¥æŸ¥çœ‹[ç›¸å…³è®ºæ–‡](https://arxiv.org/abs/1910.13461)ã€‚

æˆ‘ä»¬å·²ç»ç†ŸçŸ¥äº†è®ºæ–‡ã€ŠAttention is all you needã€‹ä¸­æå‡ºçš„Transformerã€‚Transformerå·¦åŠè¾¹ä¸ºEncoderï¼Œå³åŠè¾¹ä¸ºDecoderã€‚Encoderå’ŒDecoderçš„ç»“æ„åˆ†åˆ«å¦‚ä¸‹å›¾ï¼ˆaï¼‰ã€ï¼ˆbï¼‰æ‰€ç¤ºã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/02/c7/02d7541cd7b6f0a8b8c35efb3e4d74c7.jpg?wh=1920x901 "å›¾ç‰‡æ¥æºï¼šhttps://arxiv.org/abs/1910.13461")

Encoderè´Ÿè´£å°†åŸå§‹æ–‡æœ¬è¿›è¡Œself-attentionï¼Œå¹¶è·å¾—å¥å­ä¸­æ¯ä¸ªè¯çš„è¯å‘é‡ï¼Œæœ€ç»å…¸çš„ Encoderæ¶æ„å°±æ˜¯ä¸ŠèŠ‚è¯¾æ‰€å­¦ä¹ çš„BERTï¼Œä½†æ˜¯**å•ç‹¬Encoderç»“æ„ä¸é€‚ç”¨äºæ–‡æœ¬ç”Ÿæˆä»»åŠ¡**ã€‚

Decoderçš„è¾“å…¥ä¸è¾“å‡ºä¹‹é—´é”™å¼€ä¸€ä¸ªä½ç½®ï¼Œè¿™æ˜¯ä¸ºäº†æ¨¡æ‹Ÿæ–‡æœ¬ç”Ÿæˆæ—¶ï¼Œä¸èƒ½è®©æ¨¡å‹çœ‹åˆ°æœªæ¥çš„è¯ï¼Œè¿™ç§æ–¹å¼ç§°ä¸ºAuto-Regressiveï¼ˆè‡ªå›å½’ï¼‰ã€‚ä¾‹å¦‚GPTç­‰**åŸºäºDecoderç»“æ„**çš„æ¨¡å‹é€šå¸¸é€‚ç”¨äºåšæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼Œä½†æ˜¯**æ— æ³•å­¦ä¹ åŒå‘çš„ä¸Šä¸‹æ–‡è¯­å¢ƒä¿¡æ¯**ã€‚

BARTæ¨¡å‹å°±æ˜¯å°†Encoderå’ŒDecoderç»“åˆåœ¨ä¸€èµ·çš„ä¸€ç§sequence-to-sequenceç»“æ„ï¼Œå®ƒçš„ä¸»è¦ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/a6/99/a663e08e28803d6059aae93fea1a0699.png?wh=1898x778 "å›¾ç‰‡æ¥æºï¼šhttps://arxiv.org/abs/1910.13461")

BARTæ¨¡å‹çš„ç»“æ„çœ‹ä¼¼ä¸Transformeræ²¡ä»€ä¹ˆä¸åŒï¼Œä¸»è¦åŒºåˆ«åœ¨äºBARTçš„é¢„è®­ç»ƒé˜¶æ®µã€‚é¦–å…ˆåœ¨Encoderç«¯ä½¿ç”¨å¤šç§å™ªå£°å¯¹åŸå§‹æ–‡æœ¬è¿›è¡Œ**ç ´å**ï¼Œç„¶åå†ä½¿ç”¨Decoder **é‡å»º**åŸå§‹æ–‡æœ¬ã€‚

ç”±äºBARTæœ¬èº«å°±æ˜¯åœ¨sequence-to-sequenceçš„åŸºç¡€ä¸Šæ„å»ºå¹¶ä¸”è¿›è¡Œé¢„è®­ç»ƒï¼Œå®ƒå¤©ç„¶å°±é€‚åˆåšåºåˆ—ç”Ÿæˆçš„ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼šé—®ç­”ã€æ–‡æœ¬æ‘˜è¦ã€æœºå™¨ç¿»è¯‘ç­‰ã€‚åœ¨ç”Ÿæˆä»»åŠ¡ä¸Šè·å¾—è¿›æ­¥çš„åŒæ—¶ï¼Œåœ¨ä¸€äº›æ–‡æœ¬ç†è§£ç±»ä»»åŠ¡ä¸Šå®ƒä¹Ÿå¯ä»¥å–å¾—å¾ˆå¥½çš„æ•ˆæœã€‚

ä¸‹é¢æˆ‘ä»¬è¿›å…¥å®æˆ˜é˜¶æ®µï¼Œåˆ©ç”¨BARTæ¥å®ç°è‡ªåŠ¨æ–‡æ‘˜ç”Ÿæˆã€‚

## å¿«é€Ÿæ–‡æ‘˜ç”Ÿæˆ

è¿™é‡Œæˆ‘ä»¬è¿˜æ˜¯ä½¿ç”¨hugging faceçš„Transformerså·¥å…·åŒ…ã€‚å…·ä½“çš„å®‰è£…è¿‡ç¨‹ï¼Œä¸Šä¸€èŠ‚è¯¾å·²ç»ä»‹ç»è¿‡äº†ã€‚

Transformerså·¥å…·åŒ…ä¸ºå¿«é€Ÿä½¿ç”¨è‡ªåŠ¨æ–‡æ‘˜ç”Ÿæˆæ¨¡å‹æä¾›äº†pipeline APIã€‚pipelineèšåˆäº†æ–‡æœ¬é¢„å¤„ç†æ­¥éª¤ä¸è®­ç»ƒå¥½çš„è‡ªåŠ¨æ–‡æ‘˜ç”Ÿæˆæ¨¡å‹ã€‚åˆ©ç”¨Transformersçš„pipelineï¼Œæˆ‘ä»¬åªéœ€çŸ­çŸ­å‡ è¡Œä»£ç ï¼Œå°±å¯ä»¥å¿«é€Ÿç”Ÿæˆæ–‡æœ¬æ‘˜è¦ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨pipelineç”Ÿæˆæ–‡æ‘˜çš„ä¾‹å­ï¼Œä»£ç å¦‚ä¸‹ã€‚

```python
from transformers import pipeline

summarizer = pipeline("summarization")

ARTICLE = """ New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.
A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.
Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared "I do" five more times, sometimes only within two weeks of each other.
In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her "first and only" marriage.
Barrientos, now 39, is facing two criminal counts of "offering a false instrument for filing in the first degree," referring to her false statements on the
2010 marriage license application, according to court documents.
Prosecutors said the marriages were part of an immigration scam.
On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.
After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective
Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.
All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.
Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.
Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.
The case was referred to the Bronx District Attorney\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\'s
Investigation Division. Seven of the men are from so-called "red-flagged" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.
Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.
If convicted, Barrientos faces up to four years in prison.Â  Her next court appearance is scheduled for May 18.
"""

print(summarizer(ARTICLE, max_length=130, min_length=30))
'''
è¾“å‡º:
[{'summary_text': ' Liana Barrientos, 39, is charged with two counts of "offering a false instrument for filing in
the first degree" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and
2002 . At one time, she was married to eight men at once, prosecutors say .'}]
'''
```

ç¬¬3è¡Œä»£ç çš„ä½œç”¨æ˜¯æ„å»ºä¸€ä¸ªè‡ªåŠ¨æ–‡æ‘˜çš„pipelineï¼Œpipelineä¼šè‡ªåŠ¨ä¸‹è½½å¹¶ç¼“å­˜è®­ç»ƒå¥½çš„è‡ªåŠ¨æ–‡æ‘˜ç”Ÿæˆæ¨¡å‹ã€‚è¿™ä¸ªè‡ªåŠ¨æ–‡æ‘˜ç”Ÿæˆæ¨¡å‹æ˜¯BARTæ¨¡å‹åœ¨CNN/Daily Mailæ•°æ®é›†ä¸Šè®­ç»ƒå¾—åˆ°çš„ã€‚

ç¬¬5~22è¡Œä»£ç æ˜¯å¾…ç”Ÿæˆæ‘˜è¦çš„æ–‡ç« åŸæ–‡ã€‚ç¬¬24è¡Œä»£ç æ˜¯é’ˆå¯¹æ–‡æ‘˜åŸæ–‡è‡ªåŠ¨ç”Ÿæˆæ–‡æ‘˜ï¼Œå…¶ä¸­å‚æ•°max\_lengthå’Œmin\_lengthé™åˆ¶äº†æ–‡æ‘˜çš„æœ€å¤§å’Œæœ€å°é•¿åº¦ï¼Œè¾“å‡ºçš„ç»“æœå¦‚ä¸Šé¢ä»£ç æ³¨é‡Šæ‰€ç¤ºã€‚

å¦‚æœä½ ä¸æƒ³ä½¿ç”¨Transformersæä¾›çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè€Œæ˜¯æƒ³ä½¿ç”¨è‡ªå·±çš„æ¨¡å‹æˆ–å…¶å®ƒä»»æ„æ¨¡å‹ä¹Ÿå¾ˆç®€å•ã€‚å…·ä½“ä»£ç å¦‚ä¸‹ã€‚

```python
from transformers import BartTokenizer, BartForConditionalGeneration

model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')

inputs = tokenizer([ARTICLE], max_length=1024, return_tensors='pt')

# ç”Ÿæˆæ–‡æ‘˜
summary_ids = model.generate(inputs['input_ids'], max_length=130, early_stopping=True)
summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
print(summary)
```

æµç¨‹æ˜¯ä¸€å…±åŒ…æ‹¬å››æ­¥ï¼Œæˆ‘ä»¬åˆ†åˆ«çœ‹ä¸€ä¸‹ã€‚  
ç¬¬ä¸€æ­¥æ˜¯å®ä¾‹åŒ–ä¸€ä¸ªBARTçš„æ¨¡å‹å’Œåˆ†è¯å™¨å¯¹è±¡ã€‚BartForConditionalGenerationç±»æ˜¯BARTæ¨¡å‹ç”¨äºæ‘˜è¦ç”Ÿæˆçš„ç±»ï¼ŒBartTokenizeræ˜¯BARTçš„åˆ†è¯å™¨ï¼Œå®ƒä»¬éƒ½æœ‰from\_pretrained()æ–¹æ³•ï¼Œå¯ä»¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ã€‚

from\_pretrained()å‡½æ•°éœ€è¦ä¼ å…¥ä¸€ä¸ªå­—ç¬¦ä¸²ä½œä¸ºå‚æ•°ï¼Œè¿™ä¸ªå­—ç¬¦ä¸²å¯ä»¥æ˜¯æœ¬åœ°æ¨¡å‹çš„è·¯å¾„ï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸Šä¼ åˆ°Hugging Faceæ¨¡å‹åº“ä¸­çš„æ¨¡å‹åå­—ã€‚

è¿™é‡Œâ€œfacebook/bart-large-cnnâ€æ˜¯Facebookåˆ©ç”¨CNN/Daily Mailæ•°æ®é›†è®­ç»ƒçš„BARTæ¨¡å‹ï¼Œæ¨¡å‹å…·ä½“ç»†èŠ‚ä½ å¯ä»¥å‚è€ƒ[è¿™é‡Œ](https://huggingface.co/facebook/bart-large-cnn)ã€‚

æ¥ä¸‹æ¥æ˜¯ç¬¬äºŒæ­¥ï¼Œå¯¹åŸå§‹æ–‡æœ¬è¿›è¡Œåˆ†è¯ã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨åˆ†è¯å™¨å¯¹è±¡tokenizerå¯¹åŸå§‹æ–‡æœ¬ARTICLEè¿›è¡Œåˆ†è¯ï¼Œå¹¶å¾—åˆ°è¯è¯­idçš„Tensorã€‚return\_tensors='ptâ€™è¡¨ç¤ºè¿”å›å€¼æ˜¯PyTorchçš„Tensorã€‚

ç¬¬ä¸‰æ­¥ï¼Œä½¿ç”¨generate()æ–¹æ³•ç”Ÿæˆæ‘˜è¦ã€‚å…¶ä¸­å‚æ•°max\_lengthé™åˆ¶äº†ç”Ÿæˆæ‘˜è¦çš„æœ€å¤§é•¿åº¦ï¼Œearly\_stoppingè¡¨ç¤ºç”Ÿæˆè¿‡ç¨‹æ˜¯å¦å¯æå‰åœæ­¢ã€‚generate()æ–¹æ³•çš„è¾“å‡ºæ˜¯æ‘˜è¦è¯è¯­çš„idã€‚

æœ€åä¸€æ­¥ï¼Œåˆ©ç”¨åˆ†è¯å™¨è§£ç å¾—åˆ°æœ€ç»ˆçš„æ‘˜è¦æ–‡æœ¬ã€‚åˆ©ç”¨tokenizer.decode()å‡½æ•°ï¼Œå°†è¯è¯­idè½¬æ¢ä¸ºè¯è¯­æ–‡æœ¬ã€‚å…¶ä¸­å‚æ•°skip\_special\_tokensè¡¨ç¤ºæ˜¯å¦å»æ‰â€œâ€ã€"&lt;\\s&gt;"ç­‰ä¸€äº›ç‰¹æ®Štokenã€‚

## Fine-tuning BART

ä¸‹é¢æˆ‘ä»¬æ¥çœ‹ä¸€çœ‹å¦‚ä½•ç”¨è‡ªå·±çš„æ•°æ®é›†æ¥è®­ç»ƒBARTæ¨¡å‹ã€‚

### æ¨¡å‹åŠ è½½

æ¨¡å‹åŠ è½½éƒ¨åˆ†å’Œä¹‹å‰è®²çš„ä¸€æ ·ï¼Œä¸å†è¿‡å¤šé‡å¤ã€‚è¿™é‡Œæˆ‘ä»¬è¦åˆ©ç”¨BartForConditionalGenerationç±»çš„from\_pretrained()å‡½æ•°ï¼ŒåŠ è½½ä¸€ä¸ªBARTæ¨¡å‹ã€‚

æ¨¡å‹åŠ è½½çš„ä»£ç å¦‚ä¸‹ã€‚è¿™é‡Œæˆ‘ä»¬ä¼šåœ¨Facebookè®­ç»ƒå¥½çš„æ‘˜è¦æ¨¡å‹ä¸Šï¼Œç»§ç»­Fine-tuningã€‚

```python
from transformers import BartTokenizer, BartForConditionalGeneration

tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')
model = BartForConditionalGeneration.from_pretrained('facebook/facebook/bart-large-cnn')
```

### æ•°æ®å‡†å¤‡

æ¥ä¸‹æ¥ï¼Œæ˜¯æ•°æ®å‡†å¤‡ã€‚æˆ‘ä»¬å…ˆæ¥å›é¡¾ä¸€ä¸‹ï¼Œä¹‹å‰å­¦ä¹ è¿‡çš„è¯»å–æ–‡æœ¬æ•°æ®é›†çš„æ–¹å¼ã€‚åœ¨[ç¬¬6è¯¾](https://time.geekbang.org/column/intro/100093301)ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ è¿‡ä½¿ç”¨PyTorchåŸç”Ÿçš„çš„Datasetç±»è¯»å–æ•°æ®é›†ï¼›åœ¨[ç¬¬23è¯¾](https://time.geekbang.org/column/article/462524)ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ä½¿ç”¨Torchtextå·¥å…·`torchtext.datasets`æ¥è¯»å–æ•°æ®é›†ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬è¿˜è¦å­¦ä¹ ä¸€ç§æ–°çš„æ•°æ®è¯»å–å·¥å…·ï¼šDatasetsåº“ã€‚

Datasetsåº“ä¹Ÿæ˜¯ç”±hugging faceå›¢é˜Ÿå¼€å‘çš„ï¼Œæ—¨åœ¨è½»æ¾è®¿é—®ä¸å…±äº«æ•°æ®é›†ã€‚å®˜æ–¹çš„æ–‡æ¡£åœ¨[è¿™é‡Œ](https://huggingface.co/docs/datasets/index.html)ï¼Œæœ‰å…´è¶£äº†è§£æ›´å¤šçš„åŒå­¦å¯ä»¥å»çœ‹çœ‹ã€‚

Datasetsåº“çš„å®‰è£…åŒæ ·éå¸¸ç®€å•ã€‚å¯ä»¥ä½¿ç”¨pipå®‰è£…ï¼š

```python
pip install datasets
```

æˆ–ä½¿ç”¨condaè¿›è¡Œå®‰è£…ï¼š

```python
conda install -c huggingface -c conda-forge datasets
```

Datasetsåº“ä¸­åŒæ ·åŒ…æ‹¬å¸¸è§æ•°æ®é›†ï¼Œè€Œä¸”å¸®æˆ‘ä»¬å°è£…å¥½äº†è¯»å–æ•°æ®é›†çš„æ“ä½œã€‚æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªè¯»å–IMDBæ•°æ®é›†ï¼ˆç¬¬23è¯¾è®²è¿‡ï¼‰çš„è®­ç»ƒæ•°æ®çš„ç¤ºä¾‹ï¼š

```python
import datasets
train_dataset = datasets.load_dataset("imdb", split="train")
print(train_dataset.column_names)
'''
è¾“å‡ºï¼š
['label', 'text']
'''
```

ç”¨load\_dataset()å‡½æ•°æ¥åŠ è½½æ•°æ®é›†ï¼Œå®ƒçš„å‚æ•°æ˜¯æ•°æ®é›†çš„åå­—æˆ–æœ¬åœ°æ–‡ä»¶çš„è·¯å¾„ï¼Œsplitå‚æ•°ç”¨äºæŒ‡å®šåŠ è½½è®­ç»ƒé›†ã€æµ‹è¯•é›†æˆ–éªŒè¯é›†ã€‚

æˆ‘ä»¬è¿˜å¯ä»¥ä»ä¸æ­¢ä¸€ä¸ªcsvæ–‡ä»¶ä¸­åŠ è½½æ•°æ®ï¼š

```python
data_files = {"train": "train.csv", "test": "test.csv"}
dataset = load_dataset("namespace/your_dataset_name", data_files=data_files)
print(datasets)
'''
ç¤ºä¾‹è¾“å‡ºï¼š(å®é™…è¾“å‡ºä¸æ­¤ä¸åŒ)
{train: Dataset({
    features: ['idx', 'text', 'summary'],
    num_rows: 3668
})
test: Dataset({
    features: ['idx', 'text', 'summary'],
    num_rows: 1725
})
}
'''
```

é€šè¿‡å‚æ•°data\_filesæŒ‡å®šè®­ç»ƒé›†ã€æµ‹è¯•é›†æˆ–éªŒè¯é›†æ‰€éœ€åŠ è½½çš„æ–‡ä»¶è·¯å¾„å³å¯ã€‚  
æˆ‘ä»¬å¯ä»¥ä½¿ç”¨map()å‡½æ•°æ¥å¯¹æ•°æ®é›†è¿›è¡Œä¸€äº›é¢„å¤„ç†æ“ä½œï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š

```python
def add_prefix(example):
Â  Â  example['text'] = 'My sentence: ' + example['text']
Â  Â  return example
updated_dataset = dataset.map(add_prefix)
updated_dataset['train']['text'][:5]
'''
ç¤ºä¾‹è¾“å‡ºï¼š
['My sentence: Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .',
"My sentence: Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .",
'My sentence: They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .',
'My sentence: Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .',
]
'''
```

æˆ‘ä»¬é¦–å…ˆå®šä¹‰äº†ä¸€ä¸ªadd\_prefix()å‡½æ•°ï¼Œå…¶ä½œç”¨æ˜¯ä¸ºæ•°æ®é›†çš„â€œtextâ€å­—æ®µåŠ ä¸Šä¸€ä¸ªå‰ç¼€â€œMy sentence: â€ã€‚ç„¶åè°ƒç”¨æ•°æ®é›†datasetçš„mapæ–¹æ³•ï¼Œå¯ä»¥çœ‹åˆ°è¾“å‡ºä¸­â€œtextâ€å­—æ®µçš„å†…å®¹å‰é¢éƒ½å¢åŠ äº†æŒ‡å®šå‰ç¼€ã€‚

ä¸‹é¢æˆ‘ä»¬æ¥çœ‹ä¸€çœ‹ï¼Œä½¿ç”¨è‡ªå®šä¹‰çš„æ•°æ®é›†fine-tuning BARTæ¨¡å‹åº”è¯¥æ€ä¹ˆåšã€‚å…·ä½“çš„ä»£ç å¦‚ä¸‹ï¼š

```python
from transformers.modeling_bart import shift_tokens_right

dataset = ... # Datasetsçš„å¯¹è±¡ï¼Œæ•°æ®é›†éœ€æœ‰'text'å’Œ'summary'å­—æ®µï¼Œå¹¶åŒ…å«è®­ç»ƒé›†å’ŒéªŒè¯é›†

def convert_to_features(example_batch):
Â  Â  input_encodings = tokenizer.batch_encode_plus(example_batch['text'], pad_to_max_length=True, max_length=1024, truncation=True))
Â  Â  target_encodings = tokenizer.batch_encode_plus(example_batch['summary'], pad_to_max_length=True, max_length=1024, truncation=True))
Â  Â Â 
Â  Â  labels = target_encodings['input_ids']
Â  Â  decoder_input_ids = shift_tokens_right(labels, model.config.pad_token_id)
Â  Â  labels[labels[:, :] == model.config.pad_token_id] = -100
Â  Â Â 
Â  Â  encodings = {
Â  Â  Â  Â  'input_ids': input_encodings['input_ids'],
Â  Â  Â  Â  'attention_mask': input_encodings['attention_mask'],
Â  Â  Â  Â  'decoder_input_ids': decoder_input_ids,
Â  Â  Â  Â  'labels': labels,
Â  Â  }

Â  Â  return encodings

dataset = dataset.map(convert_to_features, batched=True)
columns = ['input_ids', 'labels', 'decoder_input_ids','attention_mask',]Â 
dataset.set_format(type='torch', columns=columns)
```

é¦–å…ˆéœ€è¦åŠ è½½è‡ªå®šä¹‰çš„æ•°æ®é›†ï¼Œä½ è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªæ•°æ®é›†éœ€è¦åŒ…å«åŸæ–‡å’Œæ‘˜è¦ä¸¤ä¸ªå­—æ®µï¼Œå¹¶ä¸”åŒ…å«è®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚åŠ è½½æ•°æ®é›†çš„æ–¹æ³•å¯ä»¥ç”¨æˆ‘ä»¬åˆšåˆšè®²è¿‡çš„load\_dataset()å‡½æ•°ã€‚

ç”±äºåŠ è½½çš„æ•°æ®éœ€è¦ç»è¿‡ä¸€ç³»åˆ—é¢„å¤„ç†æ“ä½œï¼Œæ¯”å¦‚é€šè¿‡åˆ†è¯å™¨è¿›è¡Œåˆ†è¯ç­‰ç­‰çš„å¤„ç†åï¼Œæ‰èƒ½é€å…¥åˆ°æ¨¡å‹ä¸­ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°convert\_to\_features()æ¥å¤„ç†åŸæ–‡å’Œæ‘˜è¦æ–‡æœ¬ã€‚

convert\_to\_features()å‡½æ•°ä¸­çš„ä¸»è¦æ“ä½œå°±æ˜¯è°ƒç”¨tokenizeræ¥å°†æ–‡æœ¬è½¬åŒ–ä¸ºè¯è¯­idã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä»£ç ç¬¬10è¡Œä¸­æœ‰ä¸€ä¸ªshift\_tokens\_right()å‡½æ•°ï¼Œå®ƒçš„ä½œç”¨å°±æ˜¯æˆ‘ä»¬åœ¨åŸç†ä¸­ä»‹ç»è¿‡çš„Auto-Regressiveï¼Œç›®çš„æ˜¯å°†Decoderçš„è¾“å…¥å‘åç§»ä¸€ä¸ªä½ç½®ã€‚

ç„¶åæˆ‘ä»¬éœ€è¦è°ƒç”¨dataset.map()å‡½æ•°æ¥å¯¹æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†æ“ä½œï¼Œå‚æ•°batched=Trueè¡¨ç¤ºæ”¯æŒåœ¨batchæ•°æ®ä¸Šæ“ä½œã€‚

æœ€åå†åˆ©ç”¨set\_format()å‡½æ•°ç”Ÿæˆé€‰æ‹©è®­ç»ƒæ‰€éœ€çš„æ•°æ®å­—æ®µï¼Œå¹¶ç”ŸæˆPyTrochçš„Tensorã€‚åˆ°è¿™é‡Œï¼Œæ•°æ®å‡†å¤‡çš„å·¥ä½œå°±å‘Šä¸€æ®µè½äº†ã€‚

### æ¨¡å‹è®­ç»ƒ

åšå¥½äº†å‰é¢çš„å‡†å¤‡å·¥ä½œï¼Œæœ€åæˆ‘ä»¬æ¥çœ‹æ¨¡å‹è®­ç»ƒéƒ¨åˆ†ã€‚Transformerså·¥å…·å·²ç»å¸®æˆ‘ä»¬å°è£…äº†ç”¨äºè®­ç»ƒæ–‡æœ¬ç”Ÿæˆæ¨¡å‹çš„Seq2SeqTrainerç±»ï¼Œæ— éœ€æˆ‘ä»¬è‡ªå·±å†å»å®šä¹‰æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–æ–¹æ³•äº†ã€‚

å…·ä½“çš„è®­ç»ƒä»£ç å¦‚ä¸‹ã€‚

```python
from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer

training_args = Seq2SeqTrainingArguments(
Â  Â  output_dir='./models/bart-summarizer',# æ¨¡å‹è¾“å‡ºç›®å½•
Â  Â  num_train_epochs=1, # è®­ç»ƒè½®æ•°
Â  Â  per_device_train_batch_size=1,Â # è®­ç»ƒè¿‡ç¨‹bach_size
Â  Â  per_device_eval_batch_size=1, # è¯„ä¼°è¿‡ç¨‹bach_size
Â  Â  warmup_steps=500, # å­¦ä¹ ç‡ç›¸å…³å‚æ•°
Â  Â  weight_decay=0.01,Â # å­¦ä¹ ç‡ç›¸å…³å‚æ•°
Â  Â  logging_dir='./logs', # æ—¥å¿—ç›®å½•
)

trainer = Seq2SeqTrainer(
Â  Â  model=model,Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â 
Â  Â  args=training_args,Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  train_dataset=dataset['train'],Â  Â  Â  Â Â 
Â  Â  eval_dataset=dataset['validation']Â  Â 
)

trainer.train()
```

é¦–å…ˆæˆ‘ä»¬è¦å®šä¹‰ä¸€ä¸ªè®­ç»ƒå‚æ•°çš„å¯¹è±¡ï¼Œå…³äºè®­ç»ƒçš„ç›¸å…³å‚æ•°éƒ½é€šè¿‡Seq2SeqTrainingArgumentsç±»è¿›è¡Œå®šä¹‰ã€‚ç„¶åå†å®ä¾‹åŒ–ä¸€ä¸ªSeq2SeqTrainerç±»çš„å¯¹è±¡ï¼Œå°†æ¨¡å‹å’Œè®­ç»ƒæ•°æ®ä½œä¸ºå‚æ•°ä¼ å…¥å…¶ä¸­ã€‚æœ€åè°ƒç”¨train()æ–¹æ³•ï¼Œå³å¯ä¸€é”®å¼€å§‹è®­ç»ƒã€‚

## å°ç»“

æ­å–œä½ å®Œæˆäº†ä»Šå¤©çš„å­¦ä¹ ä»»åŠ¡ï¼ŒåŒæ—¶ä¹Ÿå®Œæˆäº†PyTorchçš„å…¨éƒ¨å­¦ä¹ å†…å®¹ã€‚

è¿™èŠ‚è¯¾æˆ‘ä»¬å…ˆä¸€èµ·äº†è§£äº†BARTæ¨¡å‹çš„åŸç†ä¸ç‰¹ç‚¹ï¼Œè¿™ä¸ªæ¨¡å‹æ˜¯ä¸€ä¸ªéå¸¸å®ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œèƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬å®ç°æ–‡æœ¬æ‘˜è¦ç”Ÿæˆã€‚ç„¶åæˆ‘ä»¬ç»“åˆå®ä¾‹ï¼Œå­¦ä¹ äº†å¦‚ä½•ç”¨PyTorchå¿«é€Ÿæ„å»ºä¸€ä¸ªè‡ªåŠ¨æ–‡æ‘˜ç”Ÿæˆé¡¹ç›®ï¼ŒåŒ…æ‹¬åˆ©ç”¨Transformersçš„pipelineå¿«é€Ÿç”Ÿæˆæ–‡æœ¬æ‘˜è¦å’ŒFine-tuning BARTæ¨¡å‹ã€‚

å› ä¸ºBARTæ¨¡å‹å…·æœ‰è‡ªå›å½’Transformerçš„ç»“æ„ï¼Œæ‰€ä»¥å®ƒä¸åªå¯ä»¥ç”¨äºæ‘˜è¦ç”Ÿæˆï¼Œè¿˜é€‚ç”¨äºå…¶å®ƒæ–‡æœ¬ç”Ÿæˆç±»çš„é¡¹ç›®ï¼Œä¾‹å¦‚æœºå™¨ç¿»è¯‘ã€å¯¹è¯ç”Ÿæˆç­‰ã€‚ç›¸ä¿¡ç†è§£äº†å®ƒçš„åŸºæœ¬åŸç†ä¸æ¨¡å‹Fine-tuningçš„åŸºæœ¬æµç¨‹ï¼Œä½ å¯ä»¥å¾ˆå®¹æ˜“åœ°åˆ©ç”¨BARTå®Œæˆæ–‡æœ¬ç”Ÿæˆç±»çš„ä»»åŠ¡ï¼ŒæœŸå¾…ä½ ä¸¾ä¸€åä¸‰ï¼Œäº²æ‰‹åšæ›´å¤šçš„å®éªŒã€‚

é€šè¿‡å®æˆ˜ç¯‡çš„å­¦ä¹ ï¼Œæˆ‘ä»¬ä¸€å…±æ¢è®¨ã€å®ç°äº†2ä¸ªå›¾åƒé¡¹ç›®å’Œ3ä¸ªè‡ªç„¶è¯­è¨€å¤„ç†é¡¹ç›®ã€‚å¦‚ä½•åŸºäº PyTorch æ­å»ºè‡ªå·±çš„æ·±åº¦å­¦ä¹ ç½‘ç»œï¼Œç›¸ä¿¡ä½ å·²ç»äº†ç„¶äºèƒ¸äº†ã€‚å½“æˆ‘ä»¬è§£å†³å®é™…çš„é—®é¢˜æ—¶ï¼Œé¦–å…ˆè¦ä»åŸç†å‡ºå‘ï¼Œé€‰æ‹©é€‚åˆçš„æ¨¡å‹ï¼ŒPyTorchåªæ˜¯ä¸€ä¸ªå·¥å…·ï¼Œè¾…åŠ©æˆ‘ä»¬å®ç°è‡ªå·±éœ€è¦çš„ç½‘ç»œã€‚

é™¤äº†è‡ªåŠ¨æ‘˜è¦å¤–ï¼Œå…¶ä»–å››ä¸ªé¡¹ç›®çš„å…±é€šæ€è·¯éƒ½æ˜¯æŠŠé—®é¢˜è½¬åŒ–ä¸ºåˆ†ç±»é—®é¢˜ã€‚å›¾åƒã€æ–‡æœ¬åˆ†ç±»ä¸å¿…ç»†è¯´ï¼Œå›¾åƒåˆ†å‰²å…¶å®æ˜¯åˆ¤åˆ«ä¸€ä¸ªåƒç´ æ˜¯å±äºå“ªä¸€ä¸ªç±»åˆ«ï¼Œæƒ…æ„Ÿåˆ†æåˆ™æ˜¯åˆ¤åˆ«æ–‡æœ¬æ˜¯ç§¯æç±»è¿˜æ˜¯æ¶ˆæç±»ã€‚è€Œè‡ªåŠ¨æ‘˜è¦åˆ™æ˜¯ç”Ÿæˆæ¨¡å‹ï¼Œé€šå¸¸æ˜¯åŸºäºsequence-to-sequenceçš„ç»“æ„æ¥å®ç°ã€‚

è¿™äº›æ˜¯æˆ‘é€šè¿‡ä¸€ç³»åˆ—çš„å®æˆ˜è®­ç»ƒï¼Œæœ€ç»ˆå¸Œæœ›ä½ é¢†ä¼šåˆ°çš„æ¨¡å‹æ­å»ºæ€è·¯ã€‚

## æ€è€ƒé¢˜

è‡ªä»2018å¹´BERTè¢«æå‡ºä»¥æ¥ï¼Œè·å¾—äº†å¾ˆå¤§çš„æˆåŠŸï¼Œå­¦æœ¯ç•Œé™†ç»­æå‡ºäº†å„ç±»ç›¸å…³æ¨¡å‹ï¼Œä¾‹å¦‚æˆ‘ä»¬ä»Šå¤©å­¦ä¹ çš„BARTã€‚è¯·ä½ æŸ¥ä¸€æŸ¥è¿˜æœ‰å“ªäº›BERTç³»åˆ—çš„æ¨¡å‹ï¼Œå¹¶é˜…è¯»ç›¸å…³è®ºæ–‡ï¼Œè‡ªè¡Œå­¦ä¹ ä¸€ä¸‹å®ƒä»¬çš„åŸç†ä¸ç‰¹ç‚¹ã€‚

æ¬¢è¿ä½ åœ¨ç•™è¨€åŒºå’Œæˆ‘äº¤æµäº’åŠ¨ï¼Œä¹Ÿæ¨èä½ æŠŠè¿™èŠ‚è¯¾è½¬å‘ç»™æ›´å¤šåŒäº‹ã€æœ‹å‹ï¼Œè·Ÿä»–ä¸€èµ·å­¦ä¹ è¿›æ­¥ã€‚
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ11ï¼‰</strong></div><ul>
<li><span>ifelse</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>å­¦ä¹ æ‰“å¡</p>2023-12-14</li><br/><li><span>XTZ</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è·‘é¢„å¤„ç†çš„æ—¶å€™æŠ¥äº†é”™Provided `function` which is applied to all elements of table returns a `dict` of types [&lt;class &#39;list&#39;&gt;, &lt;class &#39;list&#39;&gt;, &lt;class &#39;torch.Tensor&#39;&gt;, &lt;class &#39;torch.Tensor&#39;&gt;]. When using `batched=True`, make sure provided `function` returns a `dict` of types like `(&lt;class &#39;list&#39;&gt;, &lt;class &#39;numpy.ndarray&#39;&gt;)`ä½†æ˜¯è¿™ä¸ªè¿”å›å€¼ä¸èƒ½å»æ‰ä»»ä½•ä¸€æ¡å•Š</p>2022-09-10</li><br/><li><span>Geek_709f77</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ8ï¼‰<p>æœ‰äº¤æµç¾¤èƒ½åŠ ä¹ˆï¼Ÿ</p>2022-04-16</li><br/><li><span>(â—â€”â—)</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>è¯·é—®æ¨¡å‹ä¸‹è½½äº†ä¸€åŠï¼Œç„¶åæ–­ç½‘äº†ï¼Œè¿è¡Œçš„ç»“æœä¸ä¸€è‡´ï¼Œæ€ä¹ˆè§£å†³å‘¢ï¼Ÿæˆ–è€…æœ‰äº¤æµç¾¤å—ï¼Ÿ</p>2022-03-22</li><br/><li><span>è“è‰²å¤©ç©º  å¥½èŒå•Š</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è€å¸ˆï¼Œæœ‰å®Œæ•´çš„BARTä»£ç åœ°å€å—ï¼Ÿ</p>2022-01-27</li><br/><li><span>è“è‰²å¤©ç©º  å¥½èŒå•Š</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è¿˜æœ‰T5ã€å»å¹´æ¯”è¾ƒçƒ­çš„promptå’Œå¯¹æ¯”å­¦ä¹ ç­‰</p>2022-01-27</li><br/><li><span>é’±é’±é’±æˆ‘çˆ±é’±</span> ğŸ‘ï¼ˆ3ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>è¯·é—®è€å¸ˆçš„ä»£ç ä»“åº“åœ¨å“ªé‡Œå‘¢ï¼Ÿæ²¡æ‰¾åˆ°</p>2023-05-01</li><br/><li><span>Archerîª</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>æ–¹è€å¸ˆ ï¼Œæ‚¨å¥½ã€‚
æˆ‘åœ¨è·‘piplineæ—¶ï¼Œå°è¯•å»æå–ä¸€ä¸ªå¤§æ–‡æœ¬çš„æ‘˜è¦ã€‚
ä½†æ˜¯print(summarizer(ARTICLE, max_length=130, min_length=30))
è¿™ä¸€è¡ŒæŠ¥å‡ºé”™è¯¯ï¼šIndexError: index out of range in self ã€‚
è¯·é—®æ‚¨æœ‰é‡åˆ°è¿‡ç±»ä¼¼çš„é—®é¢˜å—ï¼Ÿå¦‚ä½•è§£å†³å‘¢ï¼Ÿ</p>2022-10-04</li><br/><li><span>äºšæ—</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>è€å¸ˆçš„ä¾‹å­æ²¡è·‘é€šï¼Œæˆ‘ç”¨å®˜ç½‘çš„æ–‡æ‘˜å¾®è°ƒï¼ŒT5-samlè®­ç»ƒ BillSum æ•°æ®é›†è·‘é€šäº†ã€‚
https:&#47;&#47;huggingface.co&#47;docs&#47;transformers&#47;tasks&#47;summarization</p>2022-06-10</li><br/><li><span>äºšæ—</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>è€å¸ˆçš„æºä»£ç è®­ç»ƒæœ‰ç‚¹ç‰›ï¼Œæˆ‘è¿˜æ˜¯ç”¨å®˜ç½‘T5ç®€å•çš„å¼„äº†å¼„ã€‚
https:&#47;&#47;huggingface.co&#47;docs&#47;transformers&#47;tasks&#47;summarization</p>2022-06-10</li><br/><li><span>äºšæ—</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>summarizer = pipeline(&quot;summarization&quot;)
No model was supplied, defaulted to sshleifer&#47;distilbart-cnn-12-6 (https:&#47;&#47;huggingface.co&#47;sshleifer&#47;distilbart-cnn-12-6)
è¿™ä¸ªsummarizationæ¨¡å‹æ²¡æ‰¾åˆ°ï¼Œå°±ä½¿ç”¨é»˜è®¤çš„æ¨¡å‹</p>2022-06-10</li><br/>
</ul>