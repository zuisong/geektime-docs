ä½ å¥½ï¼Œæˆ‘æ˜¯å—æŸ¯ã€‚

å‰é¢å‡ è®²ï¼Œæˆ‘ä»¬å·²ç»äº†è§£äº†æ‰©æ•£æ¨¡å‹çš„ç®—æ³•åŸç†å’Œç»„æˆæ¨¡å—ï¼Œå­¦ä¹ äº†Stable Diffusionæ¨¡å‹æ–°å¢çš„CLIPå’ŒVAEæ¨¡å—ã€‚æŒæ¡äº†è¿™äº›çŸ¥è¯†ï¼Œç›¸ä¿¡ä½ ä¹Ÿä¸€å®šè·ƒè·ƒæ¬²è¯•ï¼Œæƒ³è¦è®­ç»ƒä¸€ä¸ªå±äºè‡ªå·±çš„AIç»˜ç”»æ¨¡å‹ã€‚

è¿™ä¸€è®²ï¼Œæˆ‘ä»¬ä¼šå°†å‰å‡ è®²çš„çŸ¥è¯†ä¸²è”èµ·æ¥ï¼Œä»å…¨å±€çš„è§†è§’è®¨è®ºæ‰©æ•£æ¨¡å‹å¦‚ä½•è®­ç»ƒå’Œä½¿ç”¨ã€‚æˆ‘ä»¬å°†é€šè¿‡å®æˆ˜çš„å½¢å¼ï¼Œä¸€èµ·è®­ç»ƒä¸€ä¸ªæ ‡å‡†æ‰©æ•£æ¨¡å‹ï¼Œå¹¶å¾®è°ƒä¸€ä¸ªStable Diffusionæ¨¡å‹ï¼Œå¸®ä½ è¿›ä¸€æ­¥åŠ æ·±å¯¹çŸ¥è¯†çš„ç†è§£ã€‚å­¦å®Œè¿™ä¸€è®²ï¼Œæˆ‘ä»¬å°±è¿ˆå‡ºäº†æ¨¡å‹è‡ªç”±çš„å…³é”®ä¸€æ­¥ã€‚

## å…³é”®çŸ¥è¯†ä¸²è”

åœ¨å®æˆ˜ä¹‹å‰ï¼Œæˆ‘æƒ³è¯·ä½ æ€è€ƒä¸€ä¸ªé—®é¢˜ï¼šæƒ³è¦æŠŠæ ‡å‡†çš„æ‰©æ•£æ¨¡å‹å‡çº§ä¸ºStable Diffusionï¼Œéœ€è¦å‡ æ­¥æ“ä½œï¼Ÿ

ç­”æ¡ˆæ˜¯ä¸¤æ­¥ã€‚

æˆ‘ä»¬é€šè¿‡[ç¬¬6è®²](https://time.geekbang.org/column/article/681276)å·²ç»çŸ¥é“ï¼Œæ ‡å‡†æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹åŒ…å«6ä¸ªæ­¥éª¤ï¼Œåˆ†åˆ«æ˜¯éšæœºé€‰å–è®­ç»ƒå›¾åƒã€éšæœºé€‰æ‹©æ—¶é—´æ­¥tã€éšæœºç”Ÿæˆé«˜æ–¯å™ªå£°ã€ä¸€æ­¥è®¡ç®—ç¬¬tæ­¥åŠ å™ªå›¾ã€ä½¿ç”¨UNeté¢„æµ‹å™ªå£°å€¼å’Œè®¡ç®—å™ªå£°æ•°å€¼è¯¯å·®ã€‚

Stable Diffusionåœ¨æ­¤åŸºç¡€ä¸Šï¼Œå¢åŠ äº†VAEæ¨¡å—å’ŒCLIPæ¨¡å—ã€‚VAEæ¨¡å—çš„ä½œç”¨æ˜¯é™ä½è¾“å…¥å›¾åƒçš„ç»´åº¦ï¼Œä»è€ŒåŠ å¿«æ¨¡å‹è®­ç»ƒã€ç»™GPUè…¾è…¾åœ°æ–¹ï¼›CLIPæ¨¡å—çš„ä½œç”¨åˆ™æ˜¯å°†æ–‡æœ¬æè¿°é€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶æ³¨å…¥åˆ°UNetæ¨¡å—ï¼Œè®©AIç»˜ç”»æ¨¡å‹åšåˆ°è¨€å‡ºæ³•éšã€‚

æˆ‘ä»¬ä¸å¦¨å†ç¿»å‡ºStable Diffusionçš„ç®—æ³•æ¡†æ¶å›¾å›å¿†ä¸€ä¸‹ã€‚å›¾ä¸­æœ€å·¦ä¾§ç²‰è‰²åŒºåŸŸä¾¿æ˜¯VAEæ¨¡å—ï¼Œæœ€å³ä¾§çš„æ¡ä»¶æ§åˆ¶æ¨¡å—ä¾¿å¯ä»¥æ˜¯CLIPï¼ˆä¹Ÿå¯ä»¥æ˜¯å…¶ä»–æ§åˆ¶æ¡ä»¶ï¼‰ï¼Œè€Œä¸­é—´UNetéƒ¨åˆ†å±•ç¤ºçš„QKVæ¨¡å—ï¼Œä¾¿æ˜¯prompté€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å¼•å¯¼å›¾åƒç”Ÿæˆã€‚åˆ°æ­¤ä¸ºæ­¢ï¼Œæ˜¯ä¸æ˜¯ä¸€åˆ‡éƒ½ä¸²è”èµ·æ¥äº†ï¼Ÿ

![](https://static001.geekbang.org/resource/image/44/5a/4431b947bb93aafba67c8f731de29b5a.jpg?wh=3805x1907 "å›¾ç‰‡æ¥æºï¼šhttps://arxiv.org/abs/2112.10752")

äº‹å®ä¸Šï¼Œåœ¨Stable Diffusionä¸­ï¼Œè¿˜æœ‰å¾ˆå¤šå…¶ä»–é»‘é­”æ³•ï¼Œæ¯”å¦‚æ— æ¡ä»¶å¼•å¯¼æ§åˆ¶ï¼ˆClassifier-Free Guidanceï¼‰ã€å¼•å¯¼å¼ºåº¦ï¼ˆGuidance Scaleï¼‰ç­‰ï¼Œæˆ‘ä»¬ä¼šåœ¨ä¸‹ä¸€ç« è¿›ä¸€æ­¥æ¢è®¨ã€‚

çŸ¥é“äº†è¿™äº›ï¼Œæˆ‘ä»¬ä¸å¦¨ç»§ç»­æ€è€ƒä¸€ä¸ªé—®é¢˜ï¼šè®­ç»ƒä¸€ä¸ªæ ‡å‡†æ‰©æ•£æ¨¡å‹å’ŒStable Diffusionæ¨¡å‹ï¼Œéœ€è¦å‡†å¤‡å“ªäº›â€œåŸææ–™â€å‘¢ï¼Ÿ

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦GPUï¼Œæ˜¾å­˜è¶Šå¤§è¶Šå¥½ã€‚æ²¡æœ‰è‹±ä¼Ÿè¾¾æ˜¾å¡çš„åŒå­¦ï¼Œå¯ä»¥ä½¿ç”¨Colabå…è´¹çš„15G T4æ˜¾å¡ã€‚åœ¨[ç¬¬10è®²](https://time.geekbang.org/column/article/684612)ä¸­æˆ‘ä»¬è¯¦ç»†è®¨è®ºäº†Colab GPUç¯å¢ƒçš„ç”¨æ³•ï¼Œä¸ç†Ÿæ‚‰çš„è¯ä½ å¯ä»¥é€šè¿‡è¶…é“¾æ¥å›é¡¾ã€‚

![](https://static001.geekbang.org/resource/image/2a/ec/2a35be37dce07657b1e4229376388bec.png?wh=2085x841)

ç„¶åï¼Œæˆ‘ä»¬éœ€è¦è®­ç»ƒæ•°æ®ã€‚å¯¹äºæ ‡å‡†æ‰©æ•£æ¨¡å‹è€Œè¨€ï¼Œæˆ‘ä»¬åªéœ€è¦çº¯ç²¹çš„å›¾ç‰‡æ•°æ®å³å¯ï¼›å¯¹äºStable Diffusionï¼Œç”±äºæˆ‘ä»¬éœ€è¦æ–‡æœ¬å¼•å¯¼ï¼Œå°±éœ€è¦ç”¨åˆ°å›¾ç‰‡æ•°æ®å¯¹åº”çš„æ–‡æœ¬æè¿°ã€‚è¿™é‡Œçš„æ–‡æœ¬æè¿°æ—¢å¯ä»¥æ˜¯åƒCLIPè®­ç»ƒæ•°æ®é‚£ç§å¯¹åº”çš„æ–‡æœ¬æè¿°ï¼Œä¹Ÿå¯ä»¥æ˜¯ä½¿ç”¨å„ç§å›¾ç‰‡æè¿°ï¼ˆimage captionï¼‰æ¨¡å‹è·å–çš„æ–‡æœ¬æè¿°ã€‚

å¦‚æœä½ è¦è®­ç»ƒçš„æ˜¯Stable Diffusionï¼Œåœ¨ç¬¬1è®²ä¸­æˆ‘ä»¬ä¼°ç®—è¿‡ï¼Œä»å¤´å¼€å§‹è®­ç»ƒçš„æˆæœ¬å·®ä¸å¤šæ˜¯å‡ å¥—æµ·æ·€å­¦åŒºæˆ¿çš„ä»·æ ¼ï¼Œæ‰€ä»¥æˆ‘ä»¬æœ€å¥½æ˜¯åŸºäºæŸä¸ªå¼€æºé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œé’ˆå¯¹æ€§å¾®è°ƒã€‚äº‹å®ä¸Šï¼Œå¼€æºç¤¾åŒºé‡Œå¤§å¤šæ•°æ¨¡å‹éƒ½æ˜¯å¾®è°ƒå‡ºæ¥çš„ã€‚

æ­¤å¤–ï¼Œå¯¹äºStable Diffusionï¼Œæˆ‘ä»¬è¿˜éœ€è¦å‡†å¤‡å¥½é¢„å…ˆè®­ç»ƒå¥½çš„CLIPæ¨¡å‹å’ŒVAEæ¨¡å‹ã€‚

å…³äºè®­ç»ƒæ•°æ®ã€å¼€æºé¢„è®­ç»ƒæ¨¡å‹ã€CLIPå’ŒVAEï¼Œä½ éƒ½ä¸å¿…æ‹…å¿ƒã€‚åé¢çš„ä»£ç ç¯èŠ‚æˆ‘ä¼šè¯´æ˜è·å–æ–¹æ³•ã€‚ç°åœ¨ä½ åªéœ€è¦å‡†å¤‡å¥½GPUèµ„æºå³å¯ã€‚

è¿™ä¸€è®²çš„å®æˆ˜éƒ¨åˆ†ï¼Œæ‰€æœ‰æ“ä½œä½ éƒ½å¯ä»¥é€šè¿‡ç‚¹å¼€æˆ‘æä¾›çš„[Colabé“¾æ¥](https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson12/train_diffusion_v2.ipynb)æ¥å®Œæˆã€‚å½“ç„¶ï¼Œæˆ‘æ›´æ¨èä½ æ–°å»ºå…¨æ–°çš„Colabï¼Œå¯¹ç…§æˆ‘æä¾›çš„åŸå§‹Colabé€æ­¥å†™ä»£ç æ¥å®Œæˆã€‚è¿™æ ·æœ‰åŠ©äºä½ åŠ æ·±å¯¹è®­ç»ƒè¿‡ç¨‹çš„ç†è§£ã€‚

## è®­ç»ƒæ‰©æ•£æ¨¡å‹

è¿™é‡Œæˆ‘ä»¬é€šè¿‡ä¸¤ç§æ–¹å¼æ¥è®­ç»ƒæ‰©æ•£æ¨¡å‹ã€‚

ç¬¬ä¸€ç§æ˜¯ä½¿ç”¨denoising\_diffusion\_pytorchè¿™ä¸ªé«˜åº¦é›†æˆçš„å·¥å…·åŒ…ï¼Œç¬¬äºŒç§åˆ™æ˜¯åŸºäºdiffusersè¿™ç§æ›´å¤šå¼€å‘è€…ä½¿ç”¨çš„å·¥å…·åŒ…ã€‚å¯¹äºä¸“ä¸šçš„ç®—æ³•åŒå­¦è€Œè¨€ï¼Œæˆ‘æ›´æ¨èä½¿ç”¨diffusersæ¥è®­ç»ƒã€‚åŸå› æ˜¯diffuserså·¥å…·åŒ…åœ¨å®é™…çš„AIç»˜ç”»é¡¹ç›®ä¸­ç”¨å¾—æ›´å¤šï¼Œå¹¶ä¸”ä¹Ÿæ›´æ˜“äºæˆ‘ä»¬ä¿®æ”¹ä»£ç é€»è¾‘ï¼Œå®ç°å®šåˆ¶åŒ–åŠŸèƒ½ã€‚

### è®¤è¯†åŸºç¡€æ¨¡å—

å…ˆçœ‹ç¬¬ä¸€ç§è®­ç»ƒæ–¹å¼ï¼Œæˆ‘ä»¬å…ˆæŒ‰ç…§ä¸‹é¢çš„æ–¹å¼ï¼Œåœ¨Colabé‡Œå®‰è£…å¯¹åº”å·¥å…·åŒ…ã€‚ä½ å¯ä»¥ç›´æ¥ç‚¹å¼€æˆ‘çš„ [Colabé“¾æ¥](https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson12/train_diffusion_v2.ipynb)ï¼Œç‚¹å‡»æ’­æ”¾æŒ‰é”®é€æ­¥æ“ä½œã€‚

```bash
pip install denoising_diffusion_pytorch
```

è¿™ä¸ªå·¥å…·åŒ…ä¸­æä¾›äº†UNetå’Œæ‰©æ•£æ¨¡å‹ä¸¤ä¸ªå°è£…å¥½çš„æ¨¡å—ï¼Œä½ å¯ä»¥é€šè¿‡ä¸¤è¡ŒæŒ‡ä»¤åˆ›å»ºUNetï¼Œå¹¶åŸºäºåˆ›å»ºå¥½çš„UNetåˆ›å»ºä¸€ä¸ªå®Œæ•´çš„æ‰©æ•£æ¨¡å‹ï¼ŒåŒæ—¶æŒ‡å®šäº†å›¾åƒåˆ†è¾¨ç‡å’Œæ€»çš„åŠ å™ªæ­¥æ•°ã€‚

```python
from denoising_diffusion_pytorch import Unet, GaussianDiffusion
import torch 

model = Unet(
    dim = 64,  
    dim_mults = (1, 2, 4, 8)
).cuda()

diffusion = GaussianDiffusion(
    model,
    image_size = 128,
    timesteps = 1000   # number of steps
).cuda()
```

è®­ç»ƒè¿‡ç¨‹ä¹Ÿéå¸¸æ¸…çˆ½ï¼Œä¸ºäº†å¸®ä½ æ›´å¥½åœ°ç†è§£ä¸€æ¬¡è®­ç»ƒçš„è¿‡ç¨‹æ˜¯æ€æ ·çš„ã€‚æˆ‘ä»¬ç»“åˆä»£ç ä¾‹å­çœ‹ä¸€ä¸‹ï¼Œæ¯”å¦‚æˆ‘ä»¬éšæœºåˆå§‹åŒ–å…«å¼ å›¾ç‰‡ï¼Œä¾¿å¯ä»¥é€šè¿‡åé¢è¿™ä¸¤è¡Œä»£ç å®Œæˆæ‰©æ•£æ¨¡å‹çš„ä¸€æ¬¡è®­ç»ƒã€‚

```python
# ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„å›¾ç‰‡è¿›è¡Œä¸€æ¬¡è®­ç»ƒ
training_images = torch.randn(8, 3, 128, 128)
loss = diffusion(training_images.cuda())
loss.backward()
```

å¦‚æœä½ æƒ³ç”¨è‡ªå·±æœ¬åœ°çš„å›¾åƒï¼Œè€Œééšæœºåˆå§‹åŒ–çš„å›¾åƒï¼Œå¯ä»¥å‚è€ƒä¸‹é¢çš„ä»£ç ã€‚

```python
from PIL import Image
import torchvision.transforms as transforms
import torch
# é¢„è®¾ä¸€ä¸ªå˜æ¢æ“ä½œï¼Œå°†PIL Imageè½¬æ¢ä¸ºPyTorch Tensorï¼Œå¹¶å¯¹å…¶è¿›è¡Œå½’ä¸€åŒ–
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
])
# æˆ‘ä»¬è®¤ä¸ºä½ æœ‰ä¸ªåˆ—è¡¨åŒ…å«äº†8å¼ å›¾åƒçš„è·¯å¾„
image_paths = ['path_to_your_image1', 'path_to_your_image2', 'path_to_your_image3', 'path_to_your_image4', 
               'path_to_your_image5', 'path_to_your_image6', 'path_to_your_image7', 'path_to_your_image8'] 
# ä½¿ç”¨List comprehensionè¯»å–å¹¶å¤„ç†è¿™äº›å›¾ç‰‡
images = [transform(Image.open(image_path)) for image_path in image_paths] 
# å°†å¤„ç†å¥½çš„å›¾åƒListè½¬åŒ–ä¸ºä¸€ä¸ª4D Tensorï¼Œæ³¨æ„torch.stackèƒ½å¤Ÿè‡ªåŠ¨å¤„ç†3D Tensoråˆ°4D Tensorçš„è½¬æ¢
training_images = torch.stack(images)
# ç°åœ¨training_imagesåº”è¯¥æœ‰8å¼ 3x128x128çš„å›¾åƒ
print(training_images.shape)  # torch.Size([8, 3, 128, 128])
```

è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨å¾—åˆ°çš„æ¨¡å‹æ¥ç”Ÿæˆå›¾åƒã€‚ç”±äºæˆ‘ä»¬çš„æ¨¡å‹åªè®­ç»ƒäº†ä¸€æ­¥ï¼Œæ¨¡å‹çš„è¾“å‡ºä¹Ÿæ˜¯çº¯ç²¹çš„å™ªå£°å›¾ã€‚è¿™é‡Œåªæ˜¯ä¸ºäº†è®©ä½ æ‰¾ä¸€ä¸‹æ‰‹æ„Ÿã€‚

```python
sampled_images = diffusion.sample(batch_size = 4)
```

![](https://static001.geekbang.org/resource/image/2a/9f/2a5b3f82bca2a0a01272f81e6b1bbd9f.jpg?wh=4409x1486)

### æ•°æ®å‡†å¤‡

ç†è§£å®ŒåŸºæœ¬æµç¨‹ï¼Œæˆ‘ä»¬ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡Œä¸€æ¬¡è®­ç»ƒã€‚æˆ‘ä»¬ä»¥ [oxford-flowers](https://huggingface.co/datasets/nelorth/oxford-flowers) è¿™ä¸ªæ•°æ®é›†ä¸ºä¾‹ï¼Œé¦–å…ˆéœ€è¦å®‰è£…datasetsè¿™ä¸ªå·¥å…·åŒ…ã€‚

```bash
pip install datasets
```

æˆ‘ä»¬ä½¿ç”¨åé¢çš„ä»£ç å°±å¯ä»¥ä¸‹è½½è¿™ä¸ªæ•°æ®é›†ï¼Œå¹¶å°†æ•°æ®é›†ä¸­æ‰€æœ‰çš„å›¾ç‰‡å•ç‹¬å­˜å‚¨æˆpngæ ¼å¼ï¼Œç”¨pngæ ¼å¼æ›´æ–¹ä¾¿æˆ‘ä»¬æŸ¥çœ‹ã€‚å…¨éƒ¨å¤„ç†å®Œå¤§æ¦‚æœ‰8000å¼ å›¾ç‰‡ã€‚

```bash
from PIL import Image
from io import BytesIO
from datasets import load_dataset
import os
from tqdm import tqdm

dataset = load_dataset("nelorth/oxford-flowers")

# åˆ›å»ºä¸€ä¸ªç”¨äºä¿å­˜å›¾ç‰‡çš„æ–‡ä»¶å¤¹
images_dir = "./oxford-datasets/raw-images"
os.makedirs(images_dir, exist_ok=True)

# éå†æ‰€æœ‰å›¾ç‰‡å¹¶ä¿å­˜ï¼Œé’ˆå¯¹oxford-flowersï¼Œæ•´ä¸ªè¿‡ç¨‹è¦æŒç»­15åˆ†é’Ÿå·¦å³
for split in dataset.keys():
    for index, item in enumerate(tqdm(dataset[split])):
        image = item['image']
        image.save(os.path.join(images_dir, f"{split}_image_{index}.png"))
```

ä½ ä¹Ÿå¯ä»¥åœ¨ [Hugging Face](https://huggingface.co/) ä¸ŠæŒ‘é€‰ä½ å–œæ¬¢çš„å›¾åƒæ•°æ®é›†ï¼ŒæŒ‘é€‰å’Œä½¿ç”¨æ–¹æ³•å¯ä»¥å‚è€ƒåé¢çš„æˆªå›¾ã€‚

![](https://static001.geekbang.org/resource/image/96/37/960f48e7fd26e3236c84a548cf1c7237.png?wh=1710x975)

![](https://static001.geekbang.org/resource/image/2y/5a/2yyf8bd9eebe1f8e8a2d04542d34805a.png?wh=1606x872)

ç‚¹å‡»æ•°æ®é›†ä½¿ç”¨åï¼Œé€šè¿‡ä¸‹é¢ä¸¤è¡Œä»£ç å³å¯å®Œæˆæ•°æ®é›†çš„ä¸‹è½½å’Œè¯»å–ã€‚

![](https://static001.geekbang.org/resource/image/3f/12/3f68f0e2f579aacf001c053ffcd84812.png?wh=1575x406)

```python
from datasets import load_dataset
dataset = load_dataset("nelorth/oxford-flowers")
```

æ¯”æ–¹è¯´ä¸Šå›¾å±•ç¤ºçš„è¿™ä¸ªæ•°æ®é›†ï¼Œé‡Œé¢éƒ½æ˜¯ä¸€äº›ä¸åŒçš„èŠ±æœµã€‚æˆ‘ä»¬è¯¾ç¨‹é‡Œå°±é€‰æ‹©è¿™ä¸ªèŠ±æœµæ•°æ®é›†ï¼Œè®­ç»ƒçš„ç›®çš„å°±æ˜¯å¾—åˆ°ä¸€ä¸ªæ‰©æ•£æ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹å¯ä»¥ä»å™ªå£°å‡ºå‘ï¼Œé€æ­¥å»å™ªå¾—åˆ°ä¸€æœµèŠ±ã€‚

### æ¨¡å‹è®­ç»ƒ

å‡†å¤‡å·¥ä½œå®Œæˆï¼Œæˆ‘ä»¬ä¾¿å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç æ¥è¿›è¡Œå®Œæ•´è®­ç»ƒã€‚å¦‚æœä½ çš„GPUä¸å¤Ÿå¼ºå¤§ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´è®­ç»ƒçš„batch\_sizeå¤§å°ã€‚

```python
import torch
from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer

model = Unet(
    dim = 64,
    dim_mults = (1, 2, 4, 8)
).cuda()

diffusion = GaussianDiffusion(
    model,
    image_size = 128,
    timesteps = 1000   # åŠ å™ªæ€»æ­¥æ•°
).cuda()

trainer = Trainer(
    diffusion,
    './oxford-datasets/raw-images',
    train_batch_size = 16,
    train_lr = 2e-5,
    train_num_steps = 20000,          # æ€»å…±è®­ç»ƒ20000æ­¥
    gradient_accumulate_every = 2,    # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
    ema_decay = 0.995,                # æŒ‡æ•°æ»‘åŠ¨å¹³å‡decayå‚æ•°
    amp = True,                       # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒåŠ é€Ÿ
    calculate_fid = False,            # æˆ‘ä»¬å…³é—­FIDè¯„æµ‹æŒ‡æ ‡è®¡ç®—ï¼ˆæ¯”è¾ƒè€—æ—¶ï¼‰ã€‚FIDç”¨äºè¯„æµ‹ç”Ÿæˆè´¨é‡ã€‚
    save_and_sample_every = 2000      # æ¯éš”2000æ­¥ä¿å­˜ä¸€æ¬¡æ¨¡å‹
)

trainer.train()
```

è¿™é‡Œåˆ†äº«ä¸€ä¸ªå°æŠ€å·§ï¼Œå¦‚æœåœ¨ä½¿ç”¨GPUçš„æ—¶å€™æŠ¥é”™æç¤ºæ˜¾å­˜ä¸è¶³ï¼Œå¯ä»¥é€šè¿‡åé¢çš„å‘½ä»¤æ‰‹å·¥é‡Šæ”¾ä¸å†ä½¿ç”¨çš„GPUæ˜¾å­˜ã€‚

```python
import gc

del old_model # è¿™é‡Œçš„old_modelæ˜¯æŒ‡å·²ç»ä¸ä¼šå†ç”¨åˆ°çš„æ¨¡å‹
gc.collect()
torch.cuda.empty_cache()
```

å¯¹äº16Gçš„V100æ˜¾å¡è€Œè¨€ï¼Œæ•´ä¸ªä»»åŠ¡çš„è®­ç»ƒè¦æŒç»­3è‡³4ä¸ªå°æ—¶ã€‚åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯æ¬¡é—´éš”2000ä¸ªè®­ç»ƒæ­¥ï¼Œæˆ‘ä»¬ä¼šä¿å­˜ä¸€æ¬¡æ¨¡å‹æƒé‡ï¼Œå¹¶åˆ©ç”¨å½“å‰æƒé‡è¿›è¡Œå›¾åƒçš„ç”Ÿæˆã€‚

ä½ å¯ä»¥å‚è€ƒåé¢çš„å›¾ç‰‡ï¼Œèƒ½çœ‹å‡ºï¼Œéšç€è®­ç»ƒæ­¥æ•°çš„å¢å¤šï¼Œè¿™ä¸ªæ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆèƒ½åŠ›åœ¨é€æ¸å˜å¼ºã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/84/2d/840c6c627e2539d79326ab7a926bee2d.gif?wh=652x702)

### è¿›é˜¶åˆ°diffusersè®­ç»ƒ

å¯¹äºæˆ‘ä»¬æåˆ°çš„ç¬¬äºŒç§æ‰©æ•£æ¨¡å‹è®­ç»ƒæ–¹å¼ï¼ŒåŸºäºdiffuserså·¥å…·åŒ…çš„è®­ç»ƒï¼Œæˆ‘ä»¬è¦å†™çš„ä»£ç å°±ä¼šå¤šå¾—å¤šï¼Œå¹¶ä¸”å¯è°ƒèŠ‚çš„å‚æ•°ä¹Ÿä¼šå¤šå¾ˆå¤šã€‚

è¿™é‡Œæˆ‘æ”¾ä¸€ä¸ª [Colabçš„é“¾æ¥](https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson12/diffusers_training_example_annotated.ipynb)ï¼ŒåŒ…å«å®Œæ•´çš„è®­ç»ƒä»£ç ã€‚æˆ‘æ¥å¸¦ä½ ä¸€èµ·æ‹†è§£ä¸‹å…¶ä¸­çš„å…³é”®éƒ¨åˆ†ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬çœ‹æ•°æ®é›†çš„ä½¿ç”¨ã€‚é€šè¿‡datasetså·¥å…·åŒ…åŠ è½½æ•°æ®é›†ï¼Œä¸denoising\_diffusion\_pytorchçš„è®­ç»ƒä¸åŒï¼Œåœ¨diffusersè®­ç»ƒæ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬ä¸éœ€è¦å°†æ•°æ®é›†å†è½¬ä¸ºæœ¬åœ°å›¾ç‰‡æ ¼å¼ã€‚

```python
import torch
from datasets import load_dataset

# åŠ è½½æ•°æ®é›†
config.dataset_name = "huggan/smithsonian_butterflies_subset"
dataset = load_dataset(config.dataset_name, split="train")

# å°è£…æˆè®­ç»ƒç”¨çš„æ ¼å¼
train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=config.train_batch_size, shuffle=True)
```

ä¸ºäº†æå‡æ¨¡å‹çš„æ€§èƒ½ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹å›¾åƒæ•°æ®è¿›è¡Œæ•°æ®å¢å¹¿ã€‚æ‰€è°“æ•°æ®å¢å¹¿ï¼Œå°±æ˜¯å¯¹å›¾åƒåšä¸€äº›éšæœºå·¦å³ç¿»è½¬ã€éšæœºé¢œè‰²æ‰°åŠ¨ç­‰æ“ä½œï¼Œç›®çš„æ˜¯å¢å¼ºè®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§ã€‚

```python
from torchvision import transforms

preprocess = transforms.Compose(
    [
        transforms.Resize((config.image_size, config.image_size)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5]),
    ]
)
```

ç„¶åæˆ‘ä»¬çœ‹UNetç»“æ„ã€‚æŒ‰ç…§ä¸‹å›¾çš„ç»“æ„æ­å»ºUNetæ¨¡å—ï¼Œæ¯”å¦‚å›¾ä¸­è¾“å…¥å’Œè¾“å‡ºçš„åˆ†è¾¨ç‡éƒ½æ˜¯128x128ï¼Œåœ¨å®é™…UNetæ­å»ºä¸­ä½ å¯ä»¥ä»»æ„æŒ‡å®šã€‚

![](https://static001.geekbang.org/resource/image/5d/7e/5dde838e4acda1e2603e3a6dd86f127e.png?wh=2134x1046)

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢çš„ä»£ç æ¥åˆ›å»ºUNetç»“æ„ã€‚

```python
from diffusers import UNet2DModel

model = UNet2DModel(
Â  Â  sample_size=config.image_size,Â  # ç›®æ ‡å›¾åƒçš„åˆ†è¾¨ç‡
Â  Â  in_channels=3,Â  # è¾“å…¥é€šé“çš„æ•°é‡ï¼Œå¯¹äºRGBå›¾åƒä¸º3
Â  Â  out_channels=3,Â  # è¾“å‡ºé€šé“çš„æ•°é‡
Â  Â  layers_per_block=2,Â  # æ¯ä¸ªUNetå—ä¸­ä½¿ç”¨çš„ResNetå±‚çš„æ•°é‡
Â  Â  block_out_channels=(128, 128, 256, 256, 512, 512),Â  # æ¯ä¸ªUNetå—çš„è¾“å‡ºé€šé“æ•°é‡
Â  Â  down_block_types=(Â 
Â  Â  Â  Â  "DownBlock2D",Â  # å¸¸è§„çš„ResNetä¸‹é‡‡æ ·å—
Â  Â  Â  Â  "DownBlock2D",Â 
Â  Â  Â  Â  "DownBlock2D",Â 
Â  Â  Â  Â  "DownBlock2D",Â 
Â  Â  Â  Â  "AttnDownBlock2D",Â  # å…·æœ‰ç©ºé—´è‡ªæ³¨æ„åŠ›çš„ResNetä¸‹é‡‡æ ·å—
Â  Â  Â  Â  "DownBlock2D",
Â  Â  ),Â 
Â  Â  up_block_types=(
Â  Â  Â  Â  "UpBlock2D",Â  # å¸¸è§„çš„ResNetä¸Šé‡‡æ ·å—
Â  Â  Â  Â  "AttnUpBlock2D",Â  # å…·æœ‰ç©ºé—´è‡ªæ³¨æ„åŠ›çš„ResNetä¸Šé‡‡æ ·å—
Â  Â  Â  Â  "UpBlock2D",Â 
Â  Â  Â  Â  "UpBlock2D",Â 
Â  Â  Â  Â  "UpBlock2D",Â 
Â  Â  Â  Â  "UpBlock2D"Â Â 
Â  Â  Â  ),
)
```

å¯ä»¥çœ‹åˆ°ï¼Œä½¿ç”¨diffusersåˆ›å»ºUNetçš„æ­¥éª¤è¦æ¯”denoising\_diffusion\_pytorchå¤æ‚å¾ˆå¤šï¼Œå¥½å¤„æ˜¯ç»™å·¥ç¨‹å¸ˆå¸¦æ¥äº†æ›´å¤§çš„çµæ´»æ€§ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬çœ‹é‡‡æ ·å™¨çš„ç”¨æ³•ã€‚è¿™é‡Œéœ€è¦ç¡®å®šæˆ‘ä»¬åŠ å™ªç”¨çš„é‡‡æ ·å™¨ï¼Œå¸®åŠ©æˆ‘ä»¬é€šè¿‡ä¸€æ­¥è®¡ç®—å¾—åˆ°ç¬¬tæ­¥çš„åŠ å™ªç»“æœã€‚

```python
from diffusers import DDPMScheduler

noise_scheduler = DDPMScheduler(num_train_timesteps=1000)

# ä¸€æ­¥åŠ å™ªçš„è®¡ç®—
noise = torch.randn(sample_image.shape)
timesteps = torch.LongTensor([50])
noisy_image = noise_scheduler.add_noise(sample_image, noise, timesteps)
```

æ¥ç€é€šè¿‡æ¨¡å‹é¢„æµ‹å™ªå£°ï¼Œå¹¶è®¡ç®—æŸå¤±å‡½æ•°ã€‚

```python
import torch.nn.functional as F

noise_pred = model(noisy_image, timesteps).sample
loss = F.mse_loss(noise_pred, noise)
```

æœ€åï¼Œæˆ‘ä»¬å°†è¿™äº›æ¨¡å—ä¸²è”èµ·æ¥ï¼Œä¾¿å¯ä»¥å¾—åˆ°åŸºäºdiffusersè®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æ ¸å¿ƒä»£ç ã€‚

```python
for epoch in range(num_epochs):
    for step, batch in enumerate(train_dataloader):
        clean_images = batch['images']
        # å¯¹åº”äºæ‰©æ•£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ï¼šéšæœºé‡‡æ ·å™ªå£°
        noise = torch.randn(clean_images.shape).to(clean_images.device)
        bs = clean_images.shape[0]

        # å¯¹åº”äºæ‰©æ•£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ï¼šå¯¹äºbatchä¸­çš„æ¯å¼ å›¾ï¼Œéšæœºé€‰å–æ—¶é—´æ­¥t
        timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (bs,), device=clean_images.device).long()

        # å¯¹åº”äºæ‰©æ•£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ï¼šä¸€æ­¥è®¡ç®—åŠ å™ªç»“æœ
        noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)
        
        with accelerator.accumulate(model):
            # å¯¹åº”äºæ‰©æ•£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ï¼šé¢„æµ‹å™ªå£°å€¼å¹¶è®¡ç®—æŸå¤±å‡½æ•°
            noise_pred = model(noisy_images, timesteps, return_dict=False)[0]
            loss = F.mse_loss(noise_pred, noise)
            accelerator.backward(loss)
            optimizer.step()       
```

## å¾®è°ƒStable Diffusion

æå®šäº†æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒï¼Œæˆ‘ä»¬å¯ä»¥å†æŒ‘æˆ˜ä¸€ä¸‹Stable Diffusionæ¨¡å‹çš„å¾®è°ƒã€‚æˆ‘ä»¬å¯ä»¥ç›´æ¥å‚è€ƒdiffuserså®˜æ–¹æä¾›çš„[è®­ç»ƒä»£ç ](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)ï¼Œåˆ«çœ‹è¿™ä¸ªä»£ç æœ‰æ¥è¿‘1100è¡Œï¼Œå…¶å®ç›¸æ¯”äºä¸Šé¢æåˆ°çš„æ ‡å‡†æ‰©æ•£æ¨¡å‹è®­ç»ƒï¼Œæ ¸å¿ƒä¹Ÿåªæ˜¯å¤šäº†VAEå’ŒCLIPçš„éƒ¨åˆ†ã€‚

è¿™é‡Œæˆ‘èŠ‚é€‰äº†VAEå’ŒCLIPéƒ¨åˆ†çš„ä»£ç ï¼Œç›®çš„æ˜¯è®©ä½ äº†è§£è¿™ä¸¤ä¸ªæ¨¡å—æ˜¯å¦‚ä½•åŠ è½½ä½¿ç”¨çš„ã€‚

```python
tokenizer = CLIPTokenizer.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="tokenizer", revision=args.revision
)

text_encoder = CLIPTextModel.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="text_encoder", revision=args.revision
)

vae = AutoencoderKL.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="vae", revision=args.revision
)

unet = UNet2DConditionModel.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="unet", revision=args.non_ema_revision
)

# å°†vae å’Œ text_encoderçš„å‚æ•°å†»ç»“ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­æƒé‡ä¸æ›´æ–°
vae.requires_grad_(False)
text_encoder.requires_grad_(False)
```

ä½ å¯èƒ½åœ¨ä»£ç ä¸­å‘ç°äº†ä¸€ä¸ªtokenizerå˜é‡ã€‚å®ƒçš„ä½œç”¨ä¾¿æ˜¯æˆ‘ä»¬åœ¨[ç¬¬7è®²](https://time.geekbang.org/column/article/682762)ä¸­æåˆ°çš„ï¼Œå¯¹æˆ‘ä»¬è¾“å…¥çš„promptè¿›è¡Œåˆ†è¯åè·å–token\_idã€‚æœ‰äº†token\_idï¼Œæˆ‘ä»¬ä¾¿å¯ä»¥è·å–æ¨¡å‹å¯ç”¨çš„è¯åµŒå…¥å‘é‡ã€‚CLIPæ¨¡å‹çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆtext\_encoderï¼‰åŸºäºè¯åµŒå…¥å‘é‡ï¼Œä¾¿å¯ä»¥æå–æ–‡æœ¬ç‰¹å¾ã€‚VAEæ¨¡å—å’ŒCLIPæ¨¡å—éƒ½ä¸éœ€è¦æƒé‡æ›´æ–°ï¼Œå› æ­¤ä¸Šé¢çš„ä»£ç ä¸­å°†æ¢¯åº¦ï¼ˆgradï¼‰è®¾ç½®ä¸ºFalseã€‚

![](https://static001.geekbang.org/resource/image/4e/6b/4e1130cf6424d94f0yyff14a97812a6b.jpg?wh=4409x1142)

è¿™é‡Œæˆ‘éœ€è¦æŒ‡å‡ºï¼Œåœ¨ä¸€äº›æƒ…å†µä¸‹ï¼Œæ¯”å¦‚è®­ç»ƒDreamBoothå’ŒLoRAæ¨¡å‹æ—¶ï¼ŒCLIPæ–‡æœ¬ç¼–ç å™¨çš„å‚æ•°ä¹Ÿå¯ä»¥å­¦ä¹ å’Œæ›´æ–°ï¼Œè¿™èƒ½å¸®æˆ‘ä»¬æå‡æ¨¡å‹çš„æ•ˆæœã€‚

æœ€åï¼Œæˆ‘ä»¬å†çœ‹çœ‹Stable Diffusionè®­ç»ƒçš„æ ¸å¿ƒä»£ç ã€‚

```python
 for epoch in range(num_train_epochs):
     for step, batch in enumerate(train_dataloader):
     
         # VAEæ¨¡å—å°†å›¾åƒç¼–ç åˆ°æ½œåœ¨ç©ºé—´
         latents = vae.encode(batch["pixel_values"].to(weight_dtype)).latent_dist.sample()
         
         # éšæœºå™ªå£° & åŠ å™ªåˆ°ç¬¬tæ­¥
         noise = torch.randn_like(latents)
         timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps)
         noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)
         
         # ä½¿ç”¨CLIPå°†æ–‡æœ¬æè¿°ä½œä¸ºè¾“å…¥
         encoder_hidden_states = text_encoder(batch["input_ids"])[0]
         target = noise
         
         # é¢„æµ‹å™ªå£°å¹¶è®¡ç®—loss
         model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample
         loss = F.mse_loss(model_pred.float(), target.float(), reduction="mean")
         optimizer.step()
```

ç›¸ä¿¡ä½ åœ¨ä¸Šé¢çš„ä»£ç ä¸­çœ‹åˆ°äº†å¾ˆå¤šç†Ÿæ‚‰çš„åè¯ï¼ŒVAEã€æ½œåœ¨ç©ºé—´ã€CLIPã€æ–‡æœ¬æè¿°ç­‰ï¼Œè¿™äº›éƒ½æ˜¯Stable Diffusionæ¯”æ ‡å‡†æ‰©æ•£æ¨¡å‹å¤šå‡ºæ¥çš„ä¸œè¥¿ã€‚å¦‚æœä½ æƒ³è¿›ä¸€æ­¥ç¡®è®¤æ–‡æœ¬æè¿°å¦‚ä½•é€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶èµ·ä½œç”¨ï¼Œæˆ‘æ¨èä½ å»çœ‹çœ‹ [UNet2DConditionModel](https://github.com/huggingface/diffusers/blob/v0.19.3/src/diffusers/models/unet_2d_condition.py#L66) è¿™ä¸ªæ¨¡å—çš„ä»£ç ï¼ŒåŠ æ·±ç†è§£ã€‚

## å¦‚ä½•è°ƒç”¨å„ç§SDæ¨¡å‹ï¼Ÿ

å…¶å®æˆ‘ä»¬å¯ä»¥åœ¨Hugging Faceä¸­æ‰¾åˆ°å„ç§ç°æˆçš„æ¨¡å‹ï¼Œæˆ‘ä»¬åªéœ€é€šè¿‡æ¨¡å‹çš„model\_idï¼Œä¾¿å¯ä»¥ç›´æ¥åœ¨Colabä¸­è°ƒç”¨è¿™äº›æ¨¡å‹ï¼Œæˆ‘ä»¬è¿™å°±å®æˆ˜ç»ƒä¹ ä¸€ä¸‹ã€‚

æ¯”å¦‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ [Counterfeit-V2.5](https://huggingface.co/gsdf/Counterfeit-V2.5) è¿™ä¸ªæ¨¡å‹ï¼Œé¦–å…ˆè·å–åˆ°å®ƒçš„model\_idã€‚

![](https://static001.geekbang.org/resource/image/cc/d7/ccc132a8a8069879869f8e8aec42a5d7.png?wh=1722x942)

ä¹‹åï¼Œæˆ‘ä»¬é€šè¿‡åé¢çš„ä»£ç ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹ã€‚ç¬¬å››è¡Œçš„æ¨¡å‹IDå¯ä»¥çµæ´»è°ƒæ•´ï¼Œä½ å¯ä»¥åˆ‡æ¢æˆä½ å¿ƒä»ªçš„æ¨¡å‹ã€‚

```python
import torch
from diffusers import DiffusionPipeline
from diffusers import DDIMScheduler, DPMSolverMultistepScheduler, EulerAncestralDiscreteScheduler
pipeline = DiffusionPipeline.from_pretrained("gsdf/Counterfeit-V2.5")
```

ç„¶åç”¨ä¸‹é¢ä»£ç å®Œæˆåˆ‡æ¢é‡‡æ ·å™¨ï¼Œpromptè®¾ç½®ç­‰æ“ä½œï¼Œä¾¿å¯ä»¥éšå¿ƒæ‰€æ¬²åœ°åˆ›ä½œäº†ã€‚

```python
# åˆ‡æ¢ä¸ºDPMé‡‡æ ·å™¨
pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)

prompt = "((masterpiece,best quality)),1girl, solo, animal ears, rabbit"
negative_prompt = "EasyNegative, extra fingers,fewer fingers,"
images = pipeline(prompt, width = 512, height = 512, num_inference_steps=20, guidance_scale=7.5).images
```

ä½ å¯ä»¥ç‚¹å¼€æˆ‘çš„ [Colabé“¾æ¥](https://github.com/NightWalker888/ai_painting_journey/blob/main/lesson12/%E5%BC%80%E6%BA%90AI%E7%BB%98%E7%94%BB%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8bug%E4%BF%AE%E5%A4%8D.ipynb)è¿›è¡Œæ“ä½œã€‚å¯ä»¥åœ¨Hugging Faceä¸­è°ƒä¸€äº›ä½ å–œæ¬¢çš„AIç»˜ç”»æ¨¡å‹ï¼Œè¯•è¯•è‡ªå·±åŠ¨æ‰‹åˆ›ä½œä¸€äº›ä½œå“ã€‚

## æ€»ç»“æ—¶åˆ»

ä»Šå¤©æˆ‘ä»¬é€šè¿‡å®æˆ˜çš„å½¢å¼åŠ æ·±äº†å¯¹æ‰©æ•£æ¨¡å‹å’ŒStable Diffusionæ¨¡å‹çš„è®¤è¯†ã€‚åœ¨æ‰©æ•£æ¨¡å‹éƒ¨åˆ†ï¼Œæˆ‘ä»¬ä»æ•°æ®å‡†å¤‡å¼€å§‹ï¼Œä½¿ç”¨ä¸¤ç§ä¸åŒçš„å½¢å¼ä»å¤´å¼€å§‹è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œæœ€ç»ˆæ®Šé€”åŒå½’ï¼Œéƒ½èƒ½å¾—åˆ°â€œä¸å¬è¯â€çš„AIç”»å¸ˆã€‚

ä¸ºäº†è¿›ä¸€æ­¥è°ƒä¼˜ï¼Œæˆ‘ä»¬åˆå¼•å…¥VAEå’ŒCLIPæ¨¡å—ï¼Œåœ¨å¼€æºStable Diffusionæ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œå¾®è°ƒå±äºæˆ‘ä»¬è‡ªå·±çš„SDæ¨¡å‹ï¼Œå¹¶æ·±å…¥æ¢è®¨äº†å…¶ä¸­çš„ä»£ç ç»†èŠ‚ã€‚æˆ‘ä»¬ä¹Ÿæ¢ç´¢äº†å¦‚æœé€šè¿‡ä»£ç ç›´æ¥ä½¿ç”¨å¼€æºç¤¾åŒºæä¾›çš„SDæ¨¡å‹ï¼Œé€šè¿‡çŸ­çŸ­å‡ è¡Œä»£ç å°±èƒ½å®ç°AIç»˜ç”»ã€‚

åœ¨æˆ‘çœ‹æ¥ï¼Œä»¥æ‰©æ•£æ¨¡å‹ä¸ºä¸»çš„AIç»˜ç”»ï¼Œä¸æ­¤å‰GANæ—¶ä»£æœ€å¤§çš„ä¸åŒä¹‹å¤„ä¾¿æ˜¯â€œä¸å¯å°è§‘çš„å¼€æºç¤¾åŒºâ€ã€‚2022å¹´ä¹‹å‰ï¼Œå„ç§æœ‰è¶£çš„GANæ¨¡å‹å’Œç‰¹æ•ˆæ›´å¤šåƒæ˜¯ä¼ä¸šæ‰â€œç©å¾—åŠ¨â€çš„æŠ€æœ¯ï¼Œè€Œå¦‚ä»Šçš„AIç»˜ç”»åˆ™æ˜¯åœ¨æ”¾å¤§æ¯ä¸€ä¸ªçˆ±å¥½è€…çš„åˆ›é€ åŠ›ã€‚

å½“å‰ï¼Œä¼ä¸šä¼šé€‰æ‹©å½“å‰æ•ˆæœæœ€å¥½çš„å¼€æºæ¨¡å‹ï¼Œæ¯”å¦‚SDXLã€AnythingV5æ¼«ç”»æ¨¡å‹ç­‰ï¼Œè¿›ä¸€æ­¥æ„é€ æµ·é‡çš„é«˜è´¨é‡æ•°æ®ï¼Œå»å¾®è°ƒè¿™äº›SDæ¨¡å‹ã€‚æŠ€æœ¯æ–¹æ¡ˆå’Œæˆ‘ä»¬ä»Šå¤©å®æˆ˜éƒ¨åˆ†å¾®è°ƒSDæ¨¡å‹æ˜¯ä¸€æ ·çš„ï¼Œåªä¸è¿‡ä¼ä¸šæœ‰æ›´å¤šçš„GPUã€å›¾ç‰‡æ•°æ®å’Œæ ‡æ³¨å‘˜ã€‚

å³ä¾¿å¦‚æ­¤ï¼Œä¸ºä»€ä¹ˆå¼€æºç¤¾åŒºçš„æ¨¡å‹ä»æ—§æœ‰å¦‚æ­¤æŠ¢çœ¼çš„è¡¨ç°å‘¢ï¼Ÿæˆ‘ä¸ªäººè§‰å¾—ï¼Œç›¸æ¯”å¾ˆå¤šä¼ä¸šçš„KPIé©±åŠ¨ï¼Œå¼€æºç¤¾åŒºå…´è¶£é©±åŠ¨æ›´å®¹æ˜“åšå‡ºå‚ç±»ç²¾å“ã€‚å¦‚æœä½ ä¹Ÿæœ‰ç±»ä¼¼çš„æ„Ÿè§‰ï¼Œé‚£ä¹ˆæœŸå¾…ä½ å’Œæˆ‘ä¸€èµ·ï¼Œå»åšä¸€äº›æœ‰æ„æ€çš„AIç»˜ç”»æ¨¡å‹ã€‚

è¿™ä¸€è®²çš„é‡ç‚¹ï¼Œä½ å¯ä»¥ç‚¹å¼€ä¸‹é¢çš„å¯¼å›¾è¿›è¡ŒçŸ¥è¯†å›é¡¾ã€‚

![](https://static001.geekbang.org/resource/image/87/aa/878d608159bf4a358245e0d1d33050aa.jpg?wh=3600x2521)

## æ€è€ƒé¢˜

è¿™ä¸€è®²æ˜¯æˆ‘ä»¬çš„å®æˆ˜è¯¾ã€‚æˆ‘ä»¬ç•™ä¸€ä¸ªå®æˆ˜ä»»åŠ¡ã€‚åœ¨Hugging Faceä¸­é€‰æ‹©ä¸€ä¸ªä½ å–œæ¬¢çš„åŸºç¡€æ¨¡å‹ï¼Œé€šè¿‡å†™ä»£ç çš„æ–¹å¼ç”Ÿæˆä¸€ç»„ä½ å–œæ¬¢çš„å›¾ç‰‡ã€‚

æœŸå¾…ä½ åœ¨ç•™è¨€åŒºå’Œæˆ‘äº¤æµäº’åŠ¨ï¼Œä¹Ÿæ¨èä½ æŠŠä»Šå¤©çš„å†…å®¹åˆ†äº«ç»™èº«è¾¹çš„å°ä¼™ä¼´ï¼Œä¸€èµ·åˆ›é€ æ›´æœ‰ä¸ªæ€§çš„AIç»˜ç”»æ¨¡å‹ã€‚
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ13ï¼‰</strong></div><ul>
<li><span>åˆ˜</span> ğŸ‘ï¼ˆ3ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>ä½ å¥½ï¼Œæˆ‘æƒ³é—®ä¸‹ï¼Œè¿™é‡Œå¾®è°ƒæ¨¡å‹å’Œè®­ç»ƒloraæ¨¡å‹æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ</p>2023-08-27</li><br/><li><span>é™ˆä¸œ</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>æ¯æ¬¡åœ¨Google colabä¸­å®‰è£…packageï¼Œå…³é—­åå®‰è£…åŒ…è¢«åˆ é™¤ï¼Œå¦‚ä½•æ°¸ä¹…æ€§ä½¿ç”¨å®‰è£…åŒ…ï¼Ÿå°è¯•äº†å¾ˆå¤šåŠæ³•ï¼Œä¸å¯è¡Œã€‚è¯·é—®è€å¸ˆæœ‰æ°¸ä¹…æ€§å®‰è£…åŠæ³•å—ï¼Ÿè°¢è°¢</p>2023-10-22</li><br/><li><span>å¤±è½çš„èµ°åœ°é¸¡</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>å¾®è°ƒSDæ¨¡å‹ä¸­æœ‰è¡Œä»£ç ï¼štokenizer = CLIPTokenizer.from_pretrained()ã€‚å‰é¢è®²transformerçš„ç»„æˆæ—¶æåˆ°tokenå’Œè¯åµŒå…¥ï¼Œè¿™é‡Œåˆå°†å®ƒä»¬å½’å±åˆ°clipï¼Œè¯·é—®æ€ä¹ˆç†è§£è¿™ä¸¤ç§çŸ›ç›¾çš„è¯´æ³•ï¼Ÿ</p>2023-10-05</li><br/><li><span>Geek_535f73</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>Generating train split:   0%|                                                                                    | 0&#47;7169 [00:00&lt;?, ? examples&#47;s]
Traceback (most recent call last):
  File &quot;&#47;cloud&#47;sd_hbo&#47;lib&#47;python3.10&#47;site-packages&#47;datasets&#47;builder.py&quot;, line 1925, in _prepare_split_single
    for _, table in generator:
  File &quot;&#47;cloud&#47;sd_hbo&#47;lib&#47;python3.10&#47;site-packages&#47;datasets&#47;packaged_modules&#47;parquet&#47;parquet.py&quot;, line 77, in _generate_tables
    parquet_file = pq.ParquetFile(f)
  File &quot;&#47;cloud&#47;sd_hbo&#47;lib&#47;python3.10&#47;site-packages&#47;pyarrow&#47;parquet&#47;__init__.py&quot;, line 286, in __init__
    self.reader.open(
  File &quot;pyarrow&#47;_parquet.pyx&quot;, line 1227, in pyarrow._parquet.ParquetReader.open
  File &quot;pyarrow&#47;error.pxi&quot;, line 100, in pyarrow.lib.check_status
pyarrow.lib.ArrowInvalid: Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
  File &quot;&#47;cloud&#47;sd_hbo&#47;lib&#47;python3.10&#47;site-packages&#47;datasets&#47;load.py&quot;, line 2136, in load_dataset
    builder_instance.download_and_prepare(
  File &quot;&#47;cloud&#47;sd_hbo&#47;lib&#47;python3.10&#47;site-packages&#47;datasets&#47;builder.py&quot;, line 954, in download_and_prepare
    self._download_and_prepare(
  File &quot;&#47;cloud&#47;sd_hbo&#47;lib&#47;python3.10&#47;site-packages&#47;datasets&#47;builder.py&quot;, line 1049, in _download_and_prepare
    self._prepare_split(split_generator, **prepare_split_kwargs)
  File &quot;&#47;cloud&#47;sd_hbo&#47;lib&#47;python3.10&#47;site-packages&#47;datasets&#47;builder.py&quot;, line 1813, in _prepare_split
    for job_id, done, content in self._prepare_split_single(
  File &quot;&#47;cloud&#47;sd_hbo&#47;lib&#47;python3.10&#47;site-packages&#47;datasets&#47;builder.py&quot;, line 1958, in _prepare_split_single
    raise DatasetGenerationError(&quot;An error occurred while generating the dataset&quot;) from e
datasets.builder.DatasetGenerationError: An error occurred while generating the dataset</p>2023-09-02</li><br/><li><span>Geek_535f73</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>è€å¸ˆæ‚¨å¥½
æˆ‘åœ¨è‡ªå·±çš„ä»£ç ä¸­dataset = load_dataset(&quot;nelorth&#47;oxford-flowers&quot;)æ—¶é‡åˆ°è¿™ä¸ªé—®é¢˜

ç¡®å®ç½‘ä¸Šæœäº†å¾ˆä¹…éƒ½æ²¡æœ‰æ‰¾åˆ°ç­”æ¡ˆï¼Œæ‰€ä»¥æ¥è¯·æ•™æ‚¨&#47;å“­</p>2023-09-02</li><br/><li><span>Ericpoon</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è¯•è¿‡åœ¨æœ¬åœ°è¿è¡ŒSDXL0.9ï¼Œï¼ˆ1.0 è¿è¡Œä¸äº†ï¼Œå†…å­˜ä¸è¶³ï¼‰ï¼Œ0.9å¾—åˆ°çš„å›¾è±¡ç»“æœæ²¡æœ‰ç½‘ä¸Šå†™çš„é‚£ä¹ˆå¥½ï¼Œäººæˆ–åŠ¨ç‰©ä¹Ÿçœ‹ç€å¾ˆæŠ½è±¡ï¼Œæˆ‘ç”¨çš„åªæ˜¯HUGGING FACEä¸Šç»™çš„è¿è¡Œä»£ç ï¼Œä»€ä¹ˆå‚æ•°éƒ½æ²¡æœ‰ã€‚è¯·é—®è¿™ä¸ªæœ‰æ²¡æœ‰ç›¸å…³çš„å‚æ•°è®¾ç½®çš„æ–‡ç« ï¼Œä»‹ç»ä¸€ä¸‹ã€‚</p>2023-08-26</li><br/><li><span>æ˜µç§°C</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è€å¸ˆï¼Œæ‚¨å¥½ã€‚æˆ‘æƒ³åšä¸€ä¸ªæ¢è„¸ï¼Œæ¢è¡£æœçš„å›¾ç”Ÿå›¾å°åŠŸèƒ½ã€‚æœ‰åˆé€‚çš„å¼€æºæ¨¡å‹æ¨èä¹ˆï¼Ÿæˆ‘åœ¨ç”¨çš„æ—¶å€™stable-diffusion-v1-5æ¨¡å‹ç”Ÿæˆçš„å†…å®¹æ˜¯æœ‰ä¸é€‚å®œæ£€æµ‹çš„ï¼Œæ€ä¹ˆèƒ½å»æ‰è¿™ä¸ªæ£€æµ‹å‘¢ï¼Ÿ</p>2023-08-22</li><br/><li><span>ç§‹æ™¨</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è®¤è¯†åŸºç¡€æ¨¡å—
ä¼¼ä¹ç¼ºå¤±äº†è®²è§£å¦‚ä½•è¾“å‡ºå™ªå£°å›¾çš„ä»£ç </p>2023-08-18</li><br/><li><span>@äºŒåä¸€å¤§å”</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è€å¸ˆï¼Œæœ€åè°ƒç”¨sdæ¨¡å‹çš„ä»£ç ï¼Œåœ¨æœ¬åœ°è¿è¡Œæ—¶æœ‰æ²¡æœ‰åŠæ³•å»åŠ è½½æœ¬åœ°æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ¨¡å‹ï¼Œè€Œä¸æ˜¯å»ä¸‹è½½huggingfaceä¸­çš„æ¨¡å‹ï¼Œç›®å‰æ˜¯ä¼šæŠŠæ¨¡å‹ä»“åº“ä¸­çš„æ‰€æœ‰é—®ä»·éƒ½ç¼“å­˜åˆ°æœ¬åœ°ï¼Œè¿™æ ·å¯¹äºåˆ‡æ¢æ¨¡å‹æ—¶éå¸¸çš„ä¸å‹å¥½</p>2023-08-15</li><br/><li><span>peter</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è¯·æ•™è€å¸ˆå‡ ä¸ªé—®é¢˜å•Šï¼š
Q1ï¼šæœ‰æ¯”è¾ƒå¥½çš„å‚ç›´ç±»æ¨¡å‹å—ï¼Ÿæ¨èå‡ ä¸ªå•Šã€‚
Q2ï¼šå¼€æºç¤¾åŒºç½‘å€æ˜¯ä»€ä¹ˆï¼Ÿéº»çƒ¦æä¾›ä¸€ä¸‹ã€‚å‰é¢è¯¾ç¨‹ä¹Ÿè®¸æä¾›äº†ï¼Œä½†éš¾ä»¥é€ä¸ªæŸ¥æ‰¾ã€‚éƒ½æ˜¯åœ¨åœ°é“ä¸Šçœ‹çš„ï¼Œå½“æ—¶æ²¡æœ‰è®°ã€‚éº»çƒ¦è€å¸ˆäº†ã€‚</p>2023-08-12</li><br/><li><span>Toni</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>æ€è€ƒé¢˜: åœ¨ Hugging Face ä¸­é€‰æ‹©SDXL1.0
https:&#47;&#47;huggingface.co&#47;stabilityai&#47;stable-diffusion-xl-refiner-1.0
ä»£ç å¦‚ä¸‹:

pip install diffusers --upgrade

pip install invisible_watermark transformers accelerate safetensors

from diffusers import DiffusionPipeline
import torch

# load both base &amp; refiner
base = DiffusionPipeline.from_pretrained(
    &quot;stabilityai&#47;stable-diffusion-xl-base-1.0&quot;, torch_dtype=torch.float16, variant=&quot;fp16&quot;, use_safetensors=True
)
base.to(&quot;cuda&quot;)
refiner = DiffusionPipeline.from_pretrained(
    &quot;stabilityai&#47;stable-diffusion-xl-refiner-1.0&quot;,
    text_encoder_2=base.text_encoder_2,
    vae=base.vae,
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant=&quot;fp16&quot;,
)
refiner.to(&quot;cuda&quot;)

# Define how many steps and what % of steps to be run on each experts (80&#47;20) here
n_steps = 40
high_noise_frac = 0.8

prompt = &quot;RAW photo,Childhood in Beijing Hutongs,70s,two little boys playing and chasing each other,boys are dressed in shorts and vests,and appear to be very happy,the background is street,several old houses,the color tone is somewhat yellowish-brown,8k,DSLR,soft light,high quality,film grain,Fujifilm XT3&quot;
negative_prompt=&quot;mutated hands, fused fingers, too many fingers, missing fingers, poorly drawn hands, blurry eyes, blurred iris, blurry face, poorly drawn face, mutation, deformed, ugly, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, out of frame, multiple faces, long neck, nsfw&quot;

# run both experts
image = base(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=n_steps,
    denoising_end=high_noise_frac,
    output_type=&quot;latent&quot;,
).images
image1 = refiner(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=n_steps,
    denoising_start=high_noise_frac,
    image=image,
).images[0]

image1

å›¾å‘åœ¨[å¾®ä¿¡AIç»˜ç”»ä¸“æ äº¤æµç¾¤]é‡Œäº†ã€‚</p>2023-08-11</li><br/><li><span>é»„å°”æ—</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>è¯·é—®å¸‚åœºé‚£äº› sd å¤§æ¨¡å‹ï¼Œæ¯”å¦‚éº¦æ©˜ï¼Œå¢¨å¹½ï¼Œrealistic ç­‰å¤§æ¨¡å‹ï¼Œä¹Ÿæ˜¯è¿™ç§æ–¹å¼è®­ç»ƒçš„å—</p>2024-08-17</li><br/><li><span>å¥”è·‘çš„èš‚èš</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>sdå¾®è°ƒ Counterfeit-V2.5è¿™æ®µ

import torch
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained(&quot;gsdf&#47;Counterfeit-V2.5&quot;)

æŠ¥é”™

AttributeError                            Traceback (most recent call last)

&lt;ipython-input-14-2f5c494bd124&gt; in &lt;cell line: 2&gt;()
      1 import torch
----&gt; 2 from diffusers import DiffusionPipeline
      3 
      4 pipeline = DiffusionPipeline.from_pretrained(&quot;gsdf&#47;Counterfeit-V2.5&quot;)

7 frames

&#47;usr&#47;local&#47;lib&#47;python3.10&#47;dist-packages&#47;jax&#47;_src&#47;deprecations.py in getattr(name)
     52       warnings.warn(message, DeprecationWarning, stacklevel=2)
     53       return fn
---&gt; 54     raise AttributeError(f&quot;module {module!r} has no attribute {name!r}&quot;)
     55 
     56   return getattr

AttributeError: module &#39;jax.random&#39; has no attribute &#39;KeyArray&#39;</p>2024-04-11</li><br/>
</ul>