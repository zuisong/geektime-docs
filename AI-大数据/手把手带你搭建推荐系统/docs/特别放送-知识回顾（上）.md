你好，我是黄鸿波。

不知不觉咱们的课程已经接近尾声了，这节课我来带你划下重点，一起复习一下架构篇以及数据篇的内容，话不多说，我们现在开始吧。

[01｜推荐系统：我们应该怎样学习推荐系统？](https://time.geekbang.org/column/article/647453)

本节课的重点在于了解推荐系统的整体概念，知道它整体运行的原理，此外，我还为你梳理了推荐系统的学习方法，为接下来数据篇的学习做准备。

![](https://static001.geekbang.org/resource/image/a2/e8/a288b69eaf9518f9453b41df9a026fe8.jpg?wh=3000x1592)

[02｜Netflix推荐系统：企业级的推荐系统架构是怎样的？](https://time.geekbang.org/column/article/647865)

本节课的重点在于掌握Netflix推荐系统在企业中的整体架构以及工作流程，同时熟悉在线层、近似在线层、离线层这几个层之间的关系。

![](https://static001.geekbang.org/resource/image/5d/40/5d1bab2fc92352a9387f88f06d7e7b40.jpg?wh=3000x1490)

[03｜数据处理：我们应该如何获取和处理数据？](https://time.geekbang.org/column/article/648143)

本节课的重点在于了解数据的获取方式以及具体形态，同时熟悉各类数据处理方法和它们对应的应用场景。

![](https://static001.geekbang.org/resource/image/00/3d/009098fdd2f92e7c726d6193bc7fd93d.jpg?wh=3000x1298)

[04｜MongoDB：如何安装和使用MongoDB数据库？](https://time.geekbang.org/column/article/648830)

本节课的重点在于MongoDB数据库的大致了解以及安装，并能够简单使用它。我在目录的设计上重点突出了“手把手”搭建的过程，所以也看到有的同学反馈这节课太过于基础了。如果你有MongoDB数据库以及Redis数据库的安装经验，可以直接学习第六节课。

![](https://static001.geekbang.org/resource/image/a9/e5/a9e481b46ef6bf6227yy20da30fcd4e5.jpg?wh=3000x1298)

[05｜Redis：如何安装和使用Redis数据库？](https://time.geekbang.org/column/article/649902)

本节课和上节课的定位类似，也是在手把手带你安装和使用Redis数据库，如果你已经会了，直接跳过即可，这两节课是想照顾一下基础薄弱的同学。

![](https://static001.geekbang.org/resource/image/a7/ba/a7828fe586f792cb83250c35088ca7ba.jpg?wh=3000x1244)

[06｜网络爬虫：爬取一个网站的流程是怎样的？](https://time.geekbang.org/column/article/650545)

本节课的重点在于熟悉爬虫的主要工作流程，一共分为四步，即发起请求、获取相应内容、解析内容和保存数据。

![](https://static001.geekbang.org/resource/image/c5/1c/c5bd26a5cyyfc2b18be8b448dfde981c.jpg?wh=2970x1466)

[07｜数据获取：什么是Scrapy框架？](https://time.geekbang.org/column/article/651624)

本节课的重点在于了解Scrapy框架的原理和主要模块（Scrapy引擎、调度器、下载器、爬虫、管道、下载中间件、Spider中间件），以及它们是如何协作的。并且能够在Anaconda环境中创建一个Scrapy环境，搭建一个最简单的Scrapy框架跑起来。

![](https://static001.geekbang.org/resource/image/9a/26/9aa58c9f6218e5aec088ab4cd13bb926.jpg?wh=3000x1526)

[08｜数据获取：如何使用Scrapy框架爬取新闻数据？](https://time.geekbang.org/column/article/652864)

本节课的重点在于爬取新浪新闻中的数据，并对爬取到的数据进行解析。其中包括页面分析、爬取列表以及爬取详情页。

![](https://static001.geekbang.org/resource/image/df/a2/df180bb340e3b0436d69ce7ea75785a2.jpg?wh=3000x992)

[09｜数据存储：如何将爬取到的数据存入数据库中？](https://time.geekbang.org/column/article/653611)

本节课的重点在于熟悉在scrapy中对数据进行处理和保存，并能够在settings.py文件下加入我们的Pipelines相关的内容。

![](https://static001.geekbang.org/resource/image/b3/1b/b3870100284d7afdea50ca185608531b.jpg?wh=3000x1346)

[10｜数据加工：如何将原始数据做成内容画像？](https://time.geekbang.org/column/article/655495)

本节课的重点在于了解非结构化文本内容画像的生成处理方式，比如文本分类、文本聚类、关键词提取等等。同时，你也需要熟悉如何使用Python配合MongoDB来做一个简单的内容画像。

![](https://static001.geekbang.org/resource/image/a1/00/a153b47e67a448f7488102beb5b62000.jpg?wh=3000x1928)

这次的复习课到这里也就结束了，下节课我将继续带你复习召回篇与服务搭建篇的内容，如果你觉得这节课对你有帮助，也欢迎分享给有需要的朋友！