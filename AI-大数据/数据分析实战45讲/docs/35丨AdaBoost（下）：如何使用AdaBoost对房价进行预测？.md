ä»Šå¤©æˆ‘å¸¦ä½ ç”¨AdaBoostç®—æ³•åšä¸€ä¸ªå®æˆ˜é¡¹ç›®ã€‚AdaBoostä¸ä»…å¯ä»¥ç”¨äºåˆ†ç±»é—®é¢˜ï¼Œè¿˜å¯ä»¥ç”¨äºå›å½’åˆ†æã€‚

æˆ‘ä»¬å…ˆåšä¸ªç®€å•å›å¿†ï¼Œä»€ä¹ˆæ˜¯åˆ†ç±»ï¼Œä»€ä¹ˆæ˜¯å›å½’å‘¢ï¼Ÿå®é™…ä¸Šåˆ†ç±»å’Œå›å½’çš„æœ¬è´¨æ˜¯ä¸€æ ·çš„ï¼Œéƒ½æ˜¯å¯¹æœªçŸ¥äº‹ç‰©åšé¢„æµ‹ã€‚ä¸åŒä¹‹å¤„åœ¨äºè¾“å‡ºç»“æœçš„ç±»å‹ï¼Œåˆ†ç±»è¾“å‡ºçš„æ˜¯ä¸€ä¸ªç¦»æ•£å€¼ï¼Œå› ä¸ºç‰©ä½“çš„åˆ†ç±»æ•°æœ‰é™çš„ï¼Œè€Œå›å½’è¾“å‡ºçš„æ˜¯è¿ç»­å€¼ï¼Œä¹Ÿå°±æ˜¯åœ¨ä¸€ä¸ªåŒºé—´èŒƒå›´å†…ä»»ä½•å–å€¼éƒ½æœ‰å¯èƒ½ã€‚

è¿™æ¬¡æˆ‘ä»¬çš„ä¸»è¦ç›®æ ‡æ˜¯ä½¿ç”¨AdaBoosté¢„æµ‹æˆ¿ä»·ï¼Œè¿™æ˜¯ä¸€ä¸ªå›å½’é—®é¢˜ã€‚é™¤äº†å¯¹é¡¹ç›®è¿›è¡Œç¼–ç å®æˆ˜å¤–ï¼Œæˆ‘å¸Œæœ›ä½ èƒ½æŒæ¡ï¼š

1. AdaBoostå·¥å…·çš„ä½¿ç”¨ï¼ŒåŒ…æ‹¬ä½¿ç”¨AdaBoostè¿›è¡Œåˆ†ç±»ï¼Œä»¥åŠå›å½’åˆ†æã€‚
2. ä½¿ç”¨å…¶ä»–çš„å›å½’å·¥å…·ï¼Œæ¯”å¦‚å†³ç­–æ ‘å›å½’ï¼Œå¯¹æ¯”AdaBoostå›å½’å’Œå†³ç­–æ ‘å›å½’çš„ç»“æœã€‚

## å¦‚ä½•ä½¿ç”¨AdaBoostå·¥å…·

æˆ‘ä»¬å¯ä»¥ç›´æ¥åœ¨sklearnä¸­ä½¿ç”¨AdaBoostã€‚å¦‚æœæˆ‘ä»¬è¦ç”¨AdaBoostè¿›è¡Œåˆ†ç±»ï¼Œéœ€è¦åœ¨ä½¿ç”¨å‰å¼•ç”¨ä»£ç ï¼š

```
from sklearn.ensemble import AdaBoostClassifier
```

æˆ‘ä»¬ä¹‹å‰è®²åˆ°è¿‡ï¼Œå¦‚æœä½ çœ‹åˆ°äº†Classifierè¿™ä¸ªç±»ï¼Œä¸€èˆ¬éƒ½ä¼šå¯¹åº”ç€Regressorç±»ã€‚AdaBoostä¹Ÿä¸ä¾‹å¤–ï¼Œå›å½’å·¥å…·åŒ…çš„å¼•ç”¨ä»£ç å¦‚ä¸‹ï¼š

```
from sklearn.ensemble import AdaBoostRegressor
```

æˆ‘ä»¬å…ˆçœ‹ä¸‹å¦‚ä½•åœ¨sklearnä¸­åˆ›å»ºAdaBooståˆ†ç±»å™¨ã€‚
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ24ï¼‰</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/62/a5/43aa0c27.jpg" width="30px"><span>TKbook</span> ğŸ‘ï¼ˆ18ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>æºä»£ç ä¸­ï¼š
# ä» 12000 ä¸ªæ•°æ®ä¸­å–å‰ 2000 è¡Œä½œä¸ºæµ‹è¯•é›†ï¼Œå…¶ä½™ä½œä¸ºè®­ç»ƒé›†
test_x, test_y = X[2000:],y[2000:]
train_x, train_y = X[:2000],y[:2000]

è¿™ä¸ªéƒ¨åˆ†çš„ä»£ç å†™é”™äº†å§
åº”è¯¥æ˜¯ï¼š
test_x, test_y = x[: 2000], y[: 2000]
train_x, train_y = x[2000:], y[2000:]</div>2019-03-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg" width="30px"><span>third</span> ğŸ‘ï¼ˆ7ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>ç»“æœä»ç„¶ä¸ºAdaBoostç®—æ³•æœ€ä¼˜ã€‚
ä¸ªäººå‘ç°ï¼Œå‰ä¸¤ä¸ªåˆ†ç±»å™¨å‡ºç»“æœå¾ˆå¿«
åˆ†ææœ€ä¼˜ï¼š
1.AdaBoostç®—æ³•ç»è¿‡äº†æ›´å¤šè¿ç®—ï¼Œç‰¹åˆ«æ˜¯åœ¨è¿­ä»£å¼±åˆ†ç±»å™¨å’Œç»„åˆä¸Š
2.è‰¯å¥½ç»„åˆèµ·æ¥çš„ä¸ªä½“ï¼Œèƒ½å¤Ÿåˆ›é€ æ›´å¤§çš„ä»·å€¼ã€‚

å†³ç­–æ ‘å¼±åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º 0.7867
å†³ç­–æ ‘åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º 0.7891
AdaBoost åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º 0.8138

import numpy as np
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.feature_extraction import DictVectorizer

# 1.æ•°æ®åŠ è½½
train_data=pd.read_csv(&#39;.&#47;Titanic_Data&#47;train.csv&#39;)
test_data=pd.read_csv(&#39;.&#47;Titanic_Data&#47;test.csv&#39;)

# 2.æ•°æ®æ¸…æ´—
# ä½¿ç”¨å¹³å‡å¹´é¾„æ¥å¡«å……å¹´é¾„ä¸­çš„ NaN å€¼
train_data[&#39;Age&#39;].fillna(train_data[&#39;Age&#39;].mean(),inplace=True)
test_data[&#39;Age&#39;].fillna(test_data[&#39;Age&#39;].mean(),inplace=True)
# å‡ä»·å¡«å……
train_data[&#39;Fare&#39;].fillna(train_data[&#39;Fare&#39;].mean(),inplace=True)
test_data[&#39;Fare&#39;].fillna(test_data[&#39;Fare&#39;].mean(),inplace=True)
# ä½¿ç”¨ç™»é™†æœ€å¤šçš„æ¸¯å£æ¥å¡«å……
train_data[&#39;Embarked&#39;].fillna(&#39;S&#39;,inplace=True)
test_data[&#39;Embarked&#39;].fillna(&#39;S&#39;,inplace=True)

# ç‰¹å¾é€‰æ‹©
features=[&#39;Pclass&#39;,&#39;Sex&#39;,&#39;Age&#39;,&#39;SibSp&#39;,&#39;Parch&#39;,&#39;Fare&#39;,&#39;Embarked&#39;]
train_features=train_data[features]
train_labels=train_data[&#39;Survived&#39;]
test_features=test_data[features]

# å°†ç¬¦å·åŒ–çš„Embarkedå¯¹è±¡æŠ½è±¡å¤„ç†æˆ0&#47;1è¿›è¡Œè¡¨ç¤º
dvec=DictVectorizer(sparse=False)
train_features=dvec.fit_transform(train_features.to_dict(orient=&#39;record&#39;))
test_features=dvec.transform(test_features.to_dict(orient=&#39;record&#39;))

# å†³ç­–æ ‘å¼±åˆ†ç±»å™¨
dt_stump = DecisionTreeClassifier(max_depth=1,min_samples_leaf=1)
dt_stump.fit(train_features, train_labels)

print(u&#39;å†³ç­–æ ‘å¼±åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º %.4lf&#39; % np.mean(cross_val_score(dt_stump, train_features, train_labels, cv=10)))

# å†³ç­–æ ‘åˆ†ç±»å™¨
dt = DecisionTreeClassifier()
dt.fit(train_features, train_labels)

print(u&#39;å†³ç­–æ ‘åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º %.4lf&#39; % np.mean(cross_val_score(dt, train_features, train_labels, cv=10)))

# AdaBoost åˆ†ç±»å™¨
ada = AdaBoostClassifier(base_estimator=dt_stump,n_estimators=200)
ada.fit(train_features, train_labels)

print(u&#39;AdaBoost åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º %.4lf&#39; % np.mean(cross_val_score(ada, train_features, train_labels, cv=10)))</div>2019-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg" width="30px"><span>Geek_hve78z</span> ğŸ‘ï¼ˆ6ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>ç”±äºä¹˜å®¢æµ‹è¯•é›†ç¼ºå¤±çœŸå®å€¼ï¼Œé‡‡ç”¨ K æŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡
--------------------
è¿è¡Œç»“æœï¼š
å†³ç­–æ ‘å¼±åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º 0.7867
å†³ç­–æ ‘åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º 0.7813
AdaBoost åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º 0.8138
-------------------------
ä»£ç ï¼š
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import  AdaBoostClassifier
import pandas as pd
from sklearn.feature_extraction import DictVectorizer
from sklearn.model_selection import cross_val_score

# è®¾ç½® AdaBoost è¿­ä»£æ¬¡æ•°
n_estimators=200

# æ•°æ®åŠ è½½
train_data=pd.read_csv(&#39;.&#47;Titanic_Data&#47;train.csv&#39;)
test_data=pd.read_csv(&#39;.&#47;Titanic_Data&#47;test.csv&#39;)

# æ¨¡å— 2ï¼šæ•°æ®æ¸…æ´—
# ä½¿ç”¨å¹³å‡å¹´é¾„æ¥å¡«å……å¹´é¾„ä¸­çš„ NaN å€¼
train_data[&#39;Age&#39;].fillna(train_data[&#39;Age&#39;].mean(),inplace=True)
test_data[&#39;Age&#39;].fillna(test_data[&#39;Age&#39;].mean(),inplace=True)
# ä½¿ç”¨ç¥¨ä»·çš„å‡å€¼å¡«å……ç¥¨ä»·ä¸­çš„ nan å€¼
train_data[&#39;Fare&#39;].fillna(train_data[&#39;Fare&#39;].mean(),inplace=True)
test_data[&#39;Fare&#39;].fillna(test_data[&#39;Fare&#39;].mean(),inplace=True)
# ä½¿ç”¨ç™»å½•æœ€å¤šçš„æ¸¯å£æ¥å¡«å……ç™»å½•æ¸¯å£Embarkedçš„ nan å€¼
train_data[&#39;Embarked&#39;].fillna(&#39;S&#39;,inplace=True)
test_data[&#39;Embarked&#39;].fillna(&#39;S&#39;,inplace=True)

# ç‰¹å¾é€‰æ‹©
features=[&#39;Pclass&#39;,&#39;Sex&#39;,&#39;Age&#39;,&#39;SibSp&#39;,&#39;Parch&#39;,&#39;Fare&#39;,&#39;Embarked&#39;]
train_features=train_data[features]
train_labels=train_data[&#39;Survived&#39;]
test_features=test_data[features]

# å°†ç¬¦å·åŒ–çš„Embarkedå¯¹è±¡å¤„ç†æˆ0&#47;1è¿›è¡Œè¡¨ç¤º
dvec=DictVectorizer(sparse=False)
train_features=dvec.fit_transform(train_features.to_dict(orient=&#39;record&#39;))
test_features=dvec.transform(test_features.to_dict(orient=&#39;record&#39;))

# å†³ç­–æ ‘å¼±åˆ†ç±»å™¨
dt_stump = DecisionTreeClassifier(max_depth=1,min_samples_leaf=1)
dt_stump.fit(train_features, train_labels)

print(u&#39;å†³ç­–æ ‘å¼±åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º %.4lf&#39; % np.mean(cross_val_score(dt_stump, train_features, train_labels, cv=10)))

# å†³ç­–æ ‘åˆ†ç±»å™¨
dt = DecisionTreeClassifier()
dt.fit(train_features, train_labels)

print(u&#39;å†³ç­–æ ‘åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º %.4lf&#39; % np.mean(cross_val_score(dt, train_features, train_labels, cv=10)))

# AdaBoost åˆ†ç±»å™¨
ada = AdaBoostClassifier(base_estimator=dt_stump,n_estimators=n_estimators)
ada.fit(train_features, train_labels)

print(u&#39;AdaBoost åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º %.4lf&#39; % np.mean(cross_val_score(ada, train_features, train_labels, cv=10)))</div>2019-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/77/be/1f2409e8.jpg" width="30px"><span>æ¢æ—æ¾</span> ğŸ‘ï¼ˆ3ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è·‘ç¬¬äºŒå—ä»£ç æ˜¯éœ€è¦å¼•å…¥ä¸¤ä¸ªæ¨¡å—
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
</div>2019-03-04</li><br/><li><img src="" width="30px"><span>Liam</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>ax = fig.add_subplot(111)ax.plot([1,n_estimators],[dt_stump_err]*2, &#39;k-&#39;, label=u&#39;å†³ç­–æ ‘å¼±åˆ†ç±»å™¨ é”™è¯¯ç‡&#39;)ax.plot([1,n_estimators],[dt_err]*2,&#39;k--&#39;, label=u&#39;å†³ç­–æ ‘æ¨¡å‹ é”™è¯¯ç‡&#39;)ada_err = np.zeros((n_estimators,)).  ç–‘é—®ï¼šè¿™é‡Œ*2æ˜¯ä»€ä¹ˆæ„æ€ï¼Œèƒ½è§£æä¸‹ä»£ç å—ï¼Ÿ</div>2021-03-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg" width="30px"><span>æ»¢</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>å¾—åˆ°ç»“æœï¼š
CARTå†³ç­–æ ‘KæŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡: 0.39480897860892333
AdaBoostKæŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡: 0.4376641797318339

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.feature_extraction import DictVectorizer
from sklearn.model_selection import cross_val_predict
import pandas as pd
import numpy as np

#è¯»å–æ•°æ®
path = &#39;&#47;Users&#47;apple&#47;Desktop&#47;GitHubProject&#47;Read mark&#47;æ•°æ®åˆ†æ&#47;geekTime&#47;data&#47;&#39;
train_data = pd.read_csv(path + &#39;Titannic_Data_train.csv&#39;)
test_data = pd.read_csv(path + &#39;Titannic_Data_test.csv&#39;)

#æ•°æ®æ¸…æ´—
train_data[&#39;Age&#39;].fillna(train_data[&#39;Age&#39;].mean(),inplace=True)
test_data[&#39;Age&#39;].fillna(test_data[&#39;Age&#39;].mean(), inplace=True)
train_data[&#39;Embarked&#39;].fillna(&#39;S&#39;, inplace=True)
test_data[&#39;Embarked&#39;].fillna(&#39;S&#39;, inplace=True)

#ç‰¹å¾é€‰æ‹©
features = [&#39;Pclass&#39;,&#39;Sex&#39;,&#39;Age&#39;,&#39;SibSp&#39;,&#39;Parch&#39;,&#39;Embarked&#39;]
train_features = train_data[features]
train_result = train_data[&#39;Survived&#39;]
test_features = test_data[features]
devc = DictVectorizer(sparse=False)
train_features = devc.fit_transform(train_features.to_dict(orient=&#39;record&#39;))
test_features = devc.fit_transform(test_features.to_dict(orient=&#39;record&#39;))

#æ„é€ å†³ç­–æ ‘ï¼Œè¿›è¡Œé¢„æµ‹
tree_regressor = DecisionTreeRegressor()
tree_regressor.fit(train_features,train_result)
predict_tree = tree_regressor.predict(test_features)
#äº¤å‰éªŒè¯å‡†ç¡®ç‡
print(&#39;CARTå†³ç­–æ ‘KæŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡:&#39;, np.mean(cross_val_predict(tree_regressor,train_features,train_result,cv=10)))

#æ„é€ AdaBoost
ada_regressor = AdaBoostRegressor()
ada_regressor.fit(train_features,train_result)
predict_ada = ada_regressor.predict(test_features)
#äº¤å‰éªŒè¯å‡†ç¡®ç‡
print(&#39;AdaBoostKæŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡:&#39;,np.mean(cross_val_predict(ada_regressor,train_features,train_result,cv=10)))
</div>2019-04-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/86/d7/46842f90.jpg" width="30px"><span>å°æ™¨</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>å¼±åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º 0.7868
å†³ç­–æ ‘åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º 0.7823
AdaBooståˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º:0.8115

#!&#47;usr&#47;bin&#47;env python
# -*- coding:utf-8 -*-
# Author:Peter

import numpy as np
import pandas as pd
from sklearn.ensemble import AdaBoostClassifier
from sklearn.feature_extraction import DictVectorizer
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier

# è¿­ä»£æ¬¡æ•°
n_estimators = 200
train_data = pd.read_csv(r&#39;data&#47;Titanic_Data_train.csv&#39;)
test_data = pd.read_csv(r&#39;data&#47;Titanic_Data_Test.csv&#39;)

# ç”¨å¹³å‡å¹´é¾„å°†ç¼ºå¤±çš„å¹´é¾„è¡¥é½
train_data[&#39;Age&#39;].fillna(train_data[&#39;Age&#39;].mean(), inplace=True)
test_data[&#39;Age&#39;].fillna(test_data[&#39;Age&#39;].mean(), inplace=True)

# ç”¨å¹³å‡ç¥¨ä»·å°†ç¼ºå¤±çš„ç¥¨ä»·è¡¥é½
train_data[&#39;Fare&#39;].fillna(train_data[&#39;Fare&#39;].mean(), inplace=True)
test_data[&#39;Fare&#39;].fillna(test_data[&#39;Fare&#39;].mean(), inplace=True)

# ç”¨ç™»èˆ¹æ¸¯å£æœ€å¤šçš„Sè¡¥é½ç¼ºå¤±
train_data[&#39;Embarked&#39;].fillna(&#39;S&#39;, inplace=True)
test_data[&#39;Embarked&#39;].fillna(&#39;S&#39;, inplace=True)

# å°†å¯ç”¨æ¥åˆ†ç±»çš„æ•°æ®æ”¾åˆ°è®­ç»ƒé›†ä¸­
features = [&#39;Pclass&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;, &#39;Embarked&#39;]
train_features = train_data[features]
train_labels = train_data[&#39;Survived&#39;]
test_features = test_data[features]

# å­—ç¬¦ä¸²æ•°æ®è§„èŒƒåŒ–ï¼Œè½¬ä¸ºintå‹
dvec = DictVectorizer(sparse=False)
train_features = dvec.fit_transform(train_features.to_dict(orient=&#39;record&#39;))
test_features = dvec.transform(test_features.to_dict(orient=&#39;record&#39;))

# å¼±åˆ†ç±»å™¨
dt_stump = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1)
dt_stump.fit(train_features, train_labels)
print(u&#39;å¼±åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º %.4lf&#39; % dt_stump.score(train_features, train_labels))
# å†³ç­–æ ‘åˆ†ç±»å™¨
dt = DecisionTreeClassifier()
dt.fit(train_features, train_labels)
print(u&#39;å†³ç­–æ ‘åˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º %.4lf&#39; % np.mean(cross_val_score(dt, train_features, train_labels, cv=10)))

# AdaBooståˆ†ç±»å™¨
ada = AdaBoostClassifier(base_estimator=dt_stump, n_estimators=n_estimators)
ada.fit(train_features, train_labels)
ada_score = np.mean(cross_val_score(ada, train_features, train_labels, cv=10))
print(&quot;AdaBooståˆ†ç±»å™¨å‡†ç¡®ç‡ä¸º:%.4lf&quot; % ada_score)
</div>2021-03-10</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/J9YKHoKKd1LlzuCuKFGhnKBD1GtS9qiclsibY6vviacpCOB7uR4iaibIpdQKTzwiaVwJiaiaicB99rNx23JPQYV5wjThOWQ/132" width="30px"><span>èŒè¾°</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>åœ¨AdaBoostã€å†³ç­–æ ‘å›å½’ã€KNNæˆ¿ä»·é¢„æµ‹å¯¹æ¯”ä¸­å‘ç°ï¼Œéšæœºç§å­å¯¹å†³ç­–æ ‘çš„é¢„æµ‹ç»“æœæœ‰å½±å“ã€‚
åˆ†åˆ«æµ‹è¯•äº†ä¸‰ç§ä¸åŒçš„éšæœºç§å­ï¼š
dec_regressor=DecisionTreeRegressor(random_state=1)
dec_regressor=DecisionTreeRegressor(random_state=20)
dec_regressor=DecisionTreeRegressor(random_state=30)
æµ‹è¯•ç»“æœä¸ºï¼š
å†³ç­–æ ‘å‡æ–¹è¯¯å·®1 =  36.65
å†³ç­–æ ‘å‡æ–¹è¯¯å·®20 =  25.54
å†³ç­–æ ‘å‡æ–¹è¯¯å·®30 =  37.19
æ€è€ƒï¼š
æ­¤å¤„è€ƒè™‘è¿™é‡Œæ²¡æœ‰é™åˆ¶ç§å­çš„éšæœºæ€§ï¼Œå¯¹æ¯”çš„ç»“æœå¯èƒ½è¿‡äºéšæœºäº†ï¼Œæ— æ³•çœŸå®åæ˜ ç®—æ³•æ•ˆæœï¼Œä¸¤ç§ç®—æ³•åŸç†ä¸­éšæœºç§å­çš„åº”ç”¨æƒ…å†µä¸åŒã€‚æ€è€ƒæ˜¯ä¸æ˜¯é‡‡ç”¨å¤šæ¬¡éšæœºMSEç»“æœæ±‚å¹³å‡çš„æ–¹æ³•ä½œä¸ºã€æ¯”è¾ƒé¡¹ã€‘æ›´ä¸ºåˆé€‚
KNNç®—æ³•æ— éšæœºç§å­å½±å“ã€‚</div>2020-07-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/7d/2a/4c7e2e2f.jpg" width="30px"><span>Â§mcÂ²ompleXWr</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>ä½¿ç”¨è‡ªå¸¦çš„æ•°æ®é›†å°±ä¸ç”¨åšæ•°æ®è§„èŒƒåŒ–ä¹ˆï¼Ÿ</div>2020-06-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/51/98/3b8de985.jpg" width="30px"><span>é²¨é±¼é²¸é±¼é³„é±¼</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆï¼Œè¯·é—®AdaBoostæ¨¡å‹åœ¨é¢„æµ‹å‰éœ€ä¸éœ€è¦å¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–æˆ–è€…å½’ä¸€åŒ–ï¼Œåšæœ‰ä»€ä¹ˆå¥½å¤„ï¼Œä¸åšæœ‰ä»€ä¹ˆå¥½å¤„å‘¢</div>2020-05-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/94/6d/5cd6e8c7.jpg" width="30px"><span>å¼ è´º</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆè®²çš„å¾ˆæ¸…æ™°</div>2020-03-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg" width="30px"><span>æ»¨æ»¨</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>åˆ†ç±»å’Œå›å½’éƒ½æ˜¯åšé¢„æµ‹ï¼Œåˆ†ç±»æ˜¯ç¦»æ•£å€¼ï¼Œå›å½’æ˜¯è¿ç»­å€¼</div>2019-04-21</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/wJphZ3HcvhjVUyTWCIsCugzfQY5NAy6VJ0XoPLibDlcHWMswFmFe678zd0lUjFETia80NQhyQcVnGDlKgKPcRGyw/132" width="30px"><span>JingZ</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div># AdaBoost
ä¸€å¼€å§‹ç«Ÿç„¶è“¦ç„¶æƒ¯æ€§ç”¨äº†AdaBoostRegressorï¼Œå¾—åˆ°0.33çš„å‡†ç¡®ç‡ï¼Œæœ€åçœ‹äº†å°ä¼™ä¼´ä»£ç ï¼Œç«‹é©¬ä¿®æ­£

æ„Ÿè§‰ç®—æ³•ä»£ç ä¸å¤æ‚ï¼Œå…³é”®è¦è‡ªå·±ä»ç©ºç™½å¼€å§‹å†™ï¼Œè¿˜éœ€å¤šå®æˆ˜

from sklearn.ensemble import AdaBoostClassifier

# ä½¿ç”¨ Adaboost åˆ†ç±»æ¨¡å‹
ada = AdaBoostClassifier()
ada.fit(train_features, train_labels)

pred_labels = ada.predict(test_features)

acc_ada_classifier = round(ada.score(train_features, train_labels), 6)
print(u&#39;Adaboost score å‡†ç¡®ç‡ä¸º %.4lf&#39; % acc_ada_classifier)
print(u&#39;Adaboost cross_val_score å‡†ç¡®ç‡ä¸º %.4lf&#39; % np.mean(cross_val_score(ada, train_features, train_labels, cv=10)))

è¿è¡Œ
Adaboost score å‡†ç¡®ç‡ä¸º 0.8339
Adaboost cross_val_score å‡†ç¡®ç‡ä¸º 0.8104</div>2019-03-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/b8/21/c03839f1.jpg" width="30px"><span>FORWARDâ€•MOUNT</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆï¼Œæˆ¿ä»·é¢„æµ‹è¿™ä¸ªç®—æ³•ï¼Œ50ä¸ªå¼±åˆ†ç±»å™¨æ˜¯æ€ä¹ˆæ¥çš„ï¼Ÿ</div>2019-03-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/83/e2/297518ab.jpg" width="30px"><span>ä½³ä½³çš„çˆ¸</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>ä½ å¥½è€å¸ˆï¼Œå®Œæ•´çš„æºä»£ç åœ¨å“ªé‡Œå¯ä»¥ä¸‹è½½åˆ°?  æˆ‘è¯´çš„æ˜¯æ¯èŠ‚è¯¾é‡Œè¾¹çš„æºä»£ç ã€‚</div>2019-03-04</li><br/><li><img src="" width="30px"><span>yanyu-xin</span> ğŸ‘ï¼ˆ4ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>åœ¨è¯¾ç¨‹â€œAdaBoost ä¸å†³ç­–æ ‘æ¨¡å‹çš„æ¯”è¾ƒâ€ä»£ç ï¼Œada = AdaBoostClassifier(base_estimator=dt_stump,n_estimators=n_estimators)
å‡ºç°å¼‚å¸¸ï¼ŒTypeError AdaBoostClassifier.__init__() got an unexpected keyword argument &#39;base_estimator&#39;
è¿™ä¸ªé—®é¢˜æ˜¯ç”±äºï¼šç”±äºscikit-learnåº“åœ¨1.2ç‰ˆæœ¬æˆ–æ›´é«˜ç‰ˆæœ¬ä¸­å¯¹AdaBoostClassifierçš„å‚æ•°base_estimatorè¿›è¡Œäº†é‡å‘½åï¼Œå°†å…¶æ”¹ä¸ºestimatorã€‚æ­¤å¤–ï¼Œè­¦å‘Šä¿¡æ¯è¿˜æŒ‡å‡ºbase_estimatorå‚æ•°å°†åœ¨1.4ç‰ˆæœ¬ä¸­è¢«ç§»é™¤ã€‚

å¦å¤–å‡ºç°è­¦å‘Šä¿¡æ¯ï¼šFutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
scikit-learnåº“ä¸­çš„AdaBoostClassifieré»˜è®¤ä½¿ç”¨çš„SAMME.Rç®—æ³•å·²è¢«å¼ƒç”¨ï¼Œå¹¶ä¸”è®¡åˆ’åœ¨1.6ç‰ˆæœ¬ä¸­ç§»é™¤ã€‚ä¸ºäº†é¿å…è¿™ä¸ªè­¦å‘Šï¼Œåº”è¯¥åœ¨åˆ›å»ºAdaBoostClassifierå®ä¾‹æ—¶æ˜¾å¼æŒ‡å®šä½¿ç”¨SAMMEç®—æ³•ï¼Œè€Œä¸æ˜¯é»˜è®¤çš„SAMME.Rç®—æ³•ã€‚SAMMEå’ŒSAMME.Ræ˜¯ä¸¤ç§ä¸åŒçš„å¤šç±»AdaBoostç®—æ³•ã€‚SAMME.Ræ˜¯SAMMEçš„ä¸€ä¸ªå˜ç§ï¼Œå®ƒä¾èµ–äºæ¦‚ç‡ä¼°è®¡ï¼Œé€šå¸¸ä¼šæœ‰æ›´å¥½çš„æ€§èƒ½ï¼Œä½†ç°åœ¨ç”±äºæŸäº›åŸå› è¢«å¼ƒç”¨ã€‚è¦åœ¨æ‚¨çš„ä»£ç ä¸­æŒ‡å®šä½¿ç”¨SAMMEç®—æ³•ï¼Œæ‚¨å¯ä»¥åœ¨åˆ›å»ºAdaBoostClassifierå®ä¾‹æ—¶è®¾ç½®algorithmå‚æ•°ä¸º&#39;SAMME&#39;ã€‚ä»¥ä¸‹æ˜¯ä¿®æ”¹ä»£ç ï¼šå°†ï¼š
ada = AdaBoostClassifier(base_estimator=dt_stump,n_estimators=n_estimators)
æ”¹ä¸ºï¼š
ada = AdaBoostClassifier(estimator=dt_stump,n_estimators=n_estimators,algorithm=&#39;SAMME&#39;)</div>2024-04-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/26/9e/836f603b.jpg" width="30px"><span>KokutoDa</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>å‡†ç¡®ç‡ï¼š
adaboost äº¤å‰éªŒè¯ï¼š0.81147315855181
å†³ç­–æ ‘äº¤å‰éªŒè¯ï¼š0.7812484394506866
adaboostï¼ˆaccuracy_scoreï¼‰ï¼š0.8484848484848485
å†³ç­–æ ‘ï¼ˆaccuracy_scoreï¼‰0.9820426487093153
è€å¸ˆï¼Œä¸ºä»€ä¹ˆäº¤å‰éªŒè¯çš„å‡†ç¡®ç‡å’Œaccuracy_scoreçš„å‡†ç¡®ç‡è®¡ç®—ç»“æœç›¸åï¼Ÿ

import pandas as pd
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.feature_extraction import DictVectorizer
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
import numpy as np

# adaboost é¢„æµ‹æ³°å¦å°¼å…‹å·ç”Ÿå­˜
# æ•°æ®åŠ è½½
train_data = pd.read_csv(&#39;..&#47;Titanic_Data&#47;train.csv&#39;)
test_data = pd.read_csv(&#39;..&#47;Titanic_Data&#47;test.csv&#39;)

# æ•°æ®æ¸…æ´—
train_data[&#39;Age&#39;].fillna(train_data[&#39;Age&#39;].mean(), inplace=True)
test_data[&#39;Age&#39;].fillna(test_data[&#39;Age&#39;].mean(),inplace=True)
train_data[&#39;Fare&#39;].fillna(train_data[&#39;Fare&#39;].mean(), inplace=True)
test_data[&#39;Fare&#39;].fillna(test_data[&#39;Fare&#39;].mean(),inplace=True)
# ä½¿ç”¨ç™»å½•æœ€å¤šçš„æ¸¯å£æ¥å¡«å……ç™»å½•æ¸¯å£çš„ nan å€¼
train_data[&#39;Embarked&#39;].fillna(&#39;S&#39;, inplace=True)
test_data[&#39;Embarked&#39;].fillna(&#39;S&#39;,inplace=True)

# ç‰¹å¾é€‰æ‹©
features = [&#39;Pclass&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;, &#39;Embarked&#39;]
X_train = train_data[features]
y_train = train_data[&#39;Survived&#39;]
X_test = test_data[features]
# æ›¿æ¢æˆè®¡ç®—æœºèƒ½ç†è§£çš„
dvec=DictVectorizer(sparse=False)
X_train = dvec.fit_transform(X_train.to_dict(orient=&#39;record&#39;))

# Adaboost
ada = AdaBoostClassifier(n_estimators=200)
ada.fit(X_train, y_train)
ada_pred = ada.predict(X_train)

# å†³ç­–æ ‘
clf = DecisionTreeClassifier(criterion=&#39;entropy&#39;)
clf.fit(X_train, y_train)
clf_pred = clf.predict(X_train)

print(np.mean(cross_val_score(ada, X_train, y_train, cv=10)))
print(np.mean(cross_val_score(clf, X_train, y_train, cv=10)))
print(accuracy_score(y_train, ada_pred))
print(accuracy_score(y_train, clf_pred))</div>2021-05-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/86/79/066a062a.jpg" width="30px"><span>éåŒå‡¡æƒ³</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>äº¤ä½œä¸šï¼š
import numpy as np
import pandas as pd
from sklearn import tree
from sklearn import feature_extraction
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import  AdaBoostClassifier

# load dataset
train_data = pd.DataFrame(pd.read_csv(&#39;~&#47;Documents&#47;titanic_data&#47;train.csv&#39;))
test_data = pd.DataFrame(pd.read_csv(&#39;~&#47;Documents&#47;titanic_data&#47;test.csv&#39;))

# data cleaning
train_data[&#39;Age&#39;].fillna(train_data[&#39;Age&#39;].mean(), inplace=True)
test_data[&#39;Age&#39;].fillna(test_data[&#39;Age&#39;].mean(), inplace=True)
test_data[&#39;Fare&#39;].fillna(test_data[&#39;Fare&#39;].mean(), inplace=True)
train_data[&#39;Embarked&#39;].fillna(&#39;S&#39;, inplace=True)
test_data[&#39;Embarked&#39;].fillna(&#39;S&#39;, inplace=True)
# select features
features = [&#39;Pclass&#39;, &#39;Sex&#39;, &quot;Age&quot;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;, &#39;Embarked&#39;]
train_x = train_data[features]
train_y = train_data[&#39;Survived&#39;]
test_x = test_data[features]
# one-hot
dict_vec = feature_extraction.DictVectorizer(sparse=False)
train_x = dict_vec.fit_transform(train_x.to_dict(orient=&#39;record&#39;))
test_x = dict_vec.transform(test_x.to_dict(orient=&#39;record&#39;))
print(dict_vec.feature_names_)

# decision tree
dtc = tree.DecisionTreeClassifier()
dtc.fit(train_x, train_y)

print(&quot;å†³ç­–æ ‘å‡†ç¡®ç‡&quot;, dtc.score(train_x, train_y))
print(&quot;å†³ç­–æ ‘ï¼škæŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼š&quot;, np.mean(cross_val_score(dtc, train_x, train_y, cv= 10)))

# adaboost
ada = AdaBoostClassifier(n_estimators=50)
ada.fit(train_x, train_y)
print(&quot;AdaBoostå‡†ç¡®ç‡&quot;, ada.score(train_x, train_y))
print(&quot;AdaBoost kæŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼š&quot;, np.mean(cross_val_score(ada, train_x, train_y, cv= 10)))

å†³ç­–æ ‘å‡†ç¡®ç‡ 0.9820426487093153
å†³ç­–æ ‘ï¼škæŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼š 0.7744943820224719
AdaBoostå‡†ç¡®ç‡ 0.8338945005611672
AdaBoost kæŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼š 0.8070037453183521</div>2020-11-26</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIfCY2mvbZ2Po4efYBhMJPacb9mlOicNI6Us4ph3ianrkGlUcop8ZlzN6QiaDrnvFcNeaAfwP7XAv5fw/132" width="30px"><span>even</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>ä¸åŒçš„ç®—æ³•æœ‰ä¸åŒçš„ç‰¹ç‚¹ï¼Œè€å¸ˆæ˜¯å¦å¯ä»¥åšä¸ªæ€»ç»“å’Œå¯¹æ¯”ã€‚æ¯”å¦‚åœ¨å®é™…çš„å·¥ä½œæˆ–è€…é¡¹ç›®ä¸­ï¼Œæ ¹æ®ç»éªŒå’Œä¸åŒçš„ç®—æ³•ç‰¹ç‚¹ï¼Œå¦‚ä½•é€‰æ‹©ç®—æ³•ï¼Œä¸ºä»€ä¹ˆé€‰æ‹©è¿™ç§ç®—æ³•ã€‚å¸Œæœ›è€å¸ˆèƒ½åˆ†äº«è¿™ä¸€å—å®é™…åº”ç”¨åœºæ™¯çš„ç»éªŒã€‚</div>2020-06-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/0c/24/8ce78297.jpg" width="30px"><span>çƒ­æ°´æ³¡é¢ä¸ä¼šåš</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>å¯ä¸å¯ä»¥è§£é‡Šä¸€ä¸‹è¿™é‡Œçš„å­¦ä¹ ç‡ä½“ç°åœ¨å“ªé‡Œå‘¢ï¼Ÿä¹‹å‰çš„åŸç†è®²è§£é‡Œå¥½åƒæ²¡æœ‰ç”¨åˆ°å­¦ä¹ ç‡ï¼Ÿ</div>2020-03-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/dc/68/006ba72c.jpg" width="30px"><span>Untitled</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>ç»“æœï¼š
ada train precision =  0.8338945005611672
ada 10k precison =  0.8070037453183521
clf train precision =  0.9820426487093153
clf 10k precision =  0.7767041198501872
#ä»£ç 
import pandas as pd
import numpy as np
from sklearn.feature_extraction import DictVectorizer
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
train_data = pd.read_csv(&#39;train.csv&#39;)
test_data = pd.read_csv(&#39;test.csv&#39;)

train_data[&#39;Age&#39;].fillna(train_data[&#39;Age&#39;].mean(),inplace=True)
test_data[&#39;Age&#39;].fillna(train_data[&#39;Age&#39;].mean(),inplace=True)
train_data[&#39;Fare&#39;].fillna(train_data[&#39;Age&#39;].mean(),inplace=True)
test_data[&#39;Fare&#39;].fillna(train_data[&#39;Age&#39;].mean(),inplace=True)

train_data[&#39;Embarked&#39;].fillna(&#39;S&#39;,inplace=True)
test_data[&#39;Embarked&#39;].fillna(&#39;S&#39;,inplace=True)

features = [&#39;Pclass&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;, &#39;Embarked&#39;]
train_features = train_data[features]
train_labels = train_data[&#39;Survived&#39;]
test_features = test_data[features]

dvec=DictVectorizer(sparse=False)
train_features=dvec.fit_transform(train_features.to_dict(orient=&#39;record&#39;))
test_features=dvec.transform(test_features.to_dict(orient=&#39;record&#39;))

ada = AdaBoostClassifier()
ada.fit(train_features, train_labels)
print(&quot;ada train precision = &quot;,ada.score(train_features, train_labels))
print(&quot;ada 10k precison = &quot;, np.mean(cross_val_score(ada,train_features,train_labels,cv=10)))
clf=DecisionTreeClassifier(criterion=&#39;entropy&#39;)
clf.fit(train_features,train_labels)
print(&quot;clf train precision = &quot;, clf.score(train_features, train_labels))
print(&quot;clf 10k precision = &quot;, np.mean(cross_val_score(clf,train_features,train_labels,cv=10)))
</div>2020-03-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg" width="30px"><span>éª‘è¡Œçš„æŒæŸœJ</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>æ‰“é”™äº† é™ˆè€å¸ˆæ˜¯å¯¹çš„ æ˜¯å›å½’ç®—æ³•ğŸ˜‚é‡Œæ²¡æœ‰åˆ†ç±»ç®—æ³•çš„algorithm å‚æ•°ã€‚</div>2019-08-14</li><br/><li><img src="" width="30px"><span>hlz-123</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>è€å¸ˆï¼Œåœ¨AdaBoost ä¸å†³ç­–æ ‘æ¨¡å‹çš„æ¯”è¾ƒçš„ä¾‹å­ä¸­ï¼Œå¼±åˆ†ç±»å™¨
dt_stump = DecisionTreeClassfier(max_depth=1,min_samples_leaf=1)
ä¸ºä»€ä¹ˆä¸¤ä¸ªå‚æ•°éƒ½è®¾ç½®ä¸º1ï¼Œç›¸å½“äºåªæœ‰1ä¸ªæ ¹èŠ‚ç‚¹ï¼Œ2ä¸ªå¶èŠ‚ç‚¹ï¼Ÿ
è€Œæ™®é€šçš„å†³ç­–æ ‘åˆ†ç±»å™¨ï¼Œæ²¡æœ‰è®¾ç½®å‚æ•°ï¼Œè¿™æ˜¯ä»€ä¹ˆåŸå› ï¼Ÿ</div>2019-03-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/c1/1f/cc77944d.jpg" width="30px"><span>å®å½“çŒ«</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>fit_transformæ•°æ®ç»Ÿä¸€å¤„ç†ï¼Œæ±‚é—®ä»€ä¹ˆæ—¶å€™éœ€è¦ï¼Ÿ
åœ¨æˆ‘åŒæ—¶æ²¡æœ‰è¿›è¡Œfit_transformçš„æƒ…å†µä¸‹ï¼Œå‡†ç¡®ç‡ï¼š
å†³ç­–æ ‘å¼±åˆ†ç±»å™¨çš„å‡†ç¡®ç‡æ˜¯0.7867
å†³ç­–æ ‘åˆ†ç±»å™¨çš„å‡†ç¡®ç‡æ˜¯0.7734
AdaBooståˆ†ç±»å™¨çš„å‡†ç¡®ç‡æ˜¯0.8161
åœ¨æˆ‘å¯¹æ•°æ®åŒæ—¶è¿›è¡Œfit_transformçš„æƒ…å†µä¸‹ï¼Œå‡†ç¡®ç‡ï¼š
å†³ç­–æ ‘å¼±åˆ†ç±»å™¨çš„å‡†ç¡®ç‡æ˜¯0.7867
å†³ç­–æ ‘åˆ†ç±»å™¨çš„å‡†ç¡®ç‡æ˜¯0.7745
AdaBooståˆ†ç±»å™¨çš„å‡†ç¡®ç‡æ˜¯0.8138

ä»¥ä¸‹æ˜¯ç¬¬ä¸€ç§æƒ…å†µï¼š
train_data[&#39;Embarked&#39;] = train_data[&#39;Embarked&#39;].map({&#39;S&#39;:0, &#39;C&#39;:1, &#39;Q&#39;:2})
test_data[&#39;Embarked&#39;] = test_data[&#39;Embarked&#39;].map({&#39;S&#39;:0, &#39;C&#39;:1, &#39;Q&#39;:2})
train_data[&#39;Sex&#39;] = train_data[&#39;Sex&#39;].map({&#39;male&#39;:0, &#39;female&#39;:1})
test_data[&#39;Sex&#39;] = test_data[&#39;Sex&#39;].map({&#39;male&#39;:0, &#39;female&#39;:1})

train_data[&#39;Age&#39;].fillna(train_data[&#39;Age&#39;].mean(), inplace=True)
test_data[&#39;Age&#39;].fillna(test_data[&#39;Age&#39;].mean(), inplace=True)
train_data[&#39;Fare&#39;].fillna(train_data[&#39;Fare&#39;].mean(), inplace=True)
test_data[&#39;Fare&#39;].fillna(test_data[&#39;Fare&#39;].mean(), inplace=True)

features = [&#39;Pclass&#39;, &#39;Sex&#39;,&#39;Age&#39;,&#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;, &#39;Embarked&#39;]
train_features = train_data[features]
train_labels = train_data[&#39;Survived&#39;]
test_features = test_data[features]

#train_features = dvec.fit_transform(train_features.to_dict(orient=&#39;record&#39;))
#test_features = dvec.transform(test_features.to_dict(orient=&#39;record&#39;))

ä»¥ä¸‹æ˜¯ç¬¬äºŒç§æƒ…å†µï¼š
#train_data[&#39;Embarked&#39;] = train_data[&#39;Embarked&#39;].map({&#39;S&#39;:0, &#39;C&#39;:1, &#39;Q&#39;:2})
#test_data[&#39;Embarked&#39;] = test_data[&#39;Embarked&#39;].map({&#39;S&#39;:0, &#39;C&#39;:1, &#39;Q&#39;:2})
#train_data[&#39;Sex&#39;] = train_data[&#39;Sex&#39;].map({&#39;male&#39;:0, &#39;female&#39;:1})
#test_data[&#39;Sex&#39;] = test_data[&#39;Sex&#39;].map({&#39;male&#39;:0, &#39;female&#39;:1})

train_data[&#39;Age&#39;].fillna(train_data[&#39;Age&#39;].mean(), inplace=True)
test_data[&#39;Age&#39;].fillna(test_data[&#39;Age&#39;].mean(), inplace=True)
train_data[&#39;Fare&#39;].fillna(train_data[&#39;Fare&#39;].mean(), inplace=True)
test_data[&#39;Fare&#39;].fillna(test_data[&#39;Fare&#39;].mean(), inplace=True)

features = [&#39;Pclass&#39;, &#39;Sex&#39;,&#39;Age&#39;,&#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;, &#39;Embarked&#39;]
train_features = train_data[features]
train_labels = train_data[&#39;Survived&#39;]
test_features = test_data[features]

train_features = dvec.fit_transform(train_features.to_dict(orient=&#39;record&#39;))
test_features = dvec.transform(test_features.to_dict(orient=&#39;record&#39;))</div>2019-03-19</li><br/>
</ul>