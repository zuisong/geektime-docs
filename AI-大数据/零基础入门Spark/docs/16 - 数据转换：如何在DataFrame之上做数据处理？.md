ä½ å¥½ï¼Œæˆ‘æ˜¯å´ç£Šã€‚

åœ¨ä¸Šä¸€è®²ï¼Œæˆ‘ä»¬å­¦ä¹ äº†åˆ›å»ºDataFrameçš„å„ç§é€”å¾„ä¸æ–¹æ³•ï¼Œé‚£ä¹ˆï¼Œæœ‰äº†DataFrameä¹‹åï¼Œæˆ‘ä»¬è¯¥å¦‚ä½•åœ¨DataFrameä¹‹ä¸Šåšæ•°æ®æ¢ç´¢ã€æ•°æ®åˆ†æï¼Œä»¥åŠå„å¼å„æ ·çš„æ•°æ®è½¬æ¢å‘¢ï¼Ÿåœ¨æ•°æ®å¤„ç†å®Œæ¯•ä¹‹åï¼Œæˆ‘ä»¬åˆè¯¥å¦‚ä½•åšæ•°æ®å±•ç¤ºä¸æ•°æ®æŒä¹…åŒ–å‘¢ï¼Ÿä»Šå¤©è¿™ä¸€è®²ï¼Œæˆ‘ä»¬å°±æ¥è§£ç­”è¿™äº›ç–‘é—®ã€‚

ä¸ºäº†ç»™å¼€å‘è€…æä¾›è¶³å¤Ÿçš„çµæ´»æ€§ï¼Œå¯¹äºDataFrameä¹‹ä¸Šçš„æ•°æ®å¤„ç†ï¼ŒSpark SQLæ”¯æŒä¸¤ç±»å¼€å‘å…¥å£ï¼šä¸€ä¸ªæ˜¯å¤§å®¶æ‰€ç†ŸçŸ¥çš„ç»“æ„åŒ–æŸ¥è¯¢è¯­è¨€ï¼šSQLï¼Œå¦ä¸€ç±»æ˜¯DataFrameå¼€å‘ç®—å­ã€‚å°±å¼€å‘æ•ˆç‡ä¸æ‰§è¡Œæ•ˆç‡æ¥è¯´ï¼ŒäºŒè€…å¹¶æ— ä¼˜åŠ£ä¹‹åˆ†ï¼Œé€‰æ‹©å“ªç§å¼€å‘å…¥å£ï¼Œå®Œå…¨å–å†³äºå¼€å‘è€…çš„ä¸ªäººåå¥½ä¸å¼€å‘ä¹ æƒ¯ã€‚

ä¸RDDç±»ä¼¼ï¼ŒDataFrameæ”¯æŒç§ç±»ç¹å¤šçš„å¼€å‘ç®—å­ï¼Œä½†ç›¸æ¯”SQLè¯­è¨€ï¼ŒDataFrameç®—å­çš„å­¦ä¹ æˆæœ¬ç›¸å¯¹è¦é«˜ä¸€äº›ã€‚å› æ­¤ï¼Œæœ¬ç€å…ˆæ˜“åéš¾çš„æ€è·¯ï¼Œå’±ä»¬å…ˆæ¥è¯´è¯´DataFrameä¸­SQLè¯­å¥çš„ç”¨æ³•ï¼Œç„¶åå†å»ç†è§£DataFrameå¼€å‘ç®—å­ã€‚

## SQLè¯­å¥

å¯¹äºä»»æ„çš„DataFrameï¼Œæˆ‘ä»¬éƒ½å¯ä»¥ä½¿ç”¨createTempViewæˆ–æ˜¯createGlobalTempViewåœ¨Spark SQLä¸­åˆ›å»ºä¸´æ—¶æ•°æ®è¡¨ã€‚

ä¸¤è€…çš„åŒºåˆ«åœ¨äºï¼ŒcreateTempViewåˆ›å»ºçš„ä¸´æ—¶è¡¨ï¼Œå…¶ç”Ÿå‘½å‘¨æœŸä»…é™äºSparkSessionå†…éƒ¨ï¼Œè€ŒcreateGlobalTempViewåˆ›å»ºçš„ä¸´æ—¶è¡¨ï¼Œå¯ä»¥åœ¨åŒä¸€ä¸ªåº”ç”¨ç¨‹åºä¸­è·¨SparkSessionæä¾›è®¿é—®ã€‚æœ‰äº†ä¸´æ—¶è¡¨ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨SQLè¯­å¥çµæ´»åœ°å€’è…¾è¡¨æ•°æ®ã€‚
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ10ï¼‰</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/20/d6/b9513db0.jpg" width="30px"><span>kingcall</span> ğŸ‘ï¼ˆ11ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<div>explode ä¸ä¼šå¼•å…¥shuffle,å› ä¸ºshuffleæ˜¯åœ¨ä¼—å¤šè®¡ç®—èŠ‚ç‚¹è¿›è¡Œæ•°æ®ä¼ è¾“ï¼Œexplodeè™½ç„¶ä¼šå¯¼è‡´æ•°æ®æ¡æ•°å˜å¤šä½†æ˜¯éƒ½æ˜¯åœ¨ä¸€å°èŠ‚ç‚¹ä¸Šçš„</div>2021-10-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/3a/83/74e3fabd.jpg" width="30px"><span>ç«ç‚ç„±ç‡š</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>python ä»£ç ä¸ºï¼š

# 1-SQLè¯­å¥ï¼š
from pyspark import SparkContext, SparkConf
from pyspark.sql.session import SparkSession
sc = SparkContext()
spark = SparkSession(sc)

seq=[(&#39;Alice&#39;,18), (&#39;Bob&#39;,14)]
column = [&#39;name&#39;,&#39;age&#39;]
df=spark.createDataFrame(seq,column)
df.createTempView(&#39;t1&#39;)
query=&quot;select * from t1&quot;
result=spark.sql(query)
result.show()

# 2-æ¢ç´¢ç±»ç®—å­ï¼š
employees=[(1, &quot;John&quot;, 26, &quot;Male&quot;), (2, &quot;Lily&quot;, 28, &quot;Female&quot;), (3, &quot;Raymond&quot;, 30, &quot;Male&quot;)]
employeesDF=spark.createDataFrame(employees,[&#39;id&#39;,&#39;name&#39;,&#39;age&#39;,&#39;gender&#39;])
employeesDF.printSchema()
employeesDF.show() 
age_df=employeesDF.describe(&#39;age&#39;)
age_df.show()

# 3-æ¸…æ´—ç±»ç®—å­ï¼š
# åˆ é™¤æŸä¸€åˆ—æ•°æ®
employeesDF.drop(&#39;gender&#39;).show()
# distinctå¯¹æ‰€æœ‰æ•°æ®å»é‡ï¼Œæ³¨æ„æ— æ³•è®¾ç½®åˆ—å
employeesDF.distinct().show()
# dropDuplicateså¯ä»¥å¯¹æŸå‡ åˆ—å»é‡ï¼Œçµæ´»æ€§æ›´é«˜
employeesDF.dropDuplicates([&#39;gender&#39;]).show()

# 4-è½¬æ¢ç±»ç®—å­
# é€‰æ‹©æŸå‡ åˆ—ç»„æˆæ–°çš„df
employeesDF.select([&#39;name&#39;,&#39;gender&#39;]).show()
employeesDF.select(&#39;name&#39;).show()
# selectExprç”¨é€‰æ‹©è¡¨è¾¾å¼æ¥ç»„æˆæ–°çš„df
employeesDF.selectExpr(&quot;id&quot;, &quot;name&quot;, &quot;concat(id, &#39;_&#39;, name) as id_name&quot;).show()
# whereé€‰æ‹©æ»¡è¶³æ¡ä»¶çš„å†…å®¹
employeesDF.where(&quot;gender=&#39;Male&#39;&quot;).show()
# å¯¹åˆ—åé‡å‘½åï¼šå°†genderé‡å‘½åä¸ºsex
employeesDF.withColumnRenamed(&#39;gender&#39;,&#39;sex&#39;).show() 
# åœ¨åŸåˆ—è¿›è¡Œä¿®æ”¹åç»„æˆæ–°çš„ä¸€åˆ—ï¼Œå°†ageéƒ½+10å²
employeesDF.withColumn(&quot;crypto&quot;, employeesDF[&#39;age&#39;]+10).show()
# dropåˆ é™¤æŸä¸€åˆ—
employeesDF.withColumn(&quot;crypto&quot;, employeesDF[&#39;age&#39;]+10).drop(&#39;age&#39;).show()

# explodeæ‹†åˆ†list
seq2 =[(1, &quot;John&quot;, 26, &quot;Male&quot;,[&quot;Sports&quot;, &quot;News&quot;]),
(2, &quot;Lily&quot;, 28, &quot;Female&quot;, [&quot;Shopping&quot;, &quot;Reading&quot;]),
(3, &quot;Raymond&quot;, 30, &quot;Male&quot;, [&quot;Sports&quot;, &quot;Reading&quot;])]
employeesDF2=spark.createDataFrame(seq2,[&#39;id&#39;,&#39;name&#39;,&#39;age&#39;,&#39;gender&#39;,&#39;interests&#39;])
from pyspark.sql.functions import explode
employeesDF2.withColumn(&#39;interest&#39;,explode(employeesDF2[&#39;interests&#39;])).show()</div>2021-10-23</li><br/><li><img src="" width="30px"><span>Geek_935079</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<div>val aggResult = fullInfo.groupByè¿™é‡Œæ˜¯ä¸æ˜¯è¦æ”¹ä¸ºval aggResult = jointDF.groupBy</div>2021-11-25</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/iaQgtbE98VGIVIyribdo6dgLOnaNoe7ZdUuPr60ibsduibscrzQCTzdW2AfL9nxwe8YlSK75gOnK3YbAJKTaFPxibdg/132" width="30px"><span>å°æ</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è¯·é—®ä¸€ä¸‹ï¼šdf.select().groupBy().count()ä¸df.select().groupBy().agg(count(lit(1)))å†…éƒ¨å¤„ç†é€»è¾‘ä¼šä¸ä¸€æ ·å—ï¼Œè¿˜æ˜¯ä¼šéƒ½ä¼šç»è¿‡spark sqlä¼˜åŒ–å¼•æ“ä¼˜åŒ–æˆmapé˜¶æ®µé¢„èšåˆï¼Ÿæ¯”å¦‚ä¼šä¸ä¼šåƒrddçš„aggregateByKeyæˆ–è€…reduceByKeyä¸€æ ·åœ¨shuffle writeé˜¶æ®µåšpartitionå†…çš„é¢„èšåˆã€‚</div>2022-01-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/3a/83/74e3fabd.jpg" width="30px"><span>ç«ç‚ç„±ç‡š</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>
# 5-åˆ†æç±»ç®—å­
# åˆ›å»ºå‘˜å·¥df
seq=[(1,&#39;Mike&#39;,28,&#39;Male&#39;),
     (2, &quot;Lily&quot;, 30, &quot;Female&quot;),
     (3, &quot;Raymond&quot;, 26, &quot;Male&quot;)]
employees=spark.createDataFrame(seq,[&#39;id&#39;,&#39;name&#39;,&#39;age&#39;,&#39;gender&#39;])
employees.show()

# åˆ›å»ºè–ªæ°´df
seq2=[(1, 26000), (2, 30000), (4, 25000), (3, 20000)]
salaries=spark.createDataFrame(seq2,[&#39;id&#39;,&#39;salary&#39;])
salaries.show()

# å°†å‘˜å·¥dfå’Œè–ªæ°´dfè¿›è¡Œåˆå¹¶ï¼Œinneræ–¹å¼ï¼š
joinDF=salaries.join(employees,&#39;id&#39;,&#39;inner&#39;)
joinDF.show()

# æŒ‰ç…§æ€§åˆ«ç»Ÿè®¡å‡ºè–ªæ°´ä¹‹å’Œï¼Œå¹³å‡å€¼
from pyspark.sql import functions as f
aggResult=joinDF.groupBy(&#39;gender&#39;).agg(f.sum(&#39;salary&#39;).alias(&#39;sum_salary&#39;),f.avg(&#39;salary&#39;).alias(&#39;avg_salary&#39;))
aggResult.show()

# æ’åºï¼Œsortæ–¹æ³•å’ŒorderByæ–¹æ³•ä¸€æ ·
aggResult.sort(f.desc(&#39;sum_salary&#39;),f.asc(&#39;gender&#39;)).show()
aggResult.orderBy(f.desc(&#39;sum_salary&#39;),f.asc(&#39;gender&#39;)).show()</div>2021-10-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/3d/08/fcf92621.jpg" width="30px"><span>å°ç²é“›ğŸ¯</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è‡ªå·±å¼€å‘çš„æ—¶å€™createTempViewä¼šåœ¨å†…å­˜ä¸­åˆ›å»ºä¸´æ—¶è¡¨,é‡æ–°è¿è¡Œçš„è¯ä¼šæŠ¥table is exist é”™è¯¯,å»ºè®®ä½¿ç”¨ createOrReplaceTempView</div>2021-10-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg" width="30px"><span>GACÂ·DU</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>Sparkä¸­Shuffleç®—å­çš„åˆ†ç±»ï¼šé‡åˆ†åŒºç®—å­ã€ByKeyç®—å­ã€Joinç®—å­</div>2021-10-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/e7/8e/318cfde0.jpg" width="30px"><span>Spoon</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>Javaä»£ç å®ç°
https:&#47;&#47;github.com&#47;Spoon94&#47;spark-practice&#47;blob&#47;master&#47;src&#47;main&#47;java&#47;com&#47;spoon&#47;spark&#47;sql&#47;DataFrameOperatorJob.java</div>2022-04-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/26/eb/24e0ac9c.jpg" width="30px"><span>å¬´æ¢¦å·</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>ä»æˆ‘çš„å¼€å‘ç»éªŒå‘ç°explodeä¸ä¼šå¼•å…¥shuffle</div>2023-09-24</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIw0Nnvrrt9fV1wHVfBlPzrZmxNCRTbWPfNEbCEMtuoj6gw0LlMbbS3gtRLgLMfCoAV3TXsk5giavw/132" width="30px"><span>Geek_b2839b</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>è€å¸ˆè¯·é—®ä¸€ä¸‹ï¼Œä½¿ç”¨sparkåŒæ­¥hiveæ•°æ®åˆ°Oracleçš„æ—¶å€™ï¼Œç”±äºexecutorå¤±è´¥é‡è¯•ï¼Œå¯¼è‡´å¶å°”å‡ºç°åŒæ­¥æ—¶hiveæ•°æ®å’ŒOracleæ•°æ®ä¸ä¸€è‡´çš„æƒ…å†µï¼Œè¿™ä¸ªè¯¥æ€ä¹ˆè§£å†³å‘¢</div>2022-05-28</li><br/>
</ul>