ä½ å¥½ï¼Œæˆ‘æ˜¯å´ç£Šã€‚

åœ¨ä¸Šä¸€è®²çš„æœ€åï¼Œæˆ‘ä»¬ç”¨ä¸€å¼ è¡¨æ ¼æ•´ç†äº†Spark[å®˜ç½‘](https://spark.apache.org/docs/latest/rdd-programming-guide.html)ç»™å‡ºçš„RDDç®—å­ã€‚æƒ³è¦åœ¨Sparkä¹‹ä¸Šå¿«é€Ÿå®ç°ä¸šåŠ¡é€»è¾‘ï¼Œç†è§£å¹¶æŒæ¡è¿™äº›ç®—å­æ— ç–‘æ˜¯è‡³å…³é‡è¦çš„ã€‚

å› æ­¤ï¼Œåœ¨æ¥ä¸‹æ¥çš„å‡ è®²ï¼Œæˆ‘å°†å¸¦ä½ ä¸€èµ·æ¢³ç†è¿™äº›å¸¸è§ç®—å­çš„ç”¨æ³•ä¸ç”¨é€”ã€‚ä¸åŒçš„ç®—å­ï¼Œå°±åƒæ˜¯å¨æˆ¿é‡Œçš„ç‚’å‹ºã€é“²å­ã€åˆ€å…·å’Œå„å¼å„æ ·çš„é”…ç¢—ç“¢ç›†ï¼Œåªæœ‰ç†Ÿæ‚‰äº†è¿™äº›â€œå¨å…·â€çš„æ“ä½œæ–¹æ³•ï¼Œæ‰èƒ½åœ¨å®¢äººç‚¹é¤çš„æ—¶å€™è¿…é€Ÿåœ°åšå‡ºä¸€æ¡Œå¥½èœã€‚

ä»Šå¤©è¿™ä¸€è®²ï¼Œæˆ‘ä»¬å…ˆæ¥å­¦ä¹ åŒä¸€ä¸ªRDDå†…éƒ¨çš„æ•°æ®è½¬æ¢ã€‚æŒæ¡RDDå¸¸ç”¨ç®—å­æ˜¯åšå¥½Sparkåº”ç”¨å¼€å‘çš„åŸºç¡€ï¼Œè€Œæ•°æ®è½¬æ¢ç±»ç®—å­åˆ™æ˜¯åŸºç¡€ä¸­çš„åŸºç¡€ï¼Œå› æ­¤æˆ‘ä»¬ä¼˜å…ˆæ¥å­¦ä¹ è¿™ç±»RDDç®—å­ã€‚

åœ¨è¿™äº›ç®—å­ä¸­ï¼Œæˆ‘ä»¬é‡ç‚¹è®²è§£çš„å°±æ˜¯mapã€mapPartitionsã€flatMapã€filterã€‚è¿™4ä¸ªç®—å­å‡ ä¹å›Šæ‹¬äº†æ—¥å¸¸å¼€å‘ä¸­99%çš„æ•°æ®è½¬æ¢åœºæ™¯ï¼Œå‰©ä¸‹çš„mapPartitionsWithIndexï¼Œæˆ‘æŠŠå®ƒç•™ç»™ä½ ä½œä¸ºè¯¾åä½œä¸šå»æ¢ç´¢ã€‚

![å›¾ç‰‡](https://static001.geekbang.org/resource/image/a3/88/a3ec138b50456604bae8ce22cdf56788.jpg?wh=1599x1885 "RDDç®—å­åˆ†ç±»è¡¨")

ä¿—è¯è¯´ï¼Œå·§å¦‡éš¾ä¸ºæ— ç±³ä¹‹ç‚Šï¼Œè¦æƒ³ç©è½¬å¨æˆ¿é‡Œçš„å¨å…·ï¼Œæˆ‘ä»¬å¾—å…ˆå‡†å¤‡å¥½ç±³ã€é¢ã€æ²¹è¿™äº›é£Ÿæã€‚å­¦ä¹ RDDç®—å­ä¹Ÿæ˜¯ä¸€æ ·ï¼Œè¦æƒ³åŠ¨æ‰‹æ“ä½œè¿™äº›ç®—å­ï¼Œå’±ä»¬å¾—å…ˆæœ‰RDDæ‰è¡Œã€‚

æ‰€ä»¥ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°±ä¸€èµ·æ¥çœ‹çœ‹RDDæ˜¯æ€ä¹ˆåˆ›å»ºçš„ã€‚

## åˆ›å»ºRDD

åœ¨Sparkä¸­ï¼Œåˆ›å»ºRDDçš„å…¸å‹æ–¹å¼æœ‰ä¸¤ç§ï¼š
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ24ï¼‰</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/19/70/67/0c1359c2.jpg" width="30px"><span>qinsi</span> ğŸ‘ï¼ˆ45ï¼‰ ğŸ’¬ï¼ˆ11ï¼‰<div>ä¸æ˜¯å¾ˆæ‡‚sparkã€‚mapPartitions()é‚£é‡Œï¼Œå…‰ä»ä»£ç ä¸Šæ¥çœ‹çš„è¯ï¼Œåœ¨map()çš„é—­åŒ…é‡Œå¯ä»¥è®¿é—®åˆ°å¤–é¢mapPartitions()é—­åŒ…é‡Œçš„åŒä¸€ä¸ªmd5å®ä¾‹ï¼Œä»è€Œè¾¾åˆ°å…±äº«å®ä¾‹çš„æ•ˆæœã€‚é‚£ä¹ˆæœ‰æ²¡æœ‰å¯èƒ½åœ¨æœ€å¤–å±‚åˆ›å»ºä¸€ä¸ªå…¨å±€çš„md5å®ä¾‹ï¼Œè¿™æ ·å°±ç®—åªç”¨map()ï¼Œåœ¨é—­åŒ…é‡Œè®¿é—®çš„ä¹Ÿæ˜¯è¿™åŒä¸€ä¸ªå®ä¾‹ï¼Ÿè¿™æ ·ä¼šæœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿæˆ–è€…è¯´åœ¨è¿™ç§æƒ…å†µä¸‹mapPartitions()ç›¸æ¯”map()è¿˜æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ</div>2021-09-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f2/f5/b82f410d.jpg" width="30px"><span>Unknown element</span> ğŸ‘ï¼ˆ22ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆæ‚¨å›ç­”ä¸€æ¥¼çš„é—®é¢˜æ—¶æåˆ°çš„åºåˆ—åŒ–æ„æ€æ˜¯ä¸æ˜¯å¯¹è±¡åœ¨ä¸åŒèŠ‚ç‚¹é—´ä¼ è¾“çš„æ—¶å€™åªèƒ½åºåˆ—åŒ–ä¸ºå­—ç¬¦ä¸²ä¼ è¾“ï¼Ÿå¦‚æœæ˜¯çš„è¯é‚£æˆ‘è§‰å¾— åœ¨mapPartitionsé‡Œé¢åˆ›å»ºMD5å®ä¾‹ï¼Œmapå¼•ç”¨è¿™ä¸ªå¯¹è±¡ï¼ŒSparkå´æ²¡æœ‰æŠ¥â€œTask not Serializableâ€é”™è¯¯ æ˜¯å› ä¸ºdriveræŠŠè¿™æ®µä»£ç åˆ†å‘åˆ°äº†å„ä¸ªexecutorï¼Œè€Œåˆ›å»ºå¯¹è±¡è¿™ä¸ªå·¥ä½œæ˜¯ç”±executorå®Œæˆçš„ï¼Œæ‰€ä»¥ä¸ä¼šæŠ¥é”™ï¼Ÿ</div>2021-09-24</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKw8ictgYcqf6iaicPTOyZ2CR7iaVeeztZLZrLdrvuJib46ibZgibkhSYg85xZAglBhhsO7bY4fz5YQ8icbMA/132" width="30px"><span>Geek_eb2d3d</span> ğŸ‘ï¼ˆ8ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆï¼Œæˆ‘åœ¨ map é‡Œé¢ä½¿ç”¨ SparkContext æˆ– SparkSession åˆ›å»ºæ–°çš„ RDDï¼Œè¿™æ ·æ˜¯å¯ä»¥çš„ä¹ˆï¼Ÿ</div>2021-09-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/75/ec/c60b29f5.jpg" width="30px"><span>Alvin-L</span> ğŸ‘ï¼ˆ7ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<div>Pythonç‰ˆ,è™½ç„¶èƒ½è·‘,ä½†æ˜¯ä¸çŸ¥é“å¯¹ä¸å¯¹:
#å“ˆå¸Œå€¼è®¡æ•°
``` 
from hashlib import md5
from pyspark import SparkContext


def f(partition):
    m = md5()
    for word in partition:
        m.update(word.encode(&quot;utf8&quot;))
        yield m.hexdigest()


lineRDD = SparkContext().textFile(&quot;.&#47;wikiOfSpark.txt&quot;)
kvRDD = (
    lineRDD.flatMap(lambda line: line.split(&quot; &quot;))
    .filter(lambda word: word != &quot;&quot;)
    .mapPartitions(f)
    .map(lambda word: (word, 1))
)

kvRDD.foreach(print)

``` 

#ç›¸é‚»+è¿‡æ»¤ç‰¹æ®Šå­—ç¬¦
``` 
from pyspark import SparkContext

# å®šä¹‰ç‰¹æ®Šå­—ç¬¦åˆ—è¡¨
special_char_list = [&quot;&amp;&quot;, &quot;|&quot;, &quot;#&quot;, &quot;^&quot;, &quot;@&quot;]
# å®šä¹‰åˆ¤å®šå‡½æ•°f
def f(s):
    words = s.split(&quot;-&quot;)
    b1 = words[0] in special_char_list
    b2 = words[1] in special_char_list
    return (not b1) and (not b2)


# å®šä¹‰æ‹¼æ¥å‡½æ•°word_pair
def word_pair(line):
    words = line.split(&quot; &quot;)
    for i in range(len(words) - 1):
        yield words[i] + &quot;-&quot; + words[i + 1]


lineRDD = SparkContext().textFile(&quot;.&#47;wikiOfSpark.txt&quot;)
cleanedPairRDD = lineRDD.flatMap(word_pair).filter(f)
cleanedPairRDD.foreach(print)

``` </div>2021-09-21</li><br/><li><img src="" width="30px"><span>Geek_a30533</span> ğŸ‘ï¼ˆ4ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>å¯¹scalaçš„å‡½æ•°å®šä¹‰æ ¼å¼ä¸æ˜¯å¾ˆæ¸…æ¥šï¼Œé‚£è¾¹ç»•äº†å¥½å‡ æ¬¡ï¼Œæœ‰ä¸€ä¸ªå°ç–‘é—®ï¼Œåœ¨flatMapé‡Œçš„åŒ¿åå‡½æ•°f

line =&gt; {  
			val words: Array[String] = line.split(&quot; &quot;)  
			for (i &lt;- 0 until words.length - 1) yield words(i) + &quot;-&quot; + words(i+1)
		}

åªå®šä¹‰äº†å½¢å‚æ˜¯lineï¼Œé‚£å‡ºå‚æ˜¯æ•´ä¸ªèŠ±æ‹¬å·ä¹ˆï¼Ÿä¸»è¦æ˜¯æ²¡æœ‰returnï¼Œè®©æˆ‘ä¸€ä¸‹è¿·äº†ï¼Œéš¾é“æ˜¯æœ€åä¸€ä¸ªæ˜¯Array[String]æ‰€ä»¥è¿”å›å€¼å°±æ˜¯è¿™ä¸ªï¼Ÿä¸ç”¨å£°æ˜å—ï¼Ÿ</div>2021-10-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/39/68/56dfc8c0.jpg" width="30px"><span>å­å…®</span> ğŸ‘ï¼ˆ4ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆï¼Œè¯·é—®ï¼Œä¸€ä¸ªå˜é‡mè¢«filter ç®—å­å†…éƒ¨è®¡ç®—æ—¶ä½¿ç”¨ï¼Œè‹¥må®šä¹‰åœ¨äº†filterç®—å­æ‰€åœ¨å‡½æ•°å†…ï¼Œä¹Ÿå°±æ˜¯å˜é‡å’Œç®—å­åœ¨åŒä¸€ä¸ªå‡½æ•°é‡Œï¼Œå°±ä¸ä¼šæŠ¥åºåˆ—åŒ–é—®é¢˜ï¼Œè‹¥å®šä¹‰åœ¨äº†å‡½æ•°ä¹‹å¤–å°±ä¼šæŠ¥åºåˆ—åŒ–é—®é¢˜ï¼Œè¿™æ˜¯ä¸ºä»€ä¹ˆï¼Ÿçœ‹äº†ä¸€äº›è§£é‡Šï¼Œè¯´æ˜¯å‡½æ•°é—­åŒ…ï¼Œä¹Ÿä¸æ˜¯å¾ˆç†è§£</div>2021-09-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/27/5d/e2/1587b1b3.jpg" width="30px"><span>æœ¨ä¹‹ä¸Š</span> ğŸ‘ï¼ˆ3ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆï¼Œåœ¨å­¦ä¹ è¿™äº›ç®—å­çš„æ—¶å€™ï¼Œåƒmapï¼Œflatmapæ˜¯å¦å¯ä»¥ç±»æ¯”JAVA8çš„lambdaè¡¨è¾¾å¼+streamæµå»å­¦ä¹ </div>2022-02-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/98/73/791d0f5e.jpg" width="30px"><span>DMY</span> ğŸ‘ï¼ˆ3ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<div>æ•°æ®åšmapæ˜ å°„æ˜¯ä»¥å…ƒç´ ä¸ºç²’åº¦ï¼Œæ‰§è¡Œfå‡½æ•°ï¼›
è¿™é‡Œä¸šåŠ¡åœºæ™¯ä¸­ï¼Œfå‡½æ•°éœ€è¦è°ƒç”¨rpcï¼Œæ¯ä¸ªæ•°æ®è°ƒä¸€æ¬¡rpc+æ•°æ®é‡å¤§å°±ä¼šéå¸¸è€—æ—¶ã€‚
æ‰€ä»¥æƒ³æŠŠä¸€ç»„æ•°æ®æ‰“åŒ…æˆä¸€ä¸ªlistå‡å°‘rpcè°ƒç”¨ï¼Œæ¥æé«˜æ•ˆç‡ï¼Œè¿™é‡Œè¦æ€ä¹ˆå¤„ç†å‘¢</div>2021-10-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/07/8a/4bef6202.jpg" width="30px"><span>å¤§å®å½“</span> ğŸ‘ï¼ˆ3ï¼‰ ğŸ’¬ï¼ˆ4ï¼‰<div>åŒé—®è€å¸ˆ,AIKé—®çš„é—®é¢˜ï¼Œä»€ä¹ˆæ—¶å€™ç”¨å°æ‹¬å·ä»€ä¹ˆæ—¶å€™ç”¨èŠ±æ‹¬å·å•Šï¼Œæ„Ÿè§‰scalaå®åœ¨æœ‰ç‚¹è¿‡äºçµæ´»</div>2021-09-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/a8/77/08ee51cb.jpg" width="30px"><span>å­™æµ©</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>æœ‰ç–‘é—®ï¼Œå´è€å¸ˆï¼ŒPariedRDDä¸­çš„ï¼ˆKï¼ŒVï¼‰ï¼Œ1.å¯¹åº”çš„æ•°æ®ç±»å‹åº”è¯¥æ˜¯scalaä¸­çš„å…ƒç»„å§ï¼Ÿ2.reduceByKeyä¸ºå•¥ä¸æ”¯æŒå…ƒç´ æ˜¯mapç±»å‹ï¼Ÿæˆ–è€…å¦‚æœæˆ‘å­˜åœ¨ä¸€ä¸ªRDD[Map[String,Int]]ï¼Œæˆ‘æƒ³åšreduceByKeyæ“ä½œï¼Œåº”è¯¥æ€ä¹ˆå®ç°ï¼Ÿ</div>2021-11-05</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKGiaLDlazWNmLnB7nGbHdH3g4Akx1LxJAjx4zrriaS7AWdUXfCzy2pyfhibJ4Z0LNnSOgcSvA39LuOQ/132" width="30px"><span>Geek_390836</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>å‚è€ƒmapå’ŒmapPartitionsï¼Œä¸ºä»€ä¹ˆmapPartitionsä¸­çš„mapï¼Œæ˜¯å¯¹recordè¿›è¡Œgetbytesè€Œä¸æ˜¯word.getbytesæ“ä½œï¼Œåˆšå­¦sparkï¼Œæ±‚è€å¸ˆè§£ç­”</div>2021-09-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/6f/4f/3cf1e9c4.jpg" width="30px"><span>é’±é¹ Allen</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>mapPartitionsWithIndex  éœ€è¦ç»“åˆåˆ†åŒºç´¢å¼•ä½¿ç”¨
map filter flatMap mapPartitions mapPartitionsWithIndex  é€šè¿‡å‡½æ•°ï¼Œä¼ é€’å‚æ•°ï¼Œè¿”å›æ–°çš„RDD
mapPartitions é‡‡é›†ç³»ç»Ÿä¸­ï¼Œåªéœ€å®ä¾‹åŒ–ä¸€æ¬¡ç”µè¡¨å·ï¼Œå¯è¯»å…¶ä»–å„ç±»è¯»æ•°</div>2021-09-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/3c/c4/4ee2968a.jpg" width="30px"><span>è‰¾åˆ©ç‰¹-G</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>&#47;&#47; ç›¸é‚»è¯æ±‡è®¡æ•°ç»Ÿè®¡
package com.shouneng

import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}

object NeighboringWordCount {
  def main(args: Array[String]) {
    try {
      val conf =
        new SparkConf().setAppName(&quot;NeighboringWordCount&quot;).setMaster(&quot;local[1]&quot;)
      val sparkContext = new SparkContext(conf)
      val rootPath: String = &quot;file:&#47;&#47;&quot;
      val file: String =
        s&quot;${rootPath}&#47;home&#47;shouneng&#47;geektime&#47;Getting_Started_with_Spark&#47;chapter01&#47;wikiOfSpark.txt&quot;

      &#47;&#47; è¯»å–æ–‡ä»¶å†…å®¹
      val lineRDD: RDD[String] = sparkContext.textFile(file)
      &#47;&#47;   val wordRDD: RDD[String] = lineRDD.flatMap(line =&gt; line.split(&quot; &quot;))
      &#47;&#47;   val cleanWordRDD: RDD[String] = wordRDD.filter(word =&gt; !word.equals(&quot;&quot;))

      val wordPairRDD: RDD[String] = lineRDD.flatMap(line =&gt; {
        val words: Array[String] =
          line.split(&quot; &quot;).filter(word =&gt; !word.equals(&quot;&quot;))
        for (i &lt;- 0 until words.length - 1) yield words(i) + &quot;-&quot; + words(i + 1)
      })
      val kvRDD: RDD[(String, Int)] = wordPairRDD.map(wordPair =&gt; (wordPair, 1))
      val wordCounts: RDD[(String, Int)] = kvRDD.reduceByKey((x, y) =&gt; x + y)

      wordCounts
        .map { case (k, v) =&gt; (v, k) }
        .sortByKey(false)
        .take(5)
        .foreach(println)
    } catch {
      case ex: Exception =&gt; {
        ex.printStackTrace() &#47;&#47; æ‰“å°åˆ°æ ‡å‡†err
        System.err.println(&quot;exception===&gt;: ...&quot;) &#47;&#47; æ‰“å°åˆ°æ ‡å‡†err
      }
    }
  }
}</div>2022-01-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/a8/77/08ee51cb.jpg" width="30px"><span>å­™æµ©</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>å´è€å¸ˆï¼ŒmapPartitionsçš„æ˜¯ä¸æ˜¯ä¹Ÿé¿å…äº†å¯¹è±¡é”çš„é—®é¢˜ï¼Œå› ä¸ºpartitionså¯¹åº”çš„ä¹Ÿæ˜¯ä»»åŠ¡æ•°ã€‚</div>2021-11-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/97/c4/6c92c78a.jpg" width="30px"><span>å°å¼º</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>import org.apache.spark.rdd.RDD
 
&#47;&#47; è¿™é‡Œçš„ä¸‹åˆ’çº¿&quot;_&quot;æ˜¯å ä½ç¬¦ï¼Œä»£è¡¨æ•°æ®æ–‡ä»¶çš„æ ¹ç›®å½•
val rootPath: String = &quot;&#47;home&#47;gxchen&#47;Spark&#47;01-wordCount&quot;
val file: String = s&quot;${rootPath}&#47;wikiOfSpark.txt&quot;
 
&#47;&#47; è¯»å–æ–‡ä»¶å†…å®¹
val lineRDD: RDD[String] = spark.sparkContext.textFile(file)
 
&#47;&#47; ä»¥è¡Œä¸ºå•ä½åšåˆ†è¯
val wordPairRDD: RDD[String] = lineRDD.flatMap(line =&gt; {
	val words: Array[String] = line.split(&quot; &quot;)
	for (i &lt;- 0 until words.length - 1) yield words(i) + &quot;-&quot; + words(i+1)
})



&#47;&#47; å®šä¹‰ç‰¹æ®Šå­—ç¬¦åˆ—è¡¨
val list: List[String] = List(&quot;&amp;&quot;, &quot;|&quot;, &quot;#&quot;, &quot;^&quot;, &quot;@&quot;)
 
&#47;&#47; å®šä¹‰åˆ¤å®šå‡½æ•°f
def f(s: String): Boolean = {
	val words: Array[String] = s.split(&quot;-&quot;)
	val b1: Boolean = list.contains(words(0))
	val b2: Boolean = list.contains(words(1))
	return !b1 &amp;&amp; !b2 &#47;&#47; è¿”å›ä¸åœ¨ç‰¹æ®Šå­—ç¬¦åˆ—è¡¨ä¸­çš„è¯æ±‡å¯¹
}
 
&#47;&#47; ä½¿ç”¨filter(f)å¯¹RDDè¿›è¡Œè¿‡æ»¤
val cleanWordPairRDD: RDD[String] = wordPairRDD.filter(f)

&#47;&#47; æŠŠRDDå…ƒç´ è½¬æ¢ä¸ºï¼ˆKeyï¼ŒValueï¼‰çš„å½¢å¼
val kvRDD: RDD[(String, Int)] = cleanWordPairRDD.map(wordPair =&gt; (wordPair, 1))
&#47;&#47; æŒ‰ç…§å•è¯åšåˆ†ç»„è®¡æ•°
val wordPairCounts: RDD[(String, Int)] = kvRDD.reduceByKey((x, y) =&gt; x + y)
 
&#47;&#47; æ‰“å°è¯é¢‘æœ€é«˜çš„5ä¸ªè¯æ±‡
wordPairCounts.map{case (k, v) =&gt; (v, k)}.sortByKey(false).take(5)


è¿è¡Œäº†ä»¥ä¸Šä»£ç åï¼ŒæŠ¥é”™ã€‚æƒ³äº†åŠå¤©ä¹Ÿæ²¡å¼„æ˜ç™½ï¼Œæ±‚åŠ©ä¸€ä¸‹ï¼
21&#47;10&#47;24 04:58:42 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 3)
java.lang.ArrayIndexOutOfBoundsException: 1
        at $line33.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.f(&lt;console&gt;:29)
        at $line34.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.$anonfun$cleanWordPairRDD$1(&lt;console&gt;:27)

21&#47;10&#47;24 04:58:42 WARN TaskSetManager: Lost task 1.0 in stage 2.0 (TID 3) (localhost executor driver): java.lang.ArrayIndexOutOfBoundsException: 1

21&#47;10&#47;24 04:58:42 ERROR TaskSetManager: Task 1 in stage 2.0 failed 1 times; aborting job
21&#47;10&#47;24 04:58:42 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 2)

21&#47;10&#47;24 04:58:42 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 2) (localhost executor driver): java.lang.ArrayIndexOutOfBoundsException: 0</div>2021-10-24</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/hSGZCTvHTKaJH5WibTcC15qDKYpGdgdMFEV6mwcslOFoADP6skWCpBiae2ykkaBFDaexEY9xXBPhZMAGmj1nW8vA/132" width="30px"><span>è¿›</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>æœŸå¾…ä¸‹ä¸€è®²....</div>2021-09-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/fa/f7/a6f40eee.jpg" width="30px"><span>æ±‚ç´¢</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<div>è¯·æ•™ä¸ªé—®é¢˜ï¼Œspark sqlæ‰§è¡Œç¼“æ…¢ï¼Œç„¶è€Œèµ„æºå´é—²ç½®çŠ¶æ€ï¼Œè¿™æ˜¯ä½•è§£</div>2021-09-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg" width="30px"><span>GACÂ·DU</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>1ã€mapPartitionsWithIndexçš„åº”ç”¨åœºæ™¯ï¼šè·å–æ•°æ®æ‰€åœ¨çš„åˆ†åŒºå¹¶å¯¹ç‰¹å®šåˆ†åŒºæ•°æ®è¿›è¡Œç‰¹å®šå¤„ç†ã€‚
2ã€è¿™äº›ç®—å­é¦–å…ˆéƒ½æ˜¯æƒ°æ€§ç®—å­ï¼Œåˆéƒ½ä½¿ç”¨å‡½æ•°ä½œä¸ºå‚æ•°ä¼ å…¥ï¼Œè¾¾åˆ°ä¸€å¯¹ä¸€çš„æ•ˆæœã€‚
3ã€åœ¨mapPatitionsä¸­åªåˆ›å»ºè¿‡è¿æ¥æ•°æ®åº“çš„å…±äº«å¯¹è±¡ï¼Œå…¶ä»–çš„æ²¡æœ‰é‡åˆ°è¿‡ï¼Œè¿˜è¯·è€å¸ˆèƒ½ä¸èƒ½å¤šç»™å‡ ä¸ªå®é™…æ¡ˆä¾‹ï¼Œæé«˜ä¸€ä¸‹å¯¹mapPatitionsçš„è®¤çŸ¥ã€‚
è¿˜æƒ³å‘è€å¸ˆæä¸ªé—®é¢˜ï¼šscalaç¼–ç¨‹sparkä»€ä¹ˆæ—¶å€™ç”¨å°æ‹¬å·,ä»€ä¹ˆæ—¶å€™ç”¨ç”¨èŠ±æ‹¬å·ï¼Ÿ
wordCount.map{case (k, v) =&gt; (v, k)}.sortByKey(false).take(5)
è¿™æ®µä»£ç å¯¹äºä¸ºä»€ä¹ˆä½¿ç”¨èŠ±æ‹¬å·ï¼Œä¸æ˜¯å¾ˆæ¸…æ™°ï¼Œå°è¯•è¿‡ç”¨å°æ‹¬å·ï¼Œä½†æ˜¯æ— æ³•è°ƒç”¨sortByKeyã€‚</div>2021-09-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/27/bd/95/882bd4e0.jpg" width="30px"><span>Abigail</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ5ï¼‰<div>é‡åˆ°ä¸€ä¸ªå…³äºfilter å‡½æ•°çš„ bug on reduceByKeyã€‚
æˆ‘è¿è¡Œç¬¬ä¸€ä¸ªä¾‹å­ä»£ç å¦‚ä¸‹å¯ä»¥å¾—åˆ°æ­£ç¡®çš„ç»“æœï¼š
...
 val cleanedPairRDD: RDD[String] = wordPairRDD.filter(word =&gt; !word.equals(&quot;&quot;)) 
...
å¯ä»¥è¾“å‡ºç»“æœï¼š
scala&gt; :load WordCount03.scala
Loading WordCount03.scala...
import org.apache.spark.rdd.RDD
rootPath: String = .
file: String = .&#47;wikiOfSpark.txt
lineRDD: org.apache.spark.rdd.RDD[String] = .&#47;wikiOfSpark.txt MapPartitionsRDD[274] at textFile at WordCount03.scala:80
wordPairRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[275] at flatMap at WordCount03.scala:80
cleanedPairRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[276] at filter at WordCount03.scala:80
kvRDD: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[277] at map at WordCount03.scala:80
wordCounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[278] at reduceByKey at WordCount03.scala:80
res66: Array[(Int, String)] = Array((10,Apache-Software), (8,Apache-Spark), (7,can-be), (7,-&quot;Spark), (7,of-the))

ä¿®æ”¹ä»£ç ï¼Œæ·»åŠ filterå‡½æ•°åï¼Œä»£ç æŠ¥é”™ï¼š
ä»£ç ï¼š
...
&#47;&#47; å®šä¹‰ç‰¹æ®Šå­—ç¬¦åˆ—è¡¨
val list: List[String] = List(&quot;&amp;&quot;, &quot;|&quot;, &quot;#&quot;, &quot;^&quot;, &quot;@&quot;, &quot;\&quot;&quot;,&quot;-&quot;)
def f(s: String): Boolean = {
    val words: Array[String] = s.split(&quot;-&quot;)
    val b1: Boolean = list.contains(words(0))
    val b2: Boolean = list.contains(words(1))
    return !b1 &amp;&amp; !b2}  
val cleanedPairRDD: RDD[String] = wordPairRDD.filter(f)  
...
è¾“å‡ºæŠ¥é”™ï¼š
scala&gt; :load WordCountDebug.scala
Loading WordCountDebug.scala...
...
list: List[String] = List(&amp;, |, #, ^, @, &quot;, -)
f: (s: String)Boolean
cleanedPairRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[286] at filter at WordCountDebug.scala:84
kvRDD: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[287] at map at WordCountDebug.scala:82
wordCounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[288] at reduceByKey at WordCountDebug.scala:82
21&#47;09&#47;15 09:51:42 ERROR Executor: Exception in task 1.0 in stage 108.0 (TID 141)
java.lang.ArrayIndexOutOfBoundsException: 1
...
</div>2021-09-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/e7/8e/318cfde0.jpg" width="30px"><span>Spoon</span> ğŸ‘ï¼ˆ3ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>æœ€åfilteræ›´å»ºè®®ç”¨Setè¿™ç§æ•°æ®ç»“æ„è¿›è¡ŒcontainæŸ¥è¯¢ï¼Œsetçš„ç®—æ³•å¤æ‚åº¦ä¸ºO(1)
æœ¬èŠ‚å†…å®¹Javaç‰ˆæœ¬å®ç°
https:&#47;&#47;github.com&#47;Spoon94&#47;spark-practice&#47;blob&#47;master&#47;src&#47;main&#47;java&#47;com&#47;spoon&#47;spark&#47;core&#47;TransformOpJob.java</div>2022-03-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/58/a1/6e33ffc7.jpg" width="30px"><span>è¯·è¾“å…¥æ˜µç§°</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>è¯¾åå›ç­”
ç¬¬ä¸€é¢˜ï¼šåº”ç”¨ä¸ºæŒ‰ç…§åˆ†åŒºç´¢å¼•åšå®šåˆ¶åŒ–æ“ä½œ
ç¬¬äºŒé¢˜ï¼šå…±æ€§ä¸ºéƒ½æ˜¯è½¬æ¢ç®—å­ï¼Œå¹¶éè¡ŒåŠ¨ç®—å­
ç¬¬ä¸‰é¢˜ï¼šä¹‹å‰æ²¡ç”¨è¿‡ mapPartitions ç®—å­ï¼Œä¹Ÿä¸çŸ¥é“ï¼Œçœ‹æ¥ä¸‹ä»£ç ï¼Œå‘ç°äº†å¯ä»¥å¾ˆå¤šç”¨è¿™ä¸ªç®—å­åšä¼˜åŒ–çš„åœ°æ–¹</div>2022-04-25</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIxKpBQJbxHFG9Wjk73WkbqcGeDrjzwjPSDzLlm8C80U9dVmByrrmBa3LmIoCYUW2H3thj5VfMvGQ/132" width="30px"><span>jasonde</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>è€å¸ˆï¼Œéº»çƒ¦å’¨è¯¢ä¸€ä¸‹ç”¨mapï¼Œ mappartitionï¼Œ æ˜¯å¦ä¹Ÿå¯ä»¥å®ç°flatmap çš„ç»“æœå‘¢ï¼ŒåŠ³çƒ¦æŒ‡å¯¼ï¼Œè°¢è°¢äº†</div>2024-06-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/ee/f9/1dcffdc0.jpg" width="30px"><span>Geek_919d2f</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>ä¸ºä»€ä¹ˆä¸å¯ä»¥æŠŠval md5 = MessageDigest.getInstance(&quot;MD5&quot;) è¿™ä¸€æ®µï¼Œæå–åˆ°æ–¹æ³•å¤–é¢ï¼Œè¿™æ ·å°±å¯ä»¥ä¸ä½¿ç”¨mapPartitionsï¼Œä¸ç”¨å†å¥—ä¸€å±‚é€»è¾‘äº†</div>2023-09-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/27/d3/0a/92640aae.jpg" width="30px"><span>æˆ‘çˆ±å¤œæ¥é¦™</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆ,mapç®—å­é’ˆå¯¹ä¸€ä¸ªä¸ªå…ƒç´ è¿›è¡Œfæ“ä½œ,è¿™ä¸ªå…ƒç´ æ˜¯å’‹å®šä¹‰çš„,ä¸€è¡Œ?</div>2022-04-13</li><br/>
</ul>