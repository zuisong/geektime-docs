ä½ å¥½ï¼Œæˆ‘æ˜¯å´ç£Šã€‚

ä»è¿™èŠ‚è¯¾å¼€å§‹ï¼Œæˆ‘ä»¬å…ˆæ¥å­¦ä¹ Sparkçš„â€œåŸºç¡€çŸ¥è¯†â€æ¨¡å—ï¼Œå¯¹Sparkçš„æ¦‚å¿µå’Œæ ¸å¿ƒåŸç†å…ˆåšä¸€ä¸ªæ•´ä½“çš„äº†è§£ã€‚æˆ‘å¹¶ä¸ä¼šä»RDDã€DAGè¿™äº›åŸºæœ¬æ¦‚å¿µç»™ä½ è®²èµ·ã€‚å¦ç™½åœ°è¯´ï¼Œè¿™äº›æŠ½è±¡çš„æ¦‚å¿µæ¯ç‡¥è€Œåˆä¹å‘³ï¼Œå¯¹äºåˆšå¼€å§‹æ¥è§¦Sparkçš„ä½ æ¥è¯´ï¼Œå¾ˆéš¾å­¦è¿›å»ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¸å¦¨åå…¶é“è€Œè¡Œä¹‹ï¼Œå…ˆä»å®æˆ˜å…¥æ‰‹ï¼Œç”¨ä¸€ä¸ªå°ä¾‹å­æ¥ç›´è§‚åœ°è®¤è¯†Sparkï¼Œçœ‹çœ‹Sparkéƒ½èƒ½åšäº›ä»€ä¹ˆã€‚

è¿™å°±å¥½æ¯”æˆ‘ä»¬å­¦ä¹ ä¸€é—¨æ–°çš„ç¼–ç¨‹è¯­è¨€ï¼Œå¾€å¾€éƒ½æ˜¯ä»â€œHello Worldâ€å¼€å§‹ã€‚æˆ‘è¿˜è®°å¾—ï¼Œåˆšåˆšå­¦ç¼–ç¨‹é‚£ä¼šï¼Œå±å¹•ä¸Šæ‰“å°å‡ºçš„â€œHello Worldâ€ï¼Œè¶³è¶³è®©æˆ‘å…´å¥‹äº†ä¸€æ•´å¤©ï¼Œè®©æˆ‘è«ååœ°æœ‰ä¸€ç§â€œI can change the worldâ€çš„å†²åŠ¨ã€‚

ä»Šå¤©è¿™ä¸€è®²ï¼Œæˆ‘ä»¬å°±ä»â€œå¤§æ•°æ®çš„Hello Worldâ€å¼€å§‹ï¼Œå»å­¦ä¹ æ€ä¹ˆåœ¨Sparkä¹‹ä¸Šåšåº”ç”¨å¼€å‘ã€‚ä¸è¿‡ï¼Œâ€œå¤§æ•°æ®çš„Hello Worldâ€å¹¶ä¸æ˜¯æŠŠå­—ç¬¦ä¸²æ‰“å°åˆ°å±å¹•ä¸Šè¿™ä¹ˆç®€å•ï¼Œè€Œæ˜¯è¦å…ˆå¯¹æ–‡ä»¶ä¸­çš„å•è¯åšç»Ÿè®¡è®¡æ•°ï¼Œç„¶åå†æ‰“å°å‡ºé¢‘æ¬¡æœ€é«˜çš„5ä¸ªå•è¯ï¼Œæ±Ÿæ¹–äººç§°â€œWord Countâ€ã€‚

ä¹‹æ‰€ä»¥ä¼šé€‰æ‹©Word Countï¼Œä½œä¸ºæˆ‘ä»¬è¿ˆå…¥Sparké—¨æ§›çš„ç¬¬ä¸€ä¸ªé¡¹ç›®ï¼Œä¸»è¦æœ‰ä¸¤ä¸ªåŸå› ï¼Œä¸€æ˜¯Word Countåœºæ™¯æ¯”è¾ƒç®€å•ã€å®¹æ˜“ç†è§£ï¼›äºŒæ˜¯Word Countéº»é›€è™½å°ï¼Œä½†äº”è„ä¿±å…¨ï¼Œä¸€ä¸ªå°å°çš„Word Countï¼Œå°±èƒ½å¤Ÿç‰µå¼•å‡ºSparkè®¸å¤šçš„æ ¸å¿ƒåŸç†ï¼Œå¸®åŠ©æˆ‘ä»¬å¿«é€Ÿå…¥é—¨ã€‚
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ30ï¼‰</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/18/75/ec/c60b29f5.jpg" width="30px"><span>Alvin-L</span> ğŸ‘ï¼ˆ21ï¼‰ ğŸ’¬ï¼ˆ6ï¼‰<div>åœ¨Pythonä¸­è¿è¡Œ:
``` 
from pyspark import SparkContext

textFile = SparkContext().textFile(&quot;.&#47;wikiOfSpark.txt&quot;)
wordCount = (
    textFile.flatMap(lambda line: line.split(&quot; &quot;))
    .filter(lambda word: word != &quot;&quot;)
    .map(lambda word: (word, 1))
    .reduceByKey(lambda x, y: x + y)
    .sortBy(lambda x: x[1], False)
    .take(5)
)
print(wordCount)
#æ˜¾ç¤º: [(&#39;the&#39;, 67), (&#39;Spark&#39;, 63), (&#39;a&#39;, 54), (&#39;and&#39;, 51), (&#39;of&#39;, 50)]
``` 
</div>2021-09-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/81/63/2ceecb43.jpg" width="30px"><span>liugddx</span> ğŸ‘ï¼ˆ44ï¼‰ ğŸ’¬ï¼ˆ4ï¼‰<div>æˆ‘æ˜¯ä¸€ä¸ªå¤§æ•°æ®å°ç™½ï¼Œæˆ‘æƒ³å’¨è¯¢ä¸‹sparkå’Œhadoopåœ¨å¤§æ•°æ®ä½“ç³»ä¸‹çš„å…³ç³»ï¼Ÿ</div>2021-09-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/5e/b2/aceb3e41.jpg" width="30px"><span>Neo-dqy</span> ğŸ‘ï¼ˆ26ï¼‰ ğŸ’¬ï¼ˆ5ï¼‰<div>è€å¸ˆå¥½ï¼wordCounts.map{case (k, v) =&gt; (v, k)}.sortByKey(false).take(5)è¿™è¡Œä»£ç æˆ‘è¿˜å­˜åœ¨ç–‘é—®ï¼Œä¸ºä»€ä¹ˆè¿™é‡Œçš„mapå‡½æ•°ä½¿ç”¨äº†èŠ±æ‹¬å·{ }è€Œä¸æ˜¯ä¸Šé¢ä¸€äº›ç®—å­çš„( )ï¼ŒåŒæ—¶è¿™ä¸ªcaseåˆæ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿè¿™ä¸€è¡Œä»£ç éå¸¸åƒæˆ‘æ›¾ç»åœ¨Pythonä¸­ä½¿ç”¨å­—å…¸æ•°æ®ç»“æ„ï¼Œç„¶åæ ¹æ®å­—å…¸å€¼çš„å‡åºæ’åºã€‚æœ€åï¼Œè²Œä¼¼Scalaè¯­è¨€æœ¬èº«å°±å¯ä»¥å®ç°wordcountæ¡ˆä¾‹ï¼Œé‚£ä¹ˆå®ƒæœ¬èº«çš„å®ç°å’Œsparkå®ç°ç›¸æ¯”ï¼Œsparkæœ‰ä»€ä¹ˆä¼˜åŠ¿å‘¢ï¼Ÿ</div>2021-09-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/f7/36/ccf3b5d1.jpg" width="30px"><span>Vic</span> ğŸ‘ï¼ˆ8ï¼‰ ğŸ’¬ï¼ˆ9ï¼‰<div>é‡åˆ°è¿™ä¸ªé—®é¢˜
scala&gt; val rootPath: String = _
&lt;console&gt;:24: error: unbound placeholder parameter
       val rootPath: String = _
ç½‘ä¸Šæœä¸€ä¸‹ï¼Œè¯´è¿™æ˜¯æ±‡ç¼–é”™è¯¯ã€‚
è¦æŠŠval æ”¹æˆvar , ä½†ä¼šé‡åˆ°&quot;_&quot;è¿™defaultå€¼æ˜¯nullã€‚
org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:&#47;Users&#47;vic&#47;src&#47;data&#47;null&#47;wikiOfSpark.txt
è¿™ä¸€æ®µå°±å…ˆè·³è¿‡root_pathï¼Œç›´æ¥ç»™fileä¸€ä¸ªè·¯å¾„ï¼Œæ˜¯å¯ä»¥æˆåŠŸè¿è¡Œ&quot;word count&quot;,å¾—åˆ°å’Œè€å¸ˆä¸€æ ·çš„ç»“æœ:
[Stage 0:&gt;                                                          (0 + 2) &#47;                                                                               res0: Array[(Int, String)] = Array((67,the), (63,Spark), (54,a), (51,and), (50,of))</div>2021-09-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/5e/b2/aceb3e41.jpg" width="30px"><span>Neo-dqy</span> ğŸ‘ï¼ˆ6ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆæˆ‘å¯ä»¥å†é—®ä¸€ä¸‹ï¼Œå¦‚æœæˆ‘æ˜¯ç”¨IDEAåˆ›å»ºSparké¡¹ç›®ï¼Œæ˜¯ä¸æ˜¯åªè¦é…ç½®å¥½Scalaçš„SDKï¼Œç„¶ååœ¨pomæ–‡ä»¶ä¸­åŠ å…¥å¯¹åº”ç‰ˆæœ¬å·çš„sparkä¾èµ–ï¼Œå°±ä¼šè‡ªåŠ¨ä¸‹è½½sparkåŒ…äº†ï¼Ÿè¿™ä¸ªæ—¶å€™ä¸éœ€è¦å†å»å®˜ç½‘ä¸‹è½½sparkäº†å—ï¼ŒåŒæ—¶ä¹Ÿä¸å†éœ€è¦ä½¿ç”¨spark-shelläº†å—ï¼Ÿ</div>2021-09-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/27/bd/95/882bd4e0.jpg" width="30px"><span>Abigail</span> ğŸ‘ï¼ˆ6ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>å‰æ’å åº§ï¼ä¸‰å¹´å‰æ¥è§¦è¿‡ Spark ä»Šå¤©ä»å¤´å†å­¦ï¼</div>2021-09-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/31/85/5fd92ebe.jpg" width="30px"><span>æµ®ç”Ÿè‹¥æ¢¦</span> ğŸ‘ï¼ˆ4ï¼‰ ğŸ’¬ï¼ˆ4ï¼‰<div>Javaå®ç°ï¼š

SparkConf sparkConf = new SparkConf().setAppName(&quot;Test&quot;).setMaster(&quot;local[*]&quot;);
        JavaSparkContext JSC = new JavaSparkContext(sparkConf);

        &#47;&#47; è¯»å–æ–‡ä»¶å†…å®¹
        JavaRDD&lt;String&gt; lineRDD = JSC.textFile(&quot;wikiOfSpark.txt&quot;);
        &#47;&#47; ä»¥è¡Œä¸ºå•ä½åšåˆ†è¯
        JavaRDD&lt;String&gt; wordRDD = lineRDD.flatMap(new FlatMapFunction&lt;String, String&gt;() {
            @Override
            public Iterator&lt;String&gt; call(String s) throws Exception {
                return  Arrays.asList(s.split(&quot; &quot;)).iterator();
            }
        });
        JavaRDD&lt;String&gt; cleanWordRDD = wordRDD.filter(new Function&lt;String, Boolean&gt;() {
            @Override
            public Boolean call(String s) throws Exception {
                return !s.equals(&quot;&quot;);
            }
        });

        &#47;&#47; æŠŠRDDå…ƒç´ è½¬æ¢ä¸ºï¼ˆKeyï¼ŒValueï¼‰çš„å½¢å¼
        JavaPairRDD&lt;String, Integer&gt; kvRDD = cleanWordRDD.mapToPair(new PairFunction&lt;String, String, Integer&gt;() {
            @Override
            public Tuple2&lt;String, Integer&gt; call(String s) throws Exception {
                return new Tuple2&lt;String, Integer&gt;(s,1);
            }
        });
        &#47;&#47; æŒ‰ç…§å•è¯åšåˆ†ç»„è®¡æ•°
        JavaPairRDD&lt;String, Integer&gt; wordCounts = kvRDD.reduceByKey(new Function2&lt;Integer, Integer, Integer&gt;() {
            @Override
            public Integer call(Integer integer, Integer integer2) throws Exception {
                return integer+integer2;
            }
        });
        &#47;&#47; æ‰“å°è¯é¢‘æœ€é«˜çš„5ä¸ªè¯æ±‡(å…ˆå°†å…ƒç»„çš„key valueäº¤æ¢ä¸€ä¸‹é¡ºåºï¼Œç„¶ååœ¨è°ƒç”¨sortByKey())
        wordCounts.mapToPair((row)-&gt;  new Tuple2&lt;&gt;(row._2,row._1)).sortByKey(false).foreach(new VoidFunction&lt;Tuple2&lt;Integer, String&gt;&gt;() {
            @Override
            public void call(Tuple2&lt;Integer, String&gt; stringIntegerTuple2) throws Exception {
                System.out.println(stringIntegerTuple2._1 + &quot;:&quot; + stringIntegerTuple2._2);
            }
        });

        &#47;&#47;å…³é—­context
        JSC.close();</div>2021-12-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/3a/83/74e3fabd.jpg" width="30px"><span>ç«ç‚ç„±ç‡š</span> ğŸ‘ï¼ˆ3ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<div>Pythonç‰ˆä»£ç ä¸ºï¼š

file=&#39;~~~&#47;wikiOfSpark.txt&#39;
lineRDD=sc.textFile(file)
lineRDD.first() # ä¼šæ‰“å°å‡ºlineRDDçš„ç¬¬ä¸€è¡Œï¼š u&#39;Apache Spark&#39;ï¼Œå¦‚æœå‡ºé”™åˆ™ä¸æ‰“å°
wordRDD=lineRDD.flatMap(lambda line: line.split(&quot; &quot;))
cleanWordRDD=wordRDD.filter(lambda word: word!=&#39;&#39;)
kvRDD=cleanWordRDD.map(lambda word:(word,1))
wordCounts=kvRDD.reduceByKey(lambda x,y:x+y)
wordCounts.map(lambda (k,v):(v,k)).sortByKey(False).take(5)</div>2021-09-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f2/f5/b82f410d.jpg" width="30px"><span>Unknown element</span> ğŸ‘ï¼ˆ3ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>é—®ä¸‹æ‰§è¡Œ val lineRDD: RDD[String] = spark.sparkContext.textFile(file) æŠ¥é”™error: not found: value sparkæ˜¯æ€ä¹ˆå›äº‹ï¼Ÿ</div>2021-09-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/e6/94/98f30daf.jpg" width="30px"><span>å›½åº¦</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>2022å¹´2æœˆ5å·å­¦ä¹ æ‰“å¡è®°å½•
æœºå™¨ç¯å¢ƒï¼šROG14
æ“ä½œç³»ç»Ÿï¼šwin11 + wsl Ubuntu20.04
ç¯å¢ƒå˜é‡ï¼š
----------------------------

export SPARK_HOME=&#47;mnt&#47;c&#47;spark&#47;spark-2.4.8-bin-hadoop2.7
export JAVA_HOME=&#47;mnt&#47;c&#47;linux_environment&#47;jdk&#47;jdk1.8.0_321
export M2_HOME=&#47;mnt&#47;c&#47;linux_environment&#47;apache-maven-3.8.4
export SCALA_HOME=&#47;mnt&#47;c&#47;linux_environment&#47;scala3-3.1.1

export PATH=$SPARK_HOME&#47;bin:$SCALA_HOME&#47;bin:$M2_HOME&#47;bin:$JAVA_HOME&#47;bin:$PATH

---------------------------
å¸Œæœ›å¸®åŠ©å’Œæˆ‘ä¸€æ ·ä»é›¶å¼€å§‹ä¸€èµ·å­¦ä¹ çš„åŒå­¦èº²é¿ä¸€äº›å‘ï¼š

å‘1ï¼šjdkç‰ˆæœ¬ä¸å…¼å®¹ï¼š
ä¸€å¼€å§‹ä½¿ç”¨jdk17ç‰ˆæœ¬ï¼Œåœ¨å¯åŠ¨è¿‡ç¨‹ä¸­ä¸€ç›´æŠ¥é”™ï¼Œé™ä¸º1.8åå¯åŠ¨æˆåŠŸï¼›

å‘2ï¼šhadoopç‰ˆæœ¬é—®é¢˜ï¼š
hadoop3.2.1 é€æ­¥ä½¿ç”¨Datasetï¼ŒæŠ¥é”™ç±»å‹è½¬æ¢å¼‚å¸¸ï¼›
ç”±äºscalaç»éªŒä¸è¶³ï¼Œæš‚æ—¶æ— æ³•å¤§è§„æ¨¡æ”¹å†™è€å¸ˆçš„ä»£ç ï¼Œé™ä½ç‰ˆæœ¬ä¸ºspark2.4.8
ä¸‹è½½åœ°å€ï¼šhttps:&#47;&#47;dlcdn.apache.org&#47;spark&#47; å¯ä»¥é€‰æ‹©é€‚åˆçš„ç‰ˆæœ¬ä¸‹è½½

åŸç†æ€§çš„è¿˜æ²¡æœ‰ææ‡‚ï¼Œç›®å‰åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œè¯»æ‡‚ï¼Œç®€å•æ”¹å†™ä¸ºä¸»ï¼›

æ„Ÿè°¢å´ç£Šè€å¸ˆçš„è¯¾</div>2022-02-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/76/51/96291466.jpg" width="30px"><span>çŒ«å¤ªå¤ª</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è¯·é—®åœ¨æœ¬åœ°éƒ¨ç½²sparkç¯å¢ƒä¸éœ€è¦å…ˆå®‰è£…hadoopä¹ˆ</div>2021-11-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/46/4a/b0cd391e.jpg" width="30px"><span>å·´æ™®æ´›å¤«çš„</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<div>wordCounts.map{case (k, v) =&gt; (v, k)}.sortByKey(false) 
è¿™ä¸€æ­¥æ˜¯åšäº†ä»€ä¹ˆå‘¢ï¼Œæ²¡æœ‰è§è¿‡çš„è¯­æ³•</div>2021-09-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/17/ef/d0a1a069.jpg" width="30px"><span>Z</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>ä¸ºå•¥æˆ‘çš„ç»“æœæ˜¯å•ä¸ªå­—æ¯å‘¢ï¼Ÿ</div>2021-09-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/6f/4f/3cf1e9c4.jpg" width="30px"><span>é’±é¹ Allen</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>æ³¨æ„ç©ºæ ¼â€œ â€ï¼Œå’Œç©ºå­—ç¬¦ä¸²â€œâ€ï¼Œå‰è€…æœ‰ç©ºæ ¼ï¼Œåè€…æ²¡æœ‰

ä¹¦å†™çš„æ—¶å€™ï¼Œæ ¹æ®è‡ªå·±çš„æ–‡ä»¶æ‰€åœ¨ç›®å½•æ¥ï¼Œæ¯”å¦‚æˆ‘çš„æ˜¯ &#47;input&#47;wikiOfSpark.txt
ä¸è¦é—æ¼åç¼€åã€‚

å­¦ä¹ çš„è¿‡ç¨‹ï¼Œéœ€è¦ç»™è‡ªå·±ä¸€äº›è€å¿ƒå’Œé¼“åŠ±ï¼Œä¸€èµ·åŠ æ²¹æŠŠï¼</div>2021-09-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg" width="30px"><span>GACÂ·DU</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>Spark RDDç®—å­åˆ†ä¸ºTransformationç®—å­å’ŒActionç®—å­ï¼ŒTransformationç®—å­åŸºæœ¬ä¸Šéƒ½æ˜¯å»¶è¿Ÿè®¡ç®—ï¼Œéœ€è¦é€šè¿‡è°ƒç”¨Actionç®—å­è¿›è¡Œè§¦å‘ã€‚</div>2021-09-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/75/09/464ade1e.jpg" width="30px"><span>Luke Skywalker</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>è€å¸ˆï¼Œè¯·é—®æˆ‘è¿è¡Œspark-shellæ€»æ˜¯æŠ¥è¿™ä¸ªè­¦å‘Šæ˜¯ä»€ä¹ˆé—®é¢˜å‘¢ï¼Ÿæœäº†å¥½å¤šè§£å†³åŠæ³•ä¹Ÿæ²¡å»æ‰WARN ProcfsMetricsGetter: Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped</div>2021-10-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f2/f5/b82f410d.jpg" width="30px"><span>Unknown element</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ4ï¼‰<div>å…³äºå‰å‡ å¤©é—®çš„ æ‰§è¡Œ val lineRDD: RDD[String] = spark.sparkContext.textFile(file) æŠ¥é”™error: not found: value spark çš„é—®é¢˜ï¼Œæˆ‘ç¡®å®æ˜¯åœ¨spark-shellæ‰§è¡Œçš„ï¼Œåº”è¯¥ä¸éœ€è¦æ˜¾å¼åˆ›å»ºspark-sessionå§</div>2021-09-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/29/8d/2869a10b.jpg" width="30px"><span>zhihui</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>1.
val lineRDD: RDD[String] = spark.sparkContext.textFile(file)
ideaä¸­ï¼ŒsparkContextæŠ¥çº¢ï¼Œæç¤º â€œvalue sparkContext is not a member of sparkâ€ã€‚
ä½†æ˜¯å¤åˆ¶åˆ°spark-shellå´å¯ä»¥æ‰§è¡Œã€‚
æˆ‘æ˜¯å†™javaçš„ï¼Œæ€»è§‰çš„è¿™æ˜¯å¯¼åŒ…é—®é¢˜ï¼Œä½†åˆæ‰¾ä¸åˆ°è¿™ä¸ªåŒ…ã€‚ä¸€è„¸æ‡µã€‚
2. æˆ‘æŒ‰ç…§è€å¸ˆä»£ç å†™çš„ï¼Œä¸€æ‘¸ä¸€æ ·ã€‚æ‰§è¡Œç»“æœæ˜¯Array[(Int, String)] = Array((79,&quot;&quot;), (67,the), (63,Spark), (54,a), (51,and))</div>2021-09-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/49/bd/02b20ca1.jpg" width="30px"><span>undefined</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>WordCountä¸­æœ‰æ¶‰åŠä¸¤ç±»ç®—å­ï¼Œé¦–å…ˆæ˜¯mapã€filterã€flatMapã€ reduceByKeyã€sortByKeyã€sortByç­‰è½¬æ¢ç®—å­ï¼Œå±äºå»¶è¿Ÿæ‰§è¡Œï¼Œéœ€è¦å¦ä¸€ç§è¡ŒåŠ¨ç®—å­è¿›è¡Œè§¦å‘ï¼Œè¡ŒåŠ¨ç®—å­åŒ…æ‹¬ï¼štakeã€countã€foreachã€collectã€first; </div>2021-09-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/70/83/36ab65ec.jpg" width="30px"><span>keke</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<div>æŠ¥é”™â€œæ­¤æ—¶ä¸åº”æœ‰ \spark-3.1.2-bin-hadoop3\bin\..&#39;ã€‚â€æ˜¯å•¥é—®é¢˜å‘¢ï¼Ÿ</div>2021-09-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/da/c7/66f5fcea.jpg" width="30px"><span>å¤§å¿—</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>Win10ç³»ç»Ÿåˆè£…äº†Hadoopï¼Œå¹¶ä¸‹è½½äº†winutils.exeè¿™ä¸ªæ–‡ä»¶æ”¾åˆ°Hadoop binç›®å½•ä¸‹ï¼Œæ¢æˆäº†spark-2.4.6-bin-hadoop2.7è¿è¡Œspark-shellç»ˆäºä¸æŠ¥é”™äº†ã€‚Windowsä¸‹æ–‡ä»¶è·¯å¾„å†™æ³•val file: String = s&quot;file:&#47;&#47;&#47;D:&#47;wikiOfSpark.txt&quot;</div>2021-09-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/15/f7/aba61f1b.jpg" width="30px"><span>JavaXu</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>åœ¨macOSä¸Šï¼Œä¼¼ä¹é»˜è®¤å®‰è£…äº†scalaã€‚
æ€»ä¹‹æˆ‘å®‰è£…äº†sparkä¹‹åï¼Œspark-shellï¼Œç„¶åé”®å…¥ä»£ç ï¼Œå¯ä»¥æ‰§è¡Œå¹¶å¾—åˆ°ç»“æœã€‚

æˆ–è€…æ˜¯æˆ‘å®‰è£…çš„sparkåŒ…ï¼Œé‡Œé¢è‡ªå¸¦äº†scalaï¼Ÿ</div>2021-09-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/bb/a3/af469d27.jpg" width="30px"><span>Qilin Lou</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>æˆ‘å…¶å®æ¯”è¾ƒå–œæ¬¢ç”¨filterNotï¼Œè¿™æ ·é‡Œé¢çš„å‡½æ•°å°±ä¸ç”¨å–åï¼Œä¸è¿‡Sparké‡Œå±…ç„¶æ²¡æœ‰æä¾›</div>2021-09-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/bb/a3/af469d27.jpg" width="30px"><span>Qilin Lou</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<div>å¤§æ„äº†ï¼Œæ²¡æƒ³åˆ°ç”¨çš„æ˜¯ä¸€å°æ–°ç”µè„‘ï¼Œè¿˜å¾—å…ˆè£…Java Runtime</div>2021-09-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/15/39/095dc1c2.jpg" width="30px"><span>StÃ©phane èƒ¡</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ5ï¼‰<div>æ‚¨å¥½è€å¸ˆï¼Œè¯·é—®ä¸€ä¸‹å¤šä¹…ä¼šæ›´æ–°ä¸€è®²å‘¢ï¼Ÿ</div>2021-09-06</li><br/><li><img src="" width="30px"><span>æ¨å¸…</span> ğŸ‘ï¼ˆ8ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>è€å¸ˆï¼Œspark-3.2.1 é»˜è®¤ä»hdfsè¯»å–æ–‡ä»¶ï¼Œæ‰€ä»¥rootPathéœ€è¦åŠ ä¸Šåè®® file:&#47;&#47;.</div>2022-06-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/6f/87/669263b4.jpg" width="30px"><span>é™ˆé‡‘é‘«</span> ğŸ‘ï¼ˆ4ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>åˆå­¦äº†ä¸€éï¼Œwordcountä¸€å¥è¯å®ç°ï¼š
spark.sparkContext.textFile(file).flatMap(_.split(&quot; &quot;)).filter(!_.equals(&quot;&quot;)).map((_, 1)).reduceByKey(_ + _).map(t =&gt; (t._2, t._1)).sortByKey(false).take(5)</div>2022-04-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/c2/33/bd212cb1.jpg" width="30px"><span>ZJ</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>Java Version:

public static void main(String[] args) {
        System.setProperty(&quot;hadoop.home.dir&quot;, &quot;C:\\hadoop&quot;);
        SparkConf conf = new SparkConf().setAppName(&quot;spark-in-Java&quot;).setMaster(&quot;local[*]&quot;);
        JavaSparkContext sc = new JavaSparkContext(conf);
        JavaRDD&lt;String&gt; lineRdd = sc.textFile(&quot;src&#47;main&#47;resources&#47;sparkDev.txt&quot;);
        lineRdd.flatMap(k -&gt; Arrays.asList(k.split(&quot; &quot;)).iterator())
                .mapToPair(k -&gt; new Tuple2&lt;&gt;(k, 1))
                .reduceByKey((k1, k2) -&gt; k1 + k2)
                .mapToPair(tuple -&gt; new Tuple2&lt;&gt;(tuple._2, tuple._1))
                .sortByKey(false).take(10)
                .forEach(k -&gt; System.out.println(k._2 + &quot; has &quot; + k._1));

        sc.close();
    }</div>2023-11-25</li><br/><li><img src="" width="30px"><span>Geek_f09cec</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<div>å°†â€œ${è§£å‹ç›®å½•}&#47;binâ€é…ç½®åˆ° PATH ç¯å¢ƒå˜é‡ã€‚è¿™ä¸€æ­¥ä¸æ‡‚ï¼Œåœ¨å“ªå„¿é…ç½®ï¼Œæ€ä¹ˆé…ç½®å‘¢ï¼Ÿ</div>2022-10-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/ad/46/f3c56862.jpg" width="30px"><span>ğŸŒˆä½ æ˜¯äººé—´å››æœˆå¤©ğŸ’«</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<div>åƒæˆ‘è¿™ç§é›¶åŸºç¡€çš„ï¼Œçœ‹åˆ°å¾ˆæ‡µï¼Œç¬¬ä¸€ä¸ªdemoä»£ç æ˜¯sparkï¼Œè¿™ä¸ªå˜é‡æ€ä¹ˆæ¥çš„ï¼Ÿè¿™ä¸ªçœŸçš„é€‚åˆé›¶åŸºç¡€ï¼Ÿ</div>2022-07-04</li><br/>
</ul>