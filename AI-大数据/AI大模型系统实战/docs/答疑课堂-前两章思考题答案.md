你好，我是Tyler。

今天是中秋节，接下来我们也马上进入十一假期了。祝你双节快乐，也要给还在坚持学习的你，以及还在努力备稿的我点个赞，加加油。

现在，我们已经完成了前两章的学习，相信你已经对AI大模型系统是什么有了充分的认识，并且通过AIRC系统的学习，打下了扎实的AI系统基础。在更新过程中，我也看到了很多同学的留言评论。

这次加餐，我把前两章的思考题答案集中发布出来，希望能帮你答疑解惑。建议你先自己尝试思考、回答问题以后，再参考我提供的分析思路和问题解答，这样学习效果会更好。

# 第一章 热身篇

## [第1节课](https://time.geekbang.org/column/article/686399)

**思考题**

前一段时间，马斯克曾联合上千位人士签署联名公开信，“以担心人工智能系统将达到不可控程度，且会造成不可预知的风险为由，呼吁暂停训练更强大的人工智能6个月”。你认为他说得对吗？他所说的不可控的程度是什么？通向这种情况的技术路径和成本是什么？

**参考答案**

因为对错这个事情偏主观，这个见仁见智，留给大家探讨。所以这里重点分享一下我对“不可控场景”、“技术路径和成本”等问题的理解，希望对你有启发。

不可控场景：每个数字应用都是一个智能体，首先服务人类，之后随着时间拉长开始互相对话建立共识，最后架空人类。

技术路径和成本：需要对全社会的工作进行数字化改造，并对每个数字应用进行基于AI大模型的智能化改造，目前社会的算力和发电总量还不能支撑，不过长远看是有可能的。就算现在对大模型技术的使用都会有风控策略的参与，但是难免有“坏人”利用大模型技术搞“搏击俱乐部”。

其他：虽然管理机构正在努力制定法规，但目前，采取预防措施主要取决于公司自己。为此，Anthropic、谷歌、微软和OpenAI联合创建了前沿模型论坛，这是一个由行业主导的机构，专注于安全、谨慎的人工智能开发。

## [第2节课](https://time.geekbang.org/column/article/686408)

**思考题**

结合今天的内容，你觉得教会LLM制定计划，反思计划以及使用工具这几个方面，哪方面的训练难度更大？为什么？

**参考答案**

使用工具其实更难，因为涉及到了模型的微调训练，虽说是“微”调可是架不住模型大啊，微调的技术我们在后面也会学习。

## [第3节课](https://time.geekbang.org/column/article/686424)

**思考题**

通过 Flowise 搭建一个服务并接入你团队的 IM 系统，让他自动按产品经理的需求写临时SQL查询数据。提示：使用 SQLDatabaseChain。

**参考答案提示**

RTFM

## [第4节课](https://time.geekbang.org/column/article/686563)

**思考题**

你认为 Llama2 和 Qianwen 开源的目的是什么？

**参考答案**

通过技术影响力招募人才，同时通过开源的方式快速迭代，提高模型能力，进而推出更强的“商业化版本”大模型。

# 第二章 架构基础篇

## [第5节课](https://time.geekbang.org/column/article/688311)

**思考题**

1. 构建一个程序，支持根据文档中出现的内容，搜索本地所有文本文档，你觉得应该分为哪几个步骤？（提示：倒排索引）
2. 进一步如果需要根据你的使用习惯，让程序猜测你现在要使用哪个文件，把排名前十的文件推荐给你，要求将时延控制在100ms内，你会怎么做？（提示：多路召回）

**参考答案**

1.编写程序的参考思路。

- 通过系统API遍历所有本地文本文件，遍历过程中使用restfulAPI写入<文件地址，全文>到elasticsearch构建倒排索引。
- 通过restfulAPI调用elasticsearch接口查询倒排，获得文件地址列表。

2.编写程序的参考思路。

- 开发一个后台进程订阅系统日志，解析文件 **使用时段**，文件使用时系统 **活跃进程** 和当天是 **星期几**，分别对其建立倒排索引（使用时段/活跃进程/星期几三路召回）。
- 在用户打开程序时立刻获取当前所处时段，系统活跃进程和当天是 **星期几**，随后触发各个并行查询，对各个倒排索引查询，查询时每路只返回前N个文件即可；最后对多路返回结果根据文件最后修改时间进行归并排序。

这只是个答案方向，相信你一定有更好的方法，比如从来没使用过的文件该怎么办，可否加一个新文件召回？再加一个热点文件是不是也可以呢？

这里也要特别表扬一下@GAC·DU同学，他回答的时候还尝试写出了代码。

## [第6节课](https://time.geekbang.org/column/article/689434)

**思考题**

1. 独热编码是如何处理分类特征的？
2. 为什么需要进行正交的空间投影？
3. 解释一下在高维空间刻画特征距离的意义和作用。

**参考答案**

1. 对于有N个不同取值的分类特征，独热编码会创建一个长度为N的二进制向量，其中只有一个位置为1，表示该分类特征的取值。
2. 在没有得到特征之间的彼此关系时，让特征之间正交可以消除相互影响，避免模型得到错误信息。
3. 富含语义关系的空间中的各个特征更接近于它们在真实世界之间的关系，模型可以利用这些信息更好地完成任务。

## [第7节课](https://time.geekbang.org/column/article/689859)

**思考题**

1. 如果让你设计一个模型来完成文本摘要、文本问答、机器翻译等各类NLP任务，该为这个多任务学习算法准备什么样的训练数据？
2. 设计一个对话系统，让它在行为学派的学习框架下，自动优化自己的对话能力，给出大致流程即可。

**参考答案**

1.这里提两个思路，第一个思路是传统NLP多任务学习的思路。

为文本摘要、文本问答、机器翻译等各类NLP任务准备的训练数据可以包括以下内容。

- 文本摘要数据：可以使用新闻文章、学术论文、产品说明等文本数据来训练文本摘要模型。这些数据可以用来训练生成摘要的模型，也可以用来训练评估摘要质量的模型。
- 文本问答数据：可以使用问答数据集来训练文本问答模型。这些数据集通常包含问题和答案的对应关系。
- 机器翻译数据：可以使用平行语料库来训练机器翻译模型。平行语料库是指由同一段文本用不同语言表示的语料库。

具体来说，可以将上述数据集进行合并，以形成一个更大的多任务学习数据集。例如，可以将文本摘要数据和文本问答数据合并起来，以训练一个能够生成摘要和回答问题的模型。

第二个思路则是GPT3（大模型）的思路，也就是用所有互联网上的语料做一个大力出奇迹的多任务学习数据集 CommonCrawl。

2.RLHF（大模型）：其实这节课就是在为后面基于人类反馈的强化学习算法做铺垫，因为这是GPT3.5的核心贡献。

![](https://static001.geekbang.org/resource/image/47/03/472baf515425bcb68130e6yy7d53a603.jpg?wh=3900x2194)

## [第8节课](https://time.geekbang.org/column/article/690464)

**思考题**

1. 你认为ChatGPT中的主体、客体和环境数据分别是什么？如何基于用户、内容和场景的特征来优化ChatGPT的内容生成质量？答出大概思路即可。
2. 如何区分场景特征和用户特征，比如“用户最近30分钟内，观看的运动类视频数量”是哪类特征？
3. 如果让你选择三个算法，放入知识图谱的三个步骤中，你会选哪三个？

**参考答案**

1. 其实和搜索引擎一模一样：用户、文档和应用环境，这也是 NewBing 打响第一枪的原因。
2. “用户最近30分钟的商品点击数量”是场景特征。场景特征的变化频率比较高，所以模型的敏感性很大一部分来自于场景特征。
3. 知识图谱不是一个具体算法，而是知识抽取，知识融合和知识加工这一整套构图思路。

## [第9节课](https://time.geekbang.org/column/article/691684)

**思考题**

在线增量模型的训练为什么要用三级火箭，直接用增量模型不可以吗？

**参考答案**

不可以，因为在线的增量数据由于需要保证实时性，没有做离线反作弊，可能存在作弊数据混入其中。所以要每天替换二级火箭。

## [第10节课](https://time.geekbang.org/column/article/692789)

**思考题**

1.想一想，内容分发系统和现在的生成式 AI 系统的共性是什么？

2.我们知道 Bard 是支持给出多个草稿并展示最优结果的，如果让你为 ChatGPT 对同一问题生成的几个不同答案排序，你会怎么做？

**参考答案**

1. 内容分发系统和内容生成系统本质上都是在为用户交付内容。
2. 这个任务本质上是在做模型生成的诸多内容和用户提问之间的相关性排序，其实完全可以用 AIRC 的方式来做，目前的大多工业级大模型系统也确实是这么做的。

以上就是这次加餐的全部内容。欢迎你继续在留言区发表自己的见解或者提出疑问，积极参与互动有助于你发现自己的疑惑，沉淀自己的想法。