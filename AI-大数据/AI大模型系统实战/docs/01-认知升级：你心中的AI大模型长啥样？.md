你好，我是Tyler。从今天起，我们正式开始学习“AI大模型架构”。

最近，各大媒体热搜上都在讨论AI大模型，国内外的各个大厂也都在相关领域开疆拓土。“AI大模型将成为新一代应用平台”的观点，似乎已经成为各大公司的共识。

![图片](https://static001.geekbang.org/resource/image/b0/9f/b031006f5f880356af9cee14ff37b99f.png?wh=2560x485)

相信你学习这门课程的目的，也是为了在AI大模型的技术浪潮下，尽早熟悉甚至驾驭这个新的基础设施，走在技术的前沿。不过在开始之前，我想先问你一个问题：学习一个全新领域的时候，你一般第一件事会做什么？

我的习惯是follow数学上的方法，先搞清楚这个领域的“公理”有哪些，因为它是该领域的 **共识**，如果不能在一开始，就和领域中的大多数人建立共识，后续所有的认识都会出现偏差。所以在正式开始学习之前，我们有必要花点时间了解这些“公理”以及它们背后的历史，让自己的认知更接近该领域的专家，这样后面的学习才能事半功倍。

今天这节课里，我们主要会讨论后面这几个问题。

- AI大模型是什么？
- AI大模型能做什么？
- 为什么说AI大模型是新一代应用平台？

理解了这几个问题，你才能真正进入到属于技术人的AI大模型世界。

## AI大模型是什么？

我相信在过去的一年里，你经常听到各种名词，比如大模型、AI模型、生成式AI、AIGC、生成式AI大模型等等。好像机器突然被魔法棒点中，瞬间觉醒了智能，现在已经学会了诗歌和绘画，接下来就要开始统治和奴役人类。

实际上，在技术术语上并没有“大模型”这个说法。不过，由于它被广泛使用，大模型这个名字已经深入人心。虽然我不必刻意纠正，但作为一个严谨的技术专栏，我还是想指出一点：在学术分类上，我们无法找到“大模型”这个分类。

学术上更多更常用的术语是基础模型（foundation model或base model），在2021年8月，李飞飞和其他一百多位学者，联合发布了一份超过200页的研究报告 [On the Opportunities and Risks of Foundation Models](https://arxiv.org/abs/2108.07258)。在这篇文章中，AI专家们介绍了目前该类模型所面临的机遇和挑战，并一致将这些大模型称为基础模型（Foundation Models），所以通用的标准术语是 **基础模型** 而非大模型。

维基百科对基础模型的定义是这样的，基础模型是一种大型机器学习模型，通常在大量数据上进行大规模训练（通过自监督学习或半监督学习），以使它可以适应各类下游任务。

因此，它需要兼顾 **参数量大**（大型模型），训练 **数据量大**（大量数据大规模训练）和 **迁移学习** 能力强（适应多种下游任务）几点才能够叫做基础模型，而不只是参数量大，就能够叫做基础模型，我们在甄别时需要特别注意。

![](https://static001.geekbang.org/resource/image/4d/aa/4d603a69a5f425d12d3e41228eaf5daa.jpg?wh=3800x2138)

另一个重要的定义就是AIGC，目前工业界普遍将AIGC（Artificial Intelligence Generated Content）称为生成式人工智能。

你应该也已经观察到了，目前全球热门的AIGC应用（如ChatGPT，Midjourney）几乎都是通过“大模型”的上下文学习、涌现和思维链等能力支撑实现的，所以大众和媒体往往会把这种“智能”和“大模型”技术建立一一映射的关系。因此讨论AIGC应用时，各类媒体往往会在“生成式人工智能”后面加上“大模型”，这也就是我们常听到的“生成式人工智能大模型”。

我简单解释一下涌现和思维链。所谓“涌现”，指的是在大模型领域，当模型突破某个规模时，性能显著提升，表现出让人惊艳、意想不到的能力。所谓思维链（Chain-of-thought，CoT）指的是通过一系列有逻辑关系的思考步骤，形成一个完整的思考，进而得出答案的过程。

![](https://static001.geekbang.org/resource/image/f9/47/f9049aa792ba34579d607c119d9afe47.jpg?wh=3800x2138)

看到这里你可能仍然有些困惑，叫大模型不够专业，叫生成式人工智能大模型也怪怪的，那“大模型”究竟是什么呢？别着急，想要理解它的本质，我们有必要先梳理一下“大模型”从何而来。

### 大模型技术从何而来？

在过去的二十多年里，随着AI系统的发展，模型一直在不断增大，所以“大模型”实际上是一个相对的概念。

刚刚提到的基础模型不是凭空出现的，故事还要从AI模型为什么热衷于追求“大”开始说起。在搜索、广告和推荐等内容分发领域兴起后，我们开始能够收集到 **大规模的有监督反馈数据**，例如点击、点赞和购买等行为数据。市场也渐渐察觉，投入在人工智能技术上的投资，可以在商业上获得巨大的回报。因此，为了更好地记忆和监督海量数据中的信息，模型的参数规模开始急剧增长，模型变得越来越大。

![](https://static001.geekbang.org/resource/image/91/97/91a99e6a643e94c0e067b6d460309d97.jpg?wh=3405x660)

随后，随着DeepMind AlphaGo的走红，AI领域进入了全面爆发的阶段。重要的AI应用，如AlphaZero和无人驾驶，能够以较低成本自动生成训练数据，训练数据的规模也发生了质的飞跃。在更大规模的训练数据基础上，以计算能力和存储成本的降低为有利条件，模型的参数规模再次急剧增加，模型变得更大了。

![](https://static001.geekbang.org/resource/image/26/45/262a4d99b784a3f97611d9e4a821ac45.jpg?wh=3800x1616)

目前，以OpenAI GPT 3.0为里程碑的AI大模型正在使用全网的数据进行无监督训练，我们进入了一切皆为训练数据的时代。这使得模型可以获得 **几乎无限的训练数据**。为了对如此规模的数据进行建模，模型参数的规模越大越好，因此模型变得越来越大了。

![](https://static001.geekbang.org/resource/image/85/d0/85249a16f7b8fd5cc1bfb1d579eba7d0.jpg?wh=3800x2138)

你可能已经注意到了，大模型的“大”是一个相对概念，是一个持续的过程。更大规模的训练数据需要模型具备更强的记忆、理解和表达能力。而为了拥有更强的记忆、理解和表达能力，模型则需要更大的参数量，也就是更大的模型。

我来做个“中译中”你会更好理解：你可以把模型当成一个，在学习新知识方面如饥似渴的孩子，随着年龄的增长，他的大脑在不断发育，脑容量变得越来越大，为了让他的智力不断成长，你需要为他提供更好的老师，供养更多更复杂的知识资料。

所以模型为什么越来越“大”就很容易理解了： **内因是身体的发育，也就是存储和算力的发展。外因是人类在知识量和共享度上的发展，互联网技术使得人类个体公开可查的学习资料，在本世纪内快速膨胀。**

### 大模型技术因何而火？

不过生成式AI大模型的兴起不仅仅是由于模型规模变大，而是多个因素相互作用形成的。

首先，在近年的技术发展中，大型语言模型，特别是以GPT 3.0为代表的大模型，展现出了出色的 **涌现、思维链和上下文学习的能力**，不再停留在“人工智障”的阶段，极大地提升了自然语言理解和生成的能力，然而，这只是其中的一个必要条件。

第二个必要条件是 **跨模态建模能力的发展。** 这让同一个模型能像人类一样同时理解和处理Excel、PPT、PDF、图像和视频等多种形式的数据。加持了这样的能力，算法生成的信息量从此发生质变，生成式人工智能发挥作用的舞台就更多了。

第三个必要条件是 **生成式模型的交互方式**。生成式AI产品巧妙地利用了人类的惰性，通过新的交互方式，大大提高了产品的渗透率。这使得人们不断地使用ChatGPT，并逐渐产生了依赖。这也成为了当前AI大模型产业，迅速发展的关键点。

然而，所有这些前提条件的实现，都依赖于 **存储和计算能力的持续发展**，“孩子”身体的发育，使模型能够容纳和记忆更大规模的数据。不过，以上只是生成式AI大模型兴起的一些必要条件，但其全面走红还涉及到资本和产业发展的需求等多个因素的综合效果。通过后续的学习，你会对“AI大模型是什么”这个问题有更深入的理解。

## AI大模型能做什么？

由于大语言模型在训练数据上的多样性和数量的保证，以及大规模参数所造成的涌现和思维链能力，让它可以很好地应对如语言翻译、创意策划、文章创作和代码编写这类任务。

![](https://static001.geekbang.org/resource/image/03/be/038fab4bed946fced9cf9116505e19be.jpg?wh=1788x2024)

![](https://static001.geekbang.org/resource/image/db/77/db909100810cf9efd3a9ff98bdf7ab77.jpg?wh=2677x2194)

前面说了大模型好的方面，但是大模型技术本身也存在一些局限。比如训练数据存在时效性的问题，比方说GPT3.5只使用了2021年9月之前的数据进行训练（又如最新的GPT-4 Turbo 使用了 2023年4月之前的训练数据），无法评判那之后的事实，同时大模型在因果推断方面也存在一些问题。

大模型还会 **出现“幻觉”**，会一本正经地给你讲“林黛玉倒拔垂杨柳”的故事，当然这些既是问题，也是我们AI大模型架构的发展机遇。

至于前面说的种种局限，工业级的大模型系统是如何优雅应对的呢？这里我先卖个关子，等到后面实战架构篇我们再详细讨论。但你现在不妨先假想一下： **如果你是ChatGPT的架构师，你会如何设计基于大模型技术的架构呢？**

其实一个优秀的架构师和顶级的厨师一样，在获得一个食材之后，要尽可能保留它最大的价值和优点，并最小化甚至消除它的缺点所带来的影响。对于ChatGPT的“厨师”来说，AI大模型是一个优秀的食材，它本身具备很强的理解、摘要总结和多轮对话的能力，但是，正如前面提到的，它在数据时效性，输入长度限制和内容可信性方面的缺点也很明显。

那么我们应该如何处置这道食材呢？我们已经看到OpenAI架构师给出的方式，ChatGPT开放了联网和插件接口功能，已有的互联网应用可以通过OpenAI的API，将自己的应用放入ChatGPT的应用中心，这是平台产品的一个最鲜明的特征。

![](https://static001.geekbang.org/resource/image/54/38/540612bf440e28041178091985014638.jpg?wh=2334x1671)

利用大模型平台先天具备的优异语言能力、意图识别能力和指令翻译能力，将互联网领域的各个能力接入其中，由AI大模型作为大脑，帮助各个应用互相对话，产生化学反应，这就是GPT架构师提供的“答题思路”。

可以看出，这个平台和之前我们熟悉的平台都不一样。你不是多了一个小助手，而是接近“全能”的专业大管家。

- 作为助理，他能帮你提前安排日程，完成差旅机票酒店的预定，或者根据会议相关的资料和人数帮你预定会议室，提前发放会议议程。
- 作为秘书：他能根据你的个人习惯，每天查询你关注领域的最新消息，为你整理专属版“参考消息”。或者每个周末整理你一周交给他的工作任务，为你生成工作周报。
- 作为“伴侣”，他甚至可以接入语音合成和语音识别的插件，以及数字人的插件，像一个真正的朋友一样和你进行视频对话。

![](https://static001.geekbang.org/resource/image/0d/03/0d6b9e0b0ce41779fa2077265eea7003.jpg?wh=1777x1841)

这个能力将使ChatGPT成为当之无愧的 **新一代生态平台**。毫无疑问大模型系统平台将成为强大的生产工具，擅长使用大模型平台的用户将极大地提升个人生产效率，和其他人拉开差距。用户和开发者的全部数据会汇集于此，形成强大的马太效应。

因此，国内互联网公司也在加紧构建属于自己的AI大模型系统平台和相应的应用生态。我们身处其中，也要做好长期投入的准备，一起迎接下一轮行业洗牌时刻的到来，大潮过后方知谁是英雄。下一节课中我就会带你直观地感受大模型技术发展的无限前景，敬请期待。

## 小结

这节课，我带你熟悉了AI大模型领域的一些“公理”和发展历史。学完今天的内容，你已经和领域中的专业人员，对 “AI大模型技术是什么”这件事，达成了共识。

有了这节课作为基础，你在后面的学习不会出现大的偏差。因为你已经拥有该领域的“试金石”，可以用它对领域中的内容优劣进行评判。随着时间的流逝，这节课的内容将会对你产生最深远而重要的影响。

学到这里，相信你已经深刻体会到了这个新一代的生态平台的价值，无论你是互联网应用的开发者，还是平台型应用的建设者，此刻都是参与到这次新一轮技术革命中的最佳时间，希望你我在若干年后回看这个时代时，可以满意地面对自己的成长，而不是后悔再次因畏难或对新鲜事物的排斥和潜在机会擦肩而过。

## 思考题

前一段时间，马斯克曾联合上千位人士签署联名公开信，“以担心人工智能系统将达到不可控程度，且会造成不可预知的风险为由，呼吁暂停训练更强大的人工智能6个月”。你认为他说得对吗？他所说的不可控的程度是什么？通向这种情况的技术路径和成本是什么？

恭喜你完成我们第 1 次打卡学习，期待你在留言区和我交流互动。如果今天的课程对你有帮助，欢迎你把它转发出去！我们下节课见！