你好，我是Tyler。

前几节课，我们学习了提示语工程和模型工程。你掌握得如何？今天，我将带你整体回顾架构实战篇所学内容，并且为你揭开AI大模型系统的面纱。除了回顾总结，我还会带你从真实应用的角度了解如何构建一个AIGC系统。在这节课中，我将更多地结合我的亲身经验，为你提供一些在其他地方无法获得的具体例子。

我们首先来探讨离线系统，因为通常在开发一个系统时，都会按照先离线，后在线的顺序进行。

## 模型工程

设计离线系统的第一步，就是清晰梳理我们系统的数据流程。下面我将带你一步步梳理AIGC系统中模型训练的数据链路。

![](https://static001.geekbang.org/resource/image/e2/aa/e2a0076eeb72d029b9a55a26cfef81aa.jpg?wh=4000x1532)

首先是模型训练的数据流程。

在大语言模型对话应用中，我们可以收集到丰富的对话信息，这是宝贵的指令微调语料，AI系统会将这些对话内容，上报并存储到服务端，来获取足够多的对话数据，供给模型训练使用。

这里需要注意的是，你要重点甄别对抗样本，避免它成为攻击你大语言模型的武器，我们不能假设所有的日志反馈都是安全的，必须进行后续的风控处理，使用专门的分类模型，来识别对抗样本，并将它们从训练数据中剔除。当然这主要是离线风控策略的流程，在线的风控策略关注的主要还是模型越狱和内容安全的风险。

具体而言，你可以用OpenAI的母公司微软开源的 [PromptBench](https://github.com/microsoft/promptbench.git) 来实现你的风控策略，虽然现在各大厂使用的方法更健全，但是这个项目已经是一个很好的开源替代选择，麻雀虽小，五脏俱全。

![](https://static001.geekbang.org/resource/image/8e/d9/8e29b9894616544776b971db1a4006d9.jpg?wh=4000x2181)

经过风控处理后，你将获得相对真实的用户反馈。随后，我们就可以开始用这些反馈来制备模型训练所要使用的样本了。

### 样本制备

与AIRC的模型工程部分相比，大语言模型的样本制备过程中多了一些步骤，那就是人工标注和数据增强。

人工标注的工作，在大语言模型的开发中是非常重要的，这是领跑者保持优势的护城河。这里涉及到的人工标注数据分为两种，一种是标注人员为特定问题提供的正确答案，另一种则是标注者对多个问题答案进行排序的结果。

在 [WebGPT 那节课](https://time.geekbang.org/column/article/701454)，我们已经学习了如何使用排序数据来训练模型，以及OpenAI是如何通过使用RLHF来提高标注效率。

此外，我们还可以通过算法分析，对用户回答内容进行评价，以区分高质量和低质量的回答，基于用户在线对话内容不断生成对比语料。

数据增强的过程主要涉及到 [第25节课](https://time.geekbang.org/column/article/713908) 中学到的self-instruct工作的各种变种，比如 alpaca。我们可以利用这些方法来发挥中小型公司的“后发优势”，缩小自家大语言模型和其他先进模型之间的差距。

![](https://static001.geekbang.org/resource/image/7f/1f/7f340dd4a486fe8e7f0f91eba099b01f.png?wh=4000x2128)

### 模型制备

在完成了样本制备之后，就到了模型训练的环节，通用的训练方法我们已经 [在第九节课](https://time.geekbang.org/column/article/691684*) 详细讲解过。所以在这里，我将重点讨论大语言模型的训练技巧。

在这一环节，我们需要考虑使用一些微调提效的方法，比如使用我们之前学习的 [LoRA](https://github.com/tloen/alpaca-lora)，去降低你的算力开销，提高微调效率。

在得到模型文件之后，接下来就是模型的离线验证了，这是模型上线前的最后一步。通常情况下，我们会使用早期通过人工标注获得的种子数据，以及后期在线筛选并积累的生产数据作为准入样本数据集。

这个准入样本数据集包括了常识性的样本、逻辑推理样本、对抗样本和内容安全风险等样本。我们通过这个数据集，对待发布的模型进行准入测试，以评估模型是否达到准入标准。只有在满足要求时，模型才会上线使用。

大语言模型的发布过程区别于传统AI系统，因为大模型的参数量巨大，单次训练成本过高，同时也面临着更大的在线风险和内容合规责任。因此，很难采用基于流的在线实时的训练方式。

当然，为了解决这个问题，我们可以使用现在广泛应用的MoE（Mixture of Experts）技术，有效降低参数量。这样，在某些小型的专家模型上，我们仍然可以在局部使用 [三级火箭](https://time.geekbang.org/column/article/691684) 的方式来确保更新的实时性。

至此，我们已经完成了在线模型制备的全部流程。你可以结合后面的流程图再看一下。

![](https://static001.geekbang.org/resource/image/72/38/7245788a3cb1680033ffe4946c37c438.jpg?wh=4000x2250)

## 提示语引擎

接下来是提示语引擎外部记忆的构建，提示语引擎所提供的外部记忆包含以下几个部分。

1. 知识：它对应的是传统 AIRC 所能提供的知识。
2. 工具：即模型所能使用的工具，类似OpenAI的function。
3. 示例：提示语工程中 ICL 所用到的 few-shot 提示示例。
4. 会话：用于保存对话中 prompt 的上下文（如果是智能体，则是它的记忆信息）。

我们在知识的存储上，用到的能力和 AIRC 并无二致，但是在后面几类记忆的存储上我们要多下一些功夫。

首先是 **工具的存储和使用**，工具的存储中，包含了两部分的能力。我们分别来看一下。

第一部分与OpenAI的function功能类似。它为生态用户提供了一种方法，使他们能够将其能力接入到我们的平台中，以便大语言模型能够准确调用这些能力，通常的实现方法类似于传统微服务的注册中心。

第二部分是基于向量表示的API Bank，它类似于OpenAI提供的插件功能。一旦大语言模型根据语义相似性查找到了相关的插件向量，识别到用户的聊天意图与这些插件相关，则会组合使用这些插件来满足用户的需求。

接下来是 **示例的存储**，我们知道示例是 ICL 的最本质特征，它可以帮助大模型通过 few-shot 理解下游任务场景是 AIGC 最重要的优势之一。

所以我们需要有一个高质量的示例库，这个示例库一般来说是分领域设计的，每个领域示例库中会首先由领域专家来进行设计，生成一些针对领域特定问题的种子示例。随后，用这些种子示例，配合大语言模型，从无标签的领域数据中解析出更多的高质量示例，补充到领域示例库中。

我举个例子来帮你理解，比如在美妆领域，我们可以请一些专业美妆博主来生成一些标准问答作为示例。随后，我们为大语言模型提供海量的美妆文章，并且附上专业美妆博主给出的问答示例，则可以生成新的问答示例，这些新生成的示例在通过人工筛选后，就能反哺到示例库中。

这意味着，如果用户在线提出与美妆相关的问题，你可以将她的问题和若干个回答示例提供给大语言模型，帮助它更好地理解和回答用户的问题。

最后，是会话信息的存储，这部分数据在使用的过程中要特别考虑提示语压缩技术，因为往往用户的对话内容会很长，尤其是多智能体的场景，一些经典提示语压缩的思想你可以回顾具身智能课程里 [记忆流](https://time.geekbang.org/column/article/707992) 的部分。

至于存储引擎的构建，你可以采用前面提示语工程课程中学习过的阿里巴巴工业级开源项目 [HA3](https://github.com/alibaba/havenask/tree/main) 来完成构建。

我们再来看一下提示语引擎如何针对用户的问题，对智能体的外部记忆进行排序，再把排名靠前的内容返回给大语言模型的。

在 [第18节课](https://time.geekbang.org/column/article/702474)，我解释了为什么不能直接将这个过程整合到AIRC系统中。因为AIRC面向的客户是“人”，所以它检索出的内容更符合人的需求。但在大语言模型系统中，提示语工程面向的客户是LLM，因此我们必须考虑LLM的需求。所以，这个 **优中选优** 的过程是为了在AIRC的结果中选择更符合LLM口味的示例。

这个过程与AIRC系统的主要区别在于增加了 Selecting 和 Ordering 以及 Formatting 的工作，具体的方法包括让模型吃奶粉、吃食物、吃自己和外部觅食几类方法。因此，在前面的课程里，我们使用了六节课的篇幅来介绍这部分的工作，只从篇幅上，你也应该能感受到这部分有多重要。

相信在深入学习之后，你已经很清楚这部分工作的定位了，你可以根据后面这张图，来理解它们在整个系统架构中的位置和作用。

![](https://static001.geekbang.org/resource/image/22/2f/2287c7d5e25222da2124cba5bd5e752f.jpg?wh=4000x2029)

## 总结

好的，这节课就到这里，现在我们来做个总结吧。

因为这节课本身就是总结和串联整个章节的重点内容。所以这次的总结我想从更宏观的视角和你聊一聊我的思路。

这门课我一直在用自顶向下的思路为你讲解，这是因为AI大模型系统的内容涉及的理论和技术很多，只有通过这种方式，才能让你找准航向，不然要么是闭门造车，要么就会盲人摸象。

从这个思路出发，时至今日，你回头对比AIRC系统和AIGC系统，就会再次感受到它们血脉相通，又各有侧重。

在学习AIGC的策略建模（ [第18节课](https://time.geekbang.org/column/article/702474)）时我曾说过，我们只要仔细思考就会发现，ChatGPT 所追求的业务目标和搜索引擎是最像的。它们都需要以最高的效率找到用户期望得到的“正确答案”。搜索引擎将重点放在呈现已有内容，而AIGC系统的重点则是整合知识生成内容，包括生成计划、提供外部记忆、内容生成和验证。此外，AIGC系统还需要承担更多的合规责任。

在架构基础篇，我们学习了人工智能系统中最关键的几个内容，包括特征处理、模型工程、数据算法、离线系统和在线系统。这些构成了 AI 系统的基础架构，为我们 AIGC 系统的百丈高楼打好了地基。

至于AIGC的特殊能力，正是我们这一章重点讨论过的提示语工程技术和模型训练方法，希望你能够深入理解和掌握这部分的知识，学完这些内容，你已经掌握了 AI 大模型系统架构该如何实现。

## 思考题

课程已接近尾声，我希望你能够独立思考，概括工业级AI大模型系统与原型验证工具（如Langchain和AutoGPT）之间的区别。并且总结出你心中的大模型技术和AI大模型系统是什么。

恭喜你完成我们第 28 次打卡学习，期待你在留言区和我交流互动。如果你觉得有收获，也欢迎你分享给你身边的朋友，邀 TA 一起讨论。