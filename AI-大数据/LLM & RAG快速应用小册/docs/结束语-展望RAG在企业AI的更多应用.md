你好，我是王吕。

这是本专栏的最后一节课，我想和你聊聊企业在应用 RAG 和 LLM 时的一些问题和思考。

企业拥有自己的数据和知识，如何把这些知识的价值最大化，是企业的目标之一。现在 LLM 拥有使用自然语言和数据对话的能力，从理解用户意图到找到用户所需资料，是 RAG 的主要技能。目前使用 AI 整合企业数据和知识主要有 Fine-tuning 和 RAG 两种思路，也可以两者结合。在之前的课程中，我们简单对比过两者的特性，这里我想再和你深入地讨论一下这两种方案，给你在技术选型的时候做一些参考。

## Fine-tuning vs RAG

Fine-tuning 作为一种直接针对预训练语言模型进行额外训练的方法，能够让模型更好地适应特定领域或任务。这种方法的核心优势在于， **能够显著提升模型在目标任务上的表现**。通过使用领域特定的数据集，Fine-tuning 可以让模型学习到行业术语、专业知识结构和特定的表达方式。这使得Fine-tuned模型在处理专业领域的问题时，能够提供更加准确、相关的回答。例如，在极客时间，我们把作者的实战经验从文章中提取出来，然后基于开源模型进行微调，让 LLM 可以输出生产环境直接可用的技术方案，而不是一些通用解决方案（敬请期待）。

此外，Fine-tuning 后的模型响应速度快，无需在运行时检索外部知识库，这使得它特别适合需要实时响应的场景，比如在线客户服务或实时决策支持系统。举个例子，在我们的用户对话功能中，有时候人工客服可能不在线，用户提问如果能快速得到响应，及时解答用户问题，可以大大提高用户的信任感。

当然，使用 Fine-tuning 也要付出一些额外的成本。它需要大量的标注数据和较高的计算资源，这对许多企业来说可能是一个门槛。而且，一旦模型经过 Fine-tuning，要更新其知识就需要重新训练，如果是经常变化的知识，可能成本就非常高了。

相比之下，RAG 技术提供了一种更为灵活的解决方案，可以更好地处理 “经常变化” 的知识。RAG 通过将大语言模型与外部知识库结合，在生成回答时实时检索相关信息。这种方法非常灵活，由于是自己设计的知识库，可以做各种优化操作，保证把最准确的知识呈现给用户。企业可以随时更新知识库中的信息。

RAG 的另一个重要优势是其 **可解释性**。由于每个回答都可以追溯到具体的知识来源，这大大增强了AI系统的可信度和透明度。在需要严格监管或高度问责的行业，如金融服务或政府部门，这一特性尤为重要。然而，RAG也有其局限性。由于需要实时检索知识库，RAG系统的响应速度可能不如 Fine-tuned 模型快。此外，RAG的效果高度依赖于 **知识库的质量** 和 **检索算法的效率**，这要求我们投入大量资源来维护和优化知识库。

在实际应用中，我们可以将 Fine-tuning 和 RAG 结合使用，以充分发挥两种方法的优势。这种混合方法可以应对更复杂的场景和挑战。例如，要做一个极客时间客服系统，我们可以使用 Fine-tuned 模型来处理常见的、结构化的查询，比如一些通识或者固定不变的知识，保证快速、准确的响应。同时，对于涉及最新产品信息或政策变更的问题，系统可以切换到 RAG 模式，利用实时更新的知识库来提供最新、最相关的信息。在产品研发过程中，可以使用企业内固定的技术相关文档进行 Fine-tuning，让 LLM 回答的内容都是符合企业开发技术范围，再配合上 RAG 把一些外部的技术文档作为补充知识库，两者结合，在内部就可以很好地辅助产研人员工作。

你可以把 LLM 技术想象成编程语言，Fine-tuning 就是语言内置标准库，RAG 就相当于引用外部依赖库，两者结合，实现各种类型的业务目标。

另外，我还想和你讨论下 RAG 的更多可能性。

## RAG 的未来方向

**第一个方向是动态知识图谱的集成。** 传统的RAG系统通常使用静态的知识库，而动态知识图谱将为RAG带来更智能、更灵活的知识管理能力。这种系统不仅能够实时更新知识，还能自动建立知识之间的关联。

在前面课程中提到的 Mem0 记忆框架，最近更新了一个特性，就是 graph memory。它把用户的记忆拆分成记忆节点和关系，通过使用图数据库，保存下这些关系和节点，在使用记忆的时候，会通过图检索技术找到记忆之间的关联，从而找到关键的记忆点，然后结合当时的详细记忆，最终给出回答。这种技术可以让用户在海量记忆中去查询问题的答案，相比传统的 RAG，极大程度地提高了记忆的相关性和连续性。

还有就是最近大火的 [GraphRAG](https://microsoft.github.io/graphrag/)。GraphRAG 本身是一个理论，这个项目是由微软开源的，它包括从原始文本中提取知识图，构建社区层次结构，为这些社区生成摘要，然后在执行基于 RAG 的任务时利用这些结构等等功能。像极客时间这种，拥有大量的知识课程就非常适用，我们就是基于这个项目提取不同课程文章之间的关联关系，用在理解知识库深层知识之间的关联上。总之，这个方向对拥有大量知识的企业都值得一试。

**第二个方向是个性化** **RAG** **。** 未来的RAG系统将能够根据用户的背景、偏好和使用历史来动态调整其检索和生成策略。

例如，在极客时间，一个个性化的 RAG 系统可以根据用户的知识水平、学习风格和关注点来推荐内容和解答用户问题。这种个性化不仅限于内容的选择，还包括表达方式的调整，使得AI助手能够以最适合每个用户的方式进行交流，可以根据不同用户的喜好风格，调整 AI 小助手的说话方式。这将大大提高用户体验，使AI系统更加贴近人类的交互需求，带给用户更多的亲切感。

**第三个方向是多模态 RAG。** 上述的讨论都建立在文本模型上，如果再加上视觉模型，让大模型能像人眼一样观察世界，再把看到的东西内化到知识库中，这将会大大拓宽 RAG 的应用范围，让更多的业务能够用上大模型技术。

比如，在医疗领域，使用多模态 RAG 系统可能会同时分析病人的症状描述（文本）、X光片（图像）、心电图（时序数据）和医生的口头诊断（音频）。系统不仅能够理解每种模态的信息，还能够在这些不同模态之间建立联系，提供更加全面和准确的诊断建议。相对于只有文本内容，这种方式能够得出更加准确和有深度的诊断，也更加符合医生的诊断习惯。

通过与多模态结合，将会让大模型在更多领域发挥价值，甚至会产生新的产品形态或者服务方式。企业在这个方向上进行探索，会带来创新性的收获。

除了以上三个方向，还有很多其他的方向，这几个是我在业务实践中切身体会到的，你也可以从你的业务中发掘 LLM 和 RAG 的应用场景。从它们的本质出发，使用 Fine-tuning、RAG 亦或是两者结合的方式，本着不断挖掘企业自有知识价值的原则，从小颗粒度或者小的场景开始，一步一步开始尝试，感受这些技术带给产品形态和服务方式上的变化，并逐步把这些技术融入到产品中的细节里，给现有的业务不断增加色彩。

## 结语

想想 ChatGPT 问世不过一年多，这一年大模型经历了快速的发展，已经从玩具脱胎成真真切切的生产力工具。在这个 AI 浪潮中，谁也不能忽视它的存在，我相信再过几年，大模型肯定会融入每个企业当中，成为业务增长的新引擎。

对于个人，我们也要抓住这个机会，提高自己在大模型领域的认知，带着 AI 的眼光去看待业务，扩大我们的视野，放大我们的能力，保持自身在行业的先进性，让自己从中获得更多，也和公司一起创造更多！

最后，关于大模型，你还有哪些思考，可以在评论区一起讨论，我们共同成长！

另外，这里还有一份 [调研问卷](https://jsj.top/f/Ienyds)，期待你能谈谈对这门课程的学习体验，建议或意见都欢迎指出！