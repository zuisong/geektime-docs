你好，我是晓蕾。

不知道你有没有发现，道哥在解释一个概念的时候会讲到它和计算的内在联系。除此之外，他还会讲到不少历史故事，从历史的长视角中提取出自己的逻辑，形成判断。

今天的访谈内容，就和他的判断方法有关系。

**极客时间：有一件特别好奇的事。你在回答问题的时候，除了会从计算的角度解释，还会提到技术的历史。你是从什么时候形成“长视角”分析问题的习惯的？**

道哥：这是受博士影响。博士以前做阿里云的时候，天天跟我们讲故事，他的故事很多，经常给我们讲雷达的故事，也给我们讲电的故事，讲电力系统是怎么回事。一开始我会对他讲的故事很好奇，所以自己也会去翻一翻，后来我就有了这个习惯，会去翻一翻更多的故事。

有一次突然接触到了一个门类，叫技术史，后来就越看越觉得有道理。因为 **我们只有搞清楚一件事情的来龙去脉，才能搞得清楚它的未来。** 不管是哪一个领域的技术，都是如此。我们必须要尊重历史。

**极客时间：你在“计算讲谈社”谈到过“真正厉害的人敢于挑战问题的前提”，和你说的搞清楚来龙去脉，感觉很像。**

道哥：因为从逻辑或者说从数学的角度来讲，所有的定理或者说所有的推论和结论都是建立在一个前提假设之上的，这个前提假设在数学里叫公理。如果放到其他逻辑系统，实际上就是问题的前提。从几个简单的前提可以推导出所有的一切，真正大的改变和大的创新都是把这个前提或者假设改掉。

我来想想有没有什么合适的例子。阿里云的例子其实很典型。关于云计算，王坚博士是有非常明确的假设的，它是建立在3个基础假设之上的。首先，互联网成为基础设施；其次，云计算成为公共服务；最后，数据中心成为一台计算机。基于这三个假设，他推导出来了阿里云要做的一切。

如果这三个假设中有一个发生改变，那么后面做的所有东西都是错的。他的战略眼光在于他笃定地相信了这三个假设是未来。这也是他有勇气的地方，直接赌了。

再比如说自动驾驶遇到了很大的挑战，很可能是因为它的前提是虚假的。现在所有的城市道路是为人类的驾驶员设计的，而不是为机器设计的。光是这个前提的改变就意味着基础设施需要改变，这就变成了一件很大的事情。这也是为什么现在自动驾驶系统塞不进人类的城市。

**极客时间：这又涉及到判断的问题了。你是怎么理解技术的短期高估和长期低估的？**

道哥：这是自然规律，就是如此的。Gartner有一个技术成熟度曲线，我觉得基本上还是符合客观规律的。技术确实是短期高估、长期低估。这个规律对我们最大的好处是什么呢？就是可以用这个东西去买股票，这是最实惠的好处。

我在2018年的时候，就说赶快去买英伟达的股票。大概在三四个月前，我又说过一次，当时是跟家人说的，因为我自己不玩股票，但我有判断力，知道什么东西一定是未来。除去我个人对这家公司的好恶，你可以看到它的股票真的就是这样涨的。

为什么我2018年会有这样的判断呢？因为我做完上海城市大脑，我就知道城市大脑对英伟达的需求量有多大，它是垄断的，所以一定要买它的股票。但是这个就叫做信息的不对称，真正的信息的不对称。很多同学肯定不知道。

我为什么相信呢？我从来不觉得听消息或者分析有用，而且听完可以领先大家去买股票这件事是有道理的。因为那个叫做短期被高估，听消息去买股票叫做短期被高估，或者我们看媒体、看财报，这都叫短期被高估。

长期被低估就是我们知道这个技术对世界是有贡献的，它是有价值的，而且我们对它的价值有一个判断，这时候很多浮躁的人就会长期低估它的价值。但是如果像我们做技术的同学，我们真的相信它的价值，而且真的理解了它的价值，我们就敢赌。所以敢不敢赌，或者说具不具备这样的勇气，来自于自己的判断、认知和知识结构。

**极客时间：所以投入的前提就是弄清楚这个概念。**

道哥：对。有很多技术是伪概念，比如说元宇宙这种，这个一定是泡沫，泡沫是存在的。我们要分析清楚什么是泡沫，什么是长期坚持的，这个很不容易。或者我们可以回到最简单的一个判断方法，就是自己想不想干，就好了。不用听别人的。我想干的时候管它是泡沫还是啥，干就是了，想那么多干嘛？

**极客时间：那什么叫理解一个概念呢？需要理解到一个什么样的程度呢？**

道哥：这是一个好问题，也是比较难的问题。因为很多同学只是字面上理解，我认为还得要有所提拔。或者这么说，关于这个概念的任何问题我们都有答案，这就叫搞清楚了，否则肯定是没有搞清楚。我们如果只是理解了字面的意思，或者从别的地方听来、学来一些东西，那一定回答不了关于这个概念的任何问题。

**极客时间：确定概念的习惯是什么时候有的？**

道哥：写书期间养成的，我后来发现把事情说清楚其实就是把概念讲清楚的过程，要讲清楚一个概念是不容易的。

**极客时间：之前没有确定概念这样一个习惯吗？**

道哥：之前没有，之前没有意识到这件事情。只是发现沟通其实是通过语言文字统一思想的过程，统一思想其实就是在统一概念，我们每个人脑子里对同样一个名词的理解是不一样的，所以概念的解释才是沟通关键所在。

我们在讨论产品的时候，经常会把这个产品的概念重新解释一下。当你重新解释，就有机会重新定义。比如说阿里云有一个产品叫做个人云，那我们可以重新定义什么叫做个人云，比如说我们也可以重新定义什么叫做云，完全可以重新定义。你理解的云跟我理解的云肯定不一样的，也不一定要纠结哪个是对的，但是对于做产品的人来说，我们要做的事情就是对自己理解的名词和概念做一个定义，让别人也理解它，让别人和自己的理解一致，这个产品就成功了。

**极客时间：用黑话来讲，就是对齐吗？**

道哥：叫对焦，但是对焦一般是两个人相互的过程。如果用在产品上面的话，就是通过产品的一种传递，这是一种很强的产品的传达力。产品之所以能够被记住，是因为差异化。差异化是关键。反过来讲，差异化就是定位，因为你跟别人不一样。

**极客时间：刚才我们说到了定前提假设的问题。那你现在创业也会定前提假设吗？这种前提假设是怎么和纸上谈兵分开的呢？万一是我们以为自己理解了，其实没理解，怎么办？**

道哥：如何避免纸上谈兵，我觉得至少先把事情搞懂。首先我是一个工程师，所以我肯定了解目标和全局。其次别人也忽悠不到我。忽悠不到我是因为我真的搞懂了，搞懂的定义已经讲了。搞懂的底气来自于近期看过的内容。比如说我为了写《计算》这本书，我把来龙去脉都搞清楚了。我可以说，我把所有能找到的计算机的书都翻了一遍。我认为很多在今天做算法、机器人、人工智能的人，可能概念也会有些模糊。我相信是这样的，但是我觉得我不是。可能具体的算法我不知道怎么搞，但是大的方向我肯定判断得更准确。

我经常说我的思想先进性是世界一流的，在战略规划上肯定也是世界一流的。在阿里这么多年，在商业判断和洞察上面我还是有点自信的。举个例子，这次GPT出来之后，后面有一个很火的东西叫做AutoGPT。其实在AutoGPT出来之前，我们把它叫做自动化递归求证，大概是类似的一个概念，但是时间点是在AutoGPT之前。

最后，我是觉得因为我是真的搞懂了，所以有自信。GPT刚出来的时候，我一看到这个东西，首先相当兴奋，其次相当好奇。我觉得一定要把它搞清楚，之后读了很多的东西，我就搞懂了。其实学这个东西也不需要你花多少时间和精力的，我觉得自己也没有付出很大的时间和精力，但是因为读的东西多，读完之后互相印证一下基本上就搞懂了。

**极客时间：大部分人理解事情的两个路径，就是推理和归纳。**

你的战略洞见和规划是基于你懂它的底层逻辑，觉得这个事一定是这么发生的，所以你敢从理论上 **推理**，赌后续是可实现的。

另外一种是 **归纳**，你过往从你上大学做幻影开始，在战略洞见和决策上，因为你做过真的决策，是成功过的，而且看别人做出不同的选择，也相当于你已经验证过好多轮了。

**可以这么理解吗？**

道哥：对。我觉得关于推理这部分我是认同的，这个跟知识结构有关，当我们有一个庞大的知识结构，自然而然地就能够推理出来很多东西。如果我是一个很理性同时兼具冒险精神的人，就会相信自己的相信，而且会把行动赌在自己相信的东西上面。

但是你后面讲的归纳，我认为叫经验会更合适。因为数学归纳法不一定总是行之有效的，而经验就意味着实践过，那个就不是纸上谈兵。你真的跌过一些坑，就一定知道该怎么做。

**极客时间：从这个角度来讲，能够去做战略洞察和规划的人数是少数的。对于大部分人来说，应该做的就是慢慢积累自己的知识结构，同时通过行动积累经验？**

道哥：对，一定要行动和实践，动手做过和没动手做过区别非常大，经验很重要的。我觉得我人生密度比较大，是因为我真的经历过很多的东西。所以很多事情确实通过推理和自己的经验马上就能判断出来是否可行。如果我能够推理出来，肯定也能看出来问题在哪里。

**极客时间：最近有做过什么推理吗？可以举一个例子。**

道哥：之前有一篇文章叫《ChatGPT不算新技术革命，带不来什么新机会》，有人问我怎么看，我说文章里讲的过程确实如此，但是同样的过程，我得出了和完全相反的结论。

我是如何得出相反结论的呢？ **第一点，我认为社会里一大部分人在干的都是没啥意义的工作。** 文章里提到，互联网上99%的语料是没啥意义的，重复性的。有创造力和对人类有意义的新信息来自于那1%，那1%是不会被取代的，这部分我完全赞同。剩下99%没意义的工作，来自99%的人，这些人会面临巨大的就业危机。我们仔细想想每份工作是不是真的有创造性的，大多数我们以为创造性的工作其实不是，只是基于已有的素材做整合，这是我的观点。

**第二点，在于不能简单地拿20年前的语言模型来类比今天GPT的边界。** 因为GPT到了千亿以上的参数规模之后，开始涌现出一些意料之外的能力，光从统计概念里的预测来说，它能关联当前任务之外知识的领域。它是非线性发展的，我们不能线性地拿20年前的语言模型来类比。

我认为GPT从原理上暂时解决不了事实的正确性问题，因为事实都是发生过的事情，这依赖于长期记忆机制的建立，这块理论还不成熟。短期内GPT解不了这个问题，这就是为啥GPT一直胡说八道。99%无意义的重复工作面临被重复取代是现实，从GPT的原理来看，在没有外部知识干预情况下， **它不可能解决掉胡说八道的问题，因为这是依赖于记忆机制的建立。但恰恰是因为这样，我们才有做应用的机会**，要不然OpenAI一家就把所有事情做完了。

**极客时间：很多人的感受可能确实是这样，GPT出来之后，最开始觉得也没什么大不了的，了解一点之后觉得很震惊，再了解一些后看到它里面还是有一些东西是不完美的，觉得自己必须得做点什么。**

道哥：对，工程师看到了机会，我也第一眼看到了机会。因为我真的深入了解了它的原理，了解一下它的原理就知道了它是不完美的。想要把这个事情做好，我的判断是短期内也是不现实的，这是它的原理性的问题，要做巨大的架构改进才能解决。

## 互动小茶桌

在碎片化信息泛滥的今天，我们似乎更习惯看结论、跳过，看观点、跳过，阅尽千帆，脑子里啥也不剩，结论和观点背后的逻辑往往被忽视。很多时候我们自以为理解了一个概念，但在交流的时候也只是重复别人的观点。

关于真正理解一个概念这件事，你是怎么看的？有什么好方法吗？

欢迎你在留言区和我们互动。如果有所收获，也可以把内容分享给更多的朋友一起交流学习。我们下一节见。

戳此加入 [访谈交流群](http://jinshuju.net/f/ZCfcCK)，和道哥一起探索工程师精神。

![](https://static001.geekbang.org/resource/image/2a/6a/2a9095c2a3b559b4ea6d8e282a3b8e6a.jpg?wh=4096x1714)