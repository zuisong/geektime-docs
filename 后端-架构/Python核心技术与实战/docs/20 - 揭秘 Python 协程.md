ä½ å¥½ï¼Œæˆ‘æ˜¯æ™¯éœ„ã€‚

ä¸Šä¸€èŠ‚è¯¾çš„æœ€åï¼Œæˆ‘ä»¬ç•™ä¸‹ä¸€ä¸ªå°å°çš„æ‚¬å¿µï¼šç”Ÿæˆå™¨åœ¨ Python 2 ä¸­è¿˜æ‰®æ¼”äº†ä¸€ä¸ªé‡è¦è§’è‰²ï¼Œå°±æ˜¯ç”¨æ¥å®ç° Python åç¨‹ã€‚

é‚£ä¹ˆé¦–å…ˆä½ è¦æ˜ç™½ï¼Œä»€ä¹ˆæ˜¯åç¨‹ï¼Ÿ

åç¨‹æ˜¯å®ç°å¹¶å‘ç¼–ç¨‹çš„ä¸€ç§æ–¹å¼ã€‚ä¸€è¯´å¹¶å‘ï¼Œä½ è‚¯å®šæƒ³åˆ°äº†å¤šçº¿ç¨‹/å¤šè¿›ç¨‹æ¨¡å‹ï¼Œæ²¡é”™ï¼Œå¤šçº¿ç¨‹/å¤šè¿›ç¨‹ï¼Œæ­£æ˜¯è§£å†³å¹¶å‘é—®é¢˜çš„ç»å…¸æ¨¡å‹ä¹‹ä¸€ã€‚æœ€åˆçš„äº’è”ç½‘ä¸–ç•Œï¼Œå¤šçº¿ç¨‹/å¤šè¿›ç¨‹åœ¨æœåŠ¡å™¨å¹¶å‘ä¸­ï¼Œèµ·åˆ°ä¸¾è¶³è½»é‡çš„ä½œç”¨ã€‚

éšç€äº’è”ç½‘çš„å¿«é€Ÿå‘å±•ï¼Œä½ é€æ¸é‡åˆ°äº† C10K ç“¶é¢ˆï¼Œä¹Ÿå°±æ˜¯åŒæ—¶è¿æ¥åˆ°æœåŠ¡å™¨çš„å®¢æˆ·è¾¾åˆ°äº†ä¸€ä¸‡ä¸ªã€‚äºæ˜¯å¾ˆå¤šä»£ç è·‘å´©äº†ï¼Œè¿›ç¨‹ä¸Šä¸‹æ–‡åˆ‡æ¢å ç”¨äº†å¤§é‡çš„èµ„æºï¼Œçº¿ç¨‹ä¹Ÿé¡¶ä¸ä½å¦‚æ­¤å·¨å¤§çš„å‹åŠ›ï¼Œè¿™æ—¶ï¼Œ NGINX å¸¦ç€äº‹ä»¶å¾ªç¯å‡ºæ¥æ‹¯æ•‘ä¸–ç•Œäº†ã€‚

å¦‚æœå°†å¤šè¿›ç¨‹/å¤šçº¿ç¨‹ç±»æ¯”ä¸ºèµ·æºäºå”æœçš„è—©é•‡å‰²æ®ï¼Œé‚£ä¹ˆäº‹ä»¶å¾ªç¯ï¼Œå°±æ˜¯å®‹æœåŠ å¼ºçš„ä¸­å¤®é›†æƒåˆ¶ã€‚äº‹ä»¶å¾ªç¯å¯åŠ¨ä¸€ä¸ªç»Ÿä¸€çš„è°ƒåº¦å™¨ï¼Œè®©è°ƒåº¦å™¨æ¥å†³å®šä¸€ä¸ªæ—¶åˆ»å»è¿è¡Œå“ªä¸ªä»»åŠ¡ï¼Œäºæ˜¯çœå´äº†å¤šçº¿ç¨‹ä¸­å¯åŠ¨çº¿ç¨‹ã€ç®¡ç†çº¿ç¨‹ã€åŒæ­¥é”ç­‰å„ç§å¼€é”€ã€‚åŒä¸€æ—¶æœŸçš„ NGINXï¼Œåœ¨é«˜å¹¶å‘ä¸‹èƒ½ä¿æŒä½èµ„æºä½æ¶ˆè€—é«˜æ€§èƒ½ï¼Œç›¸æ¯” Apache ä¹Ÿæ”¯æŒæ›´å¤šçš„å¹¶å‘è¿æ¥ã€‚

å†åˆ°åæ¥ï¼Œå‡ºç°äº†ä¸€ä¸ªå¾ˆæœ‰åçš„åè¯ï¼Œå«åšå›è°ƒåœ°ç‹±ï¼ˆcallback hellï¼‰ï¼Œæ‰‹æ’¸è¿‡ JavaScript çš„æœ‹å‹è‚¯å®šçŸ¥é“æˆ‘åœ¨è¯´ä»€ä¹ˆã€‚æˆ‘ä»¬å¤§å®¶æƒŠå–œåœ°å‘ç°ï¼Œè¿™ç§å·¥å…·å®Œç¾åœ°ç»§æ‰¿äº†äº‹ä»¶å¾ªç¯çš„ä¼˜è¶Šæ€§ï¼ŒåŒæ—¶è¿˜èƒ½æä¾› async / await è¯­æ³•ç³–ï¼Œè§£å†³äº†æ‰§è¡Œæ€§å’Œå¯è¯»æ€§å…±å­˜çš„éš¾é¢˜ã€‚äºæ˜¯ï¼Œåç¨‹é€æ¸è¢«æ›´å¤šäººå‘ç°å¹¶çœ‹å¥½ï¼Œä¹Ÿæœ‰è¶Šæ¥è¶Šå¤šçš„äººå°è¯•ç”¨ Node.js åšèµ·äº†åç«¯å¼€å‘ã€‚ï¼ˆè®²ä¸ªç¬‘è¯ï¼ŒJavaScript æ˜¯ä¸€é—¨ç¼–ç¨‹è¯­è¨€ã€‚ï¼‰

å›åˆ°æˆ‘ä»¬çš„ Pythonã€‚ä½¿ç”¨ç”Ÿæˆå™¨ï¼Œæ˜¯ Python 2 å¼€å¤´çš„æ—¶ä»£å®ç°åç¨‹çš„è€æ–¹æ³•äº†ï¼ŒPython 3.7 æä¾›äº†æ–°çš„åŸºäº asyncio å’Œ async / await çš„æ–¹æ³•ã€‚æˆ‘ä»¬è¿™èŠ‚è¯¾ï¼ŒåŒæ ·çš„ï¼Œè·Ÿéšæ—¶ä»£ï¼ŒæŠ›å¼ƒæ‰ä¸å®¹æ˜“ç†è§£ã€ä¹Ÿä¸å®¹æ˜“å†™çš„æ—§çš„åŸºäºç”Ÿæˆå™¨çš„æ–¹æ³•ï¼Œç›´æ¥æ¥è®²æ–°æ–¹æ³•ã€‚

æˆ‘ä»¬å…ˆä»ä¸€ä¸ªçˆ¬è™«å®ä¾‹å‡ºå‘ï¼Œç”¨æ¸…æ™°çš„è®²è§£æ€è·¯ï¼Œå¸¦ä½ ç»“åˆå®æˆ˜æ¥ææ‡‚è¿™ä¸ªä¸ç®—ç‰¹åˆ«å®¹æ˜“ç†è§£çš„æ¦‚å¿µã€‚ä¹‹åï¼Œæˆ‘ä»¬å†ç”±æµ…å…¥æ·±ï¼Œç›´å‡»åç¨‹çš„æ ¸å¿ƒã€‚

## ä»ä¸€ä¸ªçˆ¬è™«è¯´èµ·

çˆ¬è™«ï¼Œå°±æ˜¯äº’è”ç½‘çš„èœ˜è››ï¼Œåœ¨æœç´¢å¼•æ“è¯ç”Ÿä¹‹æ—¶ï¼Œä¸å…¶ä¸€åŒæ¥åˆ°ä¸–ä¸Šã€‚çˆ¬è™«æ¯ç§’é’Ÿéƒ½ä¼šçˆ¬å–å¤§é‡çš„ç½‘é¡µï¼Œæå–å…³é”®ä¿¡æ¯åå­˜å‚¨åœ¨æ•°æ®åº“ä¸­ï¼Œä»¥ä¾¿æ—¥ååˆ†æã€‚çˆ¬è™«æœ‰éå¸¸ç®€å•çš„ Python åè¡Œä»£ç å®ç°ï¼Œä¹Ÿæœ‰ Google é‚£æ ·çš„å…¨çƒåˆ†å¸ƒå¼çˆ¬è™«çš„ä¸Šç™¾ä¸‡è¡Œä»£ç ï¼Œåˆ†å¸ƒåœ¨å†…éƒ¨ä¸Šä¸‡å°æœåŠ¡å™¨ä¸Šï¼Œå¯¹å…¨ä¸–ç•Œçš„ä¿¡æ¯è¿›è¡Œå—…æ¢ã€‚

è¯ä¸å¤šè¯´ï¼Œæˆ‘ä»¬å…ˆçœ‹ä¸€ä¸ªç®€å•çš„çˆ¬è™«ä¾‹å­ï¼š

```
import time

def crawl_page(url):
    print('crawling {}'.format(url))
    sleep_time = int(url.split('_')[-1])
    time.sleep(sleep_time)
    print('OK {}'.format(url))

def main(urls):
    for url in urls:
        crawl_page(url)

%time main(['url_1', 'url_2', 'url_3', 'url_4'])

########## è¾“å‡º ##########

crawling url_1
OK url_1
crawling url_2
OK url_2
crawling url_3
OK url_3
crawling url_4
OK url_4
Wall time: 10 s
```

ï¼ˆæ³¨æ„ï¼šæœ¬èŠ‚çš„ä¸»è¦ç›®çš„æ˜¯åç¨‹çš„åŸºç¡€æ¦‚å¿µï¼Œå› æ­¤æˆ‘ä»¬ç®€åŒ–çˆ¬è™«çš„ scrawl\_page å‡½æ•°ä¸ºä¼‘çœ æ•°ç§’ï¼Œä¼‘çœ æ—¶é—´å–å†³äº url æœ€åçš„é‚£ä¸ªæ•°å­—ã€‚ï¼‰

è¿™æ˜¯ä¸€ä¸ªå¾ˆç®€å•çš„çˆ¬è™«ï¼Œmain() å‡½æ•°æ‰§è¡Œæ—¶ï¼Œè°ƒå– crawl\_page() å‡½æ•°è¿›è¡Œç½‘ç»œé€šä¿¡ï¼Œç»è¿‡è‹¥å¹²ç§’ç­‰å¾…åæ”¶åˆ°ç»“æœï¼Œç„¶åæ‰§è¡Œä¸‹ä¸€ä¸ªã€‚

çœ‹èµ·æ¥å¾ˆç®€å•ï¼Œä½†ä½ ä»”ç»†ä¸€ç®—ï¼Œå®ƒä¹Ÿå ç”¨äº†ä¸å°‘æ—¶é—´ï¼Œäº”ä¸ªé¡µé¢åˆ†åˆ«ç”¨äº† 1 ç§’åˆ° 4 ç§’çš„æ—¶é—´ï¼ŒåŠ èµ·æ¥ä¸€å…±ç”¨äº† 10 ç§’ã€‚è¿™æ˜¾ç„¶æ•ˆç‡ä½ä¸‹ï¼Œè¯¥æ€ä¹ˆä¼˜åŒ–å‘¢ï¼Ÿ

äºæ˜¯ï¼Œä¸€ä¸ªå¾ˆç®€å•çš„æ€è·¯å‡ºç°äº†â€”â€”æˆ‘ä»¬è¿™ç§çˆ¬å–æ“ä½œï¼Œå®Œå…¨å¯ä»¥å¹¶å‘åŒ–ã€‚æˆ‘ä»¬å°±æ¥çœ‹çœ‹ä½¿ç”¨åç¨‹æ€ä¹ˆå†™ã€‚

```
import asyncio

async def crawl_page(url):
    print('crawling {}'.format(url))
    sleep_time = int(url.split('_')[-1])
    await asyncio.sleep(sleep_time)
    print('OK {}'.format(url))

async def main(urls):
    for url in urls:
        await crawl_page(url)

%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))

########## è¾“å‡º ##########

crawling url_1
OK url_1
crawling url_2
OK url_2
crawling url_3
OK url_3
crawling url_4
OK url_4
Wall time: 10 s
```

çœ‹åˆ°è¿™æ®µä»£ç ï¼Œä½ åº”è¯¥å‘ç°äº†ï¼Œåœ¨ Python 3.7 ä»¥ä¸Šç‰ˆæœ¬ä¸­ï¼Œä½¿ç”¨åç¨‹å†™å¼‚æ­¥ç¨‹åºéå¸¸ç®€å•ã€‚

é¦–å…ˆæ¥çœ‹ import asyncioï¼Œè¿™ä¸ªåº“åŒ…å«äº†å¤§éƒ¨åˆ†æˆ‘ä»¬å®ç°åç¨‹æ‰€éœ€çš„é­”æ³•å·¥å…·ã€‚

async ä¿®é¥°è¯å£°æ˜å¼‚æ­¥å‡½æ•°ï¼Œäºæ˜¯ï¼Œè¿™é‡Œçš„ crawl\_page å’Œ main éƒ½å˜æˆäº†å¼‚æ­¥å‡½æ•°ã€‚è€Œè°ƒç”¨å¼‚æ­¥å‡½æ•°ï¼Œæˆ‘ä»¬ä¾¿å¯å¾—åˆ°ä¸€ä¸ªåç¨‹å¯¹è±¡ï¼ˆcoroutine objectï¼‰ã€‚

ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœä½  `print(crawl_page(''))`ï¼Œä¾¿ä¼šè¾“å‡º`<coroutine object crawl_page at 0x000002BEDF141148>`ï¼Œæç¤ºä½ è¿™æ˜¯ä¸€ä¸ª Python çš„åç¨‹å¯¹è±¡ï¼Œè€Œå¹¶ä¸ä¼šçœŸæ­£æ‰§è¡Œè¿™ä¸ªå‡½æ•°ã€‚

å†æ¥è¯´è¯´åç¨‹çš„æ‰§è¡Œã€‚æ‰§è¡Œåç¨‹æœ‰å¤šç§æ–¹æ³•ï¼Œè¿™é‡Œæˆ‘ä»‹ç»ä¸€ä¸‹å¸¸ç”¨çš„ä¸‰ç§ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ await æ¥è°ƒç”¨ã€‚await æ‰§è¡Œçš„æ•ˆæœï¼Œå’Œ Python æ­£å¸¸æ‰§è¡Œæ˜¯ä¸€æ ·çš„ï¼Œä¹Ÿå°±æ˜¯è¯´ç¨‹åºä¼šé˜»å¡åœ¨è¿™é‡Œï¼Œè¿›å…¥è¢«è°ƒç”¨çš„åç¨‹å‡½æ•°ï¼Œæ‰§è¡Œå®Œæ¯•è¿”å›åå†ç»§ç»­ï¼Œè€Œè¿™ä¹Ÿæ˜¯ await çš„å­—é¢æ„æ€ã€‚ä»£ç ä¸­ `await asyncio.sleep(sleep_time)` ä¼šåœ¨è¿™é‡Œä¼‘æ¯è‹¥å¹²ç§’ï¼Œ`await crawl_page(url)` åˆ™ä¼šæ‰§è¡Œ crawl\_page() å‡½æ•°ã€‚

å…¶æ¬¡ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ asyncio.create\_task() æ¥åˆ›å»ºä»»åŠ¡ï¼Œè¿™ä¸ªæˆ‘ä»¬ä¸‹èŠ‚è¯¾ä¼šè¯¦ç»†è®²ä¸€ä¸‹ï¼Œä½ å…ˆç®€å•çŸ¥é“å³å¯ã€‚

æœ€åï¼Œæˆ‘ä»¬éœ€è¦ asyncio.run æ¥è§¦å‘è¿è¡Œã€‚asyncio.run è¿™ä¸ªå‡½æ•°æ˜¯ Python 3.7 ä¹‹åæ‰æœ‰çš„ç‰¹æ€§ï¼Œå¯ä»¥è®© Python çš„åç¨‹æ¥å£å˜å¾—éå¸¸ç®€å•ï¼Œä½ ä¸ç”¨å»ç†ä¼šäº‹ä»¶å¾ªç¯æ€ä¹ˆå®šä¹‰å’Œæ€ä¹ˆä½¿ç”¨çš„é—®é¢˜ï¼ˆæˆ‘ä»¬ä¼šåœ¨ä¸‹é¢è®²ï¼‰ã€‚ä¸€ä¸ªéå¸¸å¥½çš„ç¼–ç¨‹è§„èŒƒæ˜¯ï¼Œasyncio.run(main()) ä½œä¸ºä¸»ç¨‹åºçš„å…¥å£å‡½æ•°ï¼Œåœ¨ç¨‹åºè¿è¡Œå‘¨æœŸå†…ï¼Œåªè°ƒç”¨ä¸€æ¬¡ asyncio.runã€‚

è¿™æ ·ï¼Œä½ å°±å¤§æ¦‚çœ‹æ‡‚äº†åç¨‹æ˜¯æ€ä¹ˆç”¨çš„å§ã€‚ä¸å¦¨è¯•ç€è·‘ä¸€ä¸‹ä»£ç ï¼Œæ¬¸ï¼Œæ€ä¹ˆè¿˜æ˜¯ 10 ç§’ï¼Ÿ

10 ç§’å°±å¯¹äº†ï¼Œè¿˜è®°å¾—ä¸Šé¢æ‰€è¯´çš„ï¼Œawait æ˜¯åŒæ­¥è°ƒç”¨ï¼Œå› æ­¤ï¼Œ crawl\_page(url) åœ¨å½“å‰çš„è°ƒç”¨ç»“æŸä¹‹å‰ï¼Œæ˜¯ä¸ä¼šè§¦å‘ä¸‹ä¸€æ¬¡è°ƒç”¨çš„ã€‚äºæ˜¯ï¼Œè¿™ä¸ªä»£ç æ•ˆæœå°±å’Œä¸Šé¢å®Œå…¨ä¸€æ ·äº†ï¼Œç›¸å½“äºæˆ‘ä»¬ç”¨å¼‚æ­¥æ¥å£å†™äº†ä¸ªåŒæ­¥ä»£ç ã€‚

ç°åœ¨åˆè¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿ

å…¶å®å¾ˆç®€å•ï¼Œä¹Ÿæ­£æ˜¯æˆ‘æ¥ä¸‹æ¥è¦è®²çš„åç¨‹ä¸­çš„ä¸€ä¸ªé‡è¦æ¦‚å¿µï¼Œä»»åŠ¡ï¼ˆTaskï¼‰ã€‚è€è§„çŸ©ï¼Œå…ˆçœ‹ä»£ç ã€‚

```
import asyncio

async def crawl_page(url):
    print('crawling {}'.format(url))
    sleep_time = int(url.split('_')[-1])
    await asyncio.sleep(sleep_time)
    print('OK {}'.format(url))

async def main(urls):
    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]
    for task in tasks:
        await task

%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))

########## è¾“å‡º ##########

crawling url_1
crawling url_2
crawling url_3
crawling url_4
OK url_1
OK url_2
OK url_3
OK url_4
Wall time: 3.99 s
```

ä½ å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬æœ‰äº†åç¨‹å¯¹è±¡åï¼Œä¾¿å¯ä»¥é€šè¿‡ `asyncio.create_task` æ¥åˆ›å»ºä»»åŠ¡ã€‚ä»»åŠ¡åˆ›å»ºåå¾ˆå¿«å°±ä¼šè¢«è°ƒåº¦æ‰§è¡Œï¼Œè¿™æ ·ï¼Œæˆ‘ä»¬çš„ä»£ç ä¹Ÿä¸ä¼šé˜»å¡åœ¨ä»»åŠ¡è¿™é‡Œã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬è¦ç­‰æ‰€æœ‰ä»»åŠ¡éƒ½ç»“æŸæ‰è¡Œï¼Œç”¨`for task in tasks: await task` å³å¯ã€‚

è¿™æ¬¡ï¼Œä½ å°±çœ‹åˆ°æ•ˆæœäº†å§ï¼Œç»“æœæ˜¾ç¤ºï¼Œè¿è¡Œæ€»æ—¶é•¿ç­‰äºè¿è¡Œæ—¶é—´æœ€é•¿çš„çˆ¬è™«ã€‚

å½“ç„¶ï¼Œä½ ä¹Ÿå¯ä»¥æƒ³ä¸€æƒ³ï¼Œè¿™é‡Œç”¨å¤šçº¿ç¨‹åº”è¯¥æ€ä¹ˆå†™ï¼Ÿè€Œå¦‚æœéœ€è¦çˆ¬å–çš„é¡µé¢æœ‰ä¸Šä¸‡ä¸ªåˆè¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿå†å¯¹æ¯”ä¸‹åç¨‹çš„å†™æ³•ï¼Œè°æ›´æ¸…æ™°è‡ªæ˜¯ä¸€ç›®äº†ç„¶ã€‚

å…¶å®ï¼Œå¯¹äºæ‰§è¡Œ tasksï¼Œè¿˜æœ‰å¦ä¸€ç§åšæ³•ï¼š

```
import asyncio

async def crawl_page(url):
    print('crawling {}'.format(url))
    sleep_time = int(url.split('_')[-1])
    await asyncio.sleep(sleep_time)
    print('OK {}'.format(url))

async def main(urls):
    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]
    await asyncio.gather(*tasks)

%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))

########## è¾“å‡º ##########

crawling url_1
crawling url_2
crawling url_3
crawling url_4
OK url_1
OK url_2
OK url_3
OK url_4
Wall time: 4.01 s
```

è¿™é‡Œçš„ä»£ç ä¹Ÿå¾ˆå¥½ç†è§£ã€‚å”¯ä¸€è¦æ³¨æ„çš„æ˜¯ï¼Œ`*tasks` è§£åŒ…åˆ—è¡¨ï¼Œå°†åˆ—è¡¨å˜æˆäº†å‡½æ•°çš„å‚æ•°ï¼›ä¸ä¹‹å¯¹åº”çš„æ˜¯ï¼Œ `** dict` å°†å­—å…¸å˜æˆäº†å‡½æ•°çš„å‚æ•°ã€‚

å¦å¤–ï¼Œ`asyncio.create_task`ï¼Œ`asyncio.run` è¿™äº›å‡½æ•°éƒ½æ˜¯ Python 3.7 ä»¥ä¸Šçš„ç‰ˆæœ¬æ‰æä¾›çš„ï¼Œè‡ªç„¶ï¼Œç›¸æ¯”äºæ—§æ¥å£å®ƒä»¬ä¹Ÿæ›´å®¹æ˜“ç†è§£å’Œé˜…è¯»ã€‚

## è§£å¯†åç¨‹è¿è¡Œæ—¶

è¯´äº†è¿™ä¹ˆå¤šï¼Œç°åœ¨ï¼Œæˆ‘ä»¬ä¸å¦¨æ¥æ·±å…¥ä»£ç åº•å±‚çœ‹çœ‹ã€‚æœ‰äº†å‰é¢çš„çŸ¥è¯†åšåŸºç¡€ï¼Œä½ åº”è¯¥å¾ˆå®¹æ˜“ç†è§£è¿™ä¸¤æ®µä»£ç ã€‚

```
import asyncio

async def worker_1():
    print('worker_1 start')
    await asyncio.sleep(1)
    print('worker_1 done')

async def worker_2():
    print('worker_2 start')
    await asyncio.sleep(2)
    print('worker_2 done')

async def main():
    print('before await')
    await worker_1()
    print('awaited worker_1')
    await worker_2()
    print('awaited worker_2')

%time asyncio.run(main())

########## è¾“å‡º ##########

before await
worker_1 start
worker_1 done
awaited worker_1
worker_2 start
worker_2 done
awaited worker_2
Wall time: 3 s
```

```
import asyncio

async def worker_1():
    print('worker_1 start')
    await asyncio.sleep(1)
    print('worker_1 done')

async def worker_2():
    print('worker_2 start')
    await asyncio.sleep(2)
    print('worker_2 done')

async def main():
    task1 = asyncio.create_task(worker_1())
    task2 = asyncio.create_task(worker_2())
    print('before await')
    await task1
    print('awaited worker_1')
    await task2
    print('awaited worker_2')

%time asyncio.run(main())

########## è¾“å‡º ##########

before await
worker_1 start
worker_2 start
worker_1 done
awaited worker_1
worker_2 done
awaited worker_2
Wall time: 2.01 s
```

ä¸è¿‡ï¼Œç¬¬äºŒä¸ªä»£ç ï¼Œåˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆå‘¢ï¼Ÿä¸ºäº†è®©ä½ æ›´è¯¦ç»†äº†è§£åˆ°åç¨‹å’Œçº¿ç¨‹çš„å…·ä½“åŒºåˆ«ï¼Œè¿™é‡Œæˆ‘è¯¦ç»†åœ°åˆ†æäº†æ•´ä¸ªè¿‡ç¨‹ã€‚æ­¥éª¤æœ‰ç‚¹å¤šï¼Œåˆ«ç€æ€¥ï¼Œæˆ‘ä»¬æ…¢æ…¢æ¥çœ‹ã€‚

01. `asyncio.run(main())`ï¼Œç¨‹åºè¿›å…¥ main() å‡½æ•°ï¼Œäº‹ä»¶å¾ªç¯å¼€å¯ï¼›
02. task1 å’Œ task2 ä»»åŠ¡è¢«åˆ›å»ºï¼Œå¹¶è¿›å…¥äº‹ä»¶å¾ªç¯ç­‰å¾…è¿è¡Œï¼›è¿è¡Œåˆ° printï¼Œè¾“å‡º `'before await'`ï¼›
03. await task1 æ‰§è¡Œï¼Œç”¨æˆ·é€‰æ‹©ä»å½“å‰çš„ä¸»ä»»åŠ¡ä¸­åˆ‡å‡ºï¼Œäº‹ä»¶è°ƒåº¦å™¨å¼€å§‹è°ƒåº¦ worker\_1ï¼›
04. worker\_1 å¼€å§‹è¿è¡Œï¼Œè¿è¡Œ print è¾“å‡º`'worker_1 start'`ï¼Œç„¶åè¿è¡Œåˆ° `await asyncio.sleep(1)`ï¼Œ ä»å½“å‰ä»»åŠ¡åˆ‡å‡ºï¼Œäº‹ä»¶è°ƒåº¦å™¨å¼€å§‹è°ƒåº¦ worker\_2ï¼›
05. worker\_2 å¼€å§‹è¿è¡Œï¼Œè¿è¡Œ print è¾“å‡º `'worker_2 start'`ï¼Œç„¶åè¿è¡Œ `await asyncio.sleep(2)` ä»å½“å‰ä»»åŠ¡åˆ‡å‡ºï¼›
06. ä»¥ä¸Šæ‰€æœ‰äº‹ä»¶çš„è¿è¡Œæ—¶é—´ï¼Œéƒ½åº”è¯¥åœ¨ 1ms åˆ° 10ms ä¹‹é—´ï¼Œç”šè‡³å¯èƒ½æ›´çŸ­ï¼Œäº‹ä»¶è°ƒåº¦å™¨ä»è¿™ä¸ªæ—¶å€™å¼€å§‹æš‚åœè°ƒåº¦ï¼›
07. ä¸€ç§’é’Ÿåï¼Œworker\_1 çš„ sleep å®Œæˆï¼Œäº‹ä»¶è°ƒåº¦å™¨å°†æ§åˆ¶æƒé‡æ–°ä¼ ç»™ task\_1ï¼Œè¾“å‡º `'worker_1 done'`ï¼Œtask\_1 å®Œæˆä»»åŠ¡ï¼Œä»äº‹ä»¶å¾ªç¯ä¸­é€€å‡ºï¼›
08. await task1 å®Œæˆï¼Œäº‹ä»¶è°ƒåº¦å™¨å°†æ§åˆ¶å™¨ä¼ ç»™ä¸»ä»»åŠ¡ï¼Œè¾“å‡º `'awaited worker_1'`ï¼ŒÂ·ç„¶ååœ¨ await task2 å¤„ç»§ç»­ç­‰å¾…ï¼›
09. ä¸¤ç§’é’Ÿåï¼Œworker\_2 çš„ sleep å®Œæˆï¼Œäº‹ä»¶è°ƒåº¦å™¨å°†æ§åˆ¶æƒé‡æ–°ä¼ ç»™ task\_2ï¼Œè¾“å‡º `'worker_2 done'`ï¼Œtask\_2 å®Œæˆä»»åŠ¡ï¼Œä»äº‹ä»¶å¾ªç¯ä¸­é€€å‡ºï¼›
10. ä¸»ä»»åŠ¡è¾“å‡º `'awaited worker_2'`ï¼Œåç¨‹å…¨ä»»åŠ¡ç»“æŸï¼Œäº‹ä»¶å¾ªç¯ç»“æŸã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¿›é˜¶ä¸€ä¸‹ã€‚å¦‚æœæˆ‘ä»¬æƒ³ç»™æŸäº›åç¨‹ä»»åŠ¡é™å®šè¿è¡Œæ—¶é—´ï¼Œä¸€æ—¦è¶…æ—¶å°±å–æ¶ˆï¼Œåˆè¯¥æ€ä¹ˆåšå‘¢ï¼Ÿå†è¿›ä¸€æ­¥ï¼Œå¦‚æœæŸäº›åç¨‹è¿è¡Œæ—¶å‡ºç°é”™è¯¯ï¼Œåˆè¯¥æ€ä¹ˆå¤„ç†å‘¢ï¼ŸåŒæ ·çš„ï¼Œæ¥çœ‹ä»£ç ã€‚

```
import asyncio

async def worker_1():
    await asyncio.sleep(1)
    return 1

async def worker_2():
    await asyncio.sleep(2)
    return 2 / 0

async def worker_3():
    await asyncio.sleep(3)
    return 3

async def main():
    task_1 = asyncio.create_task(worker_1())
    task_2 = asyncio.create_task(worker_2())
    task_3 = asyncio.create_task(worker_3())

    await asyncio.sleep(2)
    task_3.cancel()

    res = await asyncio.gather(task_1, task_2, task_3, return_exceptions=True)
    print(res)

%time asyncio.run(main())

########## è¾“å‡º ##########

[1, ZeroDivisionError('division by zero'), CancelledError()]
Wall time: 2 s
```

ä½ å¯ä»¥çœ‹åˆ°ï¼Œworker\_1 æ­£å¸¸è¿è¡Œï¼Œworker\_2 è¿è¡Œä¸­å‡ºç°é”™è¯¯ï¼Œworker\_3 æ‰§è¡Œæ—¶é—´è¿‡é•¿è¢«æˆ‘ä»¬ cancel æ‰äº†ï¼Œè¿™äº›ä¿¡æ¯ä¼šå…¨éƒ¨ä½“ç°åœ¨æœ€ç»ˆçš„è¿”å›ç»“æœ res ä¸­ã€‚

ä¸è¿‡è¦æ³¨æ„`return_exceptions=True`è¿™è¡Œä»£ç ã€‚å¦‚æœä¸è®¾ç½®è¿™ä¸ªå‚æ•°ï¼Œé”™è¯¯å°±ä¼šå®Œæ•´åœ° throw åˆ°æˆ‘ä»¬è¿™ä¸ªæ‰§è¡Œå±‚ï¼Œä»è€Œéœ€è¦ try except æ¥æ•æ‰ï¼Œè¿™ä¹Ÿå°±æ„å‘³ç€å…¶ä»–è¿˜æ²¡è¢«æ‰§è¡Œçš„ä»»åŠ¡ä¼šè¢«å…¨éƒ¨å–æ¶ˆæ‰ã€‚ä¸ºäº†é¿å…è¿™ä¸ªå±€é¢ï¼Œæˆ‘ä»¬å°† return\_exceptions è®¾ç½®ä¸º True å³å¯ã€‚

åˆ°è¿™é‡Œï¼Œå‘ç°äº†æ²¡ï¼Œçº¿ç¨‹èƒ½å®ç°çš„ï¼Œåç¨‹éƒ½èƒ½åšåˆ°ã€‚é‚£å°±è®©æˆ‘ä»¬æ¸©ä¹ ä¸€ä¸‹è¿™äº›çŸ¥è¯†ç‚¹ï¼Œç”¨åç¨‹æ¥å®ç°ä¸€ä¸ªç»å…¸çš„ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å‹å§ã€‚

```
import asyncio
import random

async def consumer(queue, id):
    while True:
        val = await queue.get()
        print('{} get a val: {}'.format(id, val))
        await asyncio.sleep(1)

async def producer(queue, id):
    for i in range(5):
        val = random.randint(1, 10)
        await queue.put(val)
        print('{} put a val: {}'.format(id, val))
        await asyncio.sleep(1)

async def main():
    queue = asyncio.Queue()

    consumer_1 = asyncio.create_task(consumer(queue, 'consumer_1'))
    consumer_2 = asyncio.create_task(consumer(queue, 'consumer_2'))

    producer_1 = asyncio.create_task(producer(queue, 'producer_1'))
    producer_2 = asyncio.create_task(producer(queue, 'producer_2'))

    await asyncio.sleep(10)
    consumer_1.cancel()
    consumer_2.cancel()
    
    await asyncio.gather(consumer_1, consumer_2, producer_1, producer_2, return_exceptions=True)

%time asyncio.run(main())

########## è¾“å‡º ##########

producer_1 put a val: 5
producer_2 put a val: 3
consumer_1 get a val: 5
consumer_2 get a val: 3
producer_1 put a val: 1
producer_2 put a val: 3
consumer_2 get a val: 1
consumer_1 get a val: 3
producer_1 put a val: 6
producer_2 put a val: 10
consumer_1 get a val: 6
consumer_2 get a val: 10
producer_1 put a val: 4
producer_2 put a val: 5
consumer_2 get a val: 4
consumer_1 get a val: 5
producer_1 put a val: 2
producer_2 put a val: 8
consumer_1 get a val: 2
consumer_2 get a val: 8
Wall time: 10 s
```

## å®æˆ˜ï¼šè±†ç“£è¿‘æ—¥æ¨èç”µå½±çˆ¬è™«

æœ€åï¼Œè¿›å…¥ä»Šå¤©çš„å®æˆ˜ç¯èŠ‚â€”â€”å®ç°ä¸€ä¸ªå®Œæ•´çš„åç¨‹çˆ¬è™«ã€‚

ä»»åŠ¡æè¿°ï¼š[https://movie.douban.com/cinema/later/beijing/](https://movie.douban.com/cinema/later/beijing/) è¿™ä¸ªé¡µé¢æè¿°äº†åŒ—äº¬æœ€è¿‘ä¸Šæ˜ çš„ç”µå½±ï¼Œä½ èƒ½å¦é€šè¿‡ Python å¾—åˆ°è¿™äº›ç”µå½±çš„åç§°ã€ä¸Šæ˜ æ—¶é—´å’Œæµ·æŠ¥å‘¢ï¼Ÿè¿™ä¸ªé¡µé¢çš„æµ·æŠ¥æ˜¯ç¼©å°ç‰ˆçš„ï¼Œæˆ‘å¸Œæœ›ä½ èƒ½ä»å…·ä½“çš„ç”µå½±æè¿°é¡µé¢ä¸­æŠ“å–åˆ°æµ·æŠ¥ã€‚

å¬èµ·æ¥éš¾åº¦ä¸æ˜¯å¾ˆå¤§å§ï¼Ÿæˆ‘åœ¨ä¸‹é¢ç»™å‡ºäº†åŒæ­¥ç‰ˆæœ¬çš„ä»£ç å’Œåç¨‹ç‰ˆæœ¬çš„ä»£ç ï¼Œé€šè¿‡è¿è¡Œæ—¶é—´å’Œä»£ç å†™æ³•çš„å¯¹æ¯”ï¼Œå¸Œæœ›ä½ èƒ½å¯¹åç¨‹æœ‰æ›´æ·±çš„äº†è§£ã€‚ï¼ˆæ³¨æ„ï¼šä¸ºäº†çªå‡ºé‡ç‚¹ã€ç®€åŒ–ä»£ç ï¼Œè¿™é‡Œæˆ‘çœç•¥äº†å¼‚å¸¸å¤„ç†ã€‚ï¼‰

ä¸è¿‡ï¼Œåœ¨å‚è€ƒæˆ‘ç»™å‡ºçš„ä»£ç ä¹‹å‰ï¼Œä½ æ˜¯ä¸æ˜¯å¯ä»¥è‡ªå·±å…ˆåŠ¨æ‰‹å†™ä¸€ä¸‹ã€è·‘ä¸€ä¸‹å‘¢ï¼Ÿ

```
import requests
from bs4 import BeautifulSoup

def main():
    url = "https://movie.douban.com/cinema/later/beijing/"
    init_page = requests.get(url).content
    init_soup = BeautifulSoup(init_page, 'lxml')

    all_movies = init_soup.find('div', id="showing-soon")
    for each_movie in all_movies.find_all('div', class_="item"):
        all_a_tag = each_movie.find_all('a')
        all_li_tag = each_movie.find_all('li')

        movie_name = all_a_tag[1].text
        url_to_fetch = all_a_tag[1]['href']
        movie_date = all_li_tag[0].text

        response_item = requests.get(url_to_fetch).content
        soup_item = BeautifulSoup(response_item, 'lxml')
        img_tag = soup_item.find('img')

        print('{} {} {}'.format(movie_name, movie_date, img_tag['src']))

%time main()

########## è¾“å‡º ##########

é˜¿æ‹‰ä¸ 05æœˆ24æ—¥ https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2553992741.jpg
é¾™ç è¶…ï¼šå¸ƒç½—åˆ© 05æœˆ24æ—¥ https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2557371503.jpg
äº”æœˆå¤©äººç”Ÿæ— é™å…¬å¸ 05æœˆ24æ—¥ https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2554324453.jpg
... ...
ç›´æ’­æ”»ç•¥ 06æœˆ04æ—¥ https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2555957974.jpg
Wall time: 56.6 s
```

```
import asyncio
import aiohttp

from bs4 import BeautifulSoup

async def fetch_content(url):
    async with aiohttp.ClientSession(
        headers=header, connector=aiohttp.TCPConnector(ssl=False)
    ) as session:
        async with session.get(url) as response:
            return await response.text()

async def main():
    url = "https://movie.douban.com/cinema/later/beijing/"
    init_page = await fetch_content(url)
    init_soup = BeautifulSoup(init_page, 'lxml')

    movie_names, urls_to_fetch, movie_dates = [], [], []

    all_movies = init_soup.find('div', id="showing-soon")
    for each_movie in all_movies.find_all('div', class_="item"):
        all_a_tag = each_movie.find_all('a')
        all_li_tag = each_movie.find_all('li')

        movie_names.append(all_a_tag[1].text)
        urls_to_fetch.append(all_a_tag[1]['href'])
        movie_dates.append(all_li_tag[0].text)

    tasks = [fetch_content(url) for url in urls_to_fetch]
    pages = await asyncio.gather(*tasks)

    for movie_name, movie_date, page in zip(movie_names, movie_dates, pages):
        soup_item = BeautifulSoup(page, 'lxml')
        img_tag = soup_item.find('img')

        print('{} {} {}'.format(movie_name, movie_date, img_tag['src']))

%time asyncio.run(main())

########## è¾“å‡º ##########

é˜¿æ‹‰ä¸ 05æœˆ24æ—¥ https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2553992741.jpg
é¾™ç è¶…ï¼šå¸ƒç½—åˆ© 05æœˆ24æ—¥ https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2557371503.jpg
äº”æœˆå¤©äººç”Ÿæ— é™å…¬å¸ 05æœˆ24æ—¥ https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2554324453.jpg
... ...
ç›´æ’­æ”»ç•¥ 06æœˆ04æ—¥ https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2555957974.jpg
Wall time: 4.98 s
```

## æ€»ç»“

åˆ°è¿™é‡Œï¼Œä»Šå¤©çš„ä¸»è¦å†…å®¹å°±è®²å®Œäº†ã€‚ä»Šå¤©æˆ‘ç”¨äº†è¾ƒé•¿çš„ç¯‡å¹…ï¼Œä»ä¸€ä¸ªç®€å•çš„çˆ¬è™«å¼€å§‹ï¼Œåˆ°ä¸€ä¸ªçœŸæ­£çš„çˆ¬è™«ç»“æŸï¼Œåœ¨ä¸­é—´ç©¿æ’è®²è§£äº† Python åç¨‹æœ€æ–°çš„åŸºæœ¬æ¦‚å¿µå’Œç”¨æ³•ã€‚è¿™é‡Œå¸¦ä½ ç®€å•å¤ä¹ ä¸€ä¸‹ã€‚

- åç¨‹å’Œå¤šçº¿ç¨‹çš„åŒºåˆ«ï¼Œä¸»è¦åœ¨äºä¸¤ç‚¹ï¼Œä¸€æ˜¯åç¨‹ä¸ºå•çº¿ç¨‹ï¼›äºŒæ˜¯åç¨‹ç”±ç”¨æˆ·å†³å®šï¼Œåœ¨å“ªäº›åœ°æ–¹äº¤å‡ºæ§åˆ¶æƒï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªä»»åŠ¡ã€‚
- åç¨‹çš„å†™æ³•æ›´åŠ ç®€æ´æ¸…æ™°ï¼ŒæŠŠasync / await è¯­æ³•å’Œ create\_task ç»“åˆæ¥ç”¨ï¼Œå¯¹äºä¸­å°çº§åˆ«çš„å¹¶å‘éœ€æ±‚å·²ç»æ¯«æ— å‹åŠ›ã€‚
- å†™åç¨‹ç¨‹åºçš„æ—¶å€™ï¼Œä½ çš„è„‘æµ·ä¸­è¦æœ‰æ¸…æ™°çš„äº‹ä»¶å¾ªç¯æ¦‚å¿µï¼ŒçŸ¥é“ç¨‹åºåœ¨ä»€ä¹ˆæ—¶å€™éœ€è¦æš‚åœã€ç­‰å¾… I/Oï¼Œä»€ä¹ˆæ—¶å€™éœ€è¦ä¸€å¹¶æ‰§è¡Œåˆ°åº•ã€‚

æœ€åçš„æœ€åï¼Œè¯·ä¸€å®šä¸è¦è½»æ˜“ç‚«æŠ€ã€‚å¤šçº¿ç¨‹æ¨¡å‹ä¹Ÿä¸€å®šæœ‰å…¶ä¼˜ç‚¹ï¼Œä¸€ä¸ªçœŸæ­£ç‰›é€¼çš„ç¨‹åºå‘˜ï¼Œåº”è¯¥æ‡‚å¾—ï¼Œåœ¨ä»€ä¹ˆæ—¶å€™ç”¨ä»€ä¹ˆæ¨¡å‹èƒ½è¾¾åˆ°å·¥ç¨‹ä¸Šçš„æœ€ä¼˜ï¼Œè€Œä¸æ˜¯è‡ªè§‰æŸä¸ªæŠ€æœ¯éå¸¸ç‰›é€¼ï¼Œæ‰€æœ‰é¡¹ç›®åˆ›é€ æ¡ä»¶ä¹Ÿè¦ä¸Šã€‚æŠ€æœ¯æ˜¯å·¥ç¨‹ï¼Œè€Œå·¥ç¨‹åˆ™æ˜¯æ—¶é—´ã€èµ„æºã€äººåŠ›ç­‰çº·ç¹å¤æ‚çš„äº‹æƒ…çš„æŠ˜è¡·ã€‚

## æ€è€ƒé¢˜

æœ€åç»™ä½ ç•™ä¸€ä¸ªæ€è€ƒé¢˜ã€‚åç¨‹æ€ä¹ˆå®ç°å›è°ƒå‡½æ•°å‘¢ï¼Ÿæ¬¢è¿ç•™è¨€å’Œæˆ‘è®¨è®ºï¼Œä¹Ÿæ¬¢è¿ä½ æŠŠè¿™ç¯‡æ–‡ç« åˆ†äº«ç»™ä½ çš„åŒäº‹æœ‹å‹ï¼Œæˆ‘ä»¬ä¸€èµ·äº¤æµï¼Œä¸€èµ·è¿›æ­¥ã€‚
<div><strong>ç²¾é€‰ç•™è¨€ï¼ˆ15ï¼‰</strong></div><ul>
<li><span>Jingxiao</span> ğŸ‘ï¼ˆ45ï¼‰ ğŸ’¬ï¼ˆ0ï¼‰<p>æ€è€ƒé¢˜ç­”æ¡ˆï¼š

åœ¨ python 3.7 åŠä»¥ä¸Šçš„ç‰ˆæœ¬ä¸­ï¼Œæˆ‘ä»¬å¯¹ task å¯¹è±¡è°ƒç”¨ add_done_callback() å‡½æ•°ï¼Œå³å¯ç»‘å®šç‰¹å®šå›è°ƒå‡½æ•°ã€‚å›è°ƒå‡½æ•°æ¥å—ä¸€ä¸ª future å¯¹è±¡ï¼Œå¯ä»¥é€šè¿‡ future.result() æ¥è·å–åç¨‹å‡½æ•°çš„è¿”å›å€¼ã€‚

ç¤ºä¾‹å¦‚ä¸‹ï¼š

import asyncio

async def crawl_page(url):
    print(&#39;crawling {}&#39;.format(url))
    sleep_time = int(url.split(&#39;_&#39;)[-1])
    await asyncio.sleep(sleep_time)
    return &#39;OK {}&#39;.format(url)

async def main(urls):
    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]
    for task in tasks:
        task.add_done_callback(lambda future: print(&#39;result: &#39;, future.result()))
    await asyncio.gather(*tasks)

%time asyncio.run(main([&#39;url_1&#39;, &#39;url_2&#39;, &#39;url_3&#39;, &#39;url_4&#39;]))

è¾“å‡ºï¼š

crawling url_1
crawling url_2
crawling url_3
crawling url_4
result:  OK url_1
result:  OK url_2
result:  OK url_3
result:  OK url_4
Wall time: 4 s</p>2019-07-01</li><br/><li><span>Jingxiao</span> ğŸ‘ï¼ˆ77ï¼‰ ğŸ’¬ï¼ˆ10ï¼‰<p>å‘ç°è¯„è®ºåŒºå¥½å¤šæœ‹å‹è¯´æ— æ³•è¿è¡Œï¼Œåœ¨è¿™é‡Œç»Ÿä¸€è§£é‡Šä¸‹ï¼š
1. %time æ˜¯ jupyter notebook è‡ªå¸¦çš„è¯­æ³•ç³–ï¼Œç”¨æ¥ç»Ÿè®¡ä¸€è¡Œå‘½ä»¤çš„è¿è¡Œæ—¶é—´ï¼›å¦‚æœä½ çš„è¿è¡Œæ—¶æ˜¯çº¯ç²¹çš„å‘½ä»¤è¡Œ pythonï¼Œæˆ–è€… pycharmï¼Œé‚£ä¹ˆè¯·æŠŠ %time åˆ æ‰ï¼Œè‡ªå·±ç”¨ä¼ ç»Ÿçš„æ—¶é—´æˆ³æ–¹æ³•æ¥è®°å½•æ—¶é—´ä¹Ÿå¯ä»¥ï¼›æˆ–è€…ä½¿ç”¨ jupyter notebook
2. æˆ‘çš„æœ¬åœ°è§£é‡Šå™¨æ˜¯ Anaconda Python 3.7.3ï¼Œäº²æµ‹ windows &#47; ubuntu å‡å¯æ­£å¸¸è¿è¡Œï¼Œå¦‚æ— æ³•æ‰§è¡Œå¯ä»¥è¯•è¯• pip install nest-asyncioï¼Œä¾ç„¶æ— æ³•è§£å†³è¯·å°è¯•å®‰è£… Anaconda Python
3. è¿™æ¬¡ä»£ç å› ä¸ºä½¿ç”¨äº†è¾ƒæ–°çš„ APIï¼Œæ‰€ä»¥éœ€è¦è¾ƒæ–°çš„ç‰ˆæœ¬å·ï¼Œä½†æ˜¯æœ‹å‹ä»¬ä¾ç„¶å‡ºç°äº†ä¸€äº›è¿è¡Œæ—¶é—®é¢˜ï¼Œè¿™é‡Œå…ˆè¡¨ç¤ºä¸‹æ­‰æ„ï¼›åŒæ—¶ä¹Ÿæƒ³è¯´æ˜çš„æ˜¯ï¼Œåœ¨æé—®ä¹‹å‰è‡ªå·±ç»è¿‡å……åˆ†æœç´¢ï¼Œå°è¯•åè§£å†³é—®é¢˜ï¼Œå¸¦æ¥çš„å¿«æ„Ÿï¼Œå’Œèƒ½åŠ›çš„æå‡ï¼Œç›¸åº”ä¹Ÿæ˜¯å¾ˆå¤§çš„ï¼Œä¸€é—¨å·¥ç¨‹æœ€éœ€è¦çš„æ˜¯ hands on dirty workï¼ˆåŠ¨æ‰‹åšè„æ´»ï¼‰ï¼Œæ‰èƒ½è®©è‡ªå·±çš„èƒ½åŠ›å¾—åˆ°æœ¬è´¨çš„æå‡ï¼ŒåŠ æ²¹ï¼</p>2019-06-25</li><br/><li><span>Airnm.æ¯</span> ğŸ‘ï¼ˆ8ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<p>è±†ç“£é‚£ä¸ªå‘ç°requests.get(url).content&#47;textè¿”å›éƒ½ä¸ºç©ºï¼Œç„¶åæ‰“äº†ä¸‹status_codeå‘ç°æ˜¯418ï¼Œç½‘ä¸Šæ‰¾418çš„è§£é‡Šï¼Œä¸€èˆ¬æ˜¯ç½‘ç«™åçˆ¬è™«åŸºç¡€æœºåˆ¶ï¼Œéœ€è¦åŠ è¯·æ±‚å¤´æ¨¡ä»¿æµè§ˆå™¨å°±å¯è·³è¿‡ï¼Œæ”¹ä¸ºä¸‹é¢çš„æ ·å­å°±å¯é€šè¿‡ï¼šurl = &quot;https:&#47;&#47;movie.douban.com&#47;cinema&#47;later&#47;beijing&#47;&quot;
head={
    &#39;User-Agent&#39;:&#39;Mozilla&#47;5.0 (Windows NT 6.1; Win64; x64) AppleWebKit&#47;537.36 (KHTML, like Gecko) Chrome&#47;81.0.4044.113 Safari&#47;537.36&#39;,
    &#39;Referer&#39;:&#39;https:&#47;&#47;time.geekbang.org&#47;column&#47;article&#47;101855&#39;,
    &#39;Connection&#39;:&#39;keep-alive&#39;}
res = requests.get(url,headers=head)</p>2020-04-18</li><br/><li><span>jackstraw</span> ğŸ‘ï¼ˆ4ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>æœ‰ç‚¹æ²¡æ˜ç™½ï¼Œå‰é¢è¯´ä»»åŠ¡åˆ›å»ºåç«‹é©¬å°±å¼€å§‹æ‰§è¡Œäº†ä¹ˆï¼Ÿæ€ä¹ˆåé¢åœ¨è§£å¯†åº•å±‚è¿è¡Œè¿‡ç¨‹çš„æ—¶å€™ï¼Œè¯´ä»»åŠ¡åˆ›å»ºåç­‰å¾…æ‰§è¡Œï¼Ÿåˆ°åº•æ˜¯å“ªä¸€ä¸ªå‘€ï¼Ÿ</p>2020-01-14</li><br/><li><span>é•¿æœŸè§„åˆ’</span> ğŸ‘ï¼ˆ2ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è€å¸ˆï¼Œåœ¨æœ€åé‚£ä¸ªåç¨‹ä¾‹å­ä¸­ä¸ºä½•æ²¡ç”¨requestsåº“å‘¢ï¼Ÿæ˜¯å› ä¸ºå®ƒä¸æ”¯æŒåç¨‹å—</p>2019-12-20</li><br/><li><span>ä¸€å‡¡</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>åç¨‹æ˜¯å•çº¿ç¨‹æ€ä¹ˆç†è§£ï¼Ÿæ‰€æœ‰çš„åç¨‹éƒ½æ˜¯å—</p>2020-06-18</li><br/><li><span>è‹¹æœ</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>asyncio.run() cannot be called from a running event loop
è¿™ä¸ªé—®é¢˜æ˜¯å¦‚ä½•è§£å†³ï¼Œ
</p>2020-02-02</li><br/><li><span>éš°æœ‰è·</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è€å¸ˆï¼Œåœ¨å¦‚ä¸‹ä»£ç ä¸­ï¼š
async def worker_2():
    print(&#39;worker_2 start&#39;)
    await asyncio.sleep(2)
    print(&#39;worker_2 done&#39;)

å…¶ä¸­çš„await asyncio.sleep(2)æ˜¯å¦å¯ä»¥ç†è§£ä¸ºåœ¨åˆ‡å‡ºå½“å‰ç¨‹åºï¼Œ2ç§’åå†ç»§ç»­æ‰§è¡Œprint(&#39;worker_2 done&#39;)ä»£ç ï¼Ÿ
é‚£ä¹ˆå¦‚æœæˆ‘æœ‰ä¸ªè€—æ—¶ä»»åŠ¡ def xxx(): ...ï¼Œé‚£ä¹ˆè¯¥å¦‚ä½•ç”¨await asyncioæ¥è®©è¿™ä¸ªxxxå‡½æ•°è¿è¡Œå¹¶åˆ‡å‡ºå½“å‰ç¨‹åºå‘¢ï¼Ÿ</p>2019-11-28</li><br/><li><span>æ‰¶å¹½</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è¯·é—®ä¸‹æœ‰æœ¨æœ‰ç›¸å…³çš„ä¹¦ç±ï¼Œæ¥è¿›è¡Œè¿™å—çš„å­¦ä¹ å‘¢ï¼æœ‰äº›åŸç†æ€§çš„ä¸œè¥¿è¿˜æ˜¯æ²¡åŠæ³•æ·±å…¥ç†è§£ï¼Œè°¢è°¢ã€‚</p>2019-10-12</li><br/><li><span>cotter</span> ğŸ‘ï¼ˆ1ï¼‰ ğŸ’¬ï¼ˆ3ï¼‰<p>å—æ•™äº†ï¼Œç¬¬ä¸€æ¬¡å¬è¯´è¿™ä¸ªé«˜çº§åŠŸèƒ½ï¼
æˆ‘åœ¨å·¥ä½œä¸­é‡åˆ°ä¸€ä¸ªéœ€è¦å¹¶å‘çš„é—®é¢˜ï¼Œç”¨pythonåœ¨åå°å¹¶å‘æ‰§è¡Œshell ,å¹¶å‘æ•°é‡ç”¨æ—¶é—´èŒƒå›´æ§åˆ¶ï¼Œè¦ä¸åœçš„æ”¹æ—¶é—´åˆ†å¤šæ¬¡ä¸²è¡Œï¼Œæ–¹æ³•æ¯”è¾ƒç¬¨æ‹™ã€‚åç¨‹å¯ä»¥ç®€åŒ–æˆ‘çš„ä»£ç ã€‚
è€å¸ˆï¼Œå¹¶å‘å¾ˆå¤šäº‹ä»¶åº”è¯¥ä¹Ÿæ˜¯éœ€è¦æ¶ˆè€—å¾ˆå¤šèµ„æºï¼Œåç¨‹æ”¹å¦‚ä½•æ§åˆ¶å¹¶å‘æ•°é‡ï¼Ÿ</p>2019-06-24</li><br/><li><span>SUN</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ2ï¼‰<p>Jupyter ä¸­è¿è¡Œ %time asyncio.run(main([&#39;url_1&#39;, &#39;url_2&#39;, &#39;url_3&#39;, &#39;url_4&#39;])) ä¼šæŠ¥é”™ï¼š
RuntimeError: asyncio.run() cannot be called from a running event loop
Pythonã€Anacondaã€Jupyteréƒ½å®‰è£…äº†ã€‚
è¯è¯´ï¼šJupyterä¸å°±æ˜¯ä¸ºäº†æ¶ˆé™¤ä¸ªäººæœ¬åœ°å¼€å‘ç¯å¢ƒå·®å¼‚æ€§è€Œè¯ç”Ÿçš„å—ï¼Ÿè¿™ä¸ªç»“æœæœ‰ç‚¹åè®½ã€‚
å„ä½å­¦å‘˜çš„ç•™è¨€éƒ½çœ‹äº†ï¼Œæ²¡äººè§£å†³äº†æ­¤é—®é¢˜â€¦â€¦
</p>2019-10-27</li><br/><li><span>36åº¦é“</span> ğŸ‘ï¼ˆ0ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>è€å¸ˆï¼Œè¯¾ç¨‹çš„ä»£ç æ˜¯åŸºäºpy3çš„å—ï¼Ÿ</p>2019-06-24</li><br/><li><span>helloworld</span> ğŸ‘ï¼ˆ72ï¼‰ ğŸ’¬ï¼ˆ7ï¼‰<p>è¯´ä¸€ä¸‹æˆ‘å¯¹awaitçš„ç†è§£ï¼š
å¼€å‘è€…è¦æå‰çŸ¥é“ä¸€ä¸ªä»»åŠ¡çš„å“ªä¸ªç¯èŠ‚ä¼šé€ æˆI&#47;Oé˜»å¡ï¼Œç„¶åæŠŠè¿™ä¸ªç¯èŠ‚çš„ä»£ç å¼‚æ­¥åŒ–å¤„ç†ï¼Œå¹¶ä¸”é€šè¿‡awaitæ¥æ ‡è¯†åœ¨ä»»åŠ¡çš„è¯¥ç¯èŠ‚ä¸­æ–­è¯¥ä»»åŠ¡æ‰§è¡Œï¼Œä»è€Œå»æ‰§è¡Œä¸‹ä¸€ä¸ªäº‹ä»¶å¾ªç¯ä»»åŠ¡ã€‚è¿™æ ·å¯ä»¥å……åˆ†åˆ©ç”¨CPUèµ„æºï¼Œé¿å…CPUç­‰å¾…I&#47;Oé€ æˆCPUèµ„æºç™½ç™½æµªè´¹ã€‚å½“ä¹‹å‰ä»»åŠ¡çš„é‚£ä¸ªç¯èŠ‚çš„I&#47;Oå®Œæˆåï¼Œçº¿ç¨‹å¯ä»¥ä»awaitè·å–è¿”å›å€¼ï¼Œç„¶åç»§ç»­æ‰§è¡Œæ²¡æœ‰å®Œæˆçš„å‰©ä½™ä»£ç ã€‚
ç”±ä¸Šé¢åˆ†æå¯çŸ¥ï¼Œå¦‚æœä¸€ä¸ªä»»åŠ¡ä¸æ¶‰åŠåˆ°ç½‘ç»œæˆ–ç£ç›˜I&#47;Oè¿™ç§è€—æ—¶çš„æ“ä½œï¼Œè€Œåªæœ‰CPUè®¡ç®—å’Œå†…å­˜I&#47;Oçš„æ“ä½œæ—¶ï¼Œåç¨‹å¹¶å‘çš„æ€§èƒ½è¿˜ä¸å¦‚å•çº¿ç¨‹loopå¾ªç¯çš„æ€§èƒ½é«˜ã€‚</p>2019-06-27</li><br/><li><span>å¤§ä¾ 110</span> ğŸ‘ï¼ˆ45ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>æ„Ÿè§‰è¿˜æ˜¯æœ‰å¾ˆå¤šäººçœ‹ä¸æ‡‚ï¼Œæˆ‘è¯•ç€ç”¨é€šä¿—çš„è¯­å¥è®²ä¸€ä¸‹ï¼šåæˆé‡Œé¢é‡è¦çš„æ˜¯ä¸€ä¸ªå…³é”®å­—awaitçš„ç†è§£ï¼Œasyncè¡¨ç¤ºå…¶ä¿®é¥°çš„æ˜¯åç¨‹ä»»åŠ¡å³taskï¼Œawaitè¡¨ç¤ºçš„æ˜¯å½“çº¿ç¨‹æ‰§è¡Œåˆ°è¿™ä¸€å¥ï¼Œæ­¤æ—¶è¯¥taskåœ¨æ­¤å¤„æŒ‚èµ·ï¼Œç„¶åè°ƒåº¦å™¨å»æ‰§è¡Œå…¶ä»–çš„taskï¼Œå½“è¿™ä¸ªæŒ‚èµ·çš„éƒ¨åˆ†å¤„ç†å®Œï¼Œä¼šè°ƒç”¨å›æ‰å‡½æ•°å‘Šè¯‰è°ƒåº¦å™¨æˆ‘å·²ç»æ‰§è¡Œå®Œäº†ï¼Œé‚£ä¹ˆè°ƒåº¦å™¨å°±è¿”å›æ¥å¤„ç†è¿™ä¸ªtaskçš„ä½™ä¸‹è¯­å¥ã€‚
      </p>2019-12-03</li><br/><li><span>WingÂ·ä¸‰é‡‘</span> ğŸ‘ï¼ˆ36ï¼‰ ğŸ’¬ï¼ˆ1ï¼‰<p>æ€è€ƒé¢˜ï¼šç®€å•çš„ç†è§£æ˜¯æ¯ä¸ªæ–°å»ºçš„åç¨‹å¯¹è±¡éƒ½ä¼šè‡ªåŠ¨è°ƒç”¨ add_done_callback() å‡½æ•°æ¥æ·»åŠ ä¸€ä¸ªå›è°ƒå‡½æ•°ï¼Œå½“åç¨‹å¯¹è±¡çš„ Future çŠ¶æ€å¯åŠ¨æ—¶å°±ä¼šè°ƒç”¨è¯¥å›è°ƒå‡½æ•°ï¼Œä»è€Œå®ç°å›è°ƒã€‚

ç»¼åˆä¸‹å‰é¢çš„ç•™è¨€å’Œä¸ªäººçš„å­¦ä¹ ï¼Œæ€»ç»“ä¸‹ py 3.6 ç‰ˆæœ¬ä¸‹ asyncio çš„ä¸»è¦ä¸åŒï¼š
1ã€æ²¡æœ‰ run(), create_task()ï¼Œå¯ä»¥ç”¨ asyncio.get_even_loop().run_until_complete() æ¥ä»£æ›¿ run()ï¼Œç”¨ ensure_future() æ¥ä»£æ›¿ create_task()ï¼›
2ã€å¯èƒ½ä¼šå‡ºç° RuntimeError: This event loop is already runningï¼Œè§£å†³æ–¹æ¡ˆä¸€ï¼špip install nest_asyncio; import nest_asyncio; nest_asyncio.apply()ï¼›è§£å†³æ–¹æ¡ˆäºŒï¼šæœ‰äº›å‹äººè¯´æ˜¯ tornado 5.x èµ·çš„ç‰ˆæœ¬æ‰æœ‰æ­¤é—®é¢˜ï¼Œå¯è€ƒè™‘å°†å…¶ç‰ˆæœ¬é™è‡³ 4.xï¼ˆä¸æ¨èï¼‰ï¼›
3ã€%time ä¸ %%time çš„ä¸»è¦åŒºåˆ«ï¼š%time func()ï¼ˆå¿…é¡»æ˜¯åŒä¸€è¡Œï¼‰ï¼›%%time å¿…é¡»æ”¾åœ¨å•å…ƒæ ¼çš„å¼€å¤´ï¼Œå¼ºçƒˆå»ºè®®å•ç‹¬ä¸€è¡Œ + ä¸è¦ä¸ importã€def ç›¸å…³çš„è¯­å¥æ”¾åœ¨åŒä¸ªå•å…ƒæ ¼ï¼›
4ã€çˆ¬è™«ä¸­çš„ aiohttp.ClientSession(headers=header, connector=aiohttp.TCPConnector(ssl=False)) æåŠæœªå£°æ˜çš„ headerï¼Œè¦ä¹ˆå°† headers=header éƒ¨åˆ†å»æ‰ä½¿ç”¨é»˜è®¤å‚æ•°ï¼Œè¦ä¹ˆç”¨è¯¸å¦‚ header={&quot;User-Agent&quot;: &quot;Mozilla&#47;5.0 (Windows NT 6.1; Win64; x64) AppleWebKit&#47;537.36 (KHTML, like Gecko) Chrome&#47;74.0.3729.157 Safari&#47;537.36&quot;} æ¥æ˜¾å¼å£°æ˜ï¼›
5ã€tasks = [asyncio.create_task(crawl_page(url)) for url in urls]; await asyncio.gather(*tasks); 
çº¦ç­‰äº
tasks = [crawl_page(url) for url in urls]; asyncio.get_even_loop().run_until_complete(asyncio.wait(tasks));
æˆ–
tasks = [asyncio.ensure_future(crawl_page(url)) for url in urls]; await asyncio.gather(*tasks);</p>2019-06-27</li><br/>
</ul>