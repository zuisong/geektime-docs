你好，我是编辑叶芊。

4月份，我们和Tubi 组织了一场坐标北京的线下meetup活动，陈天老师与来自各个领域的工程师交流了三大话题：了解和拥抱 AIGC、AI 2.0 时代下程序员的硬核技能需求描述和架构设计、Serverless Rust。

可能有同学未能参与，这里我简单整理了第一场AIGC分享的要点内容，你也可以看视频： [如何以更有准备的姿态拥抱 AIGC 新时代](https://www.bilibili.com/video/BV1RP411S78r/?share_source=copy_web)。如果你对其他话题更感兴趣，可以看文末的其他资料链接。

* * *

AIGC发展到现在，其实也就是最近三个月被 ChatGPT带火的， ChatGPT你可以理解为是所有AIGC的一个大脑，其他各种各样的model都是四肢，由 ChatGPT指挥，那目前被热议的GPT或者LLM，究竟是个什么东西？我们和它对话的时候到底发生了什么？作为程序员我们如何高效使用ChatGPT？

我们开始今天的交流。

## LLM 或者 GPT究竟是什么?

GPT，generative pretrained transformer，预训练的大语言模型，GPT3.5是一个有1,700亿参数的模型，GPT4的模型大小OpenAI并没有公布，有人说可能是GPT3的100倍甚至更多，所以如果我们把一个参数看成一个神经元，GPT4已经接近人脑神经元的量级，而且按这个趋势看，未来GPT一定会超过人脑神经元的量级。所以如果真的把人类产生的所有知识都拿给GPT训练，能训练出一个什么样的怪物呢？我们谁也不知道。

其实，GPT1和2都不是特别成功，但在GPT3之后，同样的训练方法，只是训练的数据容量更大一些，却突然涌现了很多有意思的能力。

首先，GPT3 **可以理解广泛并且复杂的指令**。我们之前的AI像Amazon的Alexa，你需要专门写一个个的skill，Alexa能做的事情完全跟你提供了多少的skillset有关系，但是GPT的skill是无穷无尽的，我们给一些它没见过的东西，让它按指令做一些任务，它是可以顺着我们的思路做下去的。

第二个GPT **能理解例子，并且能举一反三**。这个能力是非常强大的，其实我们人类学习已有的知识，也是通过理解并提炼出其中的套路，再把这个套路应用到新的场景下，GPT也有这种能力，你告诉它这是一个什么样的样例，然后输入是什么，输出是什么，让GPT按这种方式来做一些事情，它能理解这个例子。

最后GPT能按照要求 **对复杂的任务进行分治**。“分治”是我们程序员都有的一个非常基本的素养，面对一个复杂任务复杂问题的时候，我们会把它分解成不同的模块，各个击破。现在GPT也有这种能力，当你告诉他一步一步把中间过程写出来，你会发现他能把一个比较复杂的问题分拆，最终输出比较好的结果。

## 我们跟ChatGPT对话的时候究竟发生了什么？

其实整体的思路非常简单，就是 **不停地根据上下文产生下一个token**。token是 transformer里的一个概念，你可以理解为token是把语言切分后的最小的单元，大概两个token对应一个单词或者汉字。

![图片](https://static001.geekbang.org/resource/image/2a/81/2a59887e9789807488962512597b9681.png?wh=1920x1080)

看这里的例子，我们给一个context “beautiful is better”输给GPT之后，它会根据它所学的内容、掌握的套路，预测出一个它认为最符合上下文的词，比如输出一个“than”，然后把整个result作为一个新的context输入给自己，再去补全下一个词，就这样一路下来。所以你能看到，chatGPT跟你对话的时候是一个词一个词蹦出来的。

因为GPT的机制不是一下子找到question的解决方案一次性输出，而是，根据上文去预测下一个字是什么，逐渐输出，直到它认为要表达的意思表达完了，会终止。当然可能会有很多备选，但是它会选他认为概率最高的词，最终组合成答案。

但GPT因为是一个语言模型，机制是预测，预测是有概率的， **两次预测可能产生不同的结果，所以GPT的回答捉摸不定**。如果你想让他做一件非常有确定性的事情，比如说期望每一次回答都是正确的，那这个场景可能并不适合用GPT来处理。

**另外GPT记忆有限**，对于输入和输出的token来讲，GPT3允许4K个Token，GPT4 32K的Token，因为GPT的自注意力模型，计算是做Token和Token之间的向量，最终的计算量是Token的平方，导致计算量和内存占用会随序列长度平方级增长，所以你可以想象，如果我们要做一个GPT这样的系统，并且让千百万的用户使用，一定要做一些限制，否则可能某一个用户把GPT所有的资源全部吃走了，就没办法serve其他的用户了。核心是效率、可用性、价格的权衡。

## 为什么ChatGPT能横空出世？

我觉得最主要的一点是 **提供了非常高水平的问答服务，并且使用门槛基本降到奶奶辈儿**。我们做互联网的经常说，如果说你做一个面向消费者的产品，你父母不会使用，有可能使用门槛有问题，但chatGPT使用门槛极低，这是让他成为史上最快用户过100million的consumer APP很重要的原因。

chatGPT还提供了 **非常简单且低价的 API激发社区参与**。GPT到目前为止是一个具有绝对垄断力的大语言模型，但是，它其实给出了非常便宜的API使用价格，这导致社区里有各种各样的SDK。它还提供了一个plugin的framework，虽然现在还没有确定对公众开放，不过社区在GPT API的基础上做了很多工具，解决掉一些GPT的短板，进一步降低使用门槛，比如langChain、Ilama-index、AutoGPT。最近比较火的AutoGPT，基本上，你可以认为等同一个虚拟的助理。

有了这些作为基础，就引发了GPT无限可能的场景。

现在创业市场最火热的就是ChatGPT + X，X可以是任何的SaaS服务、传统服务，比如ChatGPT + Legal，法律服务原来门槛很高，现在GPT可以帮你写诉状，承担一些原本你需要跟律师交流的事情，并且他还可以把法院的传票以一个7岁小孩都能听懂的方式，解释给你听，这就很非常厉害。

场景还有很多，我们生活中凡是跟语言、交流、信息的转换相关的，GPT都能很好地应用。

## 如何高效使用 ChatGPT？

首先你要能够使用GPT。可以访问后，很重要的一点就是你要 **问对问题**。清晰明了地表达你所问的问题，如果是一个比较复杂的问题，你要提供足够的上下文，比如精准的一步步指令，然后给一些典型的例子，这些都有助于GPT理解你想让它解决的应用场景，帮助你完成任务。

当然未来很可能会出现更好的AI，更好的工具，我们也不用写这些魔法一般的指令，但现在还不允许，那我们prompt engineering基础的技巧有哪些呢？

![图片](https://static001.geekbang.org/resource/image/52/64/5293704c95043045d38f15eb06163064.png?wh=1920x1079)

入门级的技巧就是五方面：Role、Context、Instruction、Example、Output。

- role，指定GPT是什么角色，比如you are playing a role of migration-bot。
- context，想干什么样的事情，给到充足的上下文。
- instruction，一步一步应该怎么去处理，规则详尽。
- instruction，给一些高质量的例子帮助GPT进一步理解。
- output，最后说明期待什么样的输出格式，比如希望给出的结果是一个对话、一个JSON。这很重要，尤其是你希望在程序中控制它，output需要是计算机可以继续处理的数据结构。

注意，有时候GPT会很跳脱，即便你告诉他output应该是一个JSON，它有时候还会多说两句废话，比如：“好的，JSON是这样子的，然后定义JSON”，但这不是我们希望的结果，如果无法直接转换成JSON，你可以试试用正则表达式，把里面的JSON部分拿出来，再去parse。所以你可能需要去做一些特定的处理。

具体可以参考： [https://github.com/dair-ai/Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)。

这里强调一下，你指定一个角色后，GPT会安分守纪地在角色的知识体系中，这样可以避免一些噪音，比如说你指定它是database administrator，这时候你再问宫保鸡丁怎么做，它就会拒绝回答，它会认为自己不负责回答角色认知之外的内容。

在使用的过程中，我们也要 **控制预期，了解大语言模型的限制**，就像刚才说GPT基于预测机制的结果不确定性，不适合做deterministic的问题，更适合去做一些开创性的问题。

这可能跟很多人的想象不同，大家都觉得AI是个工具，像计算器一样，但实际上现在的AI更像是一个artist，有一定的creativity，不要认为它是一个scientist。因为它可能经常信口胡说，比如我问《资治通鉴》是如何评价陈天的，GPT真的能写跟资治通鉴一模一样的文本，还搞成文言文，所以当你想让GPT去做一些确定性很强的事情，要三思。

![图片](https://static001.geekbang.org/resource/image/ed/e0/ed84b01074fd403aab79f9c0600e39e0.png?wh=1920x1072)

不要认为在智能领域我们无法替代，其实目前很多工作，GPT也可以辅助我们完成。GPT会给出一些我们没有想到的创意。

为什么能有这样的能力？因为GPT看了很多的知识，掌握了很多套路，很多不同的素材之间碰撞，找到一些所谓的经验就是套路。 **所以GPT尤其适合在N个相关或者不相关的领域中，找到那些灰色的地带，而且灰色地带，往往是创新的源头。**

现在有很多人用GPT来写文章、写论文，以往我们认为写论文是很具有开创性的，但是论文在写作过程中很大部分是要想选题、整理文献、找各种各样的参考资料，GPT完全可以做这些事情，尤其在选题这一块，你可以告诉几个你觉得可以发挥的领域，让GPT在这些领域中帮你找灰色地带。

### Demo：No-SQL 查询 Postgres

这里分享一个No-SQL 查询 Postgres 的例子（ [demo视频](https://www.bilibili.com/video/BV1RP411S78r/?share_source=copy_web&vd_source=8cd34e1b5aef8cabb219a2d806074990&t=1404)、 [源码](https://github.com/tyrchen/llm-apps/tree/master/apps)）。

- 想法：用自然语言查询 SQL database
- 核心问题：如何提供数据库 context？
- 开发工具：openai + sqlalchmy + pandas

![图片](https://static001.geekbang.org/resource/image/9b/a6/9b5e1b0f7d63d12672a949056c7a3ba6.png?wh=1920x1079)

这个例子，其实我们没有涉及一个很重要的问题，如果你把GPT类比成人脑的话，它其实有自己的长期记忆和短期记忆。长期“记忆”就是预训练过程中”记”住的内容和学习到的套路，短期“记忆”是我们和它对话过程中的上下文 (4k or 32k tokens) 。

所以短期记忆非常有限，超过短期记忆窗口的内容就没办法处理了，如果我有一个很大的数据需要处理怎么办？主要有5种方法。

- 精简上下文，尽量用精简的语言进行 prompt。
- 摘要处理，对复杂的内容预先生成摘要。
- 分批处理，依次处理上下文片段，再汇总。
- 优先处理最近的上下文，滑动窗口思路，只使用最近5条对话。
- 使用离线存储，完整上下文储存在 vector db，根据需要调用相关内容放入“短期记忆”。

### Demo：ChatPDF

这里分享一个ChatPDF 的例子（ [demo视频](https://www.bilibili.com/video/BV1RP411S78r/?share_source=copy_web&vd_source=8cd34e1b5aef8cabb219a2d806074990&t=1912)、 [源码](https://github.com/tyrchen/llm-apps/tree/master/apps)）。

- 想法：如何对大量 ChatGPT 没有学习过的非结构化内容进行问答?
- 核心问题：如何弥补短期记忆的不足？
- 工具：langchain + faiss

![图片](https://static001.geekbang.org/resource/image/7d/bc/7d1614bf06088285d06ea2652679d2bc.png?wh=1920x1081)

## GPT对我们程序员的影响

我觉得很大的一个影响是，过去十几年的训练，我们都是作为一个程序员学习如何适应机器。之前，编程语言是这样子，语法是这样子，我们要按照语法去写。那未来会是什么样子呢？因为ChatGPT是一个语言模型，理论上说，我只要懂一门语言就可以了，只要懂我的母语，可以用ChatGPT帮我干任何和语言相关的事情。编程语言也是语言，我让它把我写的语言转换成编程语言，就像我们在demo中把语言转化成SQL一样。

当然这并不是说大家不用再学任何东西了，只是 **未来可能我们更多想的是机器如何适应人**，尤其是适应那些并不具备编程经验的人，让他们也可以做出一些有意思的东西。

GPT对我们程序员的具体影响，首先是开发团队的变化。

首先是团队规模。当然现有的开发团队可能不会有什么变化，但是未来，新公司的团队规模可能更倾向于小而美。因为文档、测试等等GPT都能帮我们解决了。原本1个小团队可能需要招5个人，但之后你自己+GPT 在初期就够用了，尤其现在AutoGPT这样的工具做得越来越好，价格越来越低廉。而且团队人越少，沟通的成本越少，这也很重要。

团队的人才构成也会变化，之后可能是少量的专才，尤其是某些具体领域不得不使用的专才，以及大量能和AI高效交流的通才。以后的程序员究竟会是什么样子？我不清楚，但我觉得以后的程序员一定是要非常懂怎么跟AI打交道，知道怎么用AI更高效地处理自己的任务，以及帮助自己成长。

团队组织方式可能也会改变。因为之后语言已经不是障碍，那么假设一个中国的团队找团队成员的时候，可以全世界找了。以后交流会有一个革命性的发展，因为交流往往会影响团队的组织方式。

团队的改变，当然还有更多的可能性，欢迎你留言分享自己的想法。开发流程也会有变化，在整个开发流程中，似乎每一个环节都能找到 GPT可以帮我们的地方。

比如基于自然语言的描述，自动生成代码；自动检测代码中的错误，并提供修复建议，帮助我们提高开发效率；作为一个编程助手提供实时的编程协助；审查代码，自动发现潜在的安全风险和性能问题；自动生成和维护项目文档，降低文档维护的成本和难度；根据开发者的水平和需求提供个性化的学习教程，提高效果等等。

甚至，我们可能有一个全新的代码开发环境。也许未来的开发界面就是我们把流程绘出来，代码就写好了。现在有很多创业公司在探索这个方向，究竟未来我们写代码是什么样的开发，来达到现在百倍千倍的生产力。

![图片](https://static001.geekbang.org/resource/image/6e/0f/6e92fdyy9b226c95499d8f2943aa870f.png?wh=1920x1077)

但面对如此多的可能性，很多同学一定会担心自己是否会被淘汰。

我觉得，我们程序员最不用担心的一件事情就是失业。如果说被淘汰的程序员，也是因为无法适应新的开发模式而被淘汰。

因为 **当生产力发展了，更多需求一定会被激发出来**，比如说现在的我们人类对APP的需求是一瓶水，以后对APP的需求可能是整个汪洋大海，大概是你的奶奶都需要100款完全为她定制的APP的程度。

就像高级语言时代终结的不是程序员，反而开拓了程序员的市场；Web 开发时代终结的也不是程序员，它让非科班出身的开发者也成为程序员；AIGC 时代，传统意义上的程序员会小众化，但更多的“程序开发”的需求会带来一个全民程序员的时代。而且这套东西，总需要人把需求描述出来，等GPT生成结果之后做精调等等，这些是程序员要做的事。

只是原来我们一周出的活，现在可能10分钟就出来了，这不意味着这一周剩下的39个小时50分钟，我们就可以摸鱼了，而是要完成更多需求。

当然GPT也会影响产品开发的各个方面，比如生成式 UI / 代码 / 测试、生成式设计 、产品冷启动和运营、无处不在的高仿真机器人、智能客服、知识库 / FAQ / 人工客服 2.0。

最后提一个值得思考的点，如果说我跟AI一直对话，我把从小到大所有经历的事情、所有掌握的知识经验，都跟AI分享，最后有没有可能 AI面对外界的时候表现的行为，完全跟我一模一样，那以后人是不是可以通过这种方式永生？欢迎留言脑洞。

* * *

### 拓展阅读

[线下活动回顾：AI 时代下程序员的硬核技能，需求描述和架构设计，Serverless Rust](https://mp.weixin.qq.com/s/T9dLOzrJzvwIwEtb4itC3w)

[用魔法来激活魔法，用chatGPT生成stable diffusion提示语](https://mp.weixin.qq.com/s/NqLFaLIdARjU6SWX6OhG-w)

[开发者正确开启 ChatGPT 的钥匙](https://mp.weixin.qq.com/s/UW38adlACRHEvEG8F1I7iA)

[探索 ChatGPT：让 ChatGPT 和目前已有工具深度整合，做一个Postgres AI 助手？](https://mp.weixin.qq.com/s/FWph8YdO-Nk5LKKVsHIZsQ)