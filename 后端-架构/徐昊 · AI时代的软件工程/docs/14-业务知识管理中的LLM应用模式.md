你好，我是徐昊，今天我们来继续学习AI时代的软件工程。

经过前面的几节课的学习，我们已经看到大语言模型（Large Language Model，LLM）如何在业务知识管理的过程中辅助我们完成工作。今天，我们来总结一下在业务知识管理中，知识过程是怎么样的，以及典型的LLM模式有哪些。

## 迭代式增量交付是一个持续学习的过程

当代软件开发的基本思想是通过迭代的方式增量开发系统。在每个迭代结束后，根据收集到的反馈，调整目标和方向。这种方式下，开发人员能够利用前序迭代中学习到的知识，在后续迭代中改进交付的流程和结果。

![](https://static001.geekbang.org/resource/image/d3/5b/d3abf967c2cbd0170c4d19af6957e85b.jpg?wh=1451x805)

迭代交付的关键在于，不要一开始就想实现全部的功能和需求，而是从一部分核心需求开始，通过持续的反馈，不断增强和演进当前的软件，调整目标和计划，直到整个系统做完为止。

从迭代软件交付的全流程上看，整个过程处在复杂的认知行为模式（Complex）。每一次迭代的过程，就是 **探测（Probe）的过程，收集反馈是感知（Sense）的行为，而最后对于目标和计划的调整就是响应（Respond）**。

正如我们在前面的课程中讲到的，处于复杂认知行为模式时，我们对于不可言说知识的学习，是在行动与反馈中学习的过程。因而，迭代式增量交付实际是一个持续学习的过程。

那么在迭代式增量交付这个学习过程中，业务知识管理发挥了什么作用呢？站在迭代软件交付的全流程上，去看待业务知识管理时，不难发现业务知识管理的主要作用是提炼和传递不可言说知识：

- 从初始的业务愿景开始，产生整体解决方案（不可言说知识的提炼）；
- 结合场景将整体解决方案切分成更小粒度的用户故事，以用户故事构成迭代计划（不可言说知识的传递）；
- 按照具体的业务场景补充验收条件（不可言说知识的传递）；
- 依照反馈，改进整体解决方案（不可言说知识的提炼）。

不难看出，业务知识管理中涉及到的不可言说知识，主要是整体解决方案，传递的方式是将整体解决方案切分为更小的粒度，然后通过明确验收条件的方式，强化知识传递的效果。

## 无法加速的反馈循环

谈到复杂的认知行为模式，我们很自然地想到，能不能利用LLM直接加速这个反馈循环呢？也就是由人通过业务知识管理定义问题，让LLM直接为我们生成软件，然后我们只需要验收LLM构造的软件就可以了。

某种程度上说，这是LLM给绝大多数人带来的美好愿景。通过简单几句话的描述，LLM就能帮助我们完成软件的开发。比如，在ChatGPT上线之初，我们看到过很多这样的例子：

> 请使用JavaScript编写一个贪吃蛇的游戏
>
> 然后ChatGPT就能够生成差不多的代码：

![](https://static001.geekbang.org/resource/image/f2/1b/f2e9a67a3031d0e6063b6d8c82f15f1b.jpg?wh=1499x5881)

这一方面得益于ChatGPT丰富的训练语料，但更多是由于在互联网上有很多关于贪吃蛇的规则描述、示例代码等知识沉淀。也就是关于贪吃蛇的业务知识早就存在于互联网之上了，我们无需额外准备这些知识了。 **这里效率提升的主因并不是LLM，而是包含在训练语料中的知识**。 **因而我们无法跳过知识管理这一步，让LLM直接帮助我们生成我们想要的代码。**

除去知识管理之外，目前的LLM系统还存在技术限制。无论是ChatGPT，Claude或是别的LLM都存在上下文的限制，也就是每一次LLM只能处理有限数量的token，以及产生有限数量token的结果。 **因而LLM能够理解的上下文规模，以及能够生成的应用规模都是有限的**。对于大型系统而言，我们无法一次性将上下文传递给LLM，也无法从LLM中一次性获取整个应用。 **也就是说LLM存在一个极限的认知负载**。

而就算我们准备好了全部的知识，且我们的应用规模很小，就像贪吃蛇一样，规则明确，功能简单，代码量也不多。那么这时候， **反馈循环的瓶颈就变成了我们如何验证LLM生成的系统是正确且有效的**。要时刻记得，LLM存在“ **幻觉**”，会编造答案。

LLM生成的回答是基于其在训练数据中学到的模式和信息。模型的目标是根据输入提供有用和合理的文本，但并不能真正理解问题的含义。有时候，模型可能会生成看似合理但事实上不正确或不准确的答案。

这将意味着，每一次LLM根据我们的反馈提供新的答案时，我们都需要进行 **全量回归测试（Full regression test）**。哪怕对于贪吃蛇如此简单的系统，我们也需要测试操作、贪吃蛇变长、贪吃蛇碰到自身导致游戏终止，以及各种边界条件。 **这对于人来说，是极大的认知负载。**

因而，以目前LLM（2024年1月）的能力来看，对于绝大多数实际工作中的生产系统而言，我们无法直接使用LLM，在整个系统维度形成快速的反馈循环，从而提高知识学习和传递的效率。

而且，由于LLM和人脑都存在认知负载超标的问题，我们仍然需要依靠业务知识管理的传统技法，比如通过用户故事去切分上下文，让LLM可以在有限的上下文内提供最大的帮助。也可以让人在受控的上下文内，去验证LLM产生的结果是否符合需求。

## LLM辅助业务知识管理的几个模式

因为我们无法直接构成快速的反馈循环，我们就需要寻找其他的方式，利用LLM为业务知识管理提效。

首先，业务知识管理重在对于问题的定义，一旦问题定义错误，将带来成本巨大的返工和重做。那么我们首要任务就是验证对于问题的定义。然后才是根据问题定义，生成下游所需的新的知识，比如验收条件，比如业务模型。

在我们的课程中，介绍了两个不同的方式验证问题定义是否正确。第一个是由LLM根据业务上下文提问，通过人的回答，验证整体解决方案提取是否完整清晰；第二个是借助模型，验证业务描述是否可以通过模型展开解释。

这两个方法是完全不同的模式。第一种基于ReAct，是LLM推理能力的应用，是一种更为通用的模式，在不同的场合都能使用。

第二种，则是基于这样一个前提条件—— **模型是凝练的业务知识，模型表示了业务概念更普遍的关联。因而，模型在某种程度上，与文字表达的业务是同一种知识的不同表现形式**。那么，我们可以通过将同一个知识的不同表现形式，做相互转化，就能交叉验证其中的偏差。

这里依赖于同样的知识有不同的表示形式，应用的场景就要受到一些限制。比如，不使用业务模型的团队，就无法使用这个方法验证。

在我们的课程中，还介绍了两种生成新知识的方式。第一种方式通过多个ChatGPT会话（ChatGPT session）构造反馈循环，利用LLM提速这个循环得到最后的结果，比如利用LLM建模。这是一种更为通用的模式，在不同的场合都能应用。

第二种是基于ReAct，利用LLM基础语料中的知识（验收条件），完成验收条件初稿的生成。在更一般的场景中，我们需要结合使用ReAct和思维链（Chain of Thought，CoT）完成最终结果的生成。

## 总结

至此，如何利用LLM辅助业务知识管理就讲完了。可以看到，我们讲解了两种验证问题定义的方法，以及两种生成新知识的方法。你可能会有一个疑问，为什么我们不使用LLM帮助我们分解用户故事，而着重在业务模型和验收条件呢？

答案是 **可以，但是没必要**。我们讲解的场景，着重放在开发团队对业务知识的验证与学习（验收条件，模型展开），以及业务知识的学习上（LLM提问，辅助业务建模）。此时LLM帮助我们解决了团队瓶颈。

而用于故事分解时，我们解决的是一个庞杂认知模式（Complicated）的问题，LLM只帮助了业务分析师。而我们之前也讲过，庞杂模式如果不是有团队的放大效应，LLM并不能带来什么效率提升。因而，答案是，可以，但是没必要。

## 思考题

请尝试写一个分解用户故事的prompt模板。

欢迎在留言区分享你的想法，我会让编辑置顶一些优质回答供大家学习讨论。