你好，我是钟敬。

今天咱们来聊一下AI辅助软件开发的话题。当 GitHub Copilot 在2021年6月发布的时候，这个AI编程助手还只是在部分程序员的圈子里引起波澜。而到了2022年11月，当ChatGPT 推出的时候，包括程序员在内的很多小伙伴，则开始真正地考虑自己是否会被AI取代这个问题了。

或许你已经听到过一些颇具哲理的答案，诸如“AI不会替代你，会使用AI的人会替代你”之类。尽管这个说法有一定道理，但并没有回答一个重要的问题，就是“AI的能力边界到底在哪里”。也就是说，目前的AI能做什么，不能做什么。只有搞清楚这一点，程序员才能知道哪些方面的能力需要加强，哪些方面可以忽略，怎样不被替代，继续“愉快地为人民服务”。

为此，我安排了两次加餐，和你聊聊AI的能力边界，以及我们应该如何应对。

今天，我们先从大家可能耳熟能详的“没有银弹”这个原理说起，来探讨一下AI的能力边界。

## **“没有银弹”是什么意思？**

其实，软件界的一个特点就是技术的发展日新月异。每隔若干年，就有某项技术声称要代替程序员。比如说，远的有 COBOL 和第4代语言（4GL），近的有低代码。这些技术确实代替了程序员的一部分工作，但并没有从总体上代替程序员，到了今天，程序员的数量反而更多了。这是为什么呢？

为了分析这个问题，我们先从“没有银弹”这个理论说起。没有银弹是图灵奖获得者 Brooks 老先生在 80 年代的一篇论文中提到的，后来收入了他写的《人月神话》这本书。

没有银弹的意思是说“无论在技术还是管理方法上，都看不出有任何突破性的进步，能够独自保证在十年内大幅度地提高软件生产率、可靠性和简洁性。”

老先生这里说的大幅度，是相对于硬件发展来说的。也就是说，像摩尔定律那样，硬件能力的指数级增长，在软件开发中并没有发生。

之所以用“银弹”来比喻软件开发，是来源于欧洲狼人的传说。也就是说，软件开发有时候具有狼人的特点。一个软件项目，看起来，需求已经被充分理解了，进度也满足预期，但是可能忽然间变得错误百出，大大超出工期和成本，就好像一个看起来正常的人，会忽然变成狼一样。

这种现象造成了所谓“软件危机”，也是软件工程产生的原因。传说中，只有银质子弹才能打死狼人。所以才把突破性的软件开发技术比作银弹。

Brooks 老先生说的“十年内”是相对论文发表的80年代说的。那么到了今天，像 AI 这样的技术，是否已经成为银弹了呢？为了讨论这个问题，让我们先看看 Brooks 这个论断背后的理由是什么。

Brooks 首先把软件开发所面临的困难，分成了本质困难（Essence）和非本质困难（Accident）。相应地，为了解决这些困难要做的事情，就是本质任务和非本质任务。本质任务指的是“打造复杂的概念结构，这些概念结构构成了抽象的软件实体”。非本质任务指的是“使用编程语言表达这些抽象实体，并且在空间和时间限制内，将它们映射成机器语言”。

我们先来理解一下这里所说的“本质”和“非本质”是什么意思。Brooks 说，这一对术语来源于亚里士多德的哲学。我来通俗地解释一下。比如说，人类是胎生的，是有智慧的，这些是人的本质属性。从人类总体而言，这些属性是必然存在的，如果没有这些属性，就不是人类了。而另一方面，人的年龄、健康状况等等则是会改变的，比如说疾病，是可以消除的。因此是非本质属性。

顺便说一下，目前《人员神话》的中文版把 Essence 和 Accident 译作“根本”和“次要”，也是可以的。我这里译作“本质”和“非本质”是为了贴近原意。

在软件开发中，Brooks 把那些即使技术进步了，也不能消除的困难称为本质困难，因为这是软件开发的本质所决定的；而另一方面，非本质的困难则是可以通过技术的进步而消除的困难。

Brooks 发现，当时软件开发技术的进步，主要解决的都是非本质困难。然后他说“除非非本质任务占了所有工作的 9/10，否则即使全部非本质任务的时间缩减到零，也不会带来生产率数量级上的提高”。显然，作者意识到开发人员的大部分时间其实是和本质困难作斗争，也就是构建复杂的概念结构，所以最终得出“没有银弹”的结论。

## **软件开发的本质困难**

Brooks将软件开发的本质困难总结成了4点：复杂性、一致性、可变性和不可见性。

**复杂性（Complexity）**

所谓复杂性，说的是软件几乎是最复杂的人类产品。这种复杂性，在本质上无法用简单的方法化简。这一点应该是软件开发本质困难中最根本的一项。

我们再引申一下，复杂性其实又包含两个层面。一个是业务需求本身的复杂性；另一个是技术实现的复杂性。最终软件系统的复杂性是两者的叠加。

**一致性（Conformity）**

所谓一致性，指的是为了使软件正常运行，开发人员必须和各种人为的不一致性做斗争。这些不一致性的产生并没有什么合理的原因，仅仅是因为不同的人、不同时间、基于不同的理解所造成的，具有任意性。同样，一致性也包含两个层面，一个是保持业务概念的一致性，另一个是技术实现的一致性。

**可变性（Changeability）**

所谓可变性，指的是软件常常会面临频繁的需求变化。如果一座大楼建了一半，是不可能再去改变它的朝向的。但是软件可以。需求的变化，也导致软件更加复杂。

**不可见性（Invisibility）**

关于不可见性，我打一个比方。比如说，一块机械手表，不论多精密，都可以拆开，在显微镜下看到各个零件的构造。一座楼房不论多么高大，总可以通过建筑图纸了解内部结构。但软件不具有类似的物理上的可见性。尽管也可以通过一些技术将部分设计内容可视化，但软件内部在本质上是不可见的。也就是说，即使你把电脑拆了，也不可能看到软件的结构。

![](https://static001.geekbang.org/resource/image/8d/e1/8d02107377b5dc4657429a601f779de1.jpg?wh=1142x761)

无论技术怎样发展，这4点困难在软件开发中是不可能完全消除的，因此属于本质困难。

**社会性（Sociality）**

除了 Brooks 所说的这几点，我们可以再补充一点——社会性。

近20年，随着敏捷软件开发的进展，人们意识到软件开发实际上是一个社会工程，或者说是一种群体行为，牵涉到人的组织、沟通、协作以及心理问题。

过去，这种群体行为还只是局限在开发人员和业务人员。而随着数字化转型的发展，信息技术逐渐变成企业的核心竞争力，那么这种群体行为就扩展到了整个企业甚至企业之外。这种社会性，也不会随着技术的发展而消失。所以，我认为由此造成的困难也属于本质困难。

## 软件开发的非本质困难

讨论完本质困难，非本质困难就容易理解了。非本质困难主要是关于开发语言、开发工具、基础设施等方面的困难。我们可以结合几个例子来理解。

一个是 **计算机语言的进展**。在计算机发展的早期，需要程序员先把算法编成汇编语言，再人工翻译成机器语言，再把机器语言的二进制代码用打孔机打在纸带上，才能输入电脑。而高级语言的出现，使绝大多数程序员不需要编写汇编语言、机器语言，更不需要在纸带上打孔了。于是这几项工作的复杂性对于多数开发人员就彻底消失了。

所以，低级计算机语言带来的困难是非本质困难。而近年提出的所谓“低代码”，无非也是计算机语言的进展，在形式上和深度上有所不同，但解决的仍然是非本质困难。

二是 **云计算的进展**。如果将应用放到公有云上，开发和运维人员维护机房、申请设备等繁琐的工作就会大大减轻甚至彻底消失了。因此云计算解决的也是非本质困难。

可能有人会这么想：既然非本质困难不是本质性的，那么解决非本质困难的技术肯定就是不重要的。这是一个很大的误解。事实上，消除非本质困难的技术进步是软件开发生产力提高的重要原因。这些技术虽然不能让软件开发的生产率像硬件那样指数级提高，但会推动生产率平缓地逐年增长。Brooks把这些技术称为“铜质子弹”。

## **AI是“银弹”吗？**

前面说了那么多，相信你已经对“银弹理论”、本质困难和非本质困难有所解了。现在，我们就可以试着回答 AI 是不是银弹这个问题了。

严格地说，Copilot 和 ChatGPT 并不能涵盖整个AI的概念。它们只是基于AI里的一个分支，所谓大语言模型（LLM）。后面我们说的AI，都只针对大语言模型而言。

我们来思考一下 AI 是否能消除或大幅度降低软件开发的本质困难。

**AI可以消除软件复杂性吗？**

从需求的角度，即使我们用 AI 帮助我们开发软件，也不可能降低需求本身的复杂度。随着AI的应用，为软件的用户提供了更多的可能性，因此业务需求反而会更加复杂。另一方面，AI软件本身所依赖的技术，如机器学习、神经网络等，也增加了技术上的复杂性。因此，AI 会增加而不是降低软件的复杂性。

**AI能保证软件的一致性吗？**

相对于单纯技术上的不一致性而言，真正难解决的是软件中包含的业务概念的不一致性。这种不一致，要么引起隐含的逻辑错误，要么导致程序复杂，难以维护。或许将来的某个时候，AI通过学习业务文档以及代码实现，能够在一定程度上帮助我们找到软件中的概念不一致性，但目前还看不到 AI 在这方面的作用。

**AI能阻止业务需求的变化吗？**

和业务复杂性同理，AI辅助软件开发并不会减少业务需求本身的变化。

**AI能改变软件的不可见性吗？**

这里要说一个 AI 固有的问题，就是 AI的“不可解释性”。比如说 ChatGPT 现在变得很“聪明”，能够回答很多推理性的问题，还能指出笑话的笑点。但是，它是怎么做到的呢？这连 OpenAI 的开发者也说不清楚。

作为对比，我们举一个传统软件开发的例子。历史上，某次火箭发射失败，经过分析，发现是软件中的一个正负号写错了。在这个例子中，正负号写错，和软件行为异常，导致火箭失败，具有明确的因果关系。哪怕这个错误很隐蔽，但理论上总是可以找到的。

但是，当 ChatGPT 回答问题时，我们无法找到这种意义上的确凿的因果关系。因此无法对AI的行为做出准确的解释。当AI广泛应用于软件后，这种不可解释性会加剧软件的不可见性。

**AI能消除软件的社会性吗？**

AI 并不能代替人与人之间的沟通，因此无法消除或降低软件开发的社会性。

**AI能保证产生正确的结果吗？**

除了上面对软件开发本质困难的分析以外，AI自身还有一个局限，就是AI产生的结果，既不能保证是正确的，也不能保证是最优的。甚至常常会“一本正经地胡说八道”，而这也是大语言模型的固有问题。

所以，如果我们认可“没有银弹”的理论，那么至少目前的 AI 也不大可能是银弹。

今天我们借助 AI 不是银弹的讨论，主要是思考 AI 的能力边界，也就是 AI 不能做什么。但是不是银弹，不代表 AI没有用。事实上在很多方面能够使我们更高效地进行软件开发，可以说是一枚“铜弹”。那么AI在哪些方面能够帮到我们，相应地，AI 时代我们又该更注重发展哪些能力呢？我们下节课就来聊聊这些话题，敬请期待。

欢迎你在留言区和我交流互动，如果这节加餐对你有启发的话，也推荐你分享给更多朋友。